{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (2.7.0)\n",
      "Requirement already satisfied: torchvision in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (0.22.0)\n",
      "Requirement already satisfied: transformers in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (4.51.3)\n",
      "Requirement already satisfied: tqdm in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: requests in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (2.32.3)\n",
      "Requirement already satisfied: datasets in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (3.5.1)\n",
      "Requirement already satisfied: accelerate in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (1.6.0)\n",
      "Requirement already satisfied: bitsandbytes in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (0.42.0)\n",
      "Requirement already satisfied: tensorboard in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (2.19.0)\n",
      "Requirement already satisfied: torch-tb-profiler in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (0.4.3)\n",
      "Requirement already satisfied: openai in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (1.70.0)\n",
      "Requirement already satisfied: anthropic in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (0.50.0)\n",
      "Requirement already satisfied: google-generativeai in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (0.8.5)\n",
      "Requirement already satisfied: filelock in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: numpy in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from torchvision) (2.2.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from datasets) (3.11.18)\n",
      "Requirement already satisfied: psutil in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: scipy in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from bitsandbytes) (1.15.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from tensorboard) (2.2.2)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from tensorboard) (1.71.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from tensorboard) (3.8)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from tensorboard) (5.29.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from tensorboard) (65.5.0)\n",
      "Requirement already satisfied: six>1.9 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from tensorboard) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from openai) (2.11.1)\n",
      "Requirement already satisfied: sniffio in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from google-generativeai) (2.25.0rc1)\n",
      "Requirement already satisfied: google-api-python-client in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from google-generativeai) (2.169.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from google-generativeai) (2.40.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from aiohttp->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from aiohttp->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from aiohttp->datasets) (1.20.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision transformers tqdm requests datasets accelerate bitsandbytes tensorboard torch-tb-profiler openai anthropic google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Safe flags for Apple-silicon ---\n",
    "import os, platform\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"]           = \"false\"   # avoid fork-after-tokenizer bug\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.9\"     # leave 10 % headroom, prevents sudden kills\n",
    "os.environ[\"FLASH_ATTENTION_FORCE_DISABLE\"]    = \"1\"       # disable Flash-Attn v2 path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import platform\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer, logging\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "tb_writer = SummaryWriter(\"runs/halueval_llama\")\n",
    "\n",
    "# Reduce verbosity of transformers\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# Check if GPU is available\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\") # change this to foundry gpu if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.7.0   Free RAM: 5.742149632 GB\n",
      "MPS cap: True\n"
     ]
    }
   ],
   "source": [
    "import torch, os, platform, psutil, time\n",
    "print(\"Torch:\", torch.__version__, \"  Free RAM:\", psutil.virtual_memory().available/1e9, \"GB\")\n",
    "print(\"MPS cap:\", torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macOS-13.4-arm64-arm-64bit 2.7.0\n",
      "MPS available: True\n"
     ]
    }
   ],
   "source": [
    "print(platform.platform(), torch.__version__)\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base model using Llama from Hugging Face\n",
    "class LlamaBaseNet(nn.Module):\n",
    "    def __init__(self, model_name=\"meta-llama/Llama-2-7b-hf\", num_classes=2):\n",
    "        super().__init__()\n",
    "        # Load Llama model and tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.backbone = AutoModel.from_pretrained(model_name)\n",
    "        # self.backbone = self.backbone.half()           # fp16\n",
    "        self.backbone.gradient_checkpointing_enable()  # save RAM\n",
    "        \n",
    "        # If the tokenizer doesn't have a padding token, set it\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "            \n",
    "        # Get hidden size from config\n",
    "        self.hidden_size = self.backbone.config.hidden_size\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Linear(self.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, texts):\n",
    "        # Tokenize and move to device\n",
    "        if isinstance(texts, torch.Tensor):\n",
    "            # If input is already tokenized\n",
    "            inputs = {'input_ids': texts}\n",
    "        else:\n",
    "            # If input is raw text\n",
    "            inputs = self.tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        \n",
    "        inputs = {k: v.to(self.classifier.weight.device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Get model outputs\n",
    "        with torch.no_grad():  # Don't compute gradients for the backbone\n",
    "            outputs = self.backbone(**inputs)\n",
    "            \n",
    "        # Use the last hidden state of the last token for classification\n",
    "        last_hidden_states = outputs.last_hidden_state\n",
    "        sequence_lengths = torch.ne(inputs['input_ids'], self.tokenizer.pad_token_id).sum(-1) - 1\n",
    "        batch_size = last_hidden_states.shape[0]\n",
    "        \n",
    "        # Get the hidden state for the last token in each sequence\n",
    "        features = last_hidden_states[torch.arange(batch_size), sequence_lengths]\n",
    "        \n",
    "        # Apply classifier\n",
    "        logits = self.classifier(features)\n",
    "        \n",
    "        return logits, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hugging face auth\n",
    "\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "hf_token = os.getenv(\"HUGGING_FACE_KEY\")\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading HaluEval dataset from Hugging Face...\n",
      "Loading qa dataset...\n",
      "Loading dialogue dataset...\n",
      "Loading summarization dataset...\n",
      "Loading general dataset...\n",
      "Merging all training data...\n",
      "Merging all test data...\n",
      "HaluEval dataset preparation complete!\n",
      "Train data: data/halueval/train.jsonl\n",
      "Test data: data/halueval/test.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Load HaluEval dataset from Hugging Face\n",
    "from datasets import load_dataset\n",
    "\n",
    "def prepare_halueval_data_from_hf():\n",
    "    \"\"\"Load HaluEval dataset from Hugging Face\"\"\"\n",
    "    print(\"Loading HaluEval dataset from Hugging Face...\")\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = \"data/halueval\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Process each split\n",
    "    categories = [\"qa\", \"dialogue\", \"summarization\", \"general\"]\n",
    "    \n",
    "    # Prepare train and test sets\n",
    "    for category in categories:\n",
    "        print(f\"Loading {category} dataset...\")\n",
    "        # Load the dataset for this category\n",
    "        dataset = load_dataset(\"pminervini/HaluEval\", category)\n",
    "        \n",
    "        # The dataset has a 'data' split containing all examples\n",
    "        data = dataset['data']\n",
    "        \n",
    "        # Split into train/test (80/20 split)\n",
    "        splits = data.train_test_split(test_size=0.2, seed=42)\n",
    "        \n",
    "        # Save as jsonl\n",
    "        with open(f\"{output_dir}/{category}_train.jsonl\", 'w', encoding='utf-8') as f:\n",
    "            for item in splits['train']:\n",
    "                formatted_item = {\n",
    "                    'question': item.get('instruction', ''),\n",
    "                    'response': item.get('output', ''),\n",
    "                    'is_hallucination': 1 if item.get('label') == 'hallucinated' else 0\n",
    "                }\n",
    "                f.write(json.dumps(formatted_item) + '\\n')\n",
    "        \n",
    "        with open(f\"{output_dir}/{category}_test.jsonl\", 'w', encoding='utf-8') as f:\n",
    "            for item in splits['test']:\n",
    "                formatted_item = {\n",
    "                    'question': item.get('instruction', ''),\n",
    "                    'response': item.get('output', ''),\n",
    "                    'is_hallucination': 1 if item.get('label') == 'hallucinated' else 0\n",
    "                }\n",
    "                f.write(json.dumps(formatted_item) + '\\n')\n",
    "    \n",
    "    # Merge all training data\n",
    "    print(\"Merging all training data...\")\n",
    "    with open(f\"{output_dir}/train.jsonl\", 'w', encoding='utf-8') as outfile:\n",
    "        for category in categories:\n",
    "            with open(f\"{output_dir}/{category}_train.jsonl\", 'r', encoding='utf-8') as infile:\n",
    "                outfile.write(infile.read())\n",
    "    \n",
    "    # Merge all test data\n",
    "    print(\"Merging all test data...\")\n",
    "    with open(f\"{output_dir}/test.jsonl\", 'w', encoding='utf-8') as outfile:\n",
    "        for category in categories:\n",
    "            with open(f\"{output_dir}/{category}_test.jsonl\", 'r', encoding='utf-8') as infile:\n",
    "                outfile.write(infile.read())\n",
    "    \n",
    "    print(\"HaluEval dataset preparation complete!\")\n",
    "    print(f\"Train data: {output_dir}/train.jsonl\")\n",
    "    print(f\"Test data: {output_dir}/test.jsonl\")\n",
    "    \n",
    "    return f\"{output_dir}/train.jsonl\", f\"{output_dir}/test.jsonl\"\n",
    "\n",
    "# Run the function to get the paths\n",
    "train_data_path, test_data_path = prepare_halueval_data_from_hf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define the Epinet\n",
    "class EpiNet(nn.Module):\n",
    "    def __init__(self, feature_dim, z_dim, hidden_dims, num_classes):\n",
    "        super().__init__()\n",
    "        dims = [feature_dim + z_dim] + hidden_dims + [num_classes]\n",
    "        layers = []\n",
    "        for in_d, out_d in zip(dims, dims[1:]):\n",
    "            layers += [nn.Linear(in_d, out_d), nn.ReLU()]\n",
    "        self.mlp = nn.Sequential(*layers[:-1])  # drop final ReLU\n",
    "\n",
    "    def forward(self, features, z):\n",
    "        # stop-gradient on features\n",
    "        features = features.detach()\n",
    "        x = torch.cat([features, z], dim=1)\n",
    "        return self.mlp(x)\n",
    "\n",
    "# 4. Define the PriorNet\n",
    "class PriorNet(nn.Module):\n",
    "    def __init__(self, feature_dim, z_dim, num_classes):\n",
    "        super().__init__()\n",
    "        # Fixed random weights\n",
    "        self.fc = nn.Linear(feature_dim + z_dim, num_classes)\n",
    "        for p in self.parameters():\n",
    "            p.requires_grad = False  # fix weights\n",
    "\n",
    "    def forward(self, features, z):\n",
    "        features = features.detach()\n",
    "        x = torch.cat([features, z], dim=1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Wrap into an Epistemic Neural Network\n",
    "class EpistemicNN(nn.Module):\n",
    "    def __init__(self, base: LlamaBaseNet, epinet: EpiNet, prior: PriorNet=None):\n",
    "        super().__init__()\n",
    "        self.base = base\n",
    "        self.epinet = epinet\n",
    "        self.prior = prior\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        logits, features = self.base(x)         # base logits & features\n",
    "        δ = self.epinet(features, z)            # learnable correction\n",
    "        σP = self.prior(features, z) if self.prior else 0\n",
    "        return logits + δ + σP\n",
    "\n",
    "# 6. Sampling epistemic index z\n",
    "def sample_z(batch_size, z_dim, device):\n",
    "    # Gaussian prior\n",
    "    return torch.randn(batch_size, z_dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_enn(model, dataloader, epochs, lr, λ, z_dim, device, writer):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=λ)\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_idx, (x_batch, y_batch) in enumerate(dataloader):\n",
    "            # Move tensors to device\n",
    "            x_batch = x_batch.to(device, non_blocking=False)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            # Sample epistemic indices\n",
    "            z = sample_z(len(y_batch), z_dim, device)\n",
    "\n",
    "            # Forward pass\n",
    "            logits = model(x_batch, z)\n",
    "            loss = F.cross_entropy(logits, y_batch)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Track accuracy\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = logits.max(1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += predicted.eq(y_batch).sum().item()\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{epochs}, Batch {batch_idx}, Loss: {loss.item():.4f}, \"\n",
    "                      f\"Acc: {100.*correct/total:.2f}%\")\n",
    "                \n",
    "            avg_loss = total_loss / (batch_idx + 1)\n",
    "            acc      = 100. * correct / total\n",
    "            global_step = epoch * len(dataloader) + batch_idx\n",
    "            writer.add_scalar(\"train/loss\", loss.item(), global_step)\n",
    "            writer.add_scalar(\"train/acc\",  acc,      global_step)\n",
    "\n",
    "            if global_step % 50 == 0:\n",
    "                writer.flush()\n",
    "                \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Average Loss: {total_loss/(batch_idx+1):.4f}, \"\n",
    "              f\"Accuracy: {100.*correct/total:.2f}%\")\n",
    "\n",
    "        torch.mps.empty_cache()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Also update the evaluation function\n",
    "def evaluate_enn(model, dataloader, z_dim, device, num_samples=10):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    epistemic_uncertainty = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in dataloader:\n",
    "            x_batch = x_batch.to(device, non_blocking=False)\n",
    "            y_batch = y_batch.to(device)\n",
    "            batch_size = len(x_batch)\n",
    "            \n",
    "            # Sample multiple z for each input\n",
    "            all_logits = []\n",
    "            for _ in range(num_samples):\n",
    "                z = sample_z(batch_size, z_dim, device)\n",
    "                logits = model(x_batch, z)\n",
    "                all_logits.append(logits)\n",
    "            \n",
    "            # Stack all predictions\n",
    "            stacked_logits = torch.stack(all_logits)  # [num_samples, batch_size, num_classes]\n",
    "            \n",
    "            # Mean prediction\n",
    "            mean_logits = stacked_logits.mean(dim=0)\n",
    "            _, predicted = mean_logits.max(1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += predicted.eq(y_batch).sum().item()\n",
    "            \n",
    "            # Calculate uncertainty - variance across samples\n",
    "            uncertainty = stacked_logits.var(dim=0).sum(dim=1)  # [batch_size]\n",
    "            epistemic_uncertainty.append(uncertainty)\n",
    "    \n",
    "    accuracy = 100. * correct / total\n",
    "    avg_uncertainty = torch.cat(epistemic_uncertainty).mean().item()\n",
    "    \n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Average Epistemic Uncertainty: {avg_uncertainty:.4f}\")\n",
    "    \n",
    "    return accuracy, avg_uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing models...\n",
      "Loading dataset...\n",
      "Loading qa dataset...\n",
      "Loading dialogue dataset...\n",
      "Loading summarization dataset...\n",
      "Loading general dataset...\n",
      "Training samples: 27605\n",
      "Testing samples: 6902\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "num_classes = 2  # Binary classification for hallucination detection\n",
    "z_dim = 16\n",
    "hidden_dims = [128, 64]\n",
    "lr = 1e-5  # Lower learning rate for LLM fine-tuning\n",
    "epochs = 3  # Reduce epochs for faster training with large model\n",
    "λ = 1e-5\n",
    "batch_size = 1  # Smaller batch size for large model\n",
    "max_length = 128\n",
    "import random\n",
    "\n",
    "# Choose a Llama model - use a smaller version if memory is limited\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"  # Start with smaller model for testing\n",
    "\n",
    "class HaluEvalDataset(Dataset):\n",
    "    def __init__(self, data_items, tokenizer):\n",
    "        self.data = data_items\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "\n",
    "        # ---------- 1. pick the *content* string ----------\n",
    "        if \"question\" in item:          # QA\n",
    "            content = f\"Context: {item['knowledge']}\\nQuestion: {item['question']}\"\n",
    "            gold   = item[\"right_answer\"]\n",
    "            halluc = item[\"hallucinated_answer\"]\n",
    "\n",
    "        elif \"dialogue_history\" in item:      # Dialogue\n",
    "            content = f\"Context: {item['knowledge']}\\nDialogue: {item['dialogue_history']}\"\n",
    "            gold   = item[\"right_response\"]\n",
    "            halluc = item[\"hallucinated_response\"]\n",
    "\n",
    "        elif \"document\" in item:              # Summarisation\n",
    "            content = f\"Document: {item['document']}\"\n",
    "            gold   = item[\"right_summary\"]\n",
    "            halluc = item[\"hallucinated_summary\"]\n",
    "\n",
    "        else:                                 # General split\n",
    "            content = f\"User query: {item['user_query']}\"\n",
    "            # general‐split has only one answer plus a Yes/No label\n",
    "            gold   = item[\"chatgpt_response\"]\n",
    "            halluc = None                     # there is no alt-answer\n",
    "\n",
    "        # ---------- 2. choose gold vs hallucinated version ----------\n",
    "        if halluc is not None and torch.rand(1).item() > 0.5:\n",
    "            text  = f\"{content}\\nAnswer: {halluc}\"\n",
    "            label = 1            # hallucination\n",
    "        else:\n",
    "            text  = f\"{content}\\nAnswer: {gold}\"\n",
    "            label = 0            # factual\n",
    "\n",
    "        # ---------- 3. tokenise ----------\n",
    "        enc = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return enc[\"input_ids\"].squeeze(0), torch.tensor(label, dtype=torch.long)\n",
    "    \n",
    "# Initialize models\n",
    "print(\"Initializing models...\")\n",
    "base = LlamaBaseNet(model_name, num_classes).to(device)\n",
    "feature_dim = base.hidden_size\n",
    "epinet = EpiNet(feature_dim, z_dim, hidden_dims, num_classes).to(device)\n",
    "prior = PriorNet(feature_dim, z_dim, num_classes).to(device)\n",
    "enn = EpistemicNN(base, epinet, prior).to(device)\n",
    "\n",
    "# Create train/test splits from the loaded HaluEval dataset\n",
    "print(\"Loading dataset...\")\n",
    "all_data = []\n",
    "categories = [\"qa\", \"dialogue\", \"summarization\", \"general\"]\n",
    "\n",
    "for category in categories:\n",
    "    print(f\"Loading {category} dataset...\")\n",
    "    dataset = load_dataset(\"pminervini/HaluEval\", category)\n",
    "    all_data.extend(dataset['data'])\n",
    "\n",
    "# Shuffle and split the data\n",
    "random.seed(42)\n",
    "random.shuffle(all_data)\n",
    "split_idx = int(0.8 * len(all_data))\n",
    "train_data = all_data[:split_idx]\n",
    "test_data = all_data[split_idx:]\n",
    "\n",
    "# -------------------- build proper Dataset objects --------------------\n",
    "train_dataset = HaluEvalDataset(train_data, base.tokenizer)\n",
    "test_dataset  = HaluEvalDataset(test_data,  base.tokenizer)\n",
    "\n",
    "trainloader = DataLoader(train_dataset,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True)\n",
    "\n",
    "testloader  = DataLoader(test_dataset,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Testing samples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
    "# enn.eval();                # no grads\n",
    "# x,y = next(iter(small_loader))\n",
    "# z   = sample_z(1, z_dim, device)\n",
    "# with torch.no_grad():      # forward only\n",
    "#     _ = enn(x.to(device), z)\n",
    "# print(\"✓ tiny batch ran\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1402"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch, gc\n",
    "\n",
    "torch.mps.empty_cache()   # releases unused cached blocks\n",
    "gc.collect()              # Python-side garbage collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaytipirneni/.pyenv/versions/3.11.11/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Batch 0, Loss: 4.2329, Acc: 0.00%\n",
      "Epoch 1/3, Batch 10, Loss: 1.6306, Acc: 36.36%\n",
      "Epoch 1/3, Batch 20, Loss: 0.1659, Acc: 57.14%\n",
      "Epoch 1/3, Batch 30, Loss: 1.9210, Acc: 51.61%\n",
      "Epoch 1/3, Batch 40, Loss: 0.4872, Acc: 56.10%\n",
      "Epoch 1/3, Batch 50, Loss: 1.0253, Acc: 52.94%\n",
      "Epoch 1/3, Batch 60, Loss: 2.2024, Acc: 54.10%\n",
      "Epoch 1/3, Batch 70, Loss: 3.1466, Acc: 56.34%\n",
      "Epoch 1/3, Batch 80, Loss: 1.1493, Acc: 50.62%\n",
      "Epoch 1/3, Batch 90, Loss: 0.5534, Acc: 52.75%\n",
      "Epoch 1/3, Batch 100, Loss: 0.0941, Acc: 51.49%\n",
      "Epoch 1/3, Batch 110, Loss: 0.0243, Acc: 53.15%\n",
      "Epoch 1/3, Batch 120, Loss: 0.6817, Acc: 54.55%\n",
      "Epoch 1/3, Batch 130, Loss: 0.0532, Acc: 53.44%\n",
      "Epoch 1/3, Batch 140, Loss: 2.5350, Acc: 53.19%\n",
      "Epoch 1/3, Batch 150, Loss: 0.9787, Acc: 54.30%\n",
      "Epoch 1/3, Batch 160, Loss: 3.2568, Acc: 54.66%\n",
      "Epoch 1/3, Batch 170, Loss: 0.0961, Acc: 55.56%\n",
      "Epoch 1/3, Batch 180, Loss: 0.0854, Acc: 56.35%\n",
      "Epoch 1/3, Batch 190, Loss: 0.1460, Acc: 56.54%\n",
      "Epoch 1/3, Batch 200, Loss: 0.3086, Acc: 55.72%\n",
      "Epoch 1/3, Batch 210, Loss: 0.0716, Acc: 56.87%\n",
      "Epoch 1/3, Batch 220, Loss: 0.1050, Acc: 57.01%\n",
      "Epoch 1/3, Batch 230, Loss: 1.1849, Acc: 56.71%\n",
      "Epoch 1/3, Batch 240, Loss: 2.4424, Acc: 56.43%\n",
      "Epoch 1/3, Batch 250, Loss: 1.3400, Acc: 56.57%\n",
      "Epoch 1/3, Batch 260, Loss: 0.0562, Acc: 56.32%\n",
      "Epoch 1/3, Batch 270, Loss: 0.4576, Acc: 57.20%\n",
      "Epoch 1/3, Batch 280, Loss: 0.3787, Acc: 56.58%\n",
      "Epoch 1/3, Batch 290, Loss: 0.9098, Acc: 56.36%\n",
      "Epoch 1/3, Batch 300, Loss: 0.3648, Acc: 56.15%\n",
      "Epoch 1/3, Batch 310, Loss: 0.4454, Acc: 55.95%\n",
      "Epoch 1/3, Batch 320, Loss: 0.8375, Acc: 55.45%\n",
      "Epoch 1/3, Batch 330, Loss: 0.7968, Acc: 54.68%\n",
      "Epoch 1/3, Batch 340, Loss: 0.3979, Acc: 55.13%\n",
      "Epoch 1/3, Batch 350, Loss: 0.1023, Acc: 55.27%\n",
      "Epoch 1/3, Batch 360, Loss: 1.6019, Acc: 55.68%\n",
      "Epoch 1/3, Batch 370, Loss: 2.3796, Acc: 55.53%\n",
      "Epoch 1/3, Batch 380, Loss: 0.0184, Acc: 55.91%\n",
      "Epoch 1/3, Batch 390, Loss: 0.0120, Acc: 56.27%\n",
      "Epoch 1/3, Batch 400, Loss: 1.6208, Acc: 55.86%\n",
      "Epoch 1/3, Batch 410, Loss: 0.0421, Acc: 55.72%\n",
      "Epoch 1/3, Batch 420, Loss: 1.5743, Acc: 55.82%\n",
      "Epoch 1/3, Batch 430, Loss: 0.7099, Acc: 55.92%\n",
      "Epoch 1/3, Batch 440, Loss: 0.0838, Acc: 55.78%\n",
      "Epoch 1/3, Batch 450, Loss: 3.7260, Acc: 55.43%\n",
      "Epoch 1/3, Batch 460, Loss: 0.0194, Acc: 54.88%\n",
      "Epoch 1/3, Batch 470, Loss: 0.2930, Acc: 54.56%\n",
      "Epoch 1/3, Batch 480, Loss: 0.6754, Acc: 53.85%\n",
      "Epoch 1/3, Batch 490, Loss: 3.0525, Acc: 53.77%\n",
      "Epoch 1/3, Batch 500, Loss: 2.0332, Acc: 53.69%\n",
      "Epoch 1/3, Batch 510, Loss: 0.0645, Acc: 53.42%\n",
      "Epoch 1/3, Batch 520, Loss: 0.1013, Acc: 53.36%\n",
      "Epoch 1/3, Batch 530, Loss: 1.8825, Acc: 53.11%\n",
      "Epoch 1/3, Batch 540, Loss: 3.9080, Acc: 52.68%\n",
      "Epoch 1/3, Batch 550, Loss: 0.7017, Acc: 52.81%\n",
      "Epoch 1/3, Batch 560, Loss: 1.1351, Acc: 53.12%\n",
      "Epoch 1/3, Batch 570, Loss: 2.1299, Acc: 53.06%\n",
      "Epoch 1/3, Batch 580, Loss: 0.0265, Acc: 53.18%\n",
      "Epoch 1/3, Batch 590, Loss: 0.3329, Acc: 52.96%\n",
      "Epoch 1/3, Batch 600, Loss: 1.0747, Acc: 52.91%\n",
      "Epoch 1/3, Batch 610, Loss: 1.0940, Acc: 53.03%\n",
      "Epoch 1/3, Batch 620, Loss: 0.4364, Acc: 53.62%\n",
      "Epoch 1/3, Batch 630, Loss: 0.2221, Acc: 53.72%\n",
      "Epoch 1/3, Batch 640, Loss: 0.5461, Acc: 53.67%\n",
      "Epoch 1/3, Batch 650, Loss: 1.8121, Acc: 53.76%\n",
      "Epoch 1/3, Batch 660, Loss: 0.0161, Acc: 53.86%\n",
      "Epoch 1/3, Batch 670, Loss: 0.2648, Acc: 53.80%\n",
      "Epoch 1/3, Batch 680, Loss: 0.9702, Acc: 53.74%\n",
      "Epoch 1/3, Batch 690, Loss: 0.8596, Acc: 53.55%\n",
      "Epoch 1/3, Batch 700, Loss: 0.2916, Acc: 53.78%\n",
      "Epoch 1/3, Batch 710, Loss: 0.2020, Acc: 53.45%\n",
      "Epoch 1/3, Batch 720, Loss: 1.4691, Acc: 53.26%\n",
      "Epoch 1/3, Batch 730, Loss: 1.5278, Acc: 53.21%\n",
      "Epoch 1/3, Batch 740, Loss: 0.4618, Acc: 53.31%\n",
      "Epoch 1/3, Batch 750, Loss: 0.9917, Acc: 53.26%\n",
      "Epoch 1/3, Batch 760, Loss: 0.7201, Acc: 53.22%\n",
      "Epoch 1/3, Batch 770, Loss: 0.3418, Acc: 53.18%\n",
      "Epoch 1/3, Batch 780, Loss: 2.1941, Acc: 53.52%\n",
      "Epoch 1/3, Batch 790, Loss: 0.4778, Acc: 53.60%\n",
      "Epoch 1/3, Batch 800, Loss: 2.5453, Acc: 53.31%\n",
      "Epoch 1/3, Batch 810, Loss: 0.5750, Acc: 53.51%\n",
      "Epoch 1/3, Batch 820, Loss: 0.1975, Acc: 53.71%\n",
      "Epoch 1/3, Batch 830, Loss: 0.9621, Acc: 53.79%\n",
      "Epoch 1/3, Batch 840, Loss: 1.0545, Acc: 53.75%\n",
      "Epoch 1/3, Batch 850, Loss: 0.2004, Acc: 54.05%\n",
      "Epoch 1/3, Batch 860, Loss: 1.5923, Acc: 54.24%\n",
      "Epoch 1/3, Batch 870, Loss: 2.3021, Acc: 54.31%\n",
      "Epoch 1/3, Batch 880, Loss: 0.1110, Acc: 54.48%\n",
      "Epoch 1/3, Batch 890, Loss: 0.7173, Acc: 54.66%\n",
      "Epoch 1/3, Batch 900, Loss: 1.5735, Acc: 54.16%\n",
      "Epoch 1/3, Batch 910, Loss: 1.5229, Acc: 54.12%\n",
      "Epoch 1/3, Batch 920, Loss: 0.5046, Acc: 54.07%\n",
      "Epoch 1/3, Batch 930, Loss: 0.0055, Acc: 54.14%\n",
      "Epoch 1/3, Batch 940, Loss: 2.1850, Acc: 53.88%\n",
      "Epoch 1/3, Batch 950, Loss: 0.2733, Acc: 53.84%\n",
      "Epoch 1/3, Batch 960, Loss: 0.3222, Acc: 53.90%\n",
      "Epoch 1/3, Batch 970, Loss: 0.7640, Acc: 53.96%\n",
      "Epoch 1/3, Batch 980, Loss: 0.7271, Acc: 53.92%\n",
      "Epoch 1/3, Batch 990, Loss: 0.6408, Acc: 53.88%\n",
      "Epoch 1/3, Batch 1000, Loss: 0.1811, Acc: 54.15%\n",
      "Epoch 1/3, Batch 1010, Loss: 0.7931, Acc: 53.91%\n",
      "Epoch 1/3, Batch 1020, Loss: 0.8095, Acc: 53.77%\n",
      "Epoch 1/3, Batch 1030, Loss: 1.1602, Acc: 53.73%\n",
      "Epoch 1/3, Batch 1040, Loss: 0.1649, Acc: 53.70%\n",
      "Epoch 1/3, Batch 1050, Loss: 2.0799, Acc: 53.66%\n",
      "Epoch 1/3, Batch 1060, Loss: 3.4105, Acc: 53.35%\n",
      "Epoch 1/3, Batch 1070, Loss: 0.2416, Acc: 52.94%\n",
      "Epoch 1/3, Batch 1080, Loss: 0.8249, Acc: 52.91%\n",
      "Epoch 1/3, Batch 1090, Loss: 0.2567, Acc: 53.07%\n",
      "Epoch 1/3, Batch 1100, Loss: 0.3542, Acc: 53.22%\n",
      "Epoch 1/3, Batch 1110, Loss: 0.6440, Acc: 53.11%\n",
      "Epoch 1/3, Batch 1120, Loss: 0.5128, Acc: 53.17%\n",
      "Epoch 1/3, Batch 1130, Loss: 0.6678, Acc: 53.05%\n",
      "Epoch 1/3, Batch 1140, Loss: 0.3390, Acc: 53.29%\n",
      "Epoch 1/3, Batch 1150, Loss: 0.4803, Acc: 53.26%\n",
      "Epoch 1/3, Batch 1160, Loss: 0.1869, Acc: 53.40%\n",
      "Epoch 1/3, Batch 1170, Loss: 0.0876, Acc: 53.54%\n",
      "Epoch 1/3, Batch 1180, Loss: 0.0491, Acc: 53.51%\n",
      "Epoch 1/3, Batch 1190, Loss: 2.7441, Acc: 53.65%\n",
      "Epoch 1/3, Batch 1200, Loss: 0.1756, Acc: 53.79%\n",
      "Epoch 1/3, Batch 1210, Loss: 0.4165, Acc: 54.00%\n",
      "Epoch 1/3, Batch 1220, Loss: 0.1870, Acc: 54.05%\n",
      "Epoch 1/3, Batch 1230, Loss: 0.0332, Acc: 54.10%\n",
      "Epoch 1/3, Batch 1240, Loss: 0.0151, Acc: 54.15%\n",
      "Epoch 1/3, Batch 1250, Loss: 0.3983, Acc: 54.12%\n",
      "Epoch 1/3, Batch 1260, Loss: 0.0121, Acc: 54.00%\n",
      "Epoch 1/3, Batch 1270, Loss: 0.0714, Acc: 54.21%\n",
      "Epoch 1/3, Batch 1280, Loss: 0.4201, Acc: 54.33%\n",
      "Epoch 1/3, Batch 1290, Loss: 0.1326, Acc: 54.30%\n",
      "Epoch 1/3, Batch 1300, Loss: 0.2311, Acc: 54.50%\n",
      "Epoch 1/3, Batch 1310, Loss: 0.8739, Acc: 54.39%\n",
      "Epoch 1/3, Batch 1320, Loss: 0.4498, Acc: 54.58%\n",
      "Epoch 1/3, Batch 1330, Loss: 0.0537, Acc: 54.47%\n",
      "Epoch 1/3, Batch 1340, Loss: 0.4373, Acc: 54.74%\n",
      "Epoch 1/3, Batch 1350, Loss: 2.2968, Acc: 54.63%\n",
      "Epoch 1/3, Batch 1360, Loss: 0.6282, Acc: 54.45%\n",
      "Epoch 1/3, Batch 1370, Loss: 1.9035, Acc: 54.41%\n",
      "Epoch 1/3, Batch 1380, Loss: 0.4654, Acc: 54.31%\n",
      "Epoch 1/3, Batch 1390, Loss: 1.9614, Acc: 54.42%\n",
      "Epoch 1/3, Batch 1400, Loss: 2.0109, Acc: 54.39%\n",
      "Epoch 1/3, Batch 1410, Loss: 1.5856, Acc: 54.22%\n",
      "Epoch 1/3, Batch 1420, Loss: 3.2373, Acc: 54.19%\n",
      "Epoch 1/3, Batch 1430, Loss: 1.4701, Acc: 54.16%\n",
      "Epoch 1/3, Batch 1440, Loss: 1.3940, Acc: 54.20%\n",
      "Epoch 1/3, Batch 1450, Loss: 0.2700, Acc: 54.45%\n",
      "Epoch 1/3, Batch 1460, Loss: 0.2662, Acc: 54.62%\n",
      "Epoch 1/3, Batch 1470, Loss: 0.6618, Acc: 54.66%\n",
      "Epoch 1/3, Batch 1480, Loss: 0.5203, Acc: 54.69%\n",
      "Epoch 1/3, Batch 1490, Loss: 0.3306, Acc: 54.73%\n",
      "Epoch 1/3, Batch 1500, Loss: 0.9011, Acc: 54.83%\n",
      "Epoch 1/3, Batch 1510, Loss: 0.2100, Acc: 55.00%\n",
      "Epoch 1/3, Batch 1520, Loss: 0.4468, Acc: 55.16%\n",
      "Epoch 1/3, Batch 1530, Loss: 0.1053, Acc: 55.19%\n",
      "Epoch 1/3, Batch 1540, Loss: 0.2578, Acc: 55.22%\n",
      "Epoch 1/3, Batch 1550, Loss: 1.6685, Acc: 55.25%\n",
      "Epoch 1/3, Batch 1560, Loss: 1.4872, Acc: 55.22%\n",
      "Epoch 1/3, Batch 1570, Loss: 0.0653, Acc: 55.25%\n",
      "Epoch 1/3, Batch 1580, Loss: 0.1021, Acc: 55.22%\n",
      "Epoch 1/3, Batch 1590, Loss: 0.1934, Acc: 55.31%\n",
      "Epoch 1/3, Batch 1600, Loss: 2.4060, Acc: 55.22%\n",
      "Epoch 1/3, Batch 1610, Loss: 0.1931, Acc: 55.18%\n",
      "Epoch 1/3, Batch 1620, Loss: 0.7299, Acc: 55.34%\n",
      "Epoch 1/3, Batch 1630, Loss: 1.8980, Acc: 55.24%\n",
      "Epoch 1/3, Batch 1640, Loss: 0.6235, Acc: 55.15%\n",
      "Epoch 1/3, Batch 1650, Loss: 0.1507, Acc: 55.24%\n",
      "Epoch 1/3, Batch 1660, Loss: 1.3743, Acc: 55.21%\n",
      "Epoch 1/3, Batch 1670, Loss: 1.6753, Acc: 55.30%\n",
      "Epoch 1/3, Batch 1680, Loss: 1.6768, Acc: 55.26%\n",
      "Epoch 1/3, Batch 1690, Loss: 0.9114, Acc: 55.12%\n",
      "Epoch 1/3, Batch 1700, Loss: 1.2231, Acc: 55.14%\n",
      "Epoch 1/3, Batch 1710, Loss: 1.9426, Acc: 55.06%\n",
      "Epoch 1/3, Batch 1720, Loss: 0.4870, Acc: 55.08%\n",
      "Epoch 1/3, Batch 1730, Loss: 0.0925, Acc: 55.17%\n",
      "Epoch 1/3, Batch 1740, Loss: 0.3979, Acc: 55.20%\n",
      "Epoch 1/3, Batch 1750, Loss: 1.7751, Acc: 55.34%\n",
      "Epoch 1/3, Batch 1760, Loss: 0.4871, Acc: 55.37%\n",
      "Epoch 1/3, Batch 1770, Loss: 0.9299, Acc: 55.39%\n",
      "Epoch 1/3, Batch 1780, Loss: 0.1432, Acc: 55.42%\n",
      "Epoch 1/3, Batch 1790, Loss: 0.2728, Acc: 55.28%\n",
      "Epoch 1/3, Batch 1800, Loss: 0.9292, Acc: 55.25%\n",
      "Epoch 1/3, Batch 1810, Loss: 0.1031, Acc: 55.22%\n",
      "Epoch 1/3, Batch 1820, Loss: 0.3216, Acc: 55.08%\n",
      "Epoch 1/3, Batch 1830, Loss: 0.4377, Acc: 55.16%\n",
      "Epoch 1/3, Batch 1840, Loss: 2.5453, Acc: 55.13%\n",
      "Epoch 1/3, Batch 1850, Loss: 1.1895, Acc: 55.16%\n",
      "Epoch 1/3, Batch 1860, Loss: 1.4285, Acc: 55.19%\n",
      "Epoch 1/3, Batch 1870, Loss: 1.8019, Acc: 55.10%\n",
      "Epoch 1/3, Batch 1880, Loss: 0.2806, Acc: 55.18%\n",
      "Epoch 1/3, Batch 1890, Loss: 0.0202, Acc: 55.26%\n",
      "Epoch 1/3, Batch 1900, Loss: 0.2230, Acc: 55.34%\n",
      "Epoch 1/3, Batch 1910, Loss: 0.0904, Acc: 55.31%\n",
      "Epoch 1/3, Batch 1920, Loss: 0.2488, Acc: 55.39%\n",
      "Epoch 1/3, Batch 1930, Loss: 1.6719, Acc: 55.36%\n",
      "Epoch 1/3, Batch 1940, Loss: 0.3792, Acc: 55.44%\n",
      "Epoch 1/3, Batch 1950, Loss: 0.3986, Acc: 55.41%\n",
      "Epoch 1/3, Batch 1960, Loss: 1.0515, Acc: 55.28%\n",
      "Epoch 1/3, Batch 1970, Loss: 2.2828, Acc: 55.25%\n",
      "Epoch 1/3, Batch 1980, Loss: 0.4250, Acc: 55.38%\n",
      "Epoch 1/3, Batch 1990, Loss: 0.1243, Acc: 55.50%\n",
      "Epoch 1/3, Batch 2000, Loss: 0.0066, Acc: 55.47%\n",
      "Epoch 1/3, Batch 2010, Loss: 0.5215, Acc: 55.54%\n",
      "Epoch 1/3, Batch 2020, Loss: 0.1937, Acc: 55.67%\n",
      "Epoch 1/3, Batch 2030, Loss: 1.2233, Acc: 55.74%\n",
      "Epoch 1/3, Batch 2040, Loss: 0.3066, Acc: 55.76%\n",
      "Epoch 1/3, Batch 2050, Loss: 0.0633, Acc: 55.78%\n",
      "Epoch 1/3, Batch 2060, Loss: 0.3421, Acc: 55.85%\n",
      "Epoch 1/3, Batch 2070, Loss: 1.1689, Acc: 55.92%\n",
      "Epoch 1/3, Batch 2080, Loss: 0.1858, Acc: 55.84%\n",
      "Epoch 1/3, Batch 2090, Loss: 0.1773, Acc: 55.95%\n",
      "Epoch 1/3, Batch 2100, Loss: 0.2745, Acc: 55.97%\n",
      "Epoch 1/3, Batch 2110, Loss: 0.2773, Acc: 55.95%\n",
      "Epoch 1/3, Batch 2120, Loss: 0.2626, Acc: 55.96%\n",
      "Epoch 1/3, Batch 2130, Loss: 0.1206, Acc: 55.84%\n",
      "Epoch 1/3, Batch 2140, Loss: 0.9579, Acc: 55.86%\n",
      "Epoch 1/3, Batch 2150, Loss: 0.4664, Acc: 55.83%\n",
      "Epoch 1/3, Batch 2160, Loss: 1.7618, Acc: 55.85%\n",
      "Epoch 1/3, Batch 2170, Loss: 0.2730, Acc: 55.92%\n",
      "Epoch 1/3, Batch 2180, Loss: 1.1920, Acc: 55.80%\n",
      "Epoch 1/3, Batch 2190, Loss: 1.9826, Acc: 55.77%\n",
      "Epoch 1/3, Batch 2200, Loss: 0.3289, Acc: 55.79%\n",
      "Epoch 1/3, Batch 2210, Loss: 1.2522, Acc: 55.77%\n",
      "Epoch 1/3, Batch 2220, Loss: 0.1006, Acc: 55.79%\n",
      "Epoch 1/3, Batch 2230, Loss: 0.4466, Acc: 55.76%\n",
      "Epoch 1/3, Batch 2240, Loss: 0.6971, Acc: 55.87%\n",
      "Epoch 1/3, Batch 2250, Loss: 0.7826, Acc: 55.89%\n",
      "Epoch 1/3, Batch 2260, Loss: 2.5825, Acc: 55.95%\n",
      "Epoch 1/3, Batch 2270, Loss: 0.2475, Acc: 55.97%\n",
      "Epoch 1/3, Batch 2280, Loss: 0.0657, Acc: 56.07%\n",
      "Epoch 1/3, Batch 2290, Loss: 0.0277, Acc: 56.05%\n",
      "Epoch 1/3, Batch 2300, Loss: 0.1218, Acc: 55.93%\n",
      "Epoch 1/3, Batch 2310, Loss: 0.2395, Acc: 56.08%\n",
      "Epoch 1/3, Batch 2320, Loss: 0.5566, Acc: 56.10%\n",
      "Epoch 1/3, Batch 2330, Loss: 0.5252, Acc: 56.03%\n",
      "Epoch 1/3, Batch 2340, Loss: 0.3605, Acc: 55.96%\n",
      "Epoch 1/3, Batch 2350, Loss: 1.8482, Acc: 55.98%\n",
      "Epoch 1/3, Batch 2360, Loss: 0.9189, Acc: 56.04%\n",
      "Epoch 1/3, Batch 2370, Loss: 0.5954, Acc: 56.05%\n",
      "Epoch 1/3, Batch 2380, Loss: 0.6084, Acc: 56.11%\n",
      "Epoch 1/3, Batch 2390, Loss: 1.5587, Acc: 56.09%\n",
      "Epoch 1/3, Batch 2400, Loss: 0.0320, Acc: 56.14%\n",
      "Epoch 1/3, Batch 2410, Loss: 0.5644, Acc: 56.12%\n",
      "Epoch 1/3, Batch 2420, Loss: 0.3831, Acc: 56.13%\n",
      "Epoch 1/3, Batch 2430, Loss: 0.4815, Acc: 56.19%\n",
      "Epoch 1/3, Batch 2440, Loss: 0.0772, Acc: 56.33%\n",
      "Epoch 1/3, Batch 2450, Loss: 3.1923, Acc: 56.34%\n",
      "Epoch 1/3, Batch 2460, Loss: 0.1980, Acc: 56.32%\n",
      "Epoch 1/3, Batch 2470, Loss: 2.5236, Acc: 56.29%\n",
      "Epoch 1/3, Batch 2480, Loss: 0.9448, Acc: 56.35%\n",
      "Epoch 1/3, Batch 2490, Loss: 1.1373, Acc: 56.36%\n",
      "Epoch 1/3, Batch 2500, Loss: 2.8211, Acc: 56.42%\n",
      "Epoch 1/3, Batch 2510, Loss: 0.1395, Acc: 56.55%\n",
      "Epoch 1/3, Batch 2520, Loss: 0.1099, Acc: 56.56%\n",
      "Epoch 1/3, Batch 2530, Loss: 1.2305, Acc: 56.50%\n",
      "Epoch 1/3, Batch 2540, Loss: 0.2847, Acc: 56.47%\n",
      "Epoch 1/3, Batch 2550, Loss: 0.2447, Acc: 56.53%\n",
      "Epoch 1/3, Batch 2560, Loss: 0.2060, Acc: 56.58%\n",
      "Epoch 1/3, Batch 2570, Loss: 0.2504, Acc: 56.63%\n",
      "Epoch 1/3, Batch 2580, Loss: 0.0258, Acc: 56.64%\n",
      "Epoch 1/3, Batch 2590, Loss: 1.0524, Acc: 56.70%\n",
      "Epoch 1/3, Batch 2600, Loss: 0.7220, Acc: 56.63%\n",
      "Epoch 1/3, Batch 2610, Loss: 0.8395, Acc: 56.53%\n",
      "Epoch 1/3, Batch 2620, Loss: 0.7983, Acc: 56.51%\n",
      "Epoch 1/3, Batch 2630, Loss: 0.3125, Acc: 56.56%\n",
      "Epoch 1/3, Batch 2640, Loss: 0.1856, Acc: 56.65%\n",
      "Epoch 1/3, Batch 2650, Loss: 1.0283, Acc: 56.73%\n",
      "Epoch 1/3, Batch 2660, Loss: 3.2358, Acc: 56.71%\n",
      "Epoch 1/3, Batch 2670, Loss: 0.4968, Acc: 56.72%\n",
      "Epoch 1/3, Batch 2680, Loss: 1.0040, Acc: 56.77%\n",
      "Epoch 1/3, Batch 2690, Loss: 0.2531, Acc: 56.82%\n",
      "Epoch 1/3, Batch 2700, Loss: 0.7736, Acc: 56.79%\n",
      "Epoch 1/3, Batch 2710, Loss: 0.5518, Acc: 56.81%\n",
      "Epoch 1/3, Batch 2720, Loss: 1.8123, Acc: 56.85%\n",
      "Epoch 1/3, Batch 2730, Loss: 0.2671, Acc: 56.79%\n",
      "Epoch 1/3, Batch 2740, Loss: 0.1996, Acc: 56.80%\n",
      "Epoch 1/3, Batch 2750, Loss: 2.1373, Acc: 56.71%\n",
      "Epoch 1/3, Batch 2760, Loss: 0.2129, Acc: 56.65%\n",
      "Epoch 1/3, Batch 2770, Loss: 2.0502, Acc: 56.62%\n",
      "Epoch 1/3, Batch 2780, Loss: 3.4622, Acc: 56.56%\n",
      "Epoch 1/3, Batch 2790, Loss: 0.5564, Acc: 56.57%\n",
      "Epoch 1/3, Batch 2800, Loss: 0.4742, Acc: 56.55%\n",
      "Epoch 1/3, Batch 2810, Loss: 0.3692, Acc: 56.56%\n",
      "Epoch 1/3, Batch 2820, Loss: 0.5376, Acc: 56.61%\n",
      "Epoch 1/3, Batch 2830, Loss: 1.1672, Acc: 56.62%\n",
      "Epoch 1/3, Batch 2840, Loss: 0.5847, Acc: 56.71%\n",
      "Epoch 1/3, Batch 2850, Loss: 0.2474, Acc: 56.82%\n",
      "Epoch 1/3, Batch 2860, Loss: 0.4095, Acc: 56.87%\n",
      "Epoch 1/3, Batch 2870, Loss: 0.2161, Acc: 56.91%\n",
      "Epoch 1/3, Batch 2880, Loss: 0.8988, Acc: 56.86%\n",
      "Epoch 1/3, Batch 2890, Loss: 0.2121, Acc: 56.87%\n",
      "Epoch 1/3, Batch 2900, Loss: 0.6631, Acc: 56.95%\n",
      "Epoch 1/3, Batch 2910, Loss: 1.3949, Acc: 56.99%\n",
      "Epoch 1/3, Batch 2920, Loss: 0.6907, Acc: 57.00%\n",
      "Epoch 1/3, Batch 2930, Loss: 0.0956, Acc: 56.98%\n",
      "Epoch 1/3, Batch 2940, Loss: 0.3075, Acc: 56.99%\n",
      "Epoch 1/3, Batch 2950, Loss: 3.4578, Acc: 57.00%\n",
      "Epoch 1/3, Batch 2960, Loss: 0.7536, Acc: 57.04%\n",
      "Epoch 1/3, Batch 2970, Loss: 0.0019, Acc: 57.02%\n",
      "Epoch 1/3, Batch 2980, Loss: 0.3808, Acc: 57.03%\n",
      "Epoch 1/3, Batch 2990, Loss: 0.7078, Acc: 57.10%\n",
      "Epoch 1/3, Batch 3000, Loss: 0.1721, Acc: 57.05%\n",
      "Epoch 1/3, Batch 3010, Loss: 0.2265, Acc: 57.09%\n",
      "Epoch 1/3, Batch 3020, Loss: 0.0740, Acc: 57.17%\n",
      "Epoch 1/3, Batch 3030, Loss: 0.1422, Acc: 57.11%\n",
      "Epoch 1/3, Batch 3040, Loss: 0.6620, Acc: 57.12%\n",
      "Epoch 1/3, Batch 3050, Loss: 3.2117, Acc: 57.06%\n",
      "Epoch 1/3, Batch 3060, Loss: 0.9762, Acc: 57.11%\n",
      "Epoch 1/3, Batch 3070, Loss: 1.7164, Acc: 57.11%\n",
      "Epoch 1/3, Batch 3080, Loss: 0.8231, Acc: 57.16%\n",
      "Epoch 1/3, Batch 3090, Loss: 0.2722, Acc: 57.13%\n",
      "Epoch 1/3, Batch 3100, Loss: 0.1453, Acc: 57.24%\n",
      "Epoch 1/3, Batch 3110, Loss: 0.6340, Acc: 57.28%\n",
      "Epoch 1/3, Batch 3120, Loss: 0.1556, Acc: 57.35%\n",
      "Epoch 1/3, Batch 3130, Loss: 0.3091, Acc: 57.39%\n",
      "Epoch 1/3, Batch 3140, Loss: 0.5002, Acc: 57.37%\n",
      "Epoch 1/3, Batch 3150, Loss: 0.2726, Acc: 57.44%\n",
      "Epoch 1/3, Batch 3160, Loss: 0.2642, Acc: 57.58%\n",
      "Epoch 1/3, Batch 3170, Loss: 0.0591, Acc: 57.62%\n",
      "Epoch 1/3, Batch 3180, Loss: 1.1146, Acc: 57.65%\n",
      "Epoch 1/3, Batch 3190, Loss: 0.1002, Acc: 57.63%\n",
      "Epoch 1/3, Batch 3200, Loss: 0.2327, Acc: 57.70%\n",
      "Epoch 1/3, Batch 3210, Loss: 0.5501, Acc: 57.71%\n",
      "Epoch 1/3, Batch 3220, Loss: 1.4241, Acc: 57.71%\n",
      "Epoch 1/3, Batch 3230, Loss: 0.0547, Acc: 57.75%\n",
      "Epoch 1/3, Batch 3240, Loss: 0.0896, Acc: 57.76%\n",
      "Epoch 1/3, Batch 3250, Loss: 0.3855, Acc: 57.80%\n",
      "Epoch 1/3, Batch 3260, Loss: 0.7771, Acc: 57.80%\n",
      "Epoch 1/3, Batch 3270, Loss: 1.0944, Acc: 57.78%\n",
      "Epoch 1/3, Batch 3280, Loss: 0.5089, Acc: 57.82%\n",
      "Epoch 1/3, Batch 3290, Loss: 1.4597, Acc: 57.82%\n",
      "Epoch 1/3, Batch 3300, Loss: 3.0980, Acc: 57.83%\n",
      "Epoch 1/3, Batch 3310, Loss: 0.2400, Acc: 57.81%\n",
      "Epoch 1/3, Batch 3320, Loss: 0.0161, Acc: 57.81%\n",
      "Epoch 1/3, Batch 3330, Loss: 1.5319, Acc: 57.85%\n",
      "Epoch 1/3, Batch 3340, Loss: 0.1036, Acc: 57.92%\n",
      "Epoch 1/3, Batch 3350, Loss: 0.7573, Acc: 57.89%\n",
      "Epoch 1/3, Batch 3360, Loss: 0.0565, Acc: 57.90%\n",
      "Epoch 1/3, Batch 3370, Loss: 0.4063, Acc: 57.96%\n",
      "Epoch 1/3, Batch 3380, Loss: 0.0586, Acc: 57.97%\n",
      "Epoch 1/3, Batch 3390, Loss: 0.2435, Acc: 57.92%\n",
      "Epoch 1/3, Batch 3400, Loss: 0.2978, Acc: 58.01%\n",
      "Epoch 1/3, Batch 3410, Loss: 1.5019, Acc: 57.96%\n",
      "Epoch 1/3, Batch 3420, Loss: 0.5999, Acc: 57.94%\n",
      "Epoch 1/3, Batch 3430, Loss: 3.7277, Acc: 57.97%\n",
      "Epoch 1/3, Batch 3440, Loss: 1.1060, Acc: 57.95%\n",
      "Epoch 1/3, Batch 3450, Loss: 0.0630, Acc: 57.98%\n",
      "Epoch 1/3, Batch 3460, Loss: 0.1460, Acc: 57.99%\n",
      "Epoch 1/3, Batch 3470, Loss: 1.5553, Acc: 57.99%\n",
      "Epoch 1/3, Batch 3480, Loss: 0.5999, Acc: 57.94%\n",
      "Epoch 1/3, Batch 3490, Loss: 4.4077, Acc: 57.98%\n",
      "Epoch 1/3, Batch 3500, Loss: 0.5993, Acc: 58.01%\n",
      "Epoch 1/3, Batch 3510, Loss: 2.0631, Acc: 58.07%\n",
      "Epoch 1/3, Batch 3520, Loss: 1.2190, Acc: 58.08%\n",
      "Epoch 1/3, Batch 3530, Loss: 2.8332, Acc: 58.11%\n",
      "Epoch 1/3, Batch 3540, Loss: 0.8958, Acc: 58.09%\n",
      "Epoch 1/3, Batch 3550, Loss: 0.0476, Acc: 58.10%\n",
      "Epoch 1/3, Batch 3560, Loss: 2.0600, Acc: 58.07%\n",
      "Epoch 1/3, Batch 3570, Loss: 0.6919, Acc: 58.16%\n",
      "Epoch 1/3, Batch 3580, Loss: 0.9471, Acc: 58.14%\n",
      "Epoch 1/3, Batch 3590, Loss: 0.3399, Acc: 58.17%\n",
      "Epoch 1/3, Batch 3600, Loss: 0.1567, Acc: 58.21%\n",
      "Epoch 1/3, Batch 3610, Loss: 0.7711, Acc: 58.18%\n",
      "Epoch 1/3, Batch 3620, Loss: 0.3450, Acc: 58.22%\n",
      "Epoch 1/3, Batch 3630, Loss: 0.1164, Acc: 58.25%\n",
      "Epoch 1/3, Batch 3640, Loss: 2.3593, Acc: 58.28%\n",
      "Epoch 1/3, Batch 3650, Loss: 0.2981, Acc: 58.29%\n",
      "Epoch 1/3, Batch 3660, Loss: 0.3750, Acc: 58.29%\n",
      "Epoch 1/3, Batch 3670, Loss: 0.3370, Acc: 58.35%\n",
      "Epoch 1/3, Batch 3680, Loss: 0.0537, Acc: 58.33%\n",
      "Epoch 1/3, Batch 3690, Loss: 0.3993, Acc: 58.30%\n",
      "Epoch 1/3, Batch 3700, Loss: 0.4156, Acc: 58.31%\n",
      "Epoch 1/3, Batch 3710, Loss: 1.0644, Acc: 58.26%\n",
      "Epoch 1/3, Batch 3720, Loss: 0.4180, Acc: 58.32%\n",
      "Epoch 1/3, Batch 3730, Loss: 0.1062, Acc: 58.40%\n",
      "Epoch 1/3, Batch 3740, Loss: 2.3368, Acc: 58.35%\n",
      "Epoch 1/3, Batch 3750, Loss: 2.9880, Acc: 58.36%\n",
      "Epoch 1/3, Batch 3760, Loss: 0.3068, Acc: 58.34%\n",
      "Epoch 1/3, Batch 3770, Loss: 0.2786, Acc: 58.37%\n",
      "Epoch 1/3, Batch 3780, Loss: 1.0364, Acc: 58.42%\n",
      "Epoch 1/3, Batch 3790, Loss: 0.0093, Acc: 58.43%\n",
      "Epoch 1/3, Batch 3800, Loss: 1.4556, Acc: 58.43%\n",
      "Epoch 1/3, Batch 3810, Loss: 0.0059, Acc: 58.44%\n",
      "Epoch 1/3, Batch 3820, Loss: 0.3159, Acc: 58.41%\n",
      "Epoch 1/3, Batch 3830, Loss: 0.4697, Acc: 58.42%\n",
      "Epoch 1/3, Batch 3840, Loss: 0.1869, Acc: 58.42%\n",
      "Epoch 1/3, Batch 3850, Loss: 0.1140, Acc: 58.35%\n",
      "Epoch 1/3, Batch 3860, Loss: 1.0598, Acc: 58.35%\n",
      "Epoch 1/3, Batch 3870, Loss: 0.3929, Acc: 58.38%\n",
      "Epoch 1/3, Batch 3880, Loss: 0.1286, Acc: 58.34%\n",
      "Epoch 1/3, Batch 3890, Loss: 0.8907, Acc: 58.34%\n",
      "Epoch 1/3, Batch 3900, Loss: 0.2261, Acc: 58.32%\n",
      "Epoch 1/3, Batch 3910, Loss: 2.3533, Acc: 58.37%\n",
      "Epoch 1/3, Batch 3920, Loss: 0.5304, Acc: 58.38%\n",
      "Epoch 1/3, Batch 3930, Loss: 1.9995, Acc: 58.31%\n",
      "Epoch 1/3, Batch 3940, Loss: 0.1717, Acc: 58.28%\n",
      "Epoch 1/3, Batch 3950, Loss: 2.1737, Acc: 58.24%\n",
      "Epoch 1/3, Batch 3960, Loss: 1.3481, Acc: 58.27%\n",
      "Epoch 1/3, Batch 3970, Loss: 0.4619, Acc: 58.30%\n",
      "Epoch 1/3, Batch 3980, Loss: 0.6772, Acc: 58.30%\n",
      "Epoch 1/3, Batch 3990, Loss: 0.1130, Acc: 58.31%\n",
      "Epoch 1/3, Batch 4000, Loss: 0.8621, Acc: 58.31%\n",
      "Epoch 1/3, Batch 4010, Loss: 1.2229, Acc: 58.36%\n",
      "Epoch 1/3, Batch 4020, Loss: 0.8526, Acc: 58.39%\n",
      "Epoch 1/3, Batch 4030, Loss: 0.1734, Acc: 58.47%\n",
      "Epoch 1/3, Batch 4040, Loss: 2.5240, Acc: 58.48%\n",
      "Epoch 1/3, Batch 4050, Loss: 0.1927, Acc: 58.48%\n",
      "Epoch 1/3, Batch 4060, Loss: 0.1414, Acc: 58.53%\n",
      "Epoch 1/3, Batch 4070, Loss: 0.2991, Acc: 58.59%\n",
      "Epoch 1/3, Batch 4080, Loss: 1.4261, Acc: 58.52%\n",
      "Epoch 1/3, Batch 4090, Loss: 0.6518, Acc: 58.54%\n",
      "Epoch 1/3, Batch 4100, Loss: 0.0335, Acc: 58.60%\n",
      "Epoch 1/3, Batch 4110, Loss: 3.1237, Acc: 58.62%\n",
      "Epoch 1/3, Batch 4120, Loss: 1.5075, Acc: 58.58%\n",
      "Epoch 1/3, Batch 4130, Loss: 0.9951, Acc: 58.56%\n",
      "Epoch 1/3, Batch 4140, Loss: 0.3585, Acc: 58.54%\n",
      "Epoch 1/3, Batch 4150, Loss: 0.1024, Acc: 58.61%\n",
      "Epoch 1/3, Batch 4160, Loss: 3.5158, Acc: 58.62%\n",
      "Epoch 1/3, Batch 4170, Loss: 0.5150, Acc: 58.62%\n",
      "Epoch 1/3, Batch 4180, Loss: 1.6177, Acc: 58.60%\n",
      "Epoch 1/3, Batch 4190, Loss: 2.3529, Acc: 58.60%\n",
      "Epoch 1/3, Batch 4200, Loss: 1.0612, Acc: 58.56%\n",
      "Epoch 1/3, Batch 4210, Loss: 1.4013, Acc: 58.49%\n",
      "Epoch 1/3, Batch 4220, Loss: 1.6494, Acc: 58.49%\n",
      "Epoch 1/3, Batch 4230, Loss: 0.0488, Acc: 58.47%\n",
      "Epoch 1/3, Batch 4240, Loss: 0.0391, Acc: 58.50%\n",
      "Epoch 1/3, Batch 4250, Loss: 0.5737, Acc: 58.50%\n",
      "Epoch 1/3, Batch 4260, Loss: 1.3783, Acc: 58.44%\n",
      "Epoch 1/3, Batch 4270, Loss: 0.2738, Acc: 58.46%\n",
      "Epoch 1/3, Batch 4280, Loss: 0.3034, Acc: 58.47%\n",
      "Epoch 1/3, Batch 4290, Loss: 0.5098, Acc: 58.54%\n",
      "Epoch 1/3, Batch 4300, Loss: 0.0968, Acc: 58.54%\n",
      "Epoch 1/3, Batch 4310, Loss: 2.2376, Acc: 58.55%\n",
      "Epoch 1/3, Batch 4320, Loss: 0.3624, Acc: 58.60%\n",
      "Epoch 1/3, Batch 4330, Loss: 0.0631, Acc: 58.60%\n",
      "Epoch 1/3, Batch 4340, Loss: 0.7241, Acc: 58.63%\n",
      "Epoch 1/3, Batch 4350, Loss: 0.5685, Acc: 58.61%\n",
      "Epoch 1/3, Batch 4360, Loss: 0.3135, Acc: 58.59%\n",
      "Epoch 1/3, Batch 4370, Loss: 1.6495, Acc: 58.59%\n",
      "Epoch 1/3, Batch 4380, Loss: 1.4349, Acc: 58.55%\n",
      "Epoch 1/3, Batch 4390, Loss: 0.1464, Acc: 58.55%\n",
      "Epoch 1/3, Batch 4400, Loss: 0.0423, Acc: 58.53%\n",
      "Epoch 1/3, Batch 4410, Loss: 0.2856, Acc: 58.56%\n",
      "Epoch 1/3, Batch 4420, Loss: 0.9999, Acc: 58.61%\n",
      "Epoch 1/3, Batch 4430, Loss: 0.1650, Acc: 58.63%\n",
      "Epoch 1/3, Batch 4440, Loss: 1.6037, Acc: 58.68%\n",
      "Epoch 1/3, Batch 4450, Loss: 0.1528, Acc: 58.68%\n",
      "Epoch 1/3, Batch 4460, Loss: 0.9835, Acc: 58.66%\n",
      "Epoch 1/3, Batch 4470, Loss: 0.4930, Acc: 58.64%\n",
      "Epoch 1/3, Batch 4480, Loss: 0.1878, Acc: 58.71%\n",
      "Epoch 1/3, Batch 4490, Loss: 0.0114, Acc: 58.72%\n",
      "Epoch 1/3, Batch 4500, Loss: 1.7175, Acc: 58.72%\n",
      "Epoch 1/3, Batch 4510, Loss: 1.1864, Acc: 58.70%\n",
      "Epoch 1/3, Batch 4520, Loss: 0.7294, Acc: 58.66%\n",
      "Epoch 1/3, Batch 4530, Loss: 0.8398, Acc: 58.64%\n",
      "Epoch 1/3, Batch 4540, Loss: 0.0090, Acc: 58.71%\n",
      "Epoch 1/3, Batch 4550, Loss: 1.3861, Acc: 58.69%\n",
      "Epoch 1/3, Batch 4560, Loss: 0.0526, Acc: 58.69%\n",
      "Epoch 1/3, Batch 4570, Loss: 0.8989, Acc: 58.67%\n",
      "Epoch 1/3, Batch 4580, Loss: 0.4838, Acc: 58.72%\n",
      "Epoch 1/3, Batch 4590, Loss: 0.9645, Acc: 58.75%\n",
      "Epoch 1/3, Batch 4600, Loss: 0.3691, Acc: 58.77%\n",
      "Epoch 1/3, Batch 4610, Loss: 1.7975, Acc: 58.77%\n",
      "Epoch 1/3, Batch 4620, Loss: 0.3721, Acc: 58.82%\n",
      "Epoch 1/3, Batch 4630, Loss: 0.2153, Acc: 58.80%\n",
      "Epoch 1/3, Batch 4640, Loss: 3.8756, Acc: 58.76%\n",
      "Epoch 1/3, Batch 4650, Loss: 0.0953, Acc: 58.76%\n",
      "Epoch 1/3, Batch 4660, Loss: 1.0999, Acc: 58.81%\n",
      "Epoch 1/3, Batch 4670, Loss: 0.3461, Acc: 58.81%\n",
      "Epoch 1/3, Batch 4680, Loss: 0.0603, Acc: 58.85%\n",
      "Epoch 1/3, Batch 4690, Loss: 0.5892, Acc: 58.84%\n",
      "Epoch 1/3, Batch 4700, Loss: 0.9354, Acc: 58.77%\n",
      "Epoch 1/3, Batch 4710, Loss: 0.0661, Acc: 58.78%\n",
      "Epoch 1/3, Batch 4720, Loss: 0.0338, Acc: 58.74%\n",
      "Epoch 1/3, Batch 4730, Loss: 0.2225, Acc: 58.76%\n",
      "Epoch 1/3, Batch 4740, Loss: 0.2024, Acc: 58.72%\n",
      "Epoch 1/3, Batch 4750, Loss: 0.5546, Acc: 58.75%\n",
      "Epoch 1/3, Batch 4760, Loss: 1.3650, Acc: 58.79%\n",
      "Epoch 1/3, Batch 4770, Loss: 0.8611, Acc: 58.79%\n",
      "Epoch 1/3, Batch 4780, Loss: 0.6278, Acc: 58.77%\n",
      "Epoch 1/3, Batch 4790, Loss: 2.6161, Acc: 58.80%\n",
      "Epoch 1/3, Batch 4800, Loss: 0.3153, Acc: 58.82%\n",
      "Epoch 1/3, Batch 4810, Loss: 0.6991, Acc: 58.74%\n",
      "Epoch 1/3, Batch 4820, Loss: 0.0152, Acc: 58.76%\n",
      "Epoch 1/3, Batch 4830, Loss: 0.0795, Acc: 58.75%\n",
      "Epoch 1/3, Batch 4840, Loss: 0.7778, Acc: 58.77%\n",
      "Epoch 1/3, Batch 4850, Loss: 1.3100, Acc: 58.79%\n",
      "Epoch 1/3, Batch 4860, Loss: 1.0098, Acc: 58.75%\n",
      "Epoch 1/3, Batch 4870, Loss: 0.0298, Acc: 58.80%\n",
      "Epoch 1/3, Batch 4880, Loss: 1.6869, Acc: 58.78%\n",
      "Epoch 1/3, Batch 4890, Loss: 0.0735, Acc: 58.82%\n",
      "Epoch 1/3, Batch 4900, Loss: 0.4212, Acc: 58.82%\n",
      "Epoch 1/3, Batch 4910, Loss: 0.2939, Acc: 58.81%\n",
      "Epoch 1/3, Batch 4920, Loss: 0.2206, Acc: 58.87%\n",
      "Epoch 1/3, Batch 4930, Loss: 0.8741, Acc: 58.87%\n",
      "Epoch 1/3, Batch 4940, Loss: 0.0712, Acc: 58.85%\n",
      "Epoch 1/3, Batch 4950, Loss: 0.7391, Acc: 58.84%\n",
      "Epoch 1/3, Batch 4960, Loss: 0.1080, Acc: 58.86%\n",
      "Epoch 1/3, Batch 4970, Loss: 0.2288, Acc: 58.86%\n",
      "Epoch 1/3, Batch 4980, Loss: 0.1277, Acc: 58.92%\n",
      "Epoch 1/3, Batch 4990, Loss: 0.4262, Acc: 58.93%\n",
      "Epoch 1/3, Batch 5000, Loss: 0.1390, Acc: 58.95%\n",
      "Epoch 1/3, Batch 5010, Loss: 1.9963, Acc: 58.89%\n",
      "Epoch 1/3, Batch 5020, Loss: 0.5366, Acc: 58.93%\n",
      "Epoch 1/3, Batch 5030, Loss: 0.2986, Acc: 58.93%\n",
      "Epoch 1/3, Batch 5040, Loss: 0.8006, Acc: 58.94%\n",
      "Epoch 1/3, Batch 5050, Loss: 1.5750, Acc: 58.88%\n",
      "Epoch 1/3, Batch 5060, Loss: 0.6958, Acc: 58.88%\n",
      "Epoch 1/3, Batch 5070, Loss: 0.4888, Acc: 58.90%\n",
      "Epoch 1/3, Batch 5080, Loss: 0.0525, Acc: 58.93%\n",
      "Epoch 1/3, Batch 5090, Loss: 1.5024, Acc: 58.89%\n",
      "Epoch 1/3, Batch 5100, Loss: 1.5108, Acc: 58.87%\n",
      "Epoch 1/3, Batch 5110, Loss: 0.9018, Acc: 58.85%\n",
      "Epoch 1/3, Batch 5120, Loss: 0.0754, Acc: 58.86%\n",
      "Epoch 1/3, Batch 5130, Loss: 2.1509, Acc: 58.88%\n",
      "Epoch 1/3, Batch 5140, Loss: 0.8250, Acc: 58.84%\n",
      "Epoch 1/3, Batch 5150, Loss: 0.0953, Acc: 58.84%\n",
      "Epoch 1/3, Batch 5160, Loss: 0.4614, Acc: 58.86%\n",
      "Epoch 1/3, Batch 5170, Loss: 3.9540, Acc: 58.85%\n",
      "Epoch 1/3, Batch 5180, Loss: 0.0225, Acc: 58.85%\n",
      "Epoch 1/3, Batch 5190, Loss: 1.8459, Acc: 58.81%\n",
      "Epoch 1/3, Batch 5200, Loss: 1.1703, Acc: 58.78%\n",
      "Epoch 1/3, Batch 5210, Loss: 0.7955, Acc: 58.78%\n",
      "Epoch 1/3, Batch 5220, Loss: 1.5539, Acc: 58.84%\n",
      "Epoch 1/3, Batch 5230, Loss: 0.3004, Acc: 58.82%\n",
      "Epoch 1/3, Batch 5240, Loss: 0.3349, Acc: 58.81%\n",
      "Epoch 1/3, Batch 5250, Loss: 0.4285, Acc: 58.79%\n",
      "Epoch 1/3, Batch 5260, Loss: 0.2106, Acc: 58.87%\n",
      "Epoch 1/3, Batch 5270, Loss: 2.2123, Acc: 58.85%\n",
      "Epoch 1/3, Batch 5280, Loss: 0.3898, Acc: 58.91%\n",
      "Epoch 1/3, Batch 5290, Loss: 0.0456, Acc: 58.91%\n",
      "Epoch 1/3, Batch 5300, Loss: 0.2174, Acc: 58.91%\n",
      "Epoch 1/3, Batch 5310, Loss: 0.0054, Acc: 58.90%\n",
      "Epoch 1/3, Batch 5320, Loss: 0.7011, Acc: 58.88%\n",
      "Epoch 1/3, Batch 5330, Loss: 0.5811, Acc: 58.86%\n",
      "Epoch 1/3, Batch 5340, Loss: 0.6242, Acc: 58.83%\n",
      "Epoch 1/3, Batch 5350, Loss: 0.5303, Acc: 58.87%\n",
      "Epoch 1/3, Batch 5360, Loss: 1.0373, Acc: 58.89%\n",
      "Epoch 1/3, Batch 5370, Loss: 1.2997, Acc: 58.83%\n",
      "Epoch 1/3, Batch 5380, Loss: 0.0155, Acc: 58.86%\n",
      "Epoch 1/3, Batch 5390, Loss: 1.1754, Acc: 58.86%\n",
      "Epoch 1/3, Batch 5400, Loss: 3.0235, Acc: 58.90%\n",
      "Epoch 1/3, Batch 5410, Loss: 0.5197, Acc: 58.86%\n",
      "Epoch 1/3, Batch 5420, Loss: 0.1736, Acc: 58.83%\n",
      "Epoch 1/3, Batch 5430, Loss: 0.4095, Acc: 58.87%\n",
      "Epoch 1/3, Batch 5440, Loss: 0.7011, Acc: 58.87%\n",
      "Epoch 1/3, Batch 5450, Loss: 0.5791, Acc: 58.89%\n",
      "Epoch 1/3, Batch 5460, Loss: 1.6988, Acc: 58.91%\n",
      "Epoch 1/3, Batch 5470, Loss: 0.3161, Acc: 58.89%\n",
      "Epoch 1/3, Batch 5480, Loss: 2.9840, Acc: 58.86%\n",
      "Epoch 1/3, Batch 5490, Loss: 0.6364, Acc: 58.88%\n",
      "Epoch 1/3, Batch 5500, Loss: 2.1043, Acc: 58.83%\n",
      "Epoch 1/3, Batch 5510, Loss: 5.1625, Acc: 58.79%\n",
      "Epoch 1/3, Batch 5520, Loss: 1.7016, Acc: 58.79%\n",
      "Epoch 1/3, Batch 5530, Loss: 1.0294, Acc: 58.80%\n",
      "Epoch 1/3, Batch 5540, Loss: 0.0049, Acc: 58.80%\n",
      "Epoch 1/3, Batch 5550, Loss: 0.5691, Acc: 58.85%\n",
      "Epoch 1/3, Batch 5560, Loss: 0.6446, Acc: 58.84%\n",
      "Epoch 1/3, Batch 5570, Loss: 0.0877, Acc: 58.84%\n",
      "Epoch 1/3, Batch 5580, Loss: 0.8217, Acc: 58.82%\n",
      "Epoch 1/3, Batch 5590, Loss: 0.0115, Acc: 58.86%\n",
      "Epoch 1/3, Batch 5600, Loss: 0.3259, Acc: 58.86%\n",
      "Epoch 1/3, Batch 5610, Loss: 0.1367, Acc: 58.83%\n",
      "Epoch 1/3, Batch 5620, Loss: 0.7700, Acc: 58.82%\n",
      "Epoch 1/3, Batch 5630, Loss: 2.0349, Acc: 58.82%\n",
      "Epoch 1/3, Batch 5640, Loss: 0.9524, Acc: 58.78%\n",
      "Epoch 1/3, Batch 5650, Loss: 0.1963, Acc: 58.77%\n",
      "Epoch 1/3, Batch 5660, Loss: 0.3515, Acc: 58.72%\n",
      "Epoch 1/3, Batch 5670, Loss: 0.0094, Acc: 58.72%\n",
      "Epoch 1/3, Batch 5680, Loss: 0.2339, Acc: 58.74%\n",
      "Epoch 1/3, Batch 5690, Loss: 0.1511, Acc: 58.72%\n",
      "Epoch 1/3, Batch 5700, Loss: 0.0793, Acc: 58.71%\n",
      "Epoch 1/3, Batch 5710, Loss: 0.3985, Acc: 58.76%\n",
      "Epoch 1/3, Batch 5720, Loss: 0.3701, Acc: 58.78%\n",
      "Epoch 1/3, Batch 5730, Loss: 0.1784, Acc: 58.80%\n",
      "Epoch 1/3, Batch 5740, Loss: 0.1124, Acc: 58.84%\n",
      "Epoch 1/3, Batch 5750, Loss: 1.1668, Acc: 58.82%\n",
      "Epoch 1/3, Batch 5760, Loss: 0.0253, Acc: 58.83%\n",
      "Epoch 1/3, Batch 5770, Loss: 1.1863, Acc: 58.85%\n",
      "Epoch 1/3, Batch 5780, Loss: 1.9611, Acc: 58.83%\n",
      "Epoch 1/3, Batch 5790, Loss: 0.0868, Acc: 58.82%\n",
      "Epoch 1/3, Batch 5800, Loss: 1.7368, Acc: 58.85%\n",
      "Epoch 1/3, Batch 5810, Loss: 1.6185, Acc: 58.84%\n",
      "Epoch 1/3, Batch 5820, Loss: 1.1490, Acc: 58.84%\n",
      "Epoch 1/3, Batch 5830, Loss: 1.7474, Acc: 58.79%\n",
      "Epoch 1/3, Batch 5840, Loss: 0.3200, Acc: 58.79%\n",
      "Epoch 1/3, Batch 5850, Loss: 3.3704, Acc: 58.81%\n",
      "Epoch 1/3, Batch 5860, Loss: 0.3087, Acc: 58.81%\n",
      "Epoch 1/3, Batch 5870, Loss: 0.1338, Acc: 58.87%\n",
      "Epoch 1/3, Batch 5880, Loss: 1.5826, Acc: 58.83%\n",
      "Epoch 1/3, Batch 5890, Loss: 0.4290, Acc: 58.80%\n",
      "Epoch 1/3, Batch 5900, Loss: 0.5389, Acc: 58.82%\n",
      "Epoch 1/3, Batch 5910, Loss: 0.3682, Acc: 58.82%\n",
      "Epoch 1/3, Batch 5920, Loss: 0.2784, Acc: 58.79%\n",
      "Epoch 1/3, Batch 5930, Loss: 0.4226, Acc: 58.81%\n",
      "Epoch 1/3, Batch 5940, Loss: 0.3439, Acc: 58.78%\n",
      "Epoch 1/3, Batch 5950, Loss: 2.0761, Acc: 58.80%\n",
      "Epoch 1/3, Batch 5960, Loss: 2.7889, Acc: 58.82%\n",
      "Epoch 1/3, Batch 5970, Loss: 1.0262, Acc: 58.82%\n",
      "Epoch 1/3, Batch 5980, Loss: 0.1502, Acc: 58.85%\n",
      "Epoch 1/3, Batch 5990, Loss: 0.1540, Acc: 58.85%\n",
      "Epoch 1/3, Batch 6000, Loss: 0.2364, Acc: 58.86%\n",
      "Epoch 1/3, Batch 6010, Loss: 2.8232, Acc: 58.88%\n",
      "Epoch 1/3, Batch 6020, Loss: 0.3657, Acc: 58.91%\n",
      "Epoch 1/3, Batch 6030, Loss: 0.6591, Acc: 58.91%\n",
      "Epoch 1/3, Batch 6040, Loss: 0.5536, Acc: 58.96%\n",
      "Epoch 1/3, Batch 6050, Loss: 0.1984, Acc: 59.00%\n",
      "Epoch 1/3, Batch 6060, Loss: 1.3855, Acc: 58.98%\n",
      "Epoch 1/3, Batch 6070, Loss: 0.1462, Acc: 59.00%\n",
      "Epoch 1/3, Batch 6080, Loss: 0.5605, Acc: 59.04%\n",
      "Epoch 1/3, Batch 6090, Loss: 0.0123, Acc: 59.05%\n",
      "Epoch 1/3, Batch 6100, Loss: 0.3035, Acc: 59.11%\n",
      "Epoch 1/3, Batch 6110, Loss: 2.4410, Acc: 59.07%\n",
      "Epoch 1/3, Batch 6120, Loss: 0.8151, Acc: 59.08%\n",
      "Epoch 1/3, Batch 6130, Loss: 0.2110, Acc: 59.08%\n",
      "Epoch 1/3, Batch 6140, Loss: 0.0186, Acc: 59.11%\n",
      "Epoch 1/3, Batch 6150, Loss: 0.3477, Acc: 59.16%\n",
      "Epoch 1/3, Batch 6160, Loss: 0.9850, Acc: 59.16%\n",
      "Epoch 1/3, Batch 6170, Loss: 1.1687, Acc: 59.15%\n",
      "Epoch 1/3, Batch 6180, Loss: 2.3646, Acc: 59.13%\n",
      "Epoch 1/3, Batch 6190, Loss: 0.0757, Acc: 59.12%\n",
      "Epoch 1/3, Batch 6200, Loss: 1.4514, Acc: 59.12%\n",
      "Epoch 1/3, Batch 6210, Loss: 1.2207, Acc: 59.06%\n",
      "Epoch 1/3, Batch 6220, Loss: 0.4155, Acc: 59.03%\n",
      "Epoch 1/3, Batch 6230, Loss: 1.8830, Acc: 59.00%\n",
      "Epoch 1/3, Batch 6240, Loss: 0.0427, Acc: 58.98%\n",
      "Epoch 1/3, Batch 6250, Loss: 0.0109, Acc: 59.00%\n",
      "Epoch 1/3, Batch 6260, Loss: 1.3677, Acc: 58.98%\n",
      "Epoch 1/3, Batch 6270, Loss: 0.0086, Acc: 59.03%\n",
      "Epoch 1/3, Batch 6280, Loss: 1.3321, Acc: 59.04%\n",
      "Epoch 1/3, Batch 6290, Loss: 0.0702, Acc: 59.04%\n",
      "Epoch 1/3, Batch 6300, Loss: 1.1451, Acc: 59.04%\n",
      "Epoch 1/3, Batch 6310, Loss: 0.0516, Acc: 59.09%\n",
      "Epoch 1/3, Batch 6320, Loss: 0.0228, Acc: 59.12%\n",
      "Epoch 1/3, Batch 6330, Loss: 0.2317, Acc: 59.12%\n",
      "Epoch 1/3, Batch 6340, Loss: 0.0152, Acc: 59.14%\n",
      "Epoch 1/3, Batch 6350, Loss: 0.7218, Acc: 59.14%\n",
      "Epoch 1/3, Batch 6360, Loss: 0.2747, Acc: 59.16%\n",
      "Epoch 1/3, Batch 6370, Loss: 0.9702, Acc: 59.16%\n",
      "Epoch 1/3, Batch 6380, Loss: 0.0301, Acc: 59.18%\n",
      "Epoch 1/3, Batch 6390, Loss: 0.1536, Acc: 59.24%\n",
      "Epoch 1/3, Batch 6400, Loss: 0.5834, Acc: 59.24%\n",
      "Epoch 1/3, Batch 6410, Loss: 2.0923, Acc: 59.24%\n",
      "Epoch 1/3, Batch 6420, Loss: 1.8599, Acc: 59.21%\n",
      "Epoch 1/3, Batch 6430, Loss: 0.6395, Acc: 59.21%\n",
      "Epoch 1/3, Batch 6440, Loss: 0.3809, Acc: 59.23%\n",
      "Epoch 1/3, Batch 6450, Loss: 0.6407, Acc: 59.22%\n",
      "Epoch 1/3, Batch 6460, Loss: 0.4785, Acc: 59.28%\n",
      "Epoch 1/3, Batch 6470, Loss: 1.6752, Acc: 59.25%\n",
      "Epoch 1/3, Batch 6480, Loss: 0.0577, Acc: 59.27%\n",
      "Epoch 1/3, Batch 6490, Loss: 0.0278, Acc: 59.30%\n",
      "Epoch 1/3, Batch 6500, Loss: 0.0304, Acc: 59.34%\n",
      "Epoch 1/3, Batch 6510, Loss: 2.0484, Acc: 59.35%\n",
      "Epoch 1/3, Batch 6520, Loss: 0.8491, Acc: 59.32%\n",
      "Epoch 1/3, Batch 6530, Loss: 0.0420, Acc: 59.33%\n",
      "Epoch 1/3, Batch 6540, Loss: 0.1231, Acc: 59.36%\n",
      "Epoch 1/3, Batch 6550, Loss: 0.6331, Acc: 59.36%\n",
      "Epoch 1/3, Batch 6560, Loss: 0.0229, Acc: 59.35%\n",
      "Epoch 1/3, Batch 6570, Loss: 0.8726, Acc: 59.34%\n",
      "Epoch 1/3, Batch 6580, Loss: 0.4581, Acc: 59.38%\n",
      "Epoch 1/3, Batch 6590, Loss: 0.3205, Acc: 59.41%\n",
      "Epoch 1/3, Batch 6600, Loss: 0.0127, Acc: 59.46%\n",
      "Epoch 1/3, Batch 6610, Loss: 1.0416, Acc: 59.45%\n",
      "Epoch 1/3, Batch 6620, Loss: 0.1968, Acc: 59.48%\n",
      "Epoch 1/3, Batch 6630, Loss: 0.4687, Acc: 59.45%\n",
      "Epoch 1/3, Batch 6640, Loss: 0.2980, Acc: 59.49%\n",
      "Epoch 1/3, Batch 6650, Loss: 0.1779, Acc: 59.51%\n",
      "Epoch 1/3, Batch 6660, Loss: 0.0772, Acc: 59.54%\n",
      "Epoch 1/3, Batch 6670, Loss: 0.1009, Acc: 59.54%\n",
      "Epoch 1/3, Batch 6680, Loss: 2.6369, Acc: 59.54%\n",
      "Epoch 1/3, Batch 6690, Loss: 1.4647, Acc: 59.51%\n",
      "Epoch 1/3, Batch 6700, Loss: 1.5189, Acc: 59.50%\n",
      "Epoch 1/3, Batch 6710, Loss: 0.0139, Acc: 59.53%\n",
      "Epoch 1/3, Batch 6720, Loss: 0.2615, Acc: 59.54%\n",
      "Epoch 1/3, Batch 6730, Loss: 0.6369, Acc: 59.56%\n",
      "Epoch 1/3, Batch 6740, Loss: 0.9209, Acc: 59.53%\n",
      "Epoch 1/3, Batch 6750, Loss: 1.4799, Acc: 59.49%\n",
      "Epoch 1/3, Batch 6760, Loss: 1.7273, Acc: 59.49%\n",
      "Epoch 1/3, Batch 6770, Loss: 0.8190, Acc: 59.50%\n",
      "Epoch 1/3, Batch 6780, Loss: 1.1692, Acc: 59.49%\n",
      "Epoch 1/3, Batch 6790, Loss: 0.6227, Acc: 59.49%\n",
      "Epoch 1/3, Batch 6800, Loss: 0.0887, Acc: 59.52%\n",
      "Epoch 1/3, Batch 6810, Loss: 0.4978, Acc: 59.54%\n",
      "Epoch 1/3, Batch 6820, Loss: 0.3032, Acc: 59.55%\n",
      "Epoch 1/3, Batch 6830, Loss: 0.5214, Acc: 59.55%\n",
      "Epoch 1/3, Batch 6840, Loss: 2.3955, Acc: 59.57%\n",
      "Epoch 1/3, Batch 6850, Loss: 0.8311, Acc: 59.55%\n",
      "Epoch 1/3, Batch 6860, Loss: 0.5787, Acc: 59.54%\n",
      "Epoch 1/3, Batch 6870, Loss: 0.5093, Acc: 59.58%\n",
      "Epoch 1/3, Batch 6880, Loss: 2.2917, Acc: 59.56%\n",
      "Epoch 1/3, Batch 6890, Loss: 0.5621, Acc: 59.54%\n",
      "Epoch 1/3, Batch 6900, Loss: 0.5461, Acc: 59.53%\n",
      "Epoch 1/3, Batch 6910, Loss: 2.3166, Acc: 59.48%\n",
      "Epoch 1/3, Batch 6920, Loss: 0.2407, Acc: 59.49%\n",
      "Epoch 1/3, Batch 6930, Loss: 0.1207, Acc: 59.49%\n",
      "Epoch 1/3, Batch 6940, Loss: 0.6580, Acc: 59.50%\n",
      "Epoch 1/3, Batch 6950, Loss: 1.0202, Acc: 59.49%\n",
      "Epoch 1/3, Batch 6960, Loss: 0.1246, Acc: 59.47%\n",
      "Epoch 1/3, Batch 6970, Loss: 3.0084, Acc: 59.45%\n",
      "Epoch 1/3, Batch 6980, Loss: 1.8106, Acc: 59.45%\n",
      "Epoch 1/3, Batch 6990, Loss: 0.6297, Acc: 59.45%\n",
      "Epoch 1/3, Batch 7000, Loss: 1.3128, Acc: 59.45%\n",
      "Epoch 1/3, Batch 7010, Loss: 0.2400, Acc: 59.48%\n",
      "Epoch 1/3, Batch 7020, Loss: 0.1305, Acc: 59.51%\n",
      "Epoch 1/3, Batch 7030, Loss: 2.0063, Acc: 59.54%\n",
      "Epoch 1/3, Batch 7040, Loss: 0.4254, Acc: 59.55%\n",
      "Epoch 1/3, Batch 7050, Loss: 0.0608, Acc: 59.58%\n",
      "Epoch 1/3, Batch 7060, Loss: 1.8236, Acc: 59.57%\n",
      "Epoch 1/3, Batch 7070, Loss: 0.1720, Acc: 59.60%\n",
      "Epoch 1/3, Batch 7080, Loss: 0.7682, Acc: 59.60%\n",
      "Epoch 1/3, Batch 7090, Loss: 0.2874, Acc: 59.57%\n",
      "Epoch 1/3, Batch 7100, Loss: 0.5963, Acc: 59.57%\n",
      "Epoch 1/3, Batch 7110, Loss: 0.0089, Acc: 59.57%\n",
      "Epoch 1/3, Batch 7120, Loss: 0.2548, Acc: 59.56%\n",
      "Epoch 1/3, Batch 7130, Loss: 1.8143, Acc: 59.51%\n",
      "Epoch 1/3, Batch 7140, Loss: 0.6347, Acc: 59.53%\n",
      "Epoch 1/3, Batch 7150, Loss: 0.2355, Acc: 59.57%\n",
      "Epoch 1/3, Batch 7160, Loss: 0.0389, Acc: 59.60%\n",
      "Epoch 1/3, Batch 7170, Loss: 1.6617, Acc: 59.60%\n",
      "Epoch 1/3, Batch 7180, Loss: 0.6434, Acc: 59.60%\n",
      "Epoch 1/3, Batch 7190, Loss: 1.3077, Acc: 59.57%\n",
      "Epoch 1/3, Batch 7200, Loss: 0.3749, Acc: 59.58%\n",
      "Epoch 1/3, Batch 7210, Loss: 0.5386, Acc: 59.59%\n",
      "Epoch 1/3, Batch 7220, Loss: 1.7602, Acc: 59.58%\n",
      "Epoch 1/3, Batch 7230, Loss: 1.4445, Acc: 59.60%\n",
      "Epoch 1/3, Batch 7240, Loss: 0.4270, Acc: 59.58%\n",
      "Epoch 1/3, Batch 7250, Loss: 2.3928, Acc: 59.58%\n",
      "Epoch 1/3, Batch 7260, Loss: 0.1475, Acc: 59.59%\n",
      "Epoch 1/3, Batch 7270, Loss: 1.4921, Acc: 59.61%\n",
      "Epoch 1/3, Batch 7280, Loss: 0.3824, Acc: 59.61%\n",
      "Epoch 1/3, Batch 7290, Loss: 2.5641, Acc: 59.61%\n",
      "Epoch 1/3, Batch 7300, Loss: 0.7051, Acc: 59.59%\n",
      "Epoch 1/3, Batch 7310, Loss: 0.0866, Acc: 59.61%\n",
      "Epoch 1/3, Batch 7320, Loss: 2.6674, Acc: 59.62%\n",
      "Epoch 1/3, Batch 7330, Loss: 0.0168, Acc: 59.62%\n",
      "Epoch 1/3, Batch 7340, Loss: 1.6576, Acc: 59.64%\n",
      "Epoch 1/3, Batch 7350, Loss: 1.4511, Acc: 59.65%\n",
      "Epoch 1/3, Batch 7360, Loss: 0.5427, Acc: 59.69%\n",
      "Epoch 1/3, Batch 7370, Loss: 1.0554, Acc: 59.69%\n",
      "Epoch 1/3, Batch 7380, Loss: 0.9709, Acc: 59.69%\n",
      "Epoch 1/3, Batch 7390, Loss: 1.0904, Acc: 59.71%\n",
      "Epoch 1/3, Batch 7400, Loss: 1.5478, Acc: 59.74%\n",
      "Epoch 1/3, Batch 7410, Loss: 0.6411, Acc: 59.75%\n",
      "Epoch 1/3, Batch 7420, Loss: 0.4680, Acc: 59.79%\n",
      "Epoch 1/3, Batch 7430, Loss: 1.3449, Acc: 59.82%\n",
      "Epoch 1/3, Batch 7440, Loss: 1.0108, Acc: 59.83%\n",
      "Epoch 1/3, Batch 7450, Loss: 1.1755, Acc: 59.82%\n",
      "Epoch 1/3, Batch 7460, Loss: 3.0767, Acc: 59.79%\n",
      "Epoch 1/3, Batch 7470, Loss: 0.0866, Acc: 59.79%\n",
      "Epoch 1/3, Batch 7480, Loss: 0.0603, Acc: 59.80%\n",
      "Epoch 1/3, Batch 7490, Loss: 0.6701, Acc: 59.81%\n",
      "Epoch 1/3, Batch 7500, Loss: 0.7308, Acc: 59.82%\n",
      "Epoch 1/3, Batch 7510, Loss: 0.7747, Acc: 59.79%\n",
      "Epoch 1/3, Batch 7520, Loss: 1.6585, Acc: 59.79%\n",
      "Epoch 1/3, Batch 7530, Loss: 0.0336, Acc: 59.79%\n",
      "Epoch 1/3, Batch 7540, Loss: 0.0584, Acc: 59.81%\n",
      "Epoch 1/3, Batch 7550, Loss: 0.1472, Acc: 59.81%\n",
      "Epoch 1/3, Batch 7560, Loss: 0.0568, Acc: 59.82%\n",
      "Epoch 1/3, Batch 7570, Loss: 0.3925, Acc: 59.83%\n",
      "Epoch 1/3, Batch 7580, Loss: 0.1657, Acc: 59.86%\n",
      "Epoch 1/3, Batch 7590, Loss: 2.2618, Acc: 59.89%\n",
      "Epoch 1/3, Batch 7600, Loss: 0.0381, Acc: 59.91%\n",
      "Epoch 1/3, Batch 7610, Loss: 1.1638, Acc: 59.91%\n",
      "Epoch 1/3, Batch 7620, Loss: 0.3418, Acc: 59.91%\n",
      "Epoch 1/3, Batch 7630, Loss: 1.3318, Acc: 59.91%\n",
      "Epoch 1/3, Batch 7640, Loss: 0.1368, Acc: 59.91%\n",
      "Epoch 1/3, Batch 7650, Loss: 0.7559, Acc: 59.93%\n",
      "Epoch 1/3, Batch 7660, Loss: 1.1899, Acc: 59.91%\n",
      "Epoch 1/3, Batch 7670, Loss: 0.3674, Acc: 59.94%\n",
      "Epoch 1/3, Batch 7680, Loss: 1.0900, Acc: 59.95%\n",
      "Epoch 1/3, Batch 7690, Loss: 0.5424, Acc: 59.98%\n",
      "Epoch 1/3, Batch 7700, Loss: 0.0330, Acc: 59.97%\n",
      "Epoch 1/3, Batch 7710, Loss: 2.8543, Acc: 59.98%\n",
      "Epoch 1/3, Batch 7720, Loss: 1.1064, Acc: 59.98%\n",
      "Epoch 1/3, Batch 7730, Loss: 0.8793, Acc: 59.98%\n",
      "Epoch 1/3, Batch 7740, Loss: 1.7729, Acc: 59.95%\n",
      "Epoch 1/3, Batch 7750, Loss: 0.1262, Acc: 59.95%\n",
      "Epoch 1/3, Batch 7760, Loss: 1.3964, Acc: 59.95%\n",
      "Epoch 1/3, Batch 7770, Loss: 0.7403, Acc: 59.93%\n",
      "Epoch 1/3, Batch 7780, Loss: 0.1874, Acc: 59.94%\n",
      "Epoch 1/3, Batch 7790, Loss: 0.0803, Acc: 59.95%\n",
      "Epoch 1/3, Batch 7800, Loss: 0.0559, Acc: 59.98%\n",
      "Epoch 1/3, Batch 7810, Loss: 2.2182, Acc: 59.95%\n",
      "Epoch 1/3, Batch 7820, Loss: 1.8212, Acc: 59.98%\n",
      "Epoch 1/3, Batch 7830, Loss: 1.4781, Acc: 59.93%\n",
      "Epoch 1/3, Batch 7840, Loss: 1.1051, Acc: 59.92%\n",
      "Epoch 1/3, Batch 7850, Loss: 1.0834, Acc: 59.89%\n",
      "Epoch 1/3, Batch 7860, Loss: 0.0089, Acc: 59.89%\n",
      "Epoch 1/3, Batch 7870, Loss: 0.1761, Acc: 59.93%\n",
      "Epoch 1/3, Batch 7880, Loss: 1.1106, Acc: 59.92%\n",
      "Epoch 1/3, Batch 7890, Loss: 0.7362, Acc: 59.89%\n",
      "Epoch 1/3, Batch 7900, Loss: 0.2148, Acc: 59.88%\n",
      "Epoch 1/3, Batch 7910, Loss: 0.3010, Acc: 59.88%\n",
      "Epoch 1/3, Batch 7920, Loss: 0.3274, Acc: 59.90%\n",
      "Epoch 1/3, Batch 7930, Loss: 0.0271, Acc: 59.92%\n",
      "Epoch 1/3, Batch 7940, Loss: 1.5092, Acc: 59.89%\n",
      "Epoch 1/3, Batch 7950, Loss: 0.2067, Acc: 59.92%\n",
      "Epoch 1/3, Batch 7960, Loss: 1.4677, Acc: 59.89%\n",
      "Epoch 1/3, Batch 7970, Loss: 0.0199, Acc: 59.90%\n",
      "Epoch 1/3, Batch 7980, Loss: 4.5054, Acc: 59.89%\n",
      "Epoch 1/3, Batch 7990, Loss: 0.0661, Acc: 59.89%\n",
      "Epoch 1/3, Batch 8000, Loss: 1.7788, Acc: 59.88%\n",
      "Epoch 1/3, Batch 8010, Loss: 0.3744, Acc: 59.87%\n",
      "Epoch 1/3, Batch 8020, Loss: 1.9483, Acc: 59.87%\n",
      "Epoch 1/3, Batch 8030, Loss: 1.5493, Acc: 59.86%\n",
      "Epoch 1/3, Batch 8040, Loss: 2.4864, Acc: 59.88%\n",
      "Epoch 1/3, Batch 8050, Loss: 1.4289, Acc: 59.89%\n",
      "Epoch 1/3, Batch 8060, Loss: 1.0781, Acc: 59.88%\n",
      "Epoch 1/3, Batch 8070, Loss: 0.4531, Acc: 59.89%\n",
      "Epoch 1/3, Batch 8080, Loss: 0.6898, Acc: 59.91%\n",
      "Epoch 1/3, Batch 8090, Loss: 1.1696, Acc: 59.94%\n",
      "Epoch 1/3, Batch 8100, Loss: 0.5518, Acc: 59.96%\n",
      "Epoch 1/3, Batch 8110, Loss: 0.4796, Acc: 59.98%\n",
      "Epoch 1/3, Batch 8120, Loss: 0.3600, Acc: 60.00%\n",
      "Epoch 1/3, Batch 8130, Loss: 3.1937, Acc: 59.99%\n",
      "Epoch 1/3, Batch 8140, Loss: 0.2864, Acc: 60.02%\n",
      "Epoch 1/3, Batch 8150, Loss: 0.2255, Acc: 60.00%\n",
      "Epoch 1/3, Batch 8160, Loss: 0.3846, Acc: 59.99%\n",
      "Epoch 1/3, Batch 8170, Loss: 0.1386, Acc: 59.96%\n",
      "Epoch 1/3, Batch 8180, Loss: 1.3345, Acc: 59.96%\n",
      "Epoch 1/3, Batch 8190, Loss: 0.5288, Acc: 59.97%\n",
      "Epoch 1/3, Batch 8200, Loss: 0.0594, Acc: 59.96%\n",
      "Epoch 1/3, Batch 8210, Loss: 0.1053, Acc: 59.96%\n",
      "Epoch 1/3, Batch 8220, Loss: 0.1218, Acc: 59.94%\n",
      "Epoch 1/3, Batch 8230, Loss: 0.8738, Acc: 59.97%\n",
      "Epoch 1/3, Batch 8240, Loss: 0.0481, Acc: 59.98%\n",
      "Epoch 1/3, Batch 8250, Loss: 1.6415, Acc: 59.97%\n",
      "Epoch 1/3, Batch 8260, Loss: 0.4178, Acc: 59.98%\n",
      "Epoch 1/3, Batch 8270, Loss: 0.5366, Acc: 59.99%\n",
      "Epoch 1/3, Batch 8280, Loss: 1.8504, Acc: 59.98%\n",
      "Epoch 1/3, Batch 8290, Loss: 0.6855, Acc: 60.00%\n",
      "Epoch 1/3, Batch 8300, Loss: 0.1268, Acc: 60.02%\n",
      "Epoch 1/3, Batch 8310, Loss: 0.6033, Acc: 60.00%\n",
      "Epoch 1/3, Batch 8320, Loss: 0.1402, Acc: 59.99%\n",
      "Epoch 1/3, Batch 8330, Loss: 0.1319, Acc: 59.98%\n",
      "Epoch 1/3, Batch 8340, Loss: 0.6327, Acc: 59.97%\n",
      "Epoch 1/3, Batch 8350, Loss: 0.8758, Acc: 59.97%\n",
      "Epoch 1/3, Batch 8360, Loss: 0.2491, Acc: 59.97%\n",
      "Epoch 1/3, Batch 8370, Loss: 1.4715, Acc: 59.95%\n",
      "Epoch 1/3, Batch 8380, Loss: 0.0020, Acc: 59.96%\n",
      "Epoch 1/3, Batch 8390, Loss: 1.2472, Acc: 59.95%\n",
      "Epoch 1/3, Batch 8400, Loss: 0.0769, Acc: 59.96%\n",
      "Epoch 1/3, Batch 8410, Loss: 0.6290, Acc: 59.98%\n",
      "Epoch 1/3, Batch 8420, Loss: 1.7135, Acc: 59.98%\n",
      "Epoch 1/3, Batch 8430, Loss: 0.6224, Acc: 59.97%\n",
      "Epoch 1/3, Batch 8440, Loss: 0.4175, Acc: 59.99%\n",
      "Epoch 1/3, Batch 8450, Loss: 0.6239, Acc: 60.00%\n",
      "Epoch 1/3, Batch 8460, Loss: 0.6704, Acc: 60.02%\n",
      "Epoch 1/3, Batch 8470, Loss: 0.0293, Acc: 60.03%\n",
      "Epoch 1/3, Batch 8480, Loss: 1.1859, Acc: 59.99%\n",
      "Epoch 1/3, Batch 8490, Loss: 0.6462, Acc: 59.99%\n",
      "Epoch 1/3, Batch 8500, Loss: 1.1110, Acc: 59.97%\n",
      "Epoch 1/3, Batch 8510, Loss: 0.0517, Acc: 60.02%\n",
      "Epoch 1/3, Batch 8520, Loss: 0.3087, Acc: 60.04%\n",
      "Epoch 1/3, Batch 8530, Loss: 0.0302, Acc: 60.06%\n",
      "Epoch 1/3, Batch 8540, Loss: 0.5449, Acc: 60.06%\n",
      "Epoch 1/3, Batch 8550, Loss: 0.3999, Acc: 60.06%\n",
      "Epoch 1/3, Batch 8560, Loss: 1.4860, Acc: 60.07%\n",
      "Epoch 1/3, Batch 8570, Loss: 0.3066, Acc: 60.09%\n",
      "Epoch 1/3, Batch 8580, Loss: 2.0728, Acc: 60.10%\n",
      "Epoch 1/3, Batch 8590, Loss: 0.1416, Acc: 60.09%\n",
      "Epoch 1/3, Batch 8600, Loss: 1.0124, Acc: 60.09%\n",
      "Epoch 1/3, Batch 8610, Loss: 1.0813, Acc: 60.05%\n",
      "Epoch 1/3, Batch 8620, Loss: 2.1292, Acc: 60.04%\n",
      "Epoch 1/3, Batch 8630, Loss: 0.1402, Acc: 60.03%\n",
      "Epoch 1/3, Batch 8640, Loss: 0.1158, Acc: 60.05%\n",
      "Epoch 1/3, Batch 8650, Loss: 0.1158, Acc: 60.09%\n",
      "Epoch 1/3, Batch 8660, Loss: 0.8954, Acc: 60.07%\n",
      "Epoch 1/3, Batch 8670, Loss: 0.6432, Acc: 60.07%\n",
      "Epoch 1/3, Batch 8680, Loss: 0.4037, Acc: 60.11%\n",
      "Epoch 1/3, Batch 8690, Loss: 0.0999, Acc: 60.11%\n",
      "Epoch 1/3, Batch 8700, Loss: 2.0009, Acc: 60.09%\n",
      "Epoch 1/3, Batch 8710, Loss: 0.3380, Acc: 60.08%\n",
      "Epoch 1/3, Batch 8720, Loss: 0.4897, Acc: 60.10%\n",
      "Epoch 1/3, Batch 8730, Loss: 0.0250, Acc: 60.11%\n",
      "Epoch 1/3, Batch 8740, Loss: 0.6384, Acc: 60.11%\n",
      "Epoch 1/3, Batch 8750, Loss: 0.2700, Acc: 60.11%\n",
      "Epoch 1/3, Batch 8760, Loss: 0.4185, Acc: 60.13%\n",
      "Epoch 1/3, Batch 8770, Loss: 0.2758, Acc: 60.15%\n",
      "Epoch 1/3, Batch 8780, Loss: 0.7138, Acc: 60.12%\n",
      "Epoch 1/3, Batch 8790, Loss: 1.0431, Acc: 60.12%\n",
      "Epoch 1/3, Batch 8800, Loss: 0.2680, Acc: 60.12%\n",
      "Epoch 1/3, Batch 8810, Loss: 1.8887, Acc: 60.12%\n",
      "Epoch 1/3, Batch 8820, Loss: 0.3789, Acc: 60.11%\n",
      "Epoch 1/3, Batch 8830, Loss: 1.7304, Acc: 60.12%\n",
      "Epoch 1/3, Batch 8840, Loss: 0.0634, Acc: 60.13%\n",
      "Epoch 1/3, Batch 8850, Loss: 1.5573, Acc: 60.12%\n",
      "Epoch 1/3, Batch 8860, Loss: 0.2316, Acc: 60.14%\n",
      "Epoch 1/3, Batch 8870, Loss: 1.2098, Acc: 60.14%\n",
      "Epoch 1/3, Batch 8880, Loss: 1.4424, Acc: 60.14%\n",
      "Epoch 1/3, Batch 8890, Loss: 1.1110, Acc: 60.15%\n",
      "Epoch 1/3, Batch 8900, Loss: 1.0263, Acc: 60.16%\n",
      "Epoch 1/3, Batch 8910, Loss: 0.6292, Acc: 60.18%\n",
      "Epoch 1/3, Batch 8920, Loss: 1.0700, Acc: 60.18%\n",
      "Epoch 1/3, Batch 8930, Loss: 0.0235, Acc: 60.18%\n",
      "Epoch 1/3, Batch 8940, Loss: 1.5410, Acc: 60.14%\n",
      "Epoch 1/3, Batch 8950, Loss: 1.8022, Acc: 60.15%\n",
      "Epoch 1/3, Batch 8960, Loss: 0.0868, Acc: 60.15%\n",
      "Epoch 1/3, Batch 8970, Loss: 0.0786, Acc: 60.15%\n",
      "Epoch 1/3, Batch 8980, Loss: 0.6110, Acc: 60.17%\n",
      "Epoch 1/3, Batch 8990, Loss: 0.5137, Acc: 60.19%\n",
      "Epoch 1/3, Batch 9000, Loss: 1.4432, Acc: 60.17%\n",
      "Epoch 1/3, Batch 9010, Loss: 0.1207, Acc: 60.16%\n",
      "Epoch 1/3, Batch 9020, Loss: 3.0389, Acc: 60.16%\n",
      "Epoch 1/3, Batch 9030, Loss: 0.5241, Acc: 60.16%\n",
      "Epoch 1/3, Batch 9040, Loss: 0.4594, Acc: 60.16%\n",
      "Epoch 1/3, Batch 9050, Loss: 1.1180, Acc: 60.16%\n",
      "Epoch 1/3, Batch 9060, Loss: 0.0184, Acc: 60.18%\n",
      "Epoch 1/3, Batch 9070, Loss: 0.0925, Acc: 60.18%\n",
      "Epoch 1/3, Batch 9080, Loss: 0.0114, Acc: 60.19%\n",
      "Epoch 1/3, Batch 9090, Loss: 0.0322, Acc: 60.22%\n",
      "Epoch 1/3, Batch 9100, Loss: 0.5447, Acc: 60.22%\n",
      "Epoch 1/3, Batch 9110, Loss: 2.6182, Acc: 60.22%\n",
      "Epoch 1/3, Batch 9120, Loss: 0.0426, Acc: 60.22%\n",
      "Epoch 1/3, Batch 9130, Loss: 0.2111, Acc: 60.26%\n",
      "Epoch 1/3, Batch 9140, Loss: 0.4521, Acc: 60.28%\n",
      "Epoch 1/3, Batch 9150, Loss: 1.2465, Acc: 60.26%\n",
      "Epoch 1/3, Batch 9160, Loss: 1.3014, Acc: 60.24%\n",
      "Epoch 1/3, Batch 9170, Loss: 0.9571, Acc: 60.24%\n",
      "Epoch 1/3, Batch 9180, Loss: 0.6756, Acc: 60.21%\n",
      "Epoch 1/3, Batch 9190, Loss: 0.0429, Acc: 60.22%\n",
      "Epoch 1/3, Batch 9200, Loss: 1.0990, Acc: 60.23%\n",
      "Epoch 1/3, Batch 9210, Loss: 1.3845, Acc: 60.22%\n",
      "Epoch 1/3, Batch 9220, Loss: 0.2030, Acc: 60.25%\n",
      "Epoch 1/3, Batch 9230, Loss: 0.5826, Acc: 60.25%\n",
      "Epoch 1/3, Batch 9240, Loss: 0.0824, Acc: 60.29%\n",
      "Epoch 1/3, Batch 9250, Loss: 0.0877, Acc: 60.31%\n",
      "Epoch 1/3, Batch 9260, Loss: 1.6042, Acc: 60.31%\n",
      "Epoch 1/3, Batch 9270, Loss: 0.5848, Acc: 60.33%\n",
      "Epoch 1/3, Batch 9280, Loss: 0.1657, Acc: 60.33%\n",
      "Epoch 1/3, Batch 9290, Loss: 0.5110, Acc: 60.33%\n",
      "Epoch 1/3, Batch 9300, Loss: 0.8636, Acc: 60.33%\n",
      "Epoch 1/3, Batch 9310, Loss: 0.1906, Acc: 60.32%\n",
      "Epoch 1/3, Batch 9320, Loss: 0.7561, Acc: 60.29%\n",
      "Epoch 1/3, Batch 9330, Loss: 1.4928, Acc: 60.29%\n",
      "Epoch 1/3, Batch 9340, Loss: 0.9696, Acc: 60.30%\n",
      "Epoch 1/3, Batch 9350, Loss: 2.8321, Acc: 60.28%\n",
      "Epoch 1/3, Batch 9360, Loss: 0.2450, Acc: 60.28%\n",
      "Epoch 1/3, Batch 9370, Loss: 0.1203, Acc: 60.27%\n",
      "Epoch 1/3, Batch 9380, Loss: 0.9065, Acc: 60.27%\n",
      "Epoch 1/3, Batch 9390, Loss: 0.1012, Acc: 60.28%\n",
      "Epoch 1/3, Batch 9400, Loss: 0.2781, Acc: 60.29%\n",
      "Epoch 1/3, Batch 9410, Loss: 0.5071, Acc: 60.30%\n",
      "Epoch 1/3, Batch 9420, Loss: 2.0682, Acc: 60.31%\n",
      "Epoch 1/3, Batch 9430, Loss: 0.1101, Acc: 60.33%\n",
      "Epoch 1/3, Batch 9440, Loss: 1.2156, Acc: 60.33%\n",
      "Epoch 1/3, Batch 9450, Loss: 0.5995, Acc: 60.33%\n",
      "Epoch 1/3, Batch 9460, Loss: 0.0671, Acc: 60.34%\n",
      "Epoch 1/3, Batch 9470, Loss: 0.8238, Acc: 60.33%\n",
      "Epoch 1/3, Batch 9480, Loss: 2.5113, Acc: 60.34%\n",
      "Epoch 1/3, Batch 9490, Loss: 0.0430, Acc: 60.35%\n",
      "Epoch 1/3, Batch 9500, Loss: 0.0049, Acc: 60.38%\n",
      "Epoch 1/3, Batch 9510, Loss: 1.0069, Acc: 60.38%\n",
      "Epoch 1/3, Batch 9520, Loss: 0.4328, Acc: 60.39%\n",
      "Epoch 1/3, Batch 9530, Loss: 0.1892, Acc: 60.40%\n",
      "Epoch 1/3, Batch 9540, Loss: 1.0935, Acc: 60.38%\n",
      "Epoch 1/3, Batch 9550, Loss: 1.2496, Acc: 60.36%\n",
      "Epoch 1/3, Batch 9560, Loss: 0.1434, Acc: 60.36%\n",
      "Epoch 1/3, Batch 9570, Loss: 3.9912, Acc: 60.35%\n",
      "Epoch 1/3, Batch 9580, Loss: 0.2884, Acc: 60.36%\n",
      "Epoch 1/3, Batch 9590, Loss: 0.3155, Acc: 60.35%\n",
      "Epoch 1/3, Batch 9600, Loss: 0.4228, Acc: 60.31%\n",
      "Epoch 1/3, Batch 9610, Loss: 0.0677, Acc: 60.31%\n",
      "Epoch 1/3, Batch 9620, Loss: 0.6848, Acc: 60.28%\n",
      "Epoch 1/3, Batch 9630, Loss: 0.5120, Acc: 60.29%\n",
      "Epoch 1/3, Batch 9640, Loss: 0.0871, Acc: 60.26%\n",
      "Epoch 1/3, Batch 9650, Loss: 0.5221, Acc: 60.26%\n",
      "Epoch 1/3, Batch 9660, Loss: 1.0114, Acc: 60.24%\n",
      "Epoch 1/3, Batch 9670, Loss: 0.9941, Acc: 60.22%\n",
      "Epoch 1/3, Batch 9680, Loss: 0.5703, Acc: 60.22%\n",
      "Epoch 1/3, Batch 9690, Loss: 0.1537, Acc: 60.22%\n",
      "Epoch 1/3, Batch 9700, Loss: 0.8698, Acc: 60.22%\n",
      "Epoch 1/3, Batch 9710, Loss: 0.4436, Acc: 60.24%\n",
      "Epoch 1/3, Batch 9720, Loss: 0.6614, Acc: 60.22%\n",
      "Epoch 1/3, Batch 9730, Loss: 0.0892, Acc: 60.23%\n",
      "Epoch 1/3, Batch 9740, Loss: 0.6763, Acc: 60.24%\n",
      "Epoch 1/3, Batch 9750, Loss: 0.7978, Acc: 60.26%\n",
      "Epoch 1/3, Batch 9760, Loss: 0.8523, Acc: 60.26%\n",
      "Epoch 1/3, Batch 9770, Loss: 0.3739, Acc: 60.27%\n",
      "Epoch 1/3, Batch 9780, Loss: 0.3441, Acc: 60.26%\n",
      "Epoch 1/3, Batch 9790, Loss: 0.7101, Acc: 60.24%\n",
      "Epoch 1/3, Batch 9800, Loss: 1.4370, Acc: 60.21%\n",
      "Epoch 1/3, Batch 9810, Loss: 0.0097, Acc: 60.22%\n",
      "Epoch 1/3, Batch 9820, Loss: 0.0039, Acc: 60.22%\n",
      "Epoch 1/3, Batch 9830, Loss: 2.6564, Acc: 60.23%\n",
      "Epoch 1/3, Batch 9840, Loss: 0.7132, Acc: 60.22%\n",
      "Epoch 1/3, Batch 9850, Loss: 0.7091, Acc: 60.24%\n",
      "Epoch 1/3, Batch 9860, Loss: 0.3864, Acc: 60.24%\n",
      "Epoch 1/3, Batch 9870, Loss: 0.2809, Acc: 60.23%\n",
      "Epoch 1/3, Batch 9880, Loss: 2.0797, Acc: 60.23%\n",
      "Epoch 1/3, Batch 9890, Loss: 1.4257, Acc: 60.23%\n",
      "Epoch 1/3, Batch 9900, Loss: 0.0685, Acc: 60.24%\n",
      "Epoch 1/3, Batch 9910, Loss: 0.3513, Acc: 60.24%\n",
      "Epoch 1/3, Batch 9920, Loss: 0.2105, Acc: 60.23%\n",
      "Epoch 1/3, Batch 9930, Loss: 0.0119, Acc: 60.24%\n",
      "Epoch 1/3, Batch 9940, Loss: 0.4387, Acc: 60.26%\n",
      "Epoch 1/3, Batch 9950, Loss: 0.2932, Acc: 60.26%\n",
      "Epoch 1/3, Batch 9960, Loss: 3.7889, Acc: 60.23%\n",
      "Epoch 1/3, Batch 9970, Loss: 0.1953, Acc: 60.24%\n",
      "Epoch 1/3, Batch 9980, Loss: 0.5088, Acc: 60.24%\n",
      "Epoch 1/3, Batch 9990, Loss: 0.3717, Acc: 60.24%\n",
      "Epoch 1/3, Batch 10000, Loss: 0.4854, Acc: 60.23%\n",
      "Epoch 1/3, Batch 10010, Loss: 0.5011, Acc: 60.22%\n",
      "Epoch 1/3, Batch 10020, Loss: 0.6068, Acc: 60.26%\n",
      "Epoch 1/3, Batch 10030, Loss: 0.0386, Acc: 60.29%\n",
      "Epoch 1/3, Batch 10040, Loss: 1.5497, Acc: 60.29%\n",
      "Epoch 1/3, Batch 10050, Loss: 0.1664, Acc: 60.31%\n",
      "Epoch 1/3, Batch 10060, Loss: 1.0690, Acc: 60.30%\n",
      "Epoch 1/3, Batch 10070, Loss: 2.1219, Acc: 60.30%\n",
      "Epoch 1/3, Batch 10080, Loss: 0.3196, Acc: 60.30%\n",
      "Epoch 1/3, Batch 10090, Loss: 0.4132, Acc: 60.33%\n",
      "Epoch 1/3, Batch 10100, Loss: 0.1799, Acc: 60.34%\n",
      "Epoch 1/3, Batch 10110, Loss: 2.1469, Acc: 60.34%\n",
      "Epoch 1/3, Batch 10120, Loss: 0.9266, Acc: 60.35%\n",
      "Epoch 1/3, Batch 10130, Loss: 0.7362, Acc: 60.35%\n",
      "Epoch 1/3, Batch 10140, Loss: 0.0854, Acc: 60.36%\n",
      "Epoch 1/3, Batch 10150, Loss: 0.3997, Acc: 60.35%\n",
      "Epoch 1/3, Batch 10160, Loss: 1.4591, Acc: 60.31%\n",
      "Epoch 1/3, Batch 10170, Loss: 0.3506, Acc: 60.30%\n",
      "Epoch 1/3, Batch 10180, Loss: 0.0005, Acc: 60.29%\n",
      "Epoch 1/3, Batch 10190, Loss: 0.9803, Acc: 60.29%\n",
      "Epoch 1/3, Batch 10200, Loss: 2.0261, Acc: 60.30%\n",
      "Epoch 1/3, Batch 10210, Loss: 0.0232, Acc: 60.31%\n",
      "Epoch 1/3, Batch 10220, Loss: 0.1554, Acc: 60.31%\n",
      "Epoch 1/3, Batch 10230, Loss: 0.1811, Acc: 60.33%\n",
      "Epoch 1/3, Batch 10240, Loss: 0.1971, Acc: 60.34%\n",
      "Epoch 1/3, Batch 10250, Loss: 0.9018, Acc: 60.34%\n",
      "Epoch 1/3, Batch 10260, Loss: 0.0181, Acc: 60.34%\n",
      "Epoch 1/3, Batch 10270, Loss: 0.7524, Acc: 60.33%\n",
      "Epoch 1/3, Batch 10280, Loss: 0.5437, Acc: 60.32%\n",
      "Epoch 1/3, Batch 10290, Loss: 1.0135, Acc: 60.31%\n",
      "Epoch 1/3, Batch 10300, Loss: 1.8668, Acc: 60.32%\n",
      "Epoch 1/3, Batch 10310, Loss: 0.9709, Acc: 60.33%\n",
      "Epoch 1/3, Batch 10320, Loss: 0.5608, Acc: 60.35%\n",
      "Epoch 1/3, Batch 10330, Loss: 0.4303, Acc: 60.36%\n",
      "Epoch 1/3, Batch 10340, Loss: 1.1613, Acc: 60.35%\n",
      "Epoch 1/3, Batch 10350, Loss: 0.3331, Acc: 60.36%\n",
      "Epoch 1/3, Batch 10360, Loss: 0.7463, Acc: 60.36%\n",
      "Epoch 1/3, Batch 10370, Loss: 1.0881, Acc: 60.35%\n",
      "Epoch 1/3, Batch 10380, Loss: 0.0166, Acc: 60.36%\n",
      "Epoch 1/3, Batch 10390, Loss: 0.5161, Acc: 60.39%\n",
      "Epoch 1/3, Batch 10400, Loss: 0.0020, Acc: 60.36%\n",
      "Epoch 1/3, Batch 10410, Loss: 3.0643, Acc: 60.34%\n",
      "Epoch 1/3, Batch 10420, Loss: 0.0894, Acc: 60.36%\n",
      "Epoch 1/3, Batch 10430, Loss: 0.9756, Acc: 60.36%\n",
      "Epoch 1/3, Batch 10440, Loss: 0.3339, Acc: 60.37%\n",
      "Epoch 1/3, Batch 10450, Loss: 0.0254, Acc: 60.37%\n",
      "Epoch 1/3, Batch 10460, Loss: 0.3491, Acc: 60.37%\n",
      "Epoch 1/3, Batch 10470, Loss: 0.0229, Acc: 60.39%\n",
      "Epoch 1/3, Batch 10480, Loss: 1.3292, Acc: 60.39%\n",
      "Epoch 1/3, Batch 10490, Loss: 0.0971, Acc: 60.39%\n",
      "Epoch 1/3, Batch 10500, Loss: 1.2900, Acc: 60.38%\n",
      "Epoch 1/3, Batch 10510, Loss: 0.2783, Acc: 60.40%\n",
      "Epoch 1/3, Batch 10520, Loss: 0.3114, Acc: 60.44%\n",
      "Epoch 1/3, Batch 10530, Loss: 0.7509, Acc: 60.43%\n",
      "Epoch 1/3, Batch 10540, Loss: 0.0773, Acc: 60.44%\n",
      "Epoch 1/3, Batch 10550, Loss: 0.2085, Acc: 60.43%\n",
      "Epoch 1/3, Batch 10560, Loss: 0.0518, Acc: 60.44%\n",
      "Epoch 1/3, Batch 10570, Loss: 1.3204, Acc: 60.42%\n",
      "Epoch 1/3, Batch 10580, Loss: 0.3653, Acc: 60.42%\n",
      "Epoch 1/3, Batch 10590, Loss: 3.4319, Acc: 60.42%\n",
      "Epoch 1/3, Batch 10600, Loss: 1.1948, Acc: 60.41%\n",
      "Epoch 1/3, Batch 10610, Loss: 0.0204, Acc: 60.43%\n",
      "Epoch 1/3, Batch 10620, Loss: 0.8042, Acc: 60.40%\n",
      "Epoch 1/3, Batch 10630, Loss: 1.2875, Acc: 60.41%\n",
      "Epoch 1/3, Batch 10640, Loss: 0.0243, Acc: 60.43%\n",
      "Epoch 1/3, Batch 10650, Loss: 0.1232, Acc: 60.45%\n",
      "Epoch 1/3, Batch 10660, Loss: 1.3248, Acc: 60.45%\n",
      "Epoch 1/3, Batch 10670, Loss: 1.1152, Acc: 60.43%\n",
      "Epoch 1/3, Batch 10680, Loss: 0.9978, Acc: 60.45%\n",
      "Epoch 1/3, Batch 10690, Loss: 2.9088, Acc: 60.45%\n",
      "Epoch 1/3, Batch 10700, Loss: 1.6680, Acc: 60.44%\n",
      "Epoch 1/3, Batch 10710, Loss: 0.0553, Acc: 60.44%\n",
      "Epoch 1/3, Batch 10720, Loss: 0.2484, Acc: 60.45%\n",
      "Epoch 1/3, Batch 10730, Loss: 0.5947, Acc: 60.43%\n",
      "Epoch 1/3, Batch 10740, Loss: 0.4446, Acc: 60.46%\n",
      "Epoch 1/3, Batch 10750, Loss: 0.0838, Acc: 60.49%\n",
      "Epoch 1/3, Batch 10760, Loss: 1.1384, Acc: 60.50%\n",
      "Epoch 1/3, Batch 10770, Loss: 0.0271, Acc: 60.51%\n",
      "Epoch 1/3, Batch 10780, Loss: 0.6585, Acc: 60.50%\n",
      "Epoch 1/3, Batch 10790, Loss: 1.1113, Acc: 60.49%\n",
      "Epoch 1/3, Batch 10800, Loss: 0.4312, Acc: 60.50%\n",
      "Epoch 1/3, Batch 10810, Loss: 0.3261, Acc: 60.48%\n",
      "Epoch 1/3, Batch 10820, Loss: 0.7288, Acc: 60.48%\n",
      "Epoch 1/3, Batch 10830, Loss: 0.3385, Acc: 60.47%\n",
      "Epoch 1/3, Batch 10840, Loss: 0.3682, Acc: 60.51%\n",
      "Epoch 1/3, Batch 10850, Loss: 0.7394, Acc: 60.49%\n",
      "Epoch 1/3, Batch 10860, Loss: 0.0474, Acc: 60.49%\n",
      "Epoch 1/3, Batch 10870, Loss: 0.7345, Acc: 60.47%\n",
      "Epoch 1/3, Batch 10880, Loss: 0.2931, Acc: 60.46%\n",
      "Epoch 1/3, Batch 10890, Loss: 0.1357, Acc: 60.46%\n",
      "Epoch 1/3, Batch 10900, Loss: 3.8883, Acc: 60.43%\n",
      "Epoch 1/3, Batch 10910, Loss: 0.6472, Acc: 60.44%\n",
      "Epoch 1/3, Batch 10920, Loss: 0.1803, Acc: 60.43%\n",
      "Epoch 1/3, Batch 10930, Loss: 0.0777, Acc: 60.45%\n",
      "Epoch 1/3, Batch 10940, Loss: 0.0018, Acc: 60.45%\n",
      "Epoch 1/3, Batch 10950, Loss: 0.1861, Acc: 60.46%\n",
      "Epoch 1/3, Batch 10960, Loss: 0.1394, Acc: 60.46%\n",
      "Epoch 1/3, Batch 10970, Loss: 0.1190, Acc: 60.47%\n",
      "Epoch 1/3, Batch 10980, Loss: 0.7125, Acc: 60.49%\n",
      "Epoch 1/3, Batch 10990, Loss: 1.5485, Acc: 60.49%\n",
      "Epoch 1/3, Batch 11000, Loss: 0.0962, Acc: 60.53%\n",
      "Epoch 1/3, Batch 11010, Loss: 0.5464, Acc: 60.52%\n",
      "Epoch 1/3, Batch 11020, Loss: 0.2374, Acc: 60.54%\n",
      "Epoch 1/3, Batch 11030, Loss: 0.0061, Acc: 60.55%\n",
      "Epoch 1/3, Batch 11040, Loss: 1.1622, Acc: 60.54%\n",
      "Epoch 1/3, Batch 11050, Loss: 0.6698, Acc: 60.51%\n",
      "Epoch 1/3, Batch 11060, Loss: 0.9373, Acc: 60.48%\n",
      "Epoch 1/3, Batch 11070, Loss: 0.2799, Acc: 60.50%\n",
      "Epoch 1/3, Batch 11080, Loss: 0.3183, Acc: 60.52%\n",
      "Epoch 1/3, Batch 11090, Loss: 0.9137, Acc: 60.52%\n",
      "Epoch 1/3, Batch 11100, Loss: 2.8234, Acc: 60.52%\n",
      "Epoch 1/3, Batch 11110, Loss: 1.5487, Acc: 60.52%\n",
      "Epoch 1/3, Batch 11120, Loss: 1.0405, Acc: 60.51%\n",
      "Epoch 1/3, Batch 11130, Loss: 0.1533, Acc: 60.52%\n",
      "Epoch 1/3, Batch 11140, Loss: 1.4105, Acc: 60.54%\n",
      "Epoch 1/3, Batch 11150, Loss: 0.2858, Acc: 60.57%\n",
      "Epoch 1/3, Batch 11160, Loss: 0.2552, Acc: 60.58%\n",
      "Epoch 1/3, Batch 11170, Loss: 0.1054, Acc: 60.57%\n",
      "Epoch 1/3, Batch 11180, Loss: 0.2126, Acc: 60.58%\n",
      "Epoch 1/3, Batch 11190, Loss: 0.1282, Acc: 60.58%\n",
      "Epoch 1/3, Batch 11200, Loss: 0.0127, Acc: 60.58%\n",
      "Epoch 1/3, Batch 11210, Loss: 0.3926, Acc: 60.58%\n",
      "Epoch 1/3, Batch 11220, Loss: 0.3050, Acc: 60.59%\n",
      "Epoch 1/3, Batch 11230, Loss: 0.0698, Acc: 60.58%\n",
      "Epoch 1/3, Batch 11240, Loss: 0.3615, Acc: 60.59%\n",
      "Epoch 1/3, Batch 11250, Loss: 0.1573, Acc: 60.61%\n",
      "Epoch 1/3, Batch 11260, Loss: 0.1989, Acc: 60.59%\n",
      "Epoch 1/3, Batch 11270, Loss: 0.0189, Acc: 60.60%\n",
      "Epoch 1/3, Batch 11280, Loss: 2.3325, Acc: 60.61%\n",
      "Epoch 1/3, Batch 11290, Loss: 0.2278, Acc: 60.61%\n",
      "Epoch 1/3, Batch 11300, Loss: 0.8545, Acc: 60.59%\n",
      "Epoch 1/3, Batch 11310, Loss: 1.4636, Acc: 60.60%\n",
      "Epoch 1/3, Batch 11320, Loss: 0.0526, Acc: 60.60%\n",
      "Epoch 1/3, Batch 11330, Loss: 1.7847, Acc: 60.59%\n",
      "Epoch 1/3, Batch 11340, Loss: 0.0183, Acc: 60.62%\n",
      "Epoch 1/3, Batch 11350, Loss: 0.2741, Acc: 60.63%\n",
      "Epoch 1/3, Batch 11360, Loss: 0.1635, Acc: 60.63%\n",
      "Epoch 1/3, Batch 11370, Loss: 0.0408, Acc: 60.63%\n",
      "Epoch 1/3, Batch 11380, Loss: 2.6350, Acc: 60.61%\n",
      "Epoch 1/3, Batch 11390, Loss: 0.1542, Acc: 60.62%\n",
      "Epoch 1/3, Batch 11400, Loss: 0.8610, Acc: 60.61%\n",
      "Epoch 1/3, Batch 11410, Loss: 0.0098, Acc: 60.59%\n",
      "Epoch 1/3, Batch 11420, Loss: 0.1451, Acc: 60.57%\n",
      "Epoch 1/3, Batch 11430, Loss: 0.0174, Acc: 60.58%\n",
      "Epoch 1/3, Batch 11440, Loss: 0.4735, Acc: 60.58%\n",
      "Epoch 1/3, Batch 11450, Loss: 0.1606, Acc: 60.59%\n",
      "Epoch 1/3, Batch 11460, Loss: 1.1835, Acc: 60.57%\n",
      "Epoch 1/3, Batch 11470, Loss: 1.0564, Acc: 60.57%\n",
      "Epoch 1/3, Batch 11480, Loss: 1.1804, Acc: 60.55%\n",
      "Epoch 1/3, Batch 11490, Loss: 2.0890, Acc: 60.55%\n",
      "Epoch 1/3, Batch 11500, Loss: 0.0038, Acc: 60.55%\n",
      "Epoch 1/3, Batch 11510, Loss: 1.1558, Acc: 60.55%\n",
      "Epoch 1/3, Batch 11520, Loss: 0.1391, Acc: 60.55%\n",
      "Epoch 1/3, Batch 11530, Loss: 0.7376, Acc: 60.57%\n",
      "Epoch 1/3, Batch 11540, Loss: 0.7143, Acc: 60.57%\n",
      "Epoch 1/3, Batch 11550, Loss: 0.0431, Acc: 60.58%\n",
      "Epoch 1/3, Batch 11560, Loss: 0.9988, Acc: 60.57%\n",
      "Epoch 1/3, Batch 11570, Loss: 1.5941, Acc: 60.58%\n",
      "Epoch 1/3, Batch 11580, Loss: 1.2609, Acc: 60.56%\n",
      "Epoch 1/3, Batch 11590, Loss: 0.3640, Acc: 60.58%\n",
      "Epoch 1/3, Batch 11600, Loss: 0.0646, Acc: 60.60%\n",
      "Epoch 1/3, Batch 11610, Loss: 1.9030, Acc: 60.61%\n",
      "Epoch 1/3, Batch 11620, Loss: 1.4328, Acc: 60.61%\n",
      "Epoch 1/3, Batch 11630, Loss: 0.2550, Acc: 60.61%\n",
      "Epoch 1/3, Batch 11640, Loss: 0.3223, Acc: 60.60%\n",
      "Epoch 1/3, Batch 11650, Loss: 0.0655, Acc: 60.62%\n",
      "Epoch 1/3, Batch 11660, Loss: 0.6010, Acc: 60.62%\n",
      "Epoch 1/3, Batch 11670, Loss: 0.3588, Acc: 60.65%\n",
      "Epoch 1/3, Batch 11680, Loss: 0.4682, Acc: 60.65%\n",
      "Epoch 1/3, Batch 11690, Loss: 0.3494, Acc: 60.65%\n",
      "Epoch 1/3, Batch 11700, Loss: 1.2457, Acc: 60.65%\n",
      "Epoch 1/3, Batch 11710, Loss: 1.0743, Acc: 60.64%\n",
      "Epoch 1/3, Batch 11720, Loss: 0.0725, Acc: 60.63%\n",
      "Epoch 1/3, Batch 11730, Loss: 0.6119, Acc: 60.63%\n",
      "Epoch 1/3, Batch 11740, Loss: 0.0023, Acc: 60.64%\n",
      "Epoch 1/3, Batch 11750, Loss: 0.0092, Acc: 60.64%\n",
      "Epoch 1/3, Batch 11760, Loss: 3.8169, Acc: 60.64%\n",
      "Epoch 1/3, Batch 11770, Loss: 0.8151, Acc: 60.62%\n",
      "Epoch 1/3, Batch 11780, Loss: 2.0550, Acc: 60.61%\n",
      "Epoch 1/3, Batch 11790, Loss: 0.8147, Acc: 60.61%\n",
      "Epoch 1/3, Batch 11800, Loss: 0.1289, Acc: 60.60%\n",
      "Epoch 1/3, Batch 11810, Loss: 0.0913, Acc: 60.60%\n",
      "Epoch 1/3, Batch 11820, Loss: 0.0264, Acc: 60.60%\n",
      "Epoch 1/3, Batch 11830, Loss: 0.1380, Acc: 60.60%\n",
      "Epoch 1/3, Batch 11840, Loss: 1.6510, Acc: 60.59%\n",
      "Epoch 1/3, Batch 11850, Loss: 1.1925, Acc: 60.59%\n",
      "Epoch 1/3, Batch 11860, Loss: 2.4775, Acc: 60.59%\n",
      "Epoch 1/3, Batch 11870, Loss: 0.9201, Acc: 60.58%\n",
      "Epoch 1/3, Batch 11880, Loss: 1.7623, Acc: 60.57%\n",
      "Epoch 1/3, Batch 11890, Loss: 0.0494, Acc: 60.57%\n",
      "Epoch 1/3, Batch 11900, Loss: 0.2138, Acc: 60.57%\n",
      "Epoch 1/3, Batch 11910, Loss: 0.0335, Acc: 60.57%\n",
      "Epoch 1/3, Batch 11920, Loss: 1.1754, Acc: 60.57%\n",
      "Epoch 1/3, Batch 11930, Loss: 1.1504, Acc: 60.56%\n",
      "Epoch 1/3, Batch 11940, Loss: 0.5412, Acc: 60.56%\n",
      "Epoch 1/3, Batch 11950, Loss: 0.0085, Acc: 60.55%\n",
      "Epoch 1/3, Batch 11960, Loss: 0.4982, Acc: 60.54%\n",
      "Epoch 1/3, Batch 11970, Loss: 0.7473, Acc: 60.53%\n",
      "Epoch 1/3, Batch 11980, Loss: 0.1430, Acc: 60.53%\n",
      "Epoch 1/3, Batch 11990, Loss: 2.0890, Acc: 60.52%\n",
      "Epoch 1/3, Batch 12000, Loss: 0.0184, Acc: 60.52%\n",
      "Epoch 1/3, Batch 12010, Loss: 0.9695, Acc: 60.51%\n",
      "Epoch 1/3, Batch 12020, Loss: 1.4045, Acc: 60.50%\n",
      "Epoch 1/3, Batch 12030, Loss: 0.2296, Acc: 60.52%\n",
      "Epoch 1/3, Batch 12040, Loss: 1.5213, Acc: 60.53%\n",
      "Epoch 1/3, Batch 12050, Loss: 0.0532, Acc: 60.52%\n",
      "Epoch 1/3, Batch 12060, Loss: 4.2832, Acc: 60.53%\n",
      "Epoch 1/3, Batch 12070, Loss: 1.7116, Acc: 60.53%\n",
      "Epoch 1/3, Batch 12080, Loss: 0.7041, Acc: 60.52%\n",
      "Epoch 1/3, Batch 12090, Loss: 0.9408, Acc: 60.52%\n",
      "Epoch 1/3, Batch 12100, Loss: 0.7727, Acc: 60.55%\n",
      "Epoch 1/3, Batch 12110, Loss: 1.1795, Acc: 60.55%\n",
      "Epoch 1/3, Batch 12120, Loss: 0.3158, Acc: 60.56%\n",
      "Epoch 1/3, Batch 12130, Loss: 0.1130, Acc: 60.57%\n",
      "Epoch 1/3, Batch 12140, Loss: 0.7476, Acc: 60.56%\n",
      "Epoch 1/3, Batch 12150, Loss: 0.4801, Acc: 60.56%\n",
      "Epoch 1/3, Batch 12160, Loss: 0.1430, Acc: 60.60%\n",
      "Epoch 1/3, Batch 12170, Loss: 1.2405, Acc: 60.59%\n",
      "Epoch 1/3, Batch 12180, Loss: 2.7401, Acc: 60.59%\n",
      "Epoch 1/3, Batch 12190, Loss: 0.6050, Acc: 60.59%\n",
      "Epoch 1/3, Batch 12200, Loss: 0.4957, Acc: 60.60%\n",
      "Epoch 1/3, Batch 12210, Loss: 1.8358, Acc: 60.62%\n",
      "Epoch 1/3, Batch 12220, Loss: 0.6019, Acc: 60.62%\n",
      "Epoch 1/3, Batch 12230, Loss: 0.5727, Acc: 60.62%\n",
      "Epoch 1/3, Batch 12240, Loss: 0.3909, Acc: 60.60%\n",
      "Epoch 1/3, Batch 12250, Loss: 0.5530, Acc: 60.58%\n",
      "Epoch 1/3, Batch 12260, Loss: 1.6456, Acc: 60.57%\n",
      "Epoch 1/3, Batch 12270, Loss: 0.8933, Acc: 60.56%\n",
      "Epoch 1/3, Batch 12280, Loss: 3.3667, Acc: 60.57%\n",
      "Epoch 1/3, Batch 12290, Loss: 1.0770, Acc: 60.56%\n",
      "Epoch 1/3, Batch 12300, Loss: 0.4129, Acc: 60.58%\n",
      "Epoch 1/3, Batch 12310, Loss: 2.3157, Acc: 60.54%\n",
      "Epoch 1/3, Batch 12320, Loss: 0.6746, Acc: 60.56%\n",
      "Epoch 1/3, Batch 12330, Loss: 0.0408, Acc: 60.55%\n",
      "Epoch 1/3, Batch 12340, Loss: 1.0213, Acc: 60.53%\n",
      "Epoch 1/3, Batch 12350, Loss: 1.0098, Acc: 60.55%\n",
      "Epoch 1/3, Batch 12360, Loss: 0.0247, Acc: 60.57%\n",
      "Epoch 1/3, Batch 12370, Loss: 0.0604, Acc: 60.58%\n",
      "Epoch 1/3, Batch 12380, Loss: 0.3782, Acc: 60.58%\n",
      "Epoch 1/3, Batch 12390, Loss: 0.2488, Acc: 60.60%\n",
      "Epoch 1/3, Batch 12400, Loss: 0.5290, Acc: 60.61%\n",
      "Epoch 1/3, Batch 12410, Loss: 0.4607, Acc: 60.61%\n",
      "Epoch 1/3, Batch 12420, Loss: 0.8557, Acc: 60.62%\n",
      "Epoch 1/3, Batch 12430, Loss: 1.3663, Acc: 60.61%\n",
      "Epoch 1/3, Batch 12440, Loss: 0.7889, Acc: 60.63%\n",
      "Epoch 1/3, Batch 12450, Loss: 1.8997, Acc: 60.63%\n",
      "Epoch 1/3, Batch 12460, Loss: 0.1984, Acc: 60.65%\n",
      "Epoch 1/3, Batch 12470, Loss: 0.0596, Acc: 60.66%\n",
      "Epoch 1/3, Batch 12480, Loss: 0.7365, Acc: 60.67%\n",
      "Epoch 1/3, Batch 12490, Loss: 0.4224, Acc: 60.68%\n",
      "Epoch 1/3, Batch 12500, Loss: 1.9537, Acc: 60.67%\n",
      "Epoch 1/3, Batch 12510, Loss: 2.3002, Acc: 60.67%\n",
      "Epoch 1/3, Batch 12520, Loss: 0.6923, Acc: 60.69%\n",
      "Epoch 1/3, Batch 12530, Loss: 1.6015, Acc: 60.70%\n",
      "Epoch 1/3, Batch 12540, Loss: 0.5541, Acc: 60.70%\n",
      "Epoch 1/3, Batch 12550, Loss: 3.0658, Acc: 60.71%\n",
      "Epoch 1/3, Batch 12560, Loss: 0.3666, Acc: 60.72%\n",
      "Epoch 1/3, Batch 12570, Loss: 1.5178, Acc: 60.71%\n",
      "Epoch 1/3, Batch 12580, Loss: 0.5511, Acc: 60.70%\n",
      "Epoch 1/3, Batch 12590, Loss: 0.0299, Acc: 60.69%\n",
      "Epoch 1/3, Batch 12600, Loss: 1.4673, Acc: 60.68%\n",
      "Epoch 1/3, Batch 12610, Loss: 0.8333, Acc: 60.70%\n",
      "Epoch 1/3, Batch 12620, Loss: 1.1959, Acc: 60.69%\n",
      "Epoch 1/3, Batch 12630, Loss: 0.9888, Acc: 60.72%\n",
      "Epoch 1/3, Batch 12640, Loss: 2.2857, Acc: 60.71%\n",
      "Epoch 1/3, Batch 12650, Loss: 1.6506, Acc: 60.71%\n",
      "Epoch 1/3, Batch 12660, Loss: 0.0312, Acc: 60.72%\n",
      "Epoch 1/3, Batch 12670, Loss: 0.3679, Acc: 60.72%\n",
      "Epoch 1/3, Batch 12680, Loss: 0.8296, Acc: 60.72%\n",
      "Epoch 1/3, Batch 12690, Loss: 2.0959, Acc: 60.73%\n",
      "Epoch 1/3, Batch 12700, Loss: 0.7460, Acc: 60.72%\n",
      "Epoch 1/3, Batch 12710, Loss: 0.3675, Acc: 60.74%\n",
      "Epoch 1/3, Batch 12720, Loss: 0.5508, Acc: 60.76%\n",
      "Epoch 1/3, Batch 12730, Loss: 1.1587, Acc: 60.77%\n",
      "Epoch 1/3, Batch 12740, Loss: 2.2949, Acc: 60.76%\n",
      "Epoch 1/3, Batch 12750, Loss: 0.3203, Acc: 60.76%\n",
      "Epoch 1/3, Batch 12760, Loss: 0.5341, Acc: 60.79%\n",
      "Epoch 1/3, Batch 12770, Loss: 0.0125, Acc: 60.83%\n",
      "Epoch 1/3, Batch 12780, Loss: 0.4519, Acc: 60.84%\n",
      "Epoch 1/3, Batch 12790, Loss: 0.1456, Acc: 60.84%\n",
      "Epoch 1/3, Batch 12800, Loss: 0.4318, Acc: 60.84%\n",
      "Epoch 1/3, Batch 12810, Loss: 0.7621, Acc: 60.83%\n",
      "Epoch 1/3, Batch 12820, Loss: 0.3663, Acc: 60.83%\n",
      "Epoch 1/3, Batch 12830, Loss: 1.1388, Acc: 60.84%\n",
      "Epoch 1/3, Batch 12840, Loss: 1.9115, Acc: 60.83%\n",
      "Epoch 1/3, Batch 12850, Loss: 1.0388, Acc: 60.83%\n",
      "Epoch 1/3, Batch 12860, Loss: 0.2003, Acc: 60.82%\n",
      "Epoch 1/3, Batch 12870, Loss: 0.4475, Acc: 60.83%\n",
      "Epoch 1/3, Batch 12880, Loss: 1.8260, Acc: 60.83%\n",
      "Epoch 1/3, Batch 12890, Loss: 0.1042, Acc: 60.82%\n",
      "Epoch 1/3, Batch 12900, Loss: 1.3693, Acc: 60.83%\n",
      "Epoch 1/3, Batch 12910, Loss: 0.5641, Acc: 60.82%\n",
      "Epoch 1/3, Batch 12920, Loss: 0.6729, Acc: 60.83%\n",
      "Epoch 1/3, Batch 12930, Loss: 2.4129, Acc: 60.84%\n",
      "Epoch 1/3, Batch 12940, Loss: 3.1240, Acc: 60.84%\n",
      "Epoch 1/3, Batch 12950, Loss: 0.0396, Acc: 60.85%\n",
      "Epoch 1/3, Batch 12960, Loss: 0.0904, Acc: 60.87%\n",
      "Epoch 1/3, Batch 12970, Loss: 1.9106, Acc: 60.87%\n",
      "Epoch 1/3, Batch 12980, Loss: 0.0154, Acc: 60.86%\n",
      "Epoch 1/3, Batch 12990, Loss: 0.7505, Acc: 60.87%\n",
      "Epoch 1/3, Batch 13000, Loss: 1.5008, Acc: 60.87%\n",
      "Epoch 1/3, Batch 13010, Loss: 0.2258, Acc: 60.86%\n",
      "Epoch 1/3, Batch 13020, Loss: 1.5442, Acc: 60.85%\n",
      "Epoch 1/3, Batch 13030, Loss: 0.0153, Acc: 60.85%\n",
      "Epoch 1/3, Batch 13040, Loss: 0.6372, Acc: 60.85%\n",
      "Epoch 1/3, Batch 13050, Loss: 0.2213, Acc: 60.87%\n",
      "Epoch 1/3, Batch 13060, Loss: 0.3036, Acc: 60.88%\n",
      "Epoch 1/3, Batch 13070, Loss: 0.3506, Acc: 60.88%\n",
      "Epoch 1/3, Batch 13080, Loss: 0.2092, Acc: 60.88%\n",
      "Epoch 1/3, Batch 13090, Loss: 0.9888, Acc: 60.87%\n",
      "Epoch 1/3, Batch 13100, Loss: 0.3032, Acc: 60.86%\n",
      "Epoch 1/3, Batch 13110, Loss: 0.6644, Acc: 60.88%\n",
      "Epoch 1/3, Batch 13120, Loss: 0.8409, Acc: 60.89%\n",
      "Epoch 1/3, Batch 13130, Loss: 0.1429, Acc: 60.89%\n",
      "Epoch 1/3, Batch 13140, Loss: 1.3641, Acc: 60.87%\n",
      "Epoch 1/3, Batch 13150, Loss: 0.9835, Acc: 60.85%\n",
      "Epoch 1/3, Batch 13160, Loss: 0.0548, Acc: 60.86%\n",
      "Epoch 1/3, Batch 13170, Loss: 0.2707, Acc: 60.86%\n",
      "Epoch 1/3, Batch 13180, Loss: 0.1176, Acc: 60.87%\n",
      "Epoch 1/3, Batch 13190, Loss: 0.0247, Acc: 60.87%\n",
      "Epoch 1/3, Batch 13200, Loss: 0.3847, Acc: 60.88%\n",
      "Epoch 1/3, Batch 13210, Loss: 0.1037, Acc: 60.89%\n",
      "Epoch 1/3, Batch 13220, Loss: 0.9906, Acc: 60.87%\n",
      "Epoch 1/3, Batch 13230, Loss: 0.9934, Acc: 60.87%\n",
      "Epoch 1/3, Batch 13240, Loss: 0.0974, Acc: 60.87%\n",
      "Epoch 1/3, Batch 13250, Loss: 0.0293, Acc: 60.88%\n",
      "Epoch 1/3, Batch 13260, Loss: 2.5709, Acc: 60.86%\n",
      "Epoch 1/3, Batch 13270, Loss: 0.2551, Acc: 60.89%\n",
      "Epoch 1/3, Batch 13280, Loss: 1.6769, Acc: 60.89%\n",
      "Epoch 1/3, Batch 13290, Loss: 1.7873, Acc: 60.89%\n",
      "Epoch 1/3, Batch 13300, Loss: 0.5049, Acc: 60.88%\n",
      "Epoch 1/3, Batch 13310, Loss: 0.4899, Acc: 60.86%\n",
      "Epoch 1/3, Batch 13320, Loss: 0.8766, Acc: 60.84%\n",
      "Epoch 1/3, Batch 13330, Loss: 0.9828, Acc: 60.86%\n",
      "Epoch 1/3, Batch 13340, Loss: 0.1459, Acc: 60.86%\n",
      "Epoch 1/3, Batch 13350, Loss: 0.1831, Acc: 60.86%\n",
      "Epoch 1/3, Batch 13360, Loss: 0.4104, Acc: 60.88%\n",
      "Epoch 1/3, Batch 13370, Loss: 0.2952, Acc: 60.89%\n",
      "Epoch 1/3, Batch 13380, Loss: 0.2784, Acc: 60.90%\n",
      "Epoch 1/3, Batch 13390, Loss: 0.2662, Acc: 60.91%\n",
      "Epoch 1/3, Batch 13400, Loss: 1.5461, Acc: 60.91%\n",
      "Epoch 1/3, Batch 13410, Loss: 0.0434, Acc: 60.92%\n",
      "Epoch 1/3, Batch 13420, Loss: 1.6618, Acc: 60.90%\n",
      "Epoch 1/3, Batch 13430, Loss: 0.0324, Acc: 60.92%\n",
      "Epoch 1/3, Batch 13440, Loss: 1.4105, Acc: 60.91%\n",
      "Epoch 1/3, Batch 13450, Loss: 0.0562, Acc: 60.92%\n",
      "Epoch 1/3, Batch 13460, Loss: 0.6889, Acc: 60.93%\n",
      "Epoch 1/3, Batch 13470, Loss: 1.7959, Acc: 60.92%\n",
      "Epoch 1/3, Batch 13480, Loss: 0.5196, Acc: 60.93%\n",
      "Epoch 1/3, Batch 13490, Loss: 0.0865, Acc: 60.94%\n",
      "Epoch 1/3, Batch 13500, Loss: 0.7062, Acc: 60.95%\n",
      "Epoch 1/3, Batch 13510, Loss: 0.2512, Acc: 60.97%\n",
      "Epoch 1/3, Batch 13520, Loss: 0.7239, Acc: 60.96%\n",
      "Epoch 1/3, Batch 13530, Loss: 0.9752, Acc: 60.96%\n",
      "Epoch 1/3, Batch 13540, Loss: 1.8844, Acc: 60.96%\n",
      "Epoch 1/3, Batch 13550, Loss: 0.2772, Acc: 60.96%\n",
      "Epoch 1/3, Batch 13560, Loss: 0.0723, Acc: 60.97%\n",
      "Epoch 1/3, Batch 13570, Loss: 0.2764, Acc: 60.95%\n",
      "Epoch 1/3, Batch 13580, Loss: 1.1025, Acc: 60.94%\n",
      "Epoch 1/3, Batch 13590, Loss: 0.1735, Acc: 60.93%\n",
      "Epoch 1/3, Batch 13600, Loss: 1.0564, Acc: 60.93%\n",
      "Epoch 1/3, Batch 13610, Loss: 0.5063, Acc: 60.91%\n",
      "Epoch 1/3, Batch 13620, Loss: 0.8147, Acc: 60.92%\n",
      "Epoch 1/3, Batch 13630, Loss: 0.0402, Acc: 60.93%\n",
      "Epoch 1/3, Batch 13640, Loss: 1.0093, Acc: 60.93%\n",
      "Epoch 1/3, Batch 13650, Loss: 0.4299, Acc: 60.91%\n",
      "Epoch 1/3, Batch 13660, Loss: 0.1561, Acc: 60.93%\n",
      "Epoch 1/3, Batch 13670, Loss: 0.1254, Acc: 60.92%\n",
      "Epoch 1/3, Batch 13680, Loss: 1.1932, Acc: 60.93%\n",
      "Epoch 1/3, Batch 13690, Loss: 0.8245, Acc: 60.93%\n",
      "Epoch 1/3, Batch 13700, Loss: 0.8273, Acc: 60.92%\n",
      "Epoch 1/3, Batch 13710, Loss: 0.0524, Acc: 60.93%\n",
      "Epoch 1/3, Batch 13720, Loss: 0.0731, Acc: 60.93%\n",
      "Epoch 1/3, Batch 13730, Loss: 0.5259, Acc: 60.94%\n",
      "Epoch 1/3, Batch 13740, Loss: 1.4038, Acc: 60.93%\n",
      "Epoch 1/3, Batch 13750, Loss: 0.0274, Acc: 60.94%\n",
      "Epoch 1/3, Batch 13760, Loss: 0.6833, Acc: 60.95%\n",
      "Epoch 1/3, Batch 13770, Loss: 0.6942, Acc: 60.94%\n",
      "Epoch 1/3, Batch 13780, Loss: 1.8034, Acc: 60.93%\n",
      "Epoch 1/3, Batch 13790, Loss: 0.0036, Acc: 60.95%\n",
      "Epoch 1/3, Batch 13800, Loss: 0.0860, Acc: 60.94%\n",
      "Epoch 1/3, Batch 13810, Loss: 0.7690, Acc: 60.94%\n",
      "Epoch 1/3, Batch 13820, Loss: 1.5508, Acc: 60.93%\n",
      "Epoch 1/3, Batch 13830, Loss: 0.5810, Acc: 60.92%\n",
      "Epoch 1/3, Batch 13840, Loss: 0.2954, Acc: 60.93%\n",
      "Epoch 1/3, Batch 13850, Loss: 0.4255, Acc: 60.94%\n",
      "Epoch 1/3, Batch 13860, Loss: 0.0988, Acc: 60.96%\n",
      "Epoch 1/3, Batch 13870, Loss: 1.6002, Acc: 60.95%\n",
      "Epoch 1/3, Batch 13880, Loss: 0.4302, Acc: 60.97%\n",
      "Epoch 1/3, Batch 13890, Loss: 2.1659, Acc: 60.96%\n",
      "Epoch 1/3, Batch 13900, Loss: 0.2647, Acc: 60.97%\n",
      "Epoch 1/3, Batch 13910, Loss: 0.5817, Acc: 60.97%\n",
      "Epoch 1/3, Batch 13920, Loss: 0.7843, Acc: 60.99%\n",
      "Epoch 1/3, Batch 13930, Loss: 0.1610, Acc: 60.97%\n",
      "Epoch 1/3, Batch 13940, Loss: 2.0040, Acc: 60.98%\n",
      "Epoch 1/3, Batch 13950, Loss: 0.0038, Acc: 60.97%\n",
      "Epoch 1/3, Batch 13960, Loss: 0.4744, Acc: 60.98%\n",
      "Epoch 1/3, Batch 13970, Loss: 0.9554, Acc: 60.99%\n",
      "Epoch 1/3, Batch 13980, Loss: 0.3335, Acc: 60.99%\n",
      "Epoch 1/3, Batch 13990, Loss: 0.6585, Acc: 60.99%\n",
      "Epoch 1/3, Batch 14000, Loss: 0.0165, Acc: 60.99%\n",
      "Epoch 1/3, Batch 14010, Loss: 0.4402, Acc: 60.99%\n",
      "Epoch 1/3, Batch 14020, Loss: 0.5149, Acc: 60.98%\n",
      "Epoch 1/3, Batch 14030, Loss: 0.8520, Acc: 60.98%\n",
      "Epoch 1/3, Batch 14040, Loss: 0.9333, Acc: 60.97%\n",
      "Epoch 1/3, Batch 14050, Loss: 1.2743, Acc: 60.98%\n",
      "Epoch 1/3, Batch 14060, Loss: 0.3417, Acc: 61.00%\n",
      "Epoch 1/3, Batch 14070, Loss: 0.0547, Acc: 61.00%\n",
      "Epoch 1/3, Batch 14080, Loss: 0.0147, Acc: 61.00%\n",
      "Epoch 1/3, Batch 14090, Loss: 0.7934, Acc: 61.00%\n",
      "Epoch 1/3, Batch 14100, Loss: 0.6019, Acc: 60.99%\n",
      "Epoch 1/3, Batch 14110, Loss: 0.1820, Acc: 60.99%\n",
      "Epoch 1/3, Batch 14120, Loss: 0.1216, Acc: 60.98%\n",
      "Epoch 1/3, Batch 14130, Loss: 0.4189, Acc: 60.97%\n",
      "Epoch 1/3, Batch 14140, Loss: 0.7264, Acc: 60.98%\n",
      "Epoch 1/3, Batch 14150, Loss: 0.0480, Acc: 60.99%\n",
      "Epoch 1/3, Batch 14160, Loss: 0.4643, Acc: 61.01%\n",
      "Epoch 1/3, Batch 14170, Loss: 0.3361, Acc: 61.00%\n",
      "Epoch 1/3, Batch 14180, Loss: 0.1425, Acc: 61.00%\n",
      "Epoch 1/3, Batch 14190, Loss: 0.0747, Acc: 61.00%\n",
      "Epoch 1/3, Batch 14200, Loss: 0.4757, Acc: 61.01%\n",
      "Epoch 1/3, Batch 14210, Loss: 1.4350, Acc: 60.99%\n",
      "Epoch 1/3, Batch 14220, Loss: 0.5709, Acc: 60.97%\n",
      "Epoch 1/3, Batch 14230, Loss: 1.5236, Acc: 60.97%\n",
      "Epoch 1/3, Batch 14240, Loss: 0.5627, Acc: 60.96%\n",
      "Epoch 1/3, Batch 14250, Loss: 0.5718, Acc: 60.99%\n",
      "Epoch 1/3, Batch 14260, Loss: 0.8965, Acc: 60.97%\n",
      "Epoch 1/3, Batch 14270, Loss: 1.0441, Acc: 60.97%\n",
      "Epoch 1/3, Batch 14280, Loss: 0.9773, Acc: 60.97%\n",
      "Epoch 1/3, Batch 14290, Loss: 0.0112, Acc: 60.98%\n",
      "Epoch 1/3, Batch 14300, Loss: 0.4132, Acc: 60.97%\n",
      "Epoch 1/3, Batch 14310, Loss: 0.2475, Acc: 60.98%\n",
      "Epoch 1/3, Batch 14320, Loss: 0.0073, Acc: 60.96%\n",
      "Epoch 1/3, Batch 14330, Loss: 0.8983, Acc: 60.95%\n",
      "Epoch 1/3, Batch 14340, Loss: 0.2865, Acc: 60.97%\n",
      "Epoch 1/3, Batch 14350, Loss: 1.2715, Acc: 60.96%\n",
      "Epoch 1/3, Batch 14360, Loss: 0.0319, Acc: 60.97%\n",
      "Epoch 1/3, Batch 14370, Loss: 0.2377, Acc: 60.96%\n",
      "Epoch 1/3, Batch 14380, Loss: 0.2948, Acc: 60.98%\n",
      "Epoch 1/3, Batch 14390, Loss: 0.2395, Acc: 60.98%\n",
      "Epoch 1/3, Batch 14400, Loss: 0.2584, Acc: 60.99%\n",
      "Epoch 1/3, Batch 14410, Loss: 1.0503, Acc: 60.98%\n",
      "Epoch 1/3, Batch 14420, Loss: 0.4134, Acc: 60.99%\n",
      "Epoch 1/3, Batch 14430, Loss: 0.3884, Acc: 60.99%\n",
      "Epoch 1/3, Batch 14440, Loss: 0.0160, Acc: 61.00%\n",
      "Epoch 1/3, Batch 14450, Loss: 1.0208, Acc: 61.00%\n",
      "Epoch 1/3, Batch 14460, Loss: 0.0837, Acc: 61.00%\n",
      "Epoch 1/3, Batch 14470, Loss: 1.7076, Acc: 61.00%\n",
      "Epoch 1/3, Batch 14480, Loss: 0.7475, Acc: 61.00%\n",
      "Epoch 1/3, Batch 14490, Loss: 0.3776, Acc: 61.02%\n",
      "Epoch 1/3, Batch 14500, Loss: 0.9531, Acc: 61.02%\n",
      "Epoch 1/3, Batch 14510, Loss: 1.0126, Acc: 61.01%\n",
      "Epoch 1/3, Batch 14520, Loss: 0.1252, Acc: 61.01%\n",
      "Epoch 1/3, Batch 14530, Loss: 2.3040, Acc: 61.00%\n",
      "Epoch 1/3, Batch 14540, Loss: 0.2143, Acc: 60.99%\n",
      "Epoch 1/3, Batch 14550, Loss: 1.0963, Acc: 61.00%\n",
      "Epoch 1/3, Batch 14560, Loss: 0.3487, Acc: 61.01%\n",
      "Epoch 1/3, Batch 14570, Loss: 1.2363, Acc: 60.98%\n",
      "Epoch 1/3, Batch 14580, Loss: 0.1366, Acc: 60.99%\n",
      "Epoch 1/3, Batch 14590, Loss: 0.7296, Acc: 60.99%\n",
      "Epoch 1/3, Batch 14600, Loss: 0.7408, Acc: 60.98%\n",
      "Epoch 1/3, Batch 14610, Loss: 2.5217, Acc: 60.98%\n",
      "Epoch 1/3, Batch 14620, Loss: 0.0258, Acc: 60.99%\n",
      "Epoch 1/3, Batch 14630, Loss: 0.8617, Acc: 60.98%\n",
      "Epoch 1/3, Batch 14640, Loss: 0.1547, Acc: 60.97%\n",
      "Epoch 1/3, Batch 14650, Loss: 0.6339, Acc: 60.97%\n",
      "Epoch 1/3, Batch 14660, Loss: 0.0281, Acc: 60.99%\n",
      "Epoch 1/3, Batch 14670, Loss: 1.2402, Acc: 60.99%\n",
      "Epoch 1/3, Batch 14680, Loss: 0.9497, Acc: 60.96%\n",
      "Epoch 1/3, Batch 14690, Loss: 0.0091, Acc: 60.96%\n",
      "Epoch 1/3, Batch 14700, Loss: 0.0379, Acc: 60.96%\n",
      "Epoch 1/3, Batch 14710, Loss: 0.3247, Acc: 60.97%\n",
      "Epoch 1/3, Batch 14720, Loss: 1.8277, Acc: 60.95%\n",
      "Epoch 1/3, Batch 14730, Loss: 2.7616, Acc: 60.95%\n",
      "Epoch 1/3, Batch 14740, Loss: 0.3099, Acc: 60.95%\n",
      "Epoch 1/3, Batch 14750, Loss: 1.7543, Acc: 60.96%\n",
      "Epoch 1/3, Batch 14760, Loss: 0.0156, Acc: 60.94%\n",
      "Epoch 1/3, Batch 14770, Loss: 1.4394, Acc: 60.92%\n",
      "Epoch 1/3, Batch 14780, Loss: 1.0904, Acc: 60.91%\n",
      "Epoch 1/3, Batch 14790, Loss: 2.1470, Acc: 60.90%\n",
      "Epoch 1/3, Batch 14800, Loss: 1.8354, Acc: 60.89%\n",
      "Epoch 1/3, Batch 14810, Loss: 0.9892, Acc: 60.88%\n",
      "Epoch 1/3, Batch 14820, Loss: 0.7554, Acc: 60.87%\n",
      "Epoch 1/3, Batch 14830, Loss: 0.0575, Acc: 60.87%\n",
      "Epoch 1/3, Batch 14840, Loss: 1.3938, Acc: 60.85%\n",
      "Epoch 1/3, Batch 14850, Loss: 1.1493, Acc: 60.85%\n",
      "Epoch 1/3, Batch 14860, Loss: 0.0256, Acc: 60.86%\n",
      "Epoch 1/3, Batch 14870, Loss: 0.1513, Acc: 60.86%\n",
      "Epoch 1/3, Batch 14880, Loss: 0.0210, Acc: 60.86%\n",
      "Epoch 1/3, Batch 14890, Loss: 0.1633, Acc: 60.88%\n",
      "Epoch 1/3, Batch 14900, Loss: 0.3069, Acc: 60.90%\n",
      "Epoch 1/3, Batch 14910, Loss: 0.1205, Acc: 60.91%\n",
      "Epoch 1/3, Batch 14920, Loss: 0.6516, Acc: 60.91%\n",
      "Epoch 1/3, Batch 14930, Loss: 0.9015, Acc: 60.89%\n",
      "Epoch 1/3, Batch 14940, Loss: 0.8519, Acc: 60.89%\n",
      "Epoch 1/3, Batch 14950, Loss: 0.4611, Acc: 60.90%\n",
      "Epoch 1/3, Batch 14960, Loss: 1.5398, Acc: 60.89%\n",
      "Epoch 1/3, Batch 14970, Loss: 1.5311, Acc: 60.90%\n",
      "Epoch 1/3, Batch 14980, Loss: 0.7966, Acc: 60.90%\n",
      "Epoch 1/3, Batch 14990, Loss: 1.0510, Acc: 60.88%\n",
      "Epoch 1/3, Batch 15000, Loss: 1.2684, Acc: 60.88%\n",
      "Epoch 1/3, Batch 15010, Loss: 0.0853, Acc: 60.89%\n",
      "Epoch 1/3, Batch 15020, Loss: 0.4687, Acc: 60.89%\n",
      "Epoch 1/3, Batch 15030, Loss: 0.1041, Acc: 60.90%\n",
      "Epoch 1/3, Batch 15040, Loss: 0.5905, Acc: 60.91%\n",
      "Epoch 1/3, Batch 15050, Loss: 0.6076, Acc: 60.91%\n",
      "Epoch 1/3, Batch 15060, Loss: 0.6867, Acc: 60.92%\n",
      "Epoch 1/3, Batch 15070, Loss: 0.4233, Acc: 60.92%\n",
      "Epoch 1/3, Batch 15080, Loss: 2.9496, Acc: 60.92%\n",
      "Epoch 1/3, Batch 15090, Loss: 0.0270, Acc: 60.93%\n",
      "Epoch 1/3, Batch 15100, Loss: 0.1780, Acc: 60.94%\n",
      "Epoch 1/3, Batch 15110, Loss: 0.0125, Acc: 60.95%\n",
      "Epoch 1/3, Batch 15120, Loss: 1.4068, Acc: 60.92%\n",
      "Epoch 1/3, Batch 15130, Loss: 0.1764, Acc: 60.91%\n",
      "Epoch 1/3, Batch 15140, Loss: 0.5543, Acc: 60.91%\n",
      "Epoch 1/3, Batch 15150, Loss: 0.8508, Acc: 60.89%\n",
      "Epoch 1/3, Batch 15160, Loss: 0.0332, Acc: 60.89%\n",
      "Epoch 1/3, Batch 15170, Loss: 0.1950, Acc: 60.90%\n",
      "Epoch 1/3, Batch 15180, Loss: 0.0318, Acc: 60.91%\n",
      "Epoch 1/3, Batch 15190, Loss: 0.0911, Acc: 60.92%\n",
      "Epoch 1/3, Batch 15200, Loss: 1.7359, Acc: 60.92%\n",
      "Epoch 1/3, Batch 15210, Loss: 0.8669, Acc: 60.92%\n",
      "Epoch 1/3, Batch 15220, Loss: 0.2167, Acc: 60.92%\n",
      "Epoch 1/3, Batch 15230, Loss: 0.3438, Acc: 60.92%\n",
      "Epoch 1/3, Batch 15240, Loss: 0.0341, Acc: 60.89%\n",
      "Epoch 1/3, Batch 15250, Loss: 0.1044, Acc: 60.91%\n",
      "Epoch 1/3, Batch 15260, Loss: 0.9236, Acc: 60.90%\n",
      "Epoch 1/3, Batch 15270, Loss: 2.4246, Acc: 60.90%\n",
      "Epoch 1/3, Batch 15280, Loss: 0.0305, Acc: 60.90%\n",
      "Epoch 1/3, Batch 15290, Loss: 0.0092, Acc: 60.89%\n",
      "Epoch 1/3, Batch 15300, Loss: 1.8576, Acc: 60.89%\n",
      "Epoch 1/3, Batch 15310, Loss: 0.0463, Acc: 60.90%\n",
      "Epoch 1/3, Batch 15320, Loss: 1.1310, Acc: 60.90%\n",
      "Epoch 1/3, Batch 15330, Loss: 0.1023, Acc: 60.90%\n",
      "Epoch 1/3, Batch 15340, Loss: 0.1411, Acc: 60.91%\n",
      "Epoch 1/3, Batch 15350, Loss: 0.1446, Acc: 60.91%\n",
      "Epoch 1/3, Batch 15360, Loss: 0.1809, Acc: 60.92%\n",
      "Epoch 1/3, Batch 15370, Loss: 2.3458, Acc: 60.91%\n",
      "Epoch 1/3, Batch 15380, Loss: 0.1478, Acc: 60.91%\n",
      "Epoch 1/3, Batch 15390, Loss: 0.8655, Acc: 60.91%\n",
      "Epoch 1/3, Batch 15400, Loss: 1.7520, Acc: 60.91%\n",
      "Epoch 1/3, Batch 15410, Loss: 0.0939, Acc: 60.91%\n",
      "Epoch 1/3, Batch 15420, Loss: 1.4457, Acc: 60.92%\n",
      "Epoch 1/3, Batch 15430, Loss: 1.2722, Acc: 60.90%\n",
      "Epoch 1/3, Batch 15440, Loss: 1.4444, Acc: 60.88%\n",
      "Epoch 1/3, Batch 15450, Loss: 0.6140, Acc: 60.89%\n",
      "Epoch 1/3, Batch 15460, Loss: 0.2563, Acc: 60.89%\n",
      "Epoch 1/3, Batch 15470, Loss: 0.0287, Acc: 60.88%\n",
      "Epoch 1/3, Batch 15480, Loss: 0.1761, Acc: 60.88%\n",
      "Epoch 1/3, Batch 15490, Loss: 0.4366, Acc: 60.88%\n",
      "Epoch 1/3, Batch 15500, Loss: 0.2197, Acc: 60.88%\n",
      "Epoch 1/3, Batch 15510, Loss: 0.3557, Acc: 60.87%\n",
      "Epoch 1/3, Batch 15520, Loss: 1.5740, Acc: 60.87%\n",
      "Epoch 1/3, Batch 15530, Loss: 1.3919, Acc: 60.87%\n",
      "Epoch 1/3, Batch 15540, Loss: 0.1895, Acc: 60.87%\n",
      "Epoch 1/3, Batch 15550, Loss: 0.4522, Acc: 60.86%\n",
      "Epoch 1/3, Batch 15560, Loss: 0.1130, Acc: 60.87%\n",
      "Epoch 1/3, Batch 15570, Loss: 0.1251, Acc: 60.87%\n",
      "Epoch 1/3, Batch 15580, Loss: 1.0279, Acc: 60.85%\n",
      "Epoch 1/3, Batch 15590, Loss: 1.1746, Acc: 60.84%\n",
      "Epoch 1/3, Batch 15600, Loss: 0.2007, Acc: 60.83%\n",
      "Epoch 1/3, Batch 15610, Loss: 0.2809, Acc: 60.84%\n",
      "Epoch 1/3, Batch 15620, Loss: 2.2157, Acc: 60.83%\n",
      "Epoch 1/3, Batch 15630, Loss: 0.3959, Acc: 60.83%\n",
      "Epoch 1/3, Batch 15640, Loss: 2.5193, Acc: 60.84%\n",
      "Epoch 1/3, Batch 15650, Loss: 2.4852, Acc: 60.85%\n",
      "Epoch 1/3, Batch 15660, Loss: 0.0017, Acc: 60.85%\n",
      "Epoch 1/3, Batch 15670, Loss: 0.7899, Acc: 60.84%\n",
      "Epoch 1/3, Batch 15680, Loss: 0.0347, Acc: 60.85%\n",
      "Epoch 1/3, Batch 15690, Loss: 0.1848, Acc: 60.86%\n",
      "Epoch 1/3, Batch 15700, Loss: 0.8169, Acc: 60.85%\n",
      "Epoch 1/3, Batch 15710, Loss: 0.7366, Acc: 60.84%\n",
      "Epoch 1/3, Batch 15720, Loss: 1.6953, Acc: 60.84%\n",
      "Epoch 1/3, Batch 15730, Loss: 0.3718, Acc: 60.85%\n",
      "Epoch 1/3, Batch 15740, Loss: 0.6409, Acc: 60.84%\n",
      "Epoch 1/3, Batch 15750, Loss: 1.7801, Acc: 60.83%\n",
      "Epoch 1/3, Batch 15760, Loss: 0.0467, Acc: 60.84%\n",
      "Epoch 1/3, Batch 15770, Loss: 0.3118, Acc: 60.86%\n",
      "Epoch 1/3, Batch 15780, Loss: 0.0721, Acc: 60.86%\n",
      "Epoch 1/3, Batch 15790, Loss: 0.0614, Acc: 60.85%\n",
      "Epoch 1/3, Batch 15800, Loss: 0.0798, Acc: 60.85%\n",
      "Epoch 1/3, Batch 15810, Loss: 0.5956, Acc: 60.86%\n",
      "Epoch 1/3, Batch 15820, Loss: 1.5867, Acc: 60.87%\n",
      "Epoch 1/3, Batch 15830, Loss: 3.0104, Acc: 60.86%\n",
      "Epoch 1/3, Batch 15840, Loss: 0.4452, Acc: 60.85%\n",
      "Epoch 1/3, Batch 15850, Loss: 0.7169, Acc: 60.84%\n",
      "Epoch 1/3, Batch 15860, Loss: 2.9476, Acc: 60.83%\n",
      "Epoch 1/3, Batch 15870, Loss: 0.3417, Acc: 60.84%\n",
      "Epoch 1/3, Batch 15880, Loss: 0.1099, Acc: 60.85%\n",
      "Epoch 1/3, Batch 15890, Loss: 0.2189, Acc: 60.85%\n",
      "Epoch 1/3, Batch 15900, Loss: 0.4348, Acc: 60.84%\n",
      "Epoch 1/3, Batch 15910, Loss: 0.3166, Acc: 60.83%\n",
      "Epoch 1/3, Batch 15920, Loss: 0.8025, Acc: 60.82%\n",
      "Epoch 1/3, Batch 15930, Loss: 0.4474, Acc: 60.81%\n",
      "Epoch 1/3, Batch 15940, Loss: 0.6279, Acc: 60.83%\n",
      "Epoch 1/3, Batch 15950, Loss: 2.0020, Acc: 60.84%\n",
      "Epoch 1/3, Batch 15960, Loss: 0.0995, Acc: 60.83%\n",
      "Epoch 1/3, Batch 15970, Loss: 0.0241, Acc: 60.84%\n",
      "Epoch 1/3, Batch 15980, Loss: 0.1148, Acc: 60.83%\n",
      "Epoch 1/3, Batch 15990, Loss: 0.1368, Acc: 60.83%\n",
      "Epoch 1/3, Batch 16000, Loss: 2.0615, Acc: 60.83%\n",
      "Epoch 1/3, Batch 16010, Loss: 0.2344, Acc: 60.83%\n",
      "Epoch 1/3, Batch 16020, Loss: 0.2280, Acc: 60.83%\n",
      "Epoch 1/3, Batch 16030, Loss: 0.5939, Acc: 60.84%\n",
      "Epoch 1/3, Batch 16040, Loss: 0.4566, Acc: 60.85%\n",
      "Epoch 1/3, Batch 16050, Loss: 0.5102, Acc: 60.86%\n",
      "Epoch 1/3, Batch 16060, Loss: 2.0833, Acc: 60.86%\n",
      "Epoch 1/3, Batch 16070, Loss: 0.0283, Acc: 60.86%\n",
      "Epoch 1/3, Batch 16080, Loss: 0.0245, Acc: 60.87%\n",
      "Epoch 1/3, Batch 16090, Loss: 0.2986, Acc: 60.87%\n",
      "Epoch 1/3, Batch 16100, Loss: 0.4331, Acc: 60.87%\n",
      "Epoch 1/3, Batch 16110, Loss: 0.1377, Acc: 60.88%\n",
      "Epoch 1/3, Batch 16120, Loss: 1.5791, Acc: 60.90%\n",
      "Epoch 1/3, Batch 16130, Loss: 0.8514, Acc: 60.89%\n",
      "Epoch 1/3, Batch 16140, Loss: 1.1643, Acc: 60.88%\n",
      "Epoch 1/3, Batch 16150, Loss: 0.1810, Acc: 60.88%\n",
      "Epoch 1/3, Batch 16160, Loss: 0.1610, Acc: 60.87%\n",
      "Epoch 1/3, Batch 16170, Loss: 0.5595, Acc: 60.87%\n",
      "Epoch 1/3, Batch 16180, Loss: 1.4689, Acc: 60.88%\n",
      "Epoch 1/3, Batch 16190, Loss: 1.4209, Acc: 60.87%\n",
      "Epoch 1/3, Batch 16200, Loss: 1.2012, Acc: 60.85%\n",
      "Epoch 1/3, Batch 16210, Loss: 2.4294, Acc: 60.87%\n",
      "Epoch 1/3, Batch 16220, Loss: 0.2544, Acc: 60.88%\n",
      "Epoch 1/3, Batch 16230, Loss: 0.0370, Acc: 60.90%\n",
      "Epoch 1/3, Batch 16240, Loss: 1.0339, Acc: 60.91%\n",
      "Epoch 1/3, Batch 16250, Loss: 0.1283, Acc: 60.93%\n",
      "Epoch 1/3, Batch 16260, Loss: 1.3902, Acc: 60.92%\n",
      "Epoch 1/3, Batch 16270, Loss: 0.3905, Acc: 60.92%\n",
      "Epoch 1/3, Batch 16280, Loss: 0.1124, Acc: 60.92%\n",
      "Epoch 1/3, Batch 16290, Loss: 0.0380, Acc: 60.92%\n",
      "Epoch 1/3, Batch 16300, Loss: 1.7093, Acc: 60.92%\n",
      "Epoch 1/3, Batch 16310, Loss: 0.0163, Acc: 60.91%\n",
      "Epoch 1/3, Batch 16320, Loss: 0.4228, Acc: 60.92%\n",
      "Epoch 1/3, Batch 16330, Loss: 1.0550, Acc: 60.90%\n",
      "Epoch 1/3, Batch 16340, Loss: 0.4769, Acc: 60.90%\n",
      "Epoch 1/3, Batch 16350, Loss: 1.8625, Acc: 60.91%\n",
      "Epoch 1/3, Batch 16360, Loss: 0.7011, Acc: 60.90%\n",
      "Epoch 1/3, Batch 16370, Loss: 0.6545, Acc: 60.91%\n",
      "Epoch 1/3, Batch 16380, Loss: 0.4436, Acc: 60.92%\n",
      "Epoch 1/3, Batch 16390, Loss: 0.4128, Acc: 60.91%\n",
      "Epoch 1/3, Batch 16400, Loss: 0.3318, Acc: 60.93%\n",
      "Epoch 1/3, Batch 16410, Loss: 0.0066, Acc: 60.92%\n",
      "Epoch 1/3, Batch 16420, Loss: 0.7895, Acc: 60.92%\n",
      "Epoch 1/3, Batch 16430, Loss: 0.0402, Acc: 60.93%\n",
      "Epoch 1/3, Batch 16440, Loss: 0.6663, Acc: 60.93%\n",
      "Epoch 1/3, Batch 16450, Loss: 0.0456, Acc: 60.94%\n",
      "Epoch 1/3, Batch 16460, Loss: 0.2587, Acc: 60.95%\n",
      "Epoch 1/3, Batch 16470, Loss: 0.7092, Acc: 60.95%\n",
      "Epoch 1/3, Batch 16480, Loss: 0.0061, Acc: 60.95%\n",
      "Epoch 1/3, Batch 16490, Loss: 0.0813, Acc: 60.96%\n",
      "Epoch 1/3, Batch 16500, Loss: 1.7954, Acc: 60.97%\n",
      "Epoch 1/3, Batch 16510, Loss: 0.8270, Acc: 60.95%\n",
      "Epoch 1/3, Batch 16520, Loss: 0.3712, Acc: 60.95%\n",
      "Epoch 1/3, Batch 16530, Loss: 0.7471, Acc: 60.93%\n",
      "Epoch 1/3, Batch 16540, Loss: 1.4676, Acc: 60.93%\n",
      "Epoch 1/3, Batch 16550, Loss: 1.3353, Acc: 60.92%\n",
      "Epoch 1/3, Batch 16560, Loss: 0.3051, Acc: 60.91%\n",
      "Epoch 1/3, Batch 16570, Loss: 1.8480, Acc: 60.91%\n",
      "Epoch 1/3, Batch 16580, Loss: 0.8825, Acc: 60.93%\n",
      "Epoch 1/3, Batch 16590, Loss: 1.7706, Acc: 60.92%\n",
      "Epoch 1/3, Batch 16600, Loss: 0.7804, Acc: 60.92%\n",
      "Epoch 1/3, Batch 16610, Loss: 1.1307, Acc: 60.92%\n",
      "Epoch 1/3, Batch 16620, Loss: 0.0803, Acc: 60.92%\n",
      "Epoch 1/3, Batch 16630, Loss: 0.9115, Acc: 60.91%\n",
      "Epoch 1/3, Batch 16640, Loss: 0.6430, Acc: 60.91%\n",
      "Epoch 1/3, Batch 16650, Loss: 0.1030, Acc: 60.90%\n",
      "Epoch 1/3, Batch 16660, Loss: 0.0306, Acc: 60.90%\n",
      "Epoch 1/3, Batch 16670, Loss: 0.9337, Acc: 60.89%\n",
      "Epoch 1/3, Batch 16680, Loss: 0.7592, Acc: 60.89%\n",
      "Epoch 1/3, Batch 16690, Loss: 0.5708, Acc: 60.88%\n",
      "Epoch 1/3, Batch 16700, Loss: 0.0119, Acc: 60.87%\n",
      "Epoch 1/3, Batch 16710, Loss: 0.3619, Acc: 60.86%\n",
      "Epoch 1/3, Batch 16720, Loss: 1.6798, Acc: 60.86%\n",
      "Epoch 1/3, Batch 16730, Loss: 0.4568, Acc: 60.86%\n",
      "Epoch 1/3, Batch 16740, Loss: 0.0823, Acc: 60.87%\n",
      "Epoch 1/3, Batch 16750, Loss: 0.8006, Acc: 60.88%\n",
      "Epoch 1/3, Batch 16760, Loss: 0.8403, Acc: 60.87%\n",
      "Epoch 1/3, Batch 16770, Loss: 1.1866, Acc: 60.87%\n",
      "Epoch 1/3, Batch 16780, Loss: 0.0261, Acc: 60.87%\n",
      "Epoch 1/3, Batch 16790, Loss: 0.4932, Acc: 60.89%\n",
      "Epoch 1/3, Batch 16800, Loss: 0.2995, Acc: 60.88%\n",
      "Epoch 1/3, Batch 16810, Loss: 0.3703, Acc: 60.89%\n",
      "Epoch 1/3, Batch 16820, Loss: 1.1805, Acc: 60.89%\n",
      "Epoch 1/3, Batch 16830, Loss: 0.0561, Acc: 60.89%\n",
      "Epoch 1/3, Batch 16840, Loss: 0.3621, Acc: 60.89%\n",
      "Epoch 1/3, Batch 16850, Loss: 1.6848, Acc: 60.90%\n",
      "Epoch 1/3, Batch 16860, Loss: 0.3557, Acc: 60.89%\n",
      "Epoch 1/3, Batch 16870, Loss: 0.3802, Acc: 60.89%\n",
      "Epoch 1/3, Batch 16880, Loss: 0.3607, Acc: 60.90%\n",
      "Epoch 1/3, Batch 16890, Loss: 0.8262, Acc: 60.90%\n",
      "Epoch 1/3, Batch 16900, Loss: 0.5696, Acc: 60.90%\n",
      "Epoch 1/3, Batch 16910, Loss: 1.7704, Acc: 60.89%\n",
      "Epoch 1/3, Batch 16920, Loss: 2.5323, Acc: 60.88%\n",
      "Epoch 1/3, Batch 16930, Loss: 0.0778, Acc: 60.88%\n",
      "Epoch 1/3, Batch 16940, Loss: 0.3171, Acc: 60.87%\n",
      "Epoch 1/3, Batch 16950, Loss: 0.6737, Acc: 60.86%\n",
      "Epoch 1/3, Batch 16960, Loss: 0.4303, Acc: 60.86%\n",
      "Epoch 1/3, Batch 16970, Loss: 0.1365, Acc: 60.87%\n",
      "Epoch 1/3, Batch 16980, Loss: 0.0248, Acc: 60.86%\n",
      "Epoch 1/3, Batch 16990, Loss: 0.0244, Acc: 60.84%\n",
      "Epoch 1/3, Batch 17000, Loss: 0.1620, Acc: 60.84%\n",
      "Epoch 1/3, Batch 17010, Loss: 1.7116, Acc: 60.84%\n",
      "Epoch 1/3, Batch 17020, Loss: 0.6443, Acc: 60.85%\n",
      "Epoch 1/3, Batch 17030, Loss: 0.1491, Acc: 60.85%\n",
      "Epoch 1/3, Batch 17040, Loss: 1.7277, Acc: 60.84%\n",
      "Epoch 1/3, Batch 17050, Loss: 0.1378, Acc: 60.84%\n",
      "Epoch 1/3, Batch 17060, Loss: 0.7835, Acc: 60.84%\n",
      "Epoch 1/3, Batch 17070, Loss: 0.9256, Acc: 60.85%\n",
      "Epoch 1/3, Batch 17080, Loss: 1.0733, Acc: 60.85%\n",
      "Epoch 1/3, Batch 17090, Loss: 2.4521, Acc: 60.83%\n",
      "Epoch 1/3, Batch 17100, Loss: 2.4856, Acc: 60.83%\n",
      "Epoch 1/3, Batch 17110, Loss: 0.1910, Acc: 60.83%\n",
      "Epoch 1/3, Batch 17120, Loss: 0.6641, Acc: 60.83%\n",
      "Epoch 1/3, Batch 17130, Loss: 0.6167, Acc: 60.85%\n",
      "Epoch 1/3, Batch 17140, Loss: 1.6751, Acc: 60.85%\n",
      "Epoch 1/3, Batch 17150, Loss: 0.2541, Acc: 60.84%\n",
      "Epoch 1/3, Batch 17160, Loss: 1.5408, Acc: 60.84%\n",
      "Epoch 1/3, Batch 17170, Loss: 0.9295, Acc: 60.84%\n",
      "Epoch 1/3, Batch 17180, Loss: 0.8416, Acc: 60.84%\n",
      "Epoch 1/3, Batch 17190, Loss: 0.3205, Acc: 60.85%\n",
      "Epoch 1/3, Batch 17200, Loss: 0.4868, Acc: 60.84%\n",
      "Epoch 1/3, Batch 17210, Loss: 0.4114, Acc: 60.84%\n",
      "Epoch 1/3, Batch 17220, Loss: 0.0451, Acc: 60.84%\n",
      "Epoch 1/3, Batch 17230, Loss: 1.5073, Acc: 60.84%\n",
      "Epoch 1/3, Batch 17240, Loss: 0.2465, Acc: 60.83%\n",
      "Epoch 1/3, Batch 17250, Loss: 0.9214, Acc: 60.84%\n",
      "Epoch 1/3, Batch 17260, Loss: 0.5194, Acc: 60.83%\n",
      "Epoch 1/3, Batch 17270, Loss: 0.4369, Acc: 60.83%\n",
      "Epoch 1/3, Batch 17280, Loss: 0.0265, Acc: 60.84%\n",
      "Epoch 1/3, Batch 17290, Loss: 0.9473, Acc: 60.82%\n",
      "Epoch 1/3, Batch 17300, Loss: 1.0080, Acc: 60.83%\n",
      "Epoch 1/3, Batch 17310, Loss: 0.6691, Acc: 60.85%\n",
      "Epoch 1/3, Batch 17320, Loss: 0.3882, Acc: 60.85%\n",
      "Epoch 1/3, Batch 17330, Loss: 0.5859, Acc: 60.86%\n",
      "Epoch 1/3, Batch 17340, Loss: 0.2953, Acc: 60.86%\n",
      "Epoch 1/3, Batch 17350, Loss: 0.0511, Acc: 60.87%\n",
      "Epoch 1/3, Batch 17360, Loss: 0.0699, Acc: 60.87%\n",
      "Epoch 1/3, Batch 17370, Loss: 0.8190, Acc: 60.87%\n",
      "Epoch 1/3, Batch 17380, Loss: 1.3511, Acc: 60.87%\n",
      "Epoch 1/3, Batch 17390, Loss: 0.0242, Acc: 60.86%\n",
      "Epoch 1/3, Batch 17400, Loss: 0.8541, Acc: 60.88%\n",
      "Epoch 1/3, Batch 17410, Loss: 0.0332, Acc: 60.89%\n",
      "Epoch 1/3, Batch 17420, Loss: 1.4367, Acc: 60.88%\n",
      "Epoch 1/3, Batch 17430, Loss: 0.4730, Acc: 60.88%\n",
      "Epoch 1/3, Batch 17440, Loss: 0.9104, Acc: 60.87%\n",
      "Epoch 1/3, Batch 17450, Loss: 0.0885, Acc: 60.87%\n",
      "Epoch 1/3, Batch 17460, Loss: 0.2527, Acc: 60.87%\n",
      "Epoch 1/3, Batch 17470, Loss: 0.4059, Acc: 60.86%\n",
      "Epoch 1/3, Batch 17480, Loss: 0.6767, Acc: 60.85%\n",
      "Epoch 1/3, Batch 17490, Loss: 1.3793, Acc: 60.84%\n",
      "Epoch 1/3, Batch 17500, Loss: 1.0796, Acc: 60.83%\n",
      "Epoch 1/3, Batch 17510, Loss: 0.7384, Acc: 60.82%\n",
      "Epoch 1/3, Batch 17520, Loss: 0.0551, Acc: 60.82%\n",
      "Epoch 1/3, Batch 17530, Loss: 1.0269, Acc: 60.82%\n",
      "Epoch 1/3, Batch 17540, Loss: 0.0327, Acc: 60.81%\n",
      "Epoch 1/3, Batch 17550, Loss: 0.5240, Acc: 60.82%\n",
      "Epoch 1/3, Batch 17560, Loss: 0.9354, Acc: 60.81%\n",
      "Epoch 1/3, Batch 17570, Loss: 0.1295, Acc: 60.81%\n",
      "Epoch 1/3, Batch 17580, Loss: 0.2363, Acc: 60.82%\n",
      "Epoch 1/3, Batch 17590, Loss: 0.7135, Acc: 60.79%\n",
      "Epoch 1/3, Batch 17600, Loss: 0.2591, Acc: 60.79%\n",
      "Epoch 1/3, Batch 17610, Loss: 0.8411, Acc: 60.80%\n",
      "Epoch 1/3, Batch 17620, Loss: 0.7320, Acc: 60.80%\n",
      "Epoch 1/3, Batch 17630, Loss: 0.0268, Acc: 60.80%\n",
      "Epoch 1/3, Batch 17640, Loss: 2.2763, Acc: 60.79%\n",
      "Epoch 1/3, Batch 17650, Loss: 0.4551, Acc: 60.80%\n",
      "Epoch 1/3, Batch 17660, Loss: 0.2214, Acc: 60.80%\n",
      "Epoch 1/3, Batch 17670, Loss: 0.8969, Acc: 60.79%\n",
      "Epoch 1/3, Batch 17680, Loss: 1.8306, Acc: 60.80%\n",
      "Epoch 1/3, Batch 17690, Loss: 0.8406, Acc: 60.79%\n",
      "Epoch 1/3, Batch 17700, Loss: 0.0034, Acc: 60.79%\n",
      "Epoch 1/3, Batch 17710, Loss: 2.6667, Acc: 60.79%\n",
      "Epoch 1/3, Batch 17720, Loss: 0.6693, Acc: 60.80%\n",
      "Epoch 1/3, Batch 17730, Loss: 0.3658, Acc: 60.80%\n",
      "Epoch 1/3, Batch 17740, Loss: 0.3466, Acc: 60.80%\n",
      "Epoch 1/3, Batch 17750, Loss: 0.0331, Acc: 60.81%\n",
      "Epoch 1/3, Batch 17760, Loss: 0.2296, Acc: 60.80%\n",
      "Epoch 1/3, Batch 17770, Loss: 1.4498, Acc: 60.81%\n",
      "Epoch 1/3, Batch 17780, Loss: 0.4946, Acc: 60.80%\n",
      "Epoch 1/3, Batch 17790, Loss: 0.0017, Acc: 60.81%\n",
      "Epoch 1/3, Batch 17800, Loss: 0.3319, Acc: 60.82%\n",
      "Epoch 1/3, Batch 17810, Loss: 1.0377, Acc: 60.79%\n",
      "Epoch 1/3, Batch 17820, Loss: 0.2161, Acc: 60.79%\n",
      "Epoch 1/3, Batch 17830, Loss: 0.1031, Acc: 60.79%\n",
      "Epoch 1/3, Batch 17840, Loss: 0.1379, Acc: 60.80%\n",
      "Epoch 1/3, Batch 17850, Loss: 0.9673, Acc: 60.79%\n",
      "Epoch 1/3, Batch 17860, Loss: 0.1655, Acc: 60.79%\n",
      "Epoch 1/3, Batch 17870, Loss: 1.1260, Acc: 60.79%\n",
      "Epoch 1/3, Batch 17880, Loss: 0.6105, Acc: 60.81%\n",
      "Epoch 1/3, Batch 17890, Loss: 0.1390, Acc: 60.82%\n",
      "Epoch 1/3, Batch 17900, Loss: 2.6924, Acc: 60.83%\n",
      "Epoch 1/3, Batch 17910, Loss: 2.0197, Acc: 60.84%\n",
      "Epoch 1/3, Batch 17920, Loss: 1.2610, Acc: 60.84%\n",
      "Epoch 1/3, Batch 17930, Loss: 1.0551, Acc: 60.84%\n",
      "Epoch 1/3, Batch 17940, Loss: 0.3683, Acc: 60.82%\n",
      "Epoch 1/3, Batch 17950, Loss: 1.9789, Acc: 60.82%\n",
      "Epoch 1/3, Batch 17960, Loss: 1.2060, Acc: 60.83%\n",
      "Epoch 1/3, Batch 17970, Loss: 0.4598, Acc: 60.82%\n",
      "Epoch 1/3, Batch 17980, Loss: 0.8549, Acc: 60.83%\n",
      "Epoch 1/3, Batch 17990, Loss: 2.9287, Acc: 60.83%\n",
      "Epoch 1/3, Batch 18000, Loss: 2.0336, Acc: 60.82%\n",
      "Epoch 1/3, Batch 18010, Loss: 0.2429, Acc: 60.83%\n",
      "Epoch 1/3, Batch 18020, Loss: 0.7333, Acc: 60.82%\n",
      "Epoch 1/3, Batch 18030, Loss: 0.0090, Acc: 60.83%\n",
      "Epoch 1/3, Batch 18040, Loss: 0.2723, Acc: 60.83%\n",
      "Epoch 1/3, Batch 18050, Loss: 0.8344, Acc: 60.82%\n",
      "Epoch 1/3, Batch 18060, Loss: 0.5643, Acc: 60.83%\n",
      "Epoch 1/3, Batch 18070, Loss: 0.4033, Acc: 60.84%\n",
      "Epoch 1/3, Batch 18080, Loss: 0.2545, Acc: 60.85%\n",
      "Epoch 1/3, Batch 18090, Loss: 0.4968, Acc: 60.84%\n",
      "Epoch 1/3, Batch 18100, Loss: 0.8588, Acc: 60.84%\n",
      "Epoch 1/3, Batch 18110, Loss: 1.2110, Acc: 60.82%\n",
      "Epoch 1/3, Batch 18120, Loss: 0.8471, Acc: 60.84%\n",
      "Epoch 1/3, Batch 18130, Loss: 0.4377, Acc: 60.85%\n",
      "Epoch 1/3, Batch 18140, Loss: 0.0483, Acc: 60.86%\n",
      "Epoch 1/3, Batch 18150, Loss: 0.0152, Acc: 60.85%\n",
      "Epoch 1/3, Batch 18160, Loss: 0.3482, Acc: 60.84%\n",
      "Epoch 1/3, Batch 18170, Loss: 0.3230, Acc: 60.84%\n",
      "Epoch 1/3, Batch 18180, Loss: 0.2869, Acc: 60.85%\n",
      "Epoch 1/3, Batch 18190, Loss: 1.0999, Acc: 60.85%\n",
      "Epoch 1/3, Batch 18200, Loss: 0.4306, Acc: 60.86%\n",
      "Epoch 1/3, Batch 18210, Loss: 0.2563, Acc: 60.85%\n",
      "Epoch 1/3, Batch 18220, Loss: 0.2319, Acc: 60.85%\n",
      "Epoch 1/3, Batch 18230, Loss: 0.0768, Acc: 60.86%\n",
      "Epoch 1/3, Batch 18240, Loss: 0.0178, Acc: 60.85%\n",
      "Epoch 1/3, Batch 18250, Loss: 0.2096, Acc: 60.86%\n",
      "Epoch 1/3, Batch 18260, Loss: 0.8800, Acc: 60.87%\n",
      "Epoch 1/3, Batch 18270, Loss: 0.3711, Acc: 60.86%\n",
      "Epoch 1/3, Batch 18280, Loss: 0.3830, Acc: 60.86%\n",
      "Epoch 1/3, Batch 18290, Loss: 0.8996, Acc: 60.87%\n",
      "Epoch 1/3, Batch 18300, Loss: 0.2909, Acc: 60.87%\n",
      "Epoch 1/3, Batch 18310, Loss: 0.1753, Acc: 60.88%\n",
      "Epoch 1/3, Batch 18320, Loss: 1.3507, Acc: 60.88%\n",
      "Epoch 1/3, Batch 18330, Loss: 0.7085, Acc: 60.86%\n",
      "Epoch 1/3, Batch 18340, Loss: 0.4558, Acc: 60.87%\n",
      "Epoch 1/3, Batch 18350, Loss: 0.7644, Acc: 60.88%\n",
      "Epoch 1/3, Batch 18360, Loss: 1.3898, Acc: 60.88%\n",
      "Epoch 1/3, Batch 18370, Loss: 0.1001, Acc: 60.88%\n",
      "Epoch 1/3, Batch 18380, Loss: 0.0342, Acc: 60.89%\n",
      "Epoch 1/3, Batch 18390, Loss: 1.3542, Acc: 60.89%\n",
      "Epoch 1/3, Batch 18400, Loss: 0.0076, Acc: 60.89%\n",
      "Epoch 1/3, Batch 18410, Loss: 1.2984, Acc: 60.89%\n",
      "Epoch 1/3, Batch 18420, Loss: 0.5772, Acc: 60.89%\n",
      "Epoch 1/3, Batch 18430, Loss: 0.8257, Acc: 60.88%\n",
      "Epoch 1/3, Batch 18440, Loss: 0.0131, Acc: 60.88%\n",
      "Epoch 1/3, Batch 18450, Loss: 0.1496, Acc: 60.89%\n",
      "Epoch 1/3, Batch 18460, Loss: 1.9634, Acc: 60.87%\n",
      "Epoch 1/3, Batch 18470, Loss: 1.6372, Acc: 60.88%\n",
      "Epoch 1/3, Batch 18480, Loss: 0.9730, Acc: 60.88%\n",
      "Epoch 1/3, Batch 18490, Loss: 0.1953, Acc: 60.90%\n",
      "Epoch 1/3, Batch 18500, Loss: 1.6684, Acc: 60.88%\n",
      "Epoch 1/3, Batch 18510, Loss: 0.4951, Acc: 60.89%\n",
      "Epoch 1/3, Batch 18520, Loss: 0.4222, Acc: 60.90%\n",
      "Epoch 1/3, Batch 18530, Loss: 0.5948, Acc: 60.92%\n",
      "Epoch 1/3, Batch 18540, Loss: 0.0426, Acc: 60.92%\n",
      "Epoch 1/3, Batch 18550, Loss: 1.9337, Acc: 60.92%\n",
      "Epoch 1/3, Batch 18560, Loss: 0.2131, Acc: 60.91%\n",
      "Epoch 1/3, Batch 18570, Loss: 1.6323, Acc: 60.91%\n",
      "Epoch 1/3, Batch 18580, Loss: 1.6262, Acc: 60.92%\n",
      "Epoch 1/3, Batch 18590, Loss: 0.4536, Acc: 60.92%\n",
      "Epoch 1/3, Batch 18600, Loss: 0.7463, Acc: 60.92%\n",
      "Epoch 1/3, Batch 18610, Loss: 0.4782, Acc: 60.92%\n",
      "Epoch 1/3, Batch 18620, Loss: 0.0062, Acc: 60.90%\n",
      "Epoch 1/3, Batch 18630, Loss: 1.7957, Acc: 60.91%\n",
      "Epoch 1/3, Batch 18640, Loss: 0.6902, Acc: 60.91%\n",
      "Epoch 1/3, Batch 18650, Loss: 1.1595, Acc: 60.91%\n",
      "Epoch 1/3, Batch 18660, Loss: 1.4720, Acc: 60.90%\n",
      "Epoch 1/3, Batch 18670, Loss: 1.3536, Acc: 60.90%\n",
      "Epoch 1/3, Batch 18680, Loss: 1.7863, Acc: 60.90%\n",
      "Epoch 1/3, Batch 18690, Loss: 0.0757, Acc: 60.90%\n",
      "Epoch 1/3, Batch 18700, Loss: 0.5352, Acc: 60.88%\n",
      "Epoch 1/3, Batch 18710, Loss: 0.3376, Acc: 60.88%\n",
      "Epoch 1/3, Batch 18720, Loss: 0.1919, Acc: 60.88%\n",
      "Epoch 1/3, Batch 18730, Loss: 2.3948, Acc: 60.87%\n",
      "Epoch 1/3, Batch 18740, Loss: 0.2725, Acc: 60.86%\n",
      "Epoch 1/3, Batch 18750, Loss: 0.4565, Acc: 60.84%\n",
      "Epoch 1/3, Batch 18760, Loss: 0.0247, Acc: 60.83%\n",
      "Epoch 1/3, Batch 18770, Loss: 0.5910, Acc: 60.83%\n",
      "Epoch 1/3, Batch 18780, Loss: 0.2524, Acc: 60.81%\n",
      "Epoch 1/3, Batch 18790, Loss: 0.0067, Acc: 60.82%\n",
      "Epoch 1/3, Batch 18800, Loss: 0.7217, Acc: 60.82%\n",
      "Epoch 1/3, Batch 18810, Loss: 0.1165, Acc: 60.84%\n",
      "Epoch 1/3, Batch 18820, Loss: 0.6748, Acc: 60.85%\n",
      "Epoch 1/3, Batch 18830, Loss: 0.5542, Acc: 60.85%\n",
      "Epoch 1/3, Batch 18840, Loss: 1.4301, Acc: 60.85%\n",
      "Epoch 1/3, Batch 18850, Loss: 0.1452, Acc: 60.85%\n",
      "Epoch 1/3, Batch 18860, Loss: 3.0023, Acc: 60.85%\n",
      "Epoch 1/3, Batch 18870, Loss: 0.0146, Acc: 60.84%\n",
      "Epoch 1/3, Batch 18880, Loss: 1.1161, Acc: 60.84%\n",
      "Epoch 1/3, Batch 18890, Loss: 3.5294, Acc: 60.83%\n",
      "Epoch 1/3, Batch 18900, Loss: 1.1231, Acc: 60.84%\n",
      "Epoch 1/3, Batch 18910, Loss: 0.6950, Acc: 60.84%\n",
      "Epoch 1/3, Batch 18920, Loss: 0.0443, Acc: 60.85%\n",
      "Epoch 1/3, Batch 18930, Loss: 0.6471, Acc: 60.85%\n",
      "Epoch 1/3, Batch 18940, Loss: 0.9663, Acc: 60.84%\n",
      "Epoch 1/3, Batch 18950, Loss: 1.2302, Acc: 60.84%\n",
      "Epoch 1/3, Batch 18960, Loss: 0.0896, Acc: 60.85%\n",
      "Epoch 1/3, Batch 18970, Loss: 0.0720, Acc: 60.85%\n",
      "Epoch 1/3, Batch 18980, Loss: 1.6995, Acc: 60.84%\n",
      "Epoch 1/3, Batch 18990, Loss: 1.2364, Acc: 60.83%\n",
      "Epoch 1/3, Batch 19000, Loss: 0.6361, Acc: 60.83%\n",
      "Epoch 1/3, Batch 19010, Loss: 0.4423, Acc: 60.82%\n",
      "Epoch 1/3, Batch 19020, Loss: 0.0875, Acc: 60.83%\n",
      "Epoch 1/3, Batch 19030, Loss: 0.0054, Acc: 60.84%\n",
      "Epoch 1/3, Batch 19040, Loss: 0.7681, Acc: 60.85%\n",
      "Epoch 1/3, Batch 19050, Loss: 1.4866, Acc: 60.85%\n",
      "Epoch 1/3, Batch 19060, Loss: 1.2606, Acc: 60.85%\n",
      "Epoch 1/3, Batch 19070, Loss: 0.0768, Acc: 60.85%\n",
      "Epoch 1/3, Batch 19080, Loss: 0.0396, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19090, Loss: 1.4474, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19100, Loss: 0.4235, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19110, Loss: 0.3388, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19120, Loss: 1.4783, Acc: 60.85%\n",
      "Epoch 1/3, Batch 19130, Loss: 0.2892, Acc: 60.85%\n",
      "Epoch 1/3, Batch 19140, Loss: 0.1187, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19150, Loss: 0.5146, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19160, Loss: 0.8192, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19170, Loss: 4.1773, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19180, Loss: 1.0766, Acc: 60.85%\n",
      "Epoch 1/3, Batch 19190, Loss: 0.0775, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19200, Loss: 0.0947, Acc: 60.85%\n",
      "Epoch 1/3, Batch 19210, Loss: 0.7559, Acc: 60.85%\n",
      "Epoch 1/3, Batch 19220, Loss: 0.6833, Acc: 60.87%\n",
      "Epoch 1/3, Batch 19230, Loss: 0.2613, Acc: 60.87%\n",
      "Epoch 1/3, Batch 19240, Loss: 1.6190, Acc: 60.85%\n",
      "Epoch 1/3, Batch 19250, Loss: 0.5685, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19260, Loss: 0.7568, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19270, Loss: 0.3097, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19280, Loss: 0.8325, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19290, Loss: 0.5180, Acc: 60.85%\n",
      "Epoch 1/3, Batch 19300, Loss: 0.4201, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19310, Loss: 0.7389, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19320, Loss: 0.1981, Acc: 60.87%\n",
      "Epoch 1/3, Batch 19330, Loss: 1.6845, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19340, Loss: 0.7213, Acc: 60.87%\n",
      "Epoch 1/3, Batch 19350, Loss: 2.3976, Acc: 60.87%\n",
      "Epoch 1/3, Batch 19360, Loss: 0.0484, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19370, Loss: 0.8293, Acc: 60.85%\n",
      "Epoch 1/3, Batch 19380, Loss: 0.1186, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19390, Loss: 1.0420, Acc: 60.87%\n",
      "Epoch 1/3, Batch 19400, Loss: 0.0255, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19410, Loss: 0.1145, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19420, Loss: 0.0669, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19430, Loss: 0.9384, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19440, Loss: 0.8530, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19450, Loss: 3.9083, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19460, Loss: 0.8468, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19470, Loss: 0.0425, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19480, Loss: 0.0111, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19490, Loss: 0.1713, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19500, Loss: 0.7205, Acc: 60.85%\n",
      "Epoch 1/3, Batch 19510, Loss: 0.3542, Acc: 60.87%\n",
      "Epoch 1/3, Batch 19520, Loss: 0.5087, Acc: 60.87%\n",
      "Epoch 1/3, Batch 19530, Loss: 2.5064, Acc: 60.87%\n",
      "Epoch 1/3, Batch 19540, Loss: 0.7145, Acc: 60.87%\n",
      "Epoch 1/3, Batch 19550, Loss: 0.7357, Acc: 60.87%\n",
      "Epoch 1/3, Batch 19560, Loss: 0.9406, Acc: 60.87%\n",
      "Epoch 1/3, Batch 19570, Loss: 0.7812, Acc: 60.87%\n",
      "Epoch 1/3, Batch 19580, Loss: 2.0684, Acc: 60.87%\n",
      "Epoch 1/3, Batch 19590, Loss: 0.3903, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19600, Loss: 0.2587, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19610, Loss: 0.1809, Acc: 60.87%\n",
      "Epoch 1/3, Batch 19620, Loss: 1.4347, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19630, Loss: 0.8013, Acc: 60.87%\n",
      "Epoch 1/3, Batch 19640, Loss: 0.7662, Acc: 60.87%\n",
      "Epoch 1/3, Batch 19650, Loss: 1.4779, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19660, Loss: 0.7171, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19670, Loss: 0.2899, Acc: 60.87%\n",
      "Epoch 1/3, Batch 19680, Loss: 3.6490, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19690, Loss: 0.2335, Acc: 60.87%\n",
      "Epoch 1/3, Batch 19700, Loss: 2.2591, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19710, Loss: 0.8636, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19720, Loss: 0.9659, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19730, Loss: 0.9090, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19740, Loss: 0.0031, Acc: 60.85%\n",
      "Epoch 1/3, Batch 19750, Loss: 0.6643, Acc: 60.85%\n",
      "Epoch 1/3, Batch 19760, Loss: 0.4357, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19770, Loss: 0.0138, Acc: 60.87%\n",
      "Epoch 1/3, Batch 19780, Loss: 0.6354, Acc: 60.87%\n",
      "Epoch 1/3, Batch 19790, Loss: 0.2462, Acc: 60.87%\n",
      "Epoch 1/3, Batch 19800, Loss: 0.0397, Acc: 60.88%\n",
      "Epoch 1/3, Batch 19810, Loss: 0.2424, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19820, Loss: 0.3134, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19830, Loss: 0.6270, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19840, Loss: 0.6665, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19850, Loss: 0.5996, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19860, Loss: 0.0152, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19870, Loss: 0.1713, Acc: 60.85%\n",
      "Epoch 1/3, Batch 19880, Loss: 0.7572, Acc: 60.85%\n",
      "Epoch 1/3, Batch 19890, Loss: 3.2543, Acc: 60.84%\n",
      "Epoch 1/3, Batch 19900, Loss: 1.9428, Acc: 60.84%\n",
      "Epoch 1/3, Batch 19910, Loss: 0.6527, Acc: 60.85%\n",
      "Epoch 1/3, Batch 19920, Loss: 0.9048, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19930, Loss: 1.0309, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19940, Loss: 0.1723, Acc: 60.86%\n",
      "Epoch 1/3, Batch 19950, Loss: 0.0407, Acc: 60.87%\n",
      "Epoch 1/3, Batch 19960, Loss: 0.8677, Acc: 60.88%\n",
      "Epoch 1/3, Batch 19970, Loss: 0.3484, Acc: 60.89%\n",
      "Epoch 1/3, Batch 19980, Loss: 1.9987, Acc: 60.88%\n",
      "Epoch 1/3, Batch 19990, Loss: 0.5923, Acc: 60.89%\n",
      "Epoch 1/3, Batch 20000, Loss: 0.8007, Acc: 60.89%\n",
      "Epoch 1/3, Batch 20010, Loss: 0.9887, Acc: 60.89%\n",
      "Epoch 1/3, Batch 20020, Loss: 0.9288, Acc: 60.90%\n",
      "Epoch 1/3, Batch 20030, Loss: 0.3625, Acc: 60.90%\n",
      "Epoch 1/3, Batch 20040, Loss: 0.4662, Acc: 60.90%\n",
      "Epoch 1/3, Batch 20050, Loss: 0.3106, Acc: 60.91%\n",
      "Epoch 1/3, Batch 20060, Loss: 0.0015, Acc: 60.92%\n",
      "Epoch 1/3, Batch 20070, Loss: 0.0132, Acc: 60.92%\n",
      "Epoch 1/3, Batch 20080, Loss: 0.3509, Acc: 60.92%\n",
      "Epoch 1/3, Batch 20090, Loss: 0.9922, Acc: 60.91%\n",
      "Epoch 1/3, Batch 20100, Loss: 0.0896, Acc: 60.91%\n",
      "Epoch 1/3, Batch 20110, Loss: 0.0279, Acc: 60.90%\n",
      "Epoch 1/3, Batch 20120, Loss: 1.2055, Acc: 60.90%\n",
      "Epoch 1/3, Batch 20130, Loss: 1.0273, Acc: 60.90%\n",
      "Epoch 1/3, Batch 20140, Loss: 0.6338, Acc: 60.91%\n",
      "Epoch 1/3, Batch 20150, Loss: 0.0283, Acc: 60.90%\n",
      "Epoch 1/3, Batch 20160, Loss: 0.0963, Acc: 60.90%\n",
      "Epoch 1/3, Batch 20170, Loss: 0.9921, Acc: 60.89%\n",
      "Epoch 1/3, Batch 20180, Loss: 0.1045, Acc: 60.90%\n",
      "Epoch 1/3, Batch 20190, Loss: 0.0013, Acc: 60.90%\n",
      "Epoch 1/3, Batch 20200, Loss: 0.3822, Acc: 60.91%\n",
      "Epoch 1/3, Batch 20210, Loss: 0.0566, Acc: 60.91%\n",
      "Epoch 1/3, Batch 20220, Loss: 0.6900, Acc: 60.91%\n",
      "Epoch 1/3, Batch 20230, Loss: 0.4792, Acc: 60.91%\n",
      "Epoch 1/3, Batch 20240, Loss: 0.3426, Acc: 60.92%\n",
      "Epoch 1/3, Batch 20250, Loss: 0.3997, Acc: 60.94%\n",
      "Epoch 1/3, Batch 20260, Loss: 0.1479, Acc: 60.94%\n",
      "Epoch 1/3, Batch 20270, Loss: 0.1481, Acc: 60.95%\n",
      "Epoch 1/3, Batch 20280, Loss: 2.0260, Acc: 60.94%\n",
      "Epoch 1/3, Batch 20290, Loss: 0.1273, Acc: 60.93%\n",
      "Epoch 1/3, Batch 20300, Loss: 1.5137, Acc: 60.94%\n",
      "Epoch 1/3, Batch 20310, Loss: 0.4348, Acc: 60.94%\n",
      "Epoch 1/3, Batch 20320, Loss: 1.2324, Acc: 60.94%\n",
      "Epoch 1/3, Batch 20330, Loss: 0.4423, Acc: 60.95%\n",
      "Epoch 1/3, Batch 20340, Loss: 1.6450, Acc: 60.95%\n",
      "Epoch 1/3, Batch 20350, Loss: 0.4081, Acc: 60.95%\n",
      "Epoch 1/3, Batch 20360, Loss: 0.8701, Acc: 60.95%\n",
      "Epoch 1/3, Batch 20370, Loss: 0.6549, Acc: 60.96%\n",
      "Epoch 1/3, Batch 20380, Loss: 0.5902, Acc: 60.96%\n",
      "Epoch 1/3, Batch 20390, Loss: 1.6620, Acc: 60.96%\n",
      "Epoch 1/3, Batch 20400, Loss: 0.0737, Acc: 60.96%\n",
      "Epoch 1/3, Batch 20410, Loss: 1.0344, Acc: 60.96%\n",
      "Epoch 1/3, Batch 20420, Loss: 1.0770, Acc: 60.97%\n",
      "Epoch 1/3, Batch 20430, Loss: 1.0364, Acc: 60.98%\n",
      "Epoch 1/3, Batch 20440, Loss: 0.3565, Acc: 60.98%\n",
      "Epoch 1/3, Batch 20450, Loss: 0.0172, Acc: 60.98%\n",
      "Epoch 1/3, Batch 20460, Loss: 0.4318, Acc: 60.98%\n",
      "Epoch 1/3, Batch 20470, Loss: 0.2263, Acc: 61.00%\n",
      "Epoch 1/3, Batch 20480, Loss: 0.7071, Acc: 61.00%\n",
      "Epoch 1/3, Batch 20490, Loss: 1.2952, Acc: 60.99%\n",
      "Epoch 1/3, Batch 20500, Loss: 1.1456, Acc: 61.00%\n",
      "Epoch 1/3, Batch 20510, Loss: 0.0505, Acc: 61.01%\n",
      "Epoch 1/3, Batch 20520, Loss: 0.4547, Acc: 61.01%\n",
      "Epoch 1/3, Batch 20530, Loss: 0.3808, Acc: 61.02%\n",
      "Epoch 1/3, Batch 20540, Loss: 0.4668, Acc: 61.01%\n",
      "Epoch 1/3, Batch 20550, Loss: 1.5403, Acc: 61.01%\n",
      "Epoch 1/3, Batch 20560, Loss: 1.1566, Acc: 61.01%\n",
      "Epoch 1/3, Batch 20570, Loss: 0.2445, Acc: 61.01%\n",
      "Epoch 1/3, Batch 20580, Loss: 0.7273, Acc: 61.00%\n",
      "Epoch 1/3, Batch 20590, Loss: 0.3421, Acc: 60.99%\n",
      "Epoch 1/3, Batch 20600, Loss: 0.1475, Acc: 61.00%\n",
      "Epoch 1/3, Batch 20610, Loss: 1.5023, Acc: 60.99%\n",
      "Epoch 1/3, Batch 20620, Loss: 0.0191, Acc: 60.99%\n",
      "Epoch 1/3, Batch 20630, Loss: 0.2879, Acc: 60.99%\n",
      "Epoch 1/3, Batch 20640, Loss: 0.0046, Acc: 60.99%\n",
      "Epoch 1/3, Batch 20650, Loss: 0.2938, Acc: 61.00%\n",
      "Epoch 1/3, Batch 20660, Loss: 1.5115, Acc: 60.99%\n",
      "Epoch 1/3, Batch 20670, Loss: 0.0023, Acc: 60.99%\n",
      "Epoch 1/3, Batch 20680, Loss: 0.0091, Acc: 60.99%\n",
      "Epoch 1/3, Batch 20690, Loss: 0.3503, Acc: 60.99%\n",
      "Epoch 1/3, Batch 20700, Loss: 0.0260, Acc: 61.00%\n",
      "Epoch 1/3, Batch 20710, Loss: 0.0134, Acc: 61.01%\n",
      "Epoch 1/3, Batch 20720, Loss: 0.0065, Acc: 61.00%\n",
      "Epoch 1/3, Batch 20730, Loss: 0.8567, Acc: 61.00%\n",
      "Epoch 1/3, Batch 20740, Loss: 1.0728, Acc: 61.00%\n",
      "Epoch 1/3, Batch 20750, Loss: 0.5923, Acc: 61.01%\n",
      "Epoch 1/3, Batch 20760, Loss: 1.4577, Acc: 61.01%\n",
      "Epoch 1/3, Batch 20770, Loss: 0.8181, Acc: 61.01%\n",
      "Epoch 1/3, Batch 20780, Loss: 0.3076, Acc: 61.01%\n",
      "Epoch 1/3, Batch 20790, Loss: 1.0004, Acc: 61.02%\n",
      "Epoch 1/3, Batch 20800, Loss: 0.3786, Acc: 61.03%\n",
      "Epoch 1/3, Batch 20810, Loss: 0.4334, Acc: 61.03%\n",
      "Epoch 1/3, Batch 20820, Loss: 0.5043, Acc: 61.03%\n",
      "Epoch 1/3, Batch 20830, Loss: 1.0284, Acc: 61.04%\n",
      "Epoch 1/3, Batch 20840, Loss: 0.0208, Acc: 61.04%\n",
      "Epoch 1/3, Batch 20850, Loss: 0.9707, Acc: 61.04%\n",
      "Epoch 1/3, Batch 20860, Loss: 0.2095, Acc: 61.05%\n",
      "Epoch 1/3, Batch 20870, Loss: 0.1993, Acc: 61.05%\n",
      "Epoch 1/3, Batch 20880, Loss: 0.7738, Acc: 61.03%\n",
      "Epoch 1/3, Batch 20890, Loss: 2.0846, Acc: 61.02%\n",
      "Epoch 1/3, Batch 20900, Loss: 0.1812, Acc: 61.03%\n",
      "Epoch 1/3, Batch 20910, Loss: 0.3150, Acc: 61.03%\n",
      "Epoch 1/3, Batch 20920, Loss: 0.4591, Acc: 61.04%\n",
      "Epoch 1/3, Batch 20930, Loss: 0.0009, Acc: 61.04%\n",
      "Epoch 1/3, Batch 20940, Loss: 0.0914, Acc: 61.04%\n",
      "Epoch 1/3, Batch 20950, Loss: 0.0032, Acc: 61.03%\n",
      "Epoch 1/3, Batch 20960, Loss: 0.0285, Acc: 61.03%\n",
      "Epoch 1/3, Batch 20970, Loss: 0.1516, Acc: 61.02%\n",
      "Epoch 1/3, Batch 20980, Loss: 0.5473, Acc: 61.03%\n",
      "Epoch 1/3, Batch 20990, Loss: 0.5302, Acc: 61.02%\n",
      "Epoch 1/3, Batch 21000, Loss: 0.3879, Acc: 61.03%\n",
      "Epoch 1/3, Batch 21010, Loss: 1.0355, Acc: 61.03%\n",
      "Epoch 1/3, Batch 21020, Loss: 0.4992, Acc: 61.04%\n",
      "Epoch 1/3, Batch 21030, Loss: 0.5625, Acc: 61.04%\n",
      "Epoch 1/3, Batch 21040, Loss: 0.0149, Acc: 61.04%\n",
      "Epoch 1/3, Batch 21050, Loss: 0.0732, Acc: 61.04%\n",
      "Epoch 1/3, Batch 21060, Loss: 0.3291, Acc: 61.04%\n",
      "Epoch 1/3, Batch 21070, Loss: 0.0272, Acc: 61.04%\n",
      "Epoch 1/3, Batch 21080, Loss: 2.1333, Acc: 61.05%\n",
      "Epoch 1/3, Batch 21090, Loss: 2.1016, Acc: 61.03%\n",
      "Epoch 1/3, Batch 21100, Loss: 0.5827, Acc: 61.04%\n",
      "Epoch 1/3, Batch 21110, Loss: 0.0302, Acc: 61.03%\n",
      "Epoch 1/3, Batch 21120, Loss: 0.1727, Acc: 61.02%\n",
      "Epoch 1/3, Batch 21130, Loss: 0.4026, Acc: 61.03%\n",
      "Epoch 1/3, Batch 21140, Loss: 0.0350, Acc: 61.03%\n",
      "Epoch 1/3, Batch 21150, Loss: 1.2240, Acc: 61.02%\n",
      "Epoch 1/3, Batch 21160, Loss: 0.6748, Acc: 61.02%\n",
      "Epoch 1/3, Batch 21170, Loss: 0.2179, Acc: 61.01%\n",
      "Epoch 1/3, Batch 21180, Loss: 0.0619, Acc: 61.01%\n",
      "Epoch 1/3, Batch 21190, Loss: 0.0061, Acc: 61.02%\n",
      "Epoch 1/3, Batch 21200, Loss: 0.0541, Acc: 61.01%\n",
      "Epoch 1/3, Batch 21210, Loss: 0.2333, Acc: 61.02%\n",
      "Epoch 1/3, Batch 21220, Loss: 0.5448, Acc: 61.02%\n",
      "Epoch 1/3, Batch 21230, Loss: 0.0494, Acc: 61.03%\n",
      "Epoch 1/3, Batch 21240, Loss: 0.1210, Acc: 61.03%\n",
      "Epoch 1/3, Batch 21250, Loss: 0.2983, Acc: 61.04%\n",
      "Epoch 1/3, Batch 21260, Loss: 1.1670, Acc: 61.03%\n",
      "Epoch 1/3, Batch 21270, Loss: 2.0665, Acc: 61.03%\n",
      "Epoch 1/3, Batch 21280, Loss: 0.3360, Acc: 61.03%\n",
      "Epoch 1/3, Batch 21290, Loss: 0.0336, Acc: 61.03%\n",
      "Epoch 1/3, Batch 21300, Loss: 0.0045, Acc: 61.04%\n",
      "Epoch 1/3, Batch 21310, Loss: 0.2744, Acc: 61.04%\n",
      "Epoch 1/3, Batch 21320, Loss: 1.0514, Acc: 61.05%\n",
      "Epoch 1/3, Batch 21330, Loss: 0.4073, Acc: 61.05%\n",
      "Epoch 1/3, Batch 21340, Loss: 0.0146, Acc: 61.06%\n",
      "Epoch 1/3, Batch 21350, Loss: 0.8123, Acc: 61.06%\n",
      "Epoch 1/3, Batch 21360, Loss: 0.1283, Acc: 61.06%\n",
      "Epoch 1/3, Batch 21370, Loss: 0.0765, Acc: 61.06%\n",
      "Epoch 1/3, Batch 21380, Loss: 0.7247, Acc: 61.04%\n",
      "Epoch 1/3, Batch 21390, Loss: 1.4760, Acc: 61.04%\n",
      "Epoch 1/3, Batch 21400, Loss: 1.1606, Acc: 61.03%\n",
      "Epoch 1/3, Batch 21410, Loss: 0.6002, Acc: 61.04%\n",
      "Epoch 1/3, Batch 21420, Loss: 0.4090, Acc: 61.03%\n",
      "Epoch 1/3, Batch 21430, Loss: 0.3770, Acc: 61.04%\n",
      "Epoch 1/3, Batch 21440, Loss: 1.4103, Acc: 61.05%\n",
      "Epoch 1/3, Batch 21450, Loss: 0.4101, Acc: 61.05%\n",
      "Epoch 1/3, Batch 21460, Loss: 0.0140, Acc: 61.05%\n",
      "Epoch 1/3, Batch 21470, Loss: 0.0534, Acc: 61.06%\n",
      "Epoch 1/3, Batch 21480, Loss: 0.1515, Acc: 61.07%\n",
      "Epoch 1/3, Batch 21490, Loss: 0.1025, Acc: 61.08%\n",
      "Epoch 1/3, Batch 21500, Loss: 0.6215, Acc: 61.09%\n",
      "Epoch 1/3, Batch 21510, Loss: 0.0431, Acc: 61.10%\n",
      "Epoch 1/3, Batch 21520, Loss: 1.1253, Acc: 61.09%\n",
      "Epoch 1/3, Batch 21530, Loss: 1.3390, Acc: 61.08%\n",
      "Epoch 1/3, Batch 21540, Loss: 0.7645, Acc: 61.06%\n",
      "Epoch 1/3, Batch 21550, Loss: 0.0560, Acc: 61.06%\n",
      "Epoch 1/3, Batch 21560, Loss: 0.3559, Acc: 61.05%\n",
      "Epoch 1/3, Batch 21570, Loss: 1.3610, Acc: 61.06%\n",
      "Epoch 1/3, Batch 21580, Loss: 1.0742, Acc: 61.05%\n",
      "Epoch 1/3, Batch 21590, Loss: 1.1648, Acc: 61.04%\n",
      "Epoch 1/3, Batch 21600, Loss: 0.1117, Acc: 61.05%\n",
      "Epoch 1/3, Batch 21610, Loss: 0.3008, Acc: 61.05%\n",
      "Epoch 1/3, Batch 21620, Loss: 0.5778, Acc: 61.06%\n",
      "Epoch 1/3, Batch 21630, Loss: 0.0528, Acc: 61.06%\n",
      "Epoch 1/3, Batch 21640, Loss: 1.2426, Acc: 61.05%\n",
      "Epoch 1/3, Batch 21650, Loss: 0.5719, Acc: 61.06%\n",
      "Epoch 1/3, Batch 21660, Loss: 0.0511, Acc: 61.07%\n",
      "Epoch 1/3, Batch 21670, Loss: 1.4319, Acc: 61.08%\n",
      "Epoch 1/3, Batch 21680, Loss: 0.1949, Acc: 61.08%\n",
      "Epoch 1/3, Batch 21690, Loss: 0.0102, Acc: 61.09%\n",
      "Epoch 1/3, Batch 21700, Loss: 0.1462, Acc: 61.10%\n",
      "Epoch 1/3, Batch 21710, Loss: 0.0214, Acc: 61.11%\n",
      "Epoch 1/3, Batch 21720, Loss: 0.3329, Acc: 61.11%\n",
      "Epoch 1/3, Batch 21730, Loss: 0.0504, Acc: 61.12%\n",
      "Epoch 1/3, Batch 21740, Loss: 4.6520, Acc: 61.12%\n",
      "Epoch 1/3, Batch 21750, Loss: 0.9736, Acc: 61.12%\n",
      "Epoch 1/3, Batch 21760, Loss: 0.0019, Acc: 61.12%\n",
      "Epoch 1/3, Batch 21770, Loss: 2.2784, Acc: 61.12%\n",
      "Epoch 1/3, Batch 21780, Loss: 0.0679, Acc: 61.12%\n",
      "Epoch 1/3, Batch 21790, Loss: 0.1452, Acc: 61.11%\n",
      "Epoch 1/3, Batch 21800, Loss: 1.3585, Acc: 61.11%\n",
      "Epoch 1/3, Batch 21810, Loss: 0.2434, Acc: 61.10%\n",
      "Epoch 1/3, Batch 21820, Loss: 1.1176, Acc: 61.10%\n",
      "Epoch 1/3, Batch 21830, Loss: 1.5205, Acc: 61.09%\n",
      "Epoch 1/3, Batch 21840, Loss: 1.0112, Acc: 61.09%\n",
      "Epoch 1/3, Batch 21850, Loss: 0.1179, Acc: 61.10%\n",
      "Epoch 1/3, Batch 21860, Loss: 0.0184, Acc: 61.10%\n",
      "Epoch 1/3, Batch 21870, Loss: 0.4089, Acc: 61.10%\n",
      "Epoch 1/3, Batch 21880, Loss: 1.1827, Acc: 61.10%\n",
      "Epoch 1/3, Batch 21890, Loss: 0.0091, Acc: 61.11%\n",
      "Epoch 1/3, Batch 21900, Loss: 0.4413, Acc: 61.09%\n",
      "Epoch 1/3, Batch 21910, Loss: 0.0888, Acc: 61.10%\n",
      "Epoch 1/3, Batch 21920, Loss: 0.1297, Acc: 61.11%\n",
      "Epoch 1/3, Batch 21930, Loss: 1.3111, Acc: 61.10%\n",
      "Epoch 1/3, Batch 21940, Loss: 0.3937, Acc: 61.09%\n",
      "Epoch 1/3, Batch 21950, Loss: 0.4918, Acc: 61.10%\n",
      "Epoch 1/3, Batch 21960, Loss: 0.5750, Acc: 61.10%\n",
      "Epoch 1/3, Batch 21970, Loss: 0.3301, Acc: 61.11%\n",
      "Epoch 1/3, Batch 21980, Loss: 0.7962, Acc: 61.12%\n",
      "Epoch 1/3, Batch 21990, Loss: 0.0127, Acc: 61.11%\n",
      "Epoch 1/3, Batch 22000, Loss: 0.0026, Acc: 61.10%\n",
      "Epoch 1/3, Batch 22010, Loss: 0.3715, Acc: 61.11%\n",
      "Epoch 1/3, Batch 22020, Loss: 3.8879, Acc: 61.10%\n",
      "Epoch 1/3, Batch 22030, Loss: 2.3489, Acc: 61.09%\n",
      "Epoch 1/3, Batch 22040, Loss: 0.0946, Acc: 61.09%\n",
      "Epoch 1/3, Batch 22050, Loss: 1.7975, Acc: 61.09%\n",
      "Epoch 1/3, Batch 22060, Loss: 0.0461, Acc: 61.10%\n",
      "Epoch 1/3, Batch 22070, Loss: 0.6386, Acc: 61.10%\n",
      "Epoch 1/3, Batch 22080, Loss: 0.4961, Acc: 61.10%\n",
      "Epoch 1/3, Batch 22090, Loss: 1.3337, Acc: 61.11%\n",
      "Epoch 1/3, Batch 22100, Loss: 0.6857, Acc: 61.11%\n",
      "Epoch 1/3, Batch 22110, Loss: 0.0593, Acc: 61.11%\n",
      "Epoch 1/3, Batch 22120, Loss: 0.0669, Acc: 61.10%\n",
      "Epoch 1/3, Batch 22130, Loss: 0.0756, Acc: 61.10%\n",
      "Epoch 1/3, Batch 22140, Loss: 0.8820, Acc: 61.10%\n",
      "Epoch 1/3, Batch 22150, Loss: 1.5413, Acc: 61.10%\n",
      "Epoch 1/3, Batch 22160, Loss: 0.5412, Acc: 61.09%\n",
      "Epoch 1/3, Batch 22170, Loss: 0.4985, Acc: 61.08%\n",
      "Epoch 1/3, Batch 22180, Loss: 2.0077, Acc: 61.07%\n",
      "Epoch 1/3, Batch 22190, Loss: 0.9825, Acc: 61.07%\n",
      "Epoch 1/3, Batch 22200, Loss: 0.1449, Acc: 61.09%\n",
      "Epoch 1/3, Batch 22210, Loss: 1.1751, Acc: 61.07%\n",
      "Epoch 1/3, Batch 22220, Loss: 0.6196, Acc: 61.09%\n",
      "Epoch 1/3, Batch 22230, Loss: 0.0615, Acc: 61.08%\n",
      "Epoch 1/3, Batch 22240, Loss: 0.8919, Acc: 61.08%\n",
      "Epoch 1/3, Batch 22250, Loss: 2.5330, Acc: 61.07%\n",
      "Epoch 1/3, Batch 22260, Loss: 0.5608, Acc: 61.07%\n",
      "Epoch 1/3, Batch 22270, Loss: 0.0141, Acc: 61.08%\n",
      "Epoch 1/3, Batch 22280, Loss: 0.2048, Acc: 61.09%\n",
      "Epoch 1/3, Batch 22290, Loss: 0.5734, Acc: 61.08%\n",
      "Epoch 1/3, Batch 22300, Loss: 1.1390, Acc: 61.08%\n",
      "Epoch 1/3, Batch 22310, Loss: 0.3468, Acc: 61.09%\n",
      "Epoch 1/3, Batch 22320, Loss: 0.1476, Acc: 61.10%\n",
      "Epoch 1/3, Batch 22330, Loss: 0.0224, Acc: 61.10%\n",
      "Epoch 1/3, Batch 22340, Loss: 0.3797, Acc: 61.12%\n",
      "Epoch 1/3, Batch 22350, Loss: 0.0355, Acc: 61.12%\n",
      "Epoch 1/3, Batch 22360, Loss: 0.0418, Acc: 61.12%\n",
      "Epoch 1/3, Batch 22370, Loss: 0.0412, Acc: 61.12%\n",
      "Epoch 1/3, Batch 22380, Loss: 0.3365, Acc: 61.11%\n",
      "Epoch 1/3, Batch 22390, Loss: 0.3985, Acc: 61.11%\n",
      "Epoch 1/3, Batch 22400, Loss: 0.8476, Acc: 61.11%\n",
      "Epoch 1/3, Batch 22410, Loss: 0.8919, Acc: 61.11%\n",
      "Epoch 1/3, Batch 22420, Loss: 0.0749, Acc: 61.10%\n",
      "Epoch 1/3, Batch 22430, Loss: 0.0198, Acc: 61.10%\n",
      "Epoch 1/3, Batch 22440, Loss: 0.5002, Acc: 61.10%\n",
      "Epoch 1/3, Batch 22450, Loss: 0.7154, Acc: 61.10%\n",
      "Epoch 1/3, Batch 22460, Loss: 0.5726, Acc: 61.09%\n",
      "Epoch 1/3, Batch 22470, Loss: 0.3233, Acc: 61.10%\n",
      "Epoch 1/3, Batch 22480, Loss: 0.8122, Acc: 61.11%\n",
      "Epoch 1/3, Batch 22490, Loss: 1.1773, Acc: 61.12%\n",
      "Epoch 1/3, Batch 22500, Loss: 1.7615, Acc: 61.11%\n",
      "Epoch 1/3, Batch 22510, Loss: 0.2456, Acc: 61.11%\n",
      "Epoch 1/3, Batch 22520, Loss: 2.2971, Acc: 61.11%\n",
      "Epoch 1/3, Batch 22530, Loss: 0.7508, Acc: 61.11%\n",
      "Epoch 1/3, Batch 22540, Loss: 0.6686, Acc: 61.12%\n",
      "Epoch 1/3, Batch 22550, Loss: 0.0747, Acc: 61.13%\n",
      "Epoch 1/3, Batch 22560, Loss: 1.4985, Acc: 61.12%\n",
      "Epoch 1/3, Batch 22570, Loss: 0.0639, Acc: 61.13%\n",
      "Epoch 1/3, Batch 22580, Loss: 3.1039, Acc: 61.12%\n",
      "Epoch 1/3, Batch 22590, Loss: 0.1531, Acc: 61.13%\n",
      "Epoch 1/3, Batch 22600, Loss: 1.1482, Acc: 61.13%\n",
      "Epoch 1/3, Batch 22610, Loss: 3.7103, Acc: 61.12%\n",
      "Epoch 1/3, Batch 22620, Loss: 0.0987, Acc: 61.12%\n",
      "Epoch 1/3, Batch 22630, Loss: 0.5733, Acc: 61.12%\n",
      "Epoch 1/3, Batch 22640, Loss: 0.0305, Acc: 61.12%\n",
      "Epoch 1/3, Batch 22650, Loss: 1.0963, Acc: 61.13%\n",
      "Epoch 1/3, Batch 22660, Loss: 0.5235, Acc: 61.14%\n",
      "Epoch 1/3, Batch 22670, Loss: 0.4149, Acc: 61.13%\n",
      "Epoch 1/3, Batch 22680, Loss: 0.1363, Acc: 61.13%\n",
      "Epoch 1/3, Batch 22690, Loss: 0.2222, Acc: 61.14%\n",
      "Epoch 1/3, Batch 22700, Loss: 0.0017, Acc: 61.14%\n",
      "Epoch 1/3, Batch 22710, Loss: 0.0885, Acc: 61.14%\n",
      "Epoch 1/3, Batch 22720, Loss: 0.2610, Acc: 61.14%\n",
      "Epoch 1/3, Batch 22730, Loss: 0.3328, Acc: 61.14%\n",
      "Epoch 1/3, Batch 22740, Loss: 0.4960, Acc: 61.14%\n",
      "Epoch 1/3, Batch 22750, Loss: 0.5936, Acc: 61.14%\n",
      "Epoch 1/3, Batch 22760, Loss: 0.5439, Acc: 61.15%\n",
      "Epoch 1/3, Batch 22770, Loss: 1.0347, Acc: 61.16%\n",
      "Epoch 1/3, Batch 22780, Loss: 0.1716, Acc: 61.16%\n",
      "Epoch 1/3, Batch 22790, Loss: 0.4002, Acc: 61.17%\n",
      "Epoch 1/3, Batch 22800, Loss: 1.8261, Acc: 61.16%\n",
      "Epoch 1/3, Batch 22810, Loss: 0.6346, Acc: 61.16%\n",
      "Epoch 1/3, Batch 22820, Loss: 3.5508, Acc: 61.16%\n",
      "Epoch 1/3, Batch 22830, Loss: 0.4277, Acc: 61.16%\n",
      "Epoch 1/3, Batch 22840, Loss: 1.2972, Acc: 61.16%\n",
      "Epoch 1/3, Batch 22850, Loss: 1.5233, Acc: 61.17%\n",
      "Epoch 1/3, Batch 22860, Loss: 0.8845, Acc: 61.17%\n",
      "Epoch 1/3, Batch 22870, Loss: 0.7188, Acc: 61.18%\n",
      "Epoch 1/3, Batch 22880, Loss: 0.0123, Acc: 61.19%\n",
      "Epoch 1/3, Batch 22890, Loss: 0.0166, Acc: 61.20%\n",
      "Epoch 1/3, Batch 22900, Loss: 0.5944, Acc: 61.20%\n",
      "Epoch 1/3, Batch 22910, Loss: 0.2665, Acc: 61.21%\n",
      "Epoch 1/3, Batch 22920, Loss: 0.9794, Acc: 61.21%\n",
      "Epoch 1/3, Batch 22930, Loss: 0.2720, Acc: 61.21%\n",
      "Epoch 1/3, Batch 22940, Loss: 0.0202, Acc: 61.21%\n",
      "Epoch 1/3, Batch 22950, Loss: 0.0519, Acc: 61.21%\n",
      "Epoch 1/3, Batch 22960, Loss: 0.5262, Acc: 61.21%\n",
      "Epoch 1/3, Batch 22970, Loss: 0.2121, Acc: 61.22%\n",
      "Epoch 1/3, Batch 22980, Loss: 0.3611, Acc: 61.22%\n",
      "Epoch 1/3, Batch 22990, Loss: 0.0944, Acc: 61.24%\n",
      "Epoch 1/3, Batch 23000, Loss: 1.2202, Acc: 61.24%\n",
      "Epoch 1/3, Batch 23010, Loss: 0.5326, Acc: 61.24%\n",
      "Epoch 1/3, Batch 23020, Loss: 0.4054, Acc: 61.24%\n",
      "Epoch 1/3, Batch 23030, Loss: 0.4945, Acc: 61.24%\n",
      "Epoch 1/3, Batch 23040, Loss: 0.5960, Acc: 61.25%\n",
      "Epoch 1/3, Batch 23050, Loss: 1.0638, Acc: 61.26%\n",
      "Epoch 1/3, Batch 23060, Loss: 0.0038, Acc: 61.27%\n",
      "Epoch 1/3, Batch 23070, Loss: 2.2408, Acc: 61.27%\n",
      "Epoch 1/3, Batch 23080, Loss: 0.9166, Acc: 61.26%\n",
      "Epoch 1/3, Batch 23090, Loss: 0.3296, Acc: 61.26%\n",
      "Epoch 1/3, Batch 23100, Loss: 1.5289, Acc: 61.27%\n",
      "Epoch 1/3, Batch 23110, Loss: 1.1039, Acc: 61.26%\n",
      "Epoch 1/3, Batch 23120, Loss: 0.2848, Acc: 61.27%\n",
      "Epoch 1/3, Batch 23130, Loss: 0.9254, Acc: 61.26%\n",
      "Epoch 1/3, Batch 23140, Loss: 0.0286, Acc: 61.25%\n",
      "Epoch 1/3, Batch 23150, Loss: 1.6964, Acc: 61.24%\n",
      "Epoch 1/3, Batch 23160, Loss: 0.8703, Acc: 61.24%\n",
      "Epoch 1/3, Batch 23170, Loss: 0.7209, Acc: 61.24%\n",
      "Epoch 1/3, Batch 23180, Loss: 0.2981, Acc: 61.25%\n",
      "Epoch 1/3, Batch 23190, Loss: 1.3262, Acc: 61.23%\n",
      "Epoch 1/3, Batch 23200, Loss: 0.4640, Acc: 61.23%\n",
      "Epoch 1/3, Batch 23210, Loss: 1.9313, Acc: 61.23%\n",
      "Epoch 1/3, Batch 23220, Loss: 0.3482, Acc: 61.25%\n",
      "Epoch 1/3, Batch 23230, Loss: 1.2397, Acc: 61.25%\n",
      "Epoch 1/3, Batch 23240, Loss: 1.2498, Acc: 61.25%\n",
      "Epoch 1/3, Batch 23250, Loss: 2.1344, Acc: 61.26%\n",
      "Epoch 1/3, Batch 23260, Loss: 0.3367, Acc: 61.26%\n",
      "Epoch 1/3, Batch 23270, Loss: 0.0883, Acc: 61.26%\n",
      "Epoch 1/3, Batch 23280, Loss: 0.2254, Acc: 61.26%\n",
      "Epoch 1/3, Batch 23290, Loss: 0.8294, Acc: 61.26%\n",
      "Epoch 1/3, Batch 23300, Loss: 0.1175, Acc: 61.27%\n",
      "Epoch 1/3, Batch 23310, Loss: 0.7159, Acc: 61.26%\n",
      "Epoch 1/3, Batch 23320, Loss: 1.5145, Acc: 61.27%\n",
      "Epoch 1/3, Batch 23330, Loss: 0.0372, Acc: 61.29%\n",
      "Epoch 1/3, Batch 23340, Loss: 0.7740, Acc: 61.28%\n",
      "Epoch 1/3, Batch 23350, Loss: 0.8403, Acc: 61.29%\n",
      "Epoch 1/3, Batch 23360, Loss: 0.5805, Acc: 61.29%\n",
      "Epoch 1/3, Batch 23370, Loss: 0.9326, Acc: 61.29%\n",
      "Epoch 1/3, Batch 23380, Loss: 0.0366, Acc: 61.29%\n",
      "Epoch 1/3, Batch 23390, Loss: 0.0494, Acc: 61.29%\n",
      "Epoch 1/3, Batch 23400, Loss: 0.8258, Acc: 61.28%\n",
      "Epoch 1/3, Batch 23410, Loss: 1.5336, Acc: 61.28%\n",
      "Epoch 1/3, Batch 23420, Loss: 0.8981, Acc: 61.27%\n",
      "Epoch 1/3, Batch 23430, Loss: 0.7959, Acc: 61.26%\n",
      "Epoch 1/3, Batch 23440, Loss: 0.3589, Acc: 61.25%\n",
      "Epoch 1/3, Batch 23450, Loss: 0.0441, Acc: 61.25%\n",
      "Epoch 1/3, Batch 23460, Loss: 1.5597, Acc: 61.25%\n",
      "Epoch 1/3, Batch 23470, Loss: 0.6160, Acc: 61.25%\n",
      "Epoch 1/3, Batch 23480, Loss: 0.0182, Acc: 61.25%\n",
      "Epoch 1/3, Batch 23490, Loss: 1.3758, Acc: 61.26%\n",
      "Epoch 1/3, Batch 23500, Loss: 0.1617, Acc: 61.26%\n",
      "Epoch 1/3, Batch 23510, Loss: 2.2664, Acc: 61.26%\n",
      "Epoch 1/3, Batch 23520, Loss: 0.8627, Acc: 61.26%\n",
      "Epoch 1/3, Batch 23530, Loss: 1.1899, Acc: 61.26%\n",
      "Epoch 1/3, Batch 23540, Loss: 0.4573, Acc: 61.27%\n",
      "Epoch 1/3, Batch 23550, Loss: 2.2254, Acc: 61.27%\n",
      "Epoch 1/3, Batch 23560, Loss: 2.0459, Acc: 61.27%\n",
      "Epoch 1/3, Batch 23570, Loss: 0.9172, Acc: 61.27%\n",
      "Epoch 1/3, Batch 23580, Loss: 0.5063, Acc: 61.29%\n",
      "Epoch 1/3, Batch 23590, Loss: 1.1393, Acc: 61.29%\n",
      "Epoch 1/3, Batch 23600, Loss: 1.2393, Acc: 61.29%\n",
      "Epoch 1/3, Batch 23610, Loss: 0.1995, Acc: 61.30%\n",
      "Epoch 1/3, Batch 23620, Loss: 2.2578, Acc: 61.30%\n",
      "Epoch 1/3, Batch 23630, Loss: 0.0941, Acc: 61.30%\n",
      "Epoch 1/3, Batch 23640, Loss: 1.9320, Acc: 61.30%\n",
      "Epoch 1/3, Batch 23650, Loss: 0.0405, Acc: 61.30%\n",
      "Epoch 1/3, Batch 23660, Loss: 0.0325, Acc: 61.30%\n",
      "Epoch 1/3, Batch 23670, Loss: 1.8183, Acc: 61.30%\n",
      "Epoch 1/3, Batch 23680, Loss: 0.0612, Acc: 61.31%\n",
      "Epoch 1/3, Batch 23690, Loss: 0.2853, Acc: 61.31%\n",
      "Epoch 1/3, Batch 23700, Loss: 0.2582, Acc: 61.31%\n",
      "Epoch 1/3, Batch 23710, Loss: 0.3524, Acc: 61.31%\n",
      "Epoch 1/3, Batch 23720, Loss: 0.5084, Acc: 61.30%\n",
      "Epoch 1/3, Batch 23730, Loss: 0.0211, Acc: 61.30%\n",
      "Epoch 1/3, Batch 23740, Loss: 0.0043, Acc: 61.30%\n",
      "Epoch 1/3, Batch 23750, Loss: 0.8969, Acc: 61.30%\n",
      "Epoch 1/3, Batch 23760, Loss: 0.2763, Acc: 61.30%\n",
      "Epoch 1/3, Batch 23770, Loss: 0.4544, Acc: 61.31%\n",
      "Epoch 1/3, Batch 23780, Loss: 1.5333, Acc: 61.31%\n",
      "Epoch 1/3, Batch 23790, Loss: 0.0802, Acc: 61.30%\n",
      "Epoch 1/3, Batch 23800, Loss: 0.3231, Acc: 61.32%\n",
      "Epoch 1/3, Batch 23810, Loss: 2.1921, Acc: 61.32%\n",
      "Epoch 1/3, Batch 23820, Loss: 1.2381, Acc: 61.32%\n",
      "Epoch 1/3, Batch 23830, Loss: 0.0134, Acc: 61.32%\n",
      "Epoch 1/3, Batch 23840, Loss: 2.5774, Acc: 61.32%\n",
      "Epoch 1/3, Batch 23850, Loss: 0.2278, Acc: 61.33%\n",
      "Epoch 1/3, Batch 23860, Loss: 1.3702, Acc: 61.32%\n",
      "Epoch 1/3, Batch 23870, Loss: 0.3098, Acc: 61.32%\n",
      "Epoch 1/3, Batch 23880, Loss: 0.4942, Acc: 61.32%\n",
      "Epoch 1/3, Batch 23890, Loss: 2.9135, Acc: 61.32%\n",
      "Epoch 1/3, Batch 23900, Loss: 2.6214, Acc: 61.32%\n",
      "Epoch 1/3, Batch 23910, Loss: 0.0167, Acc: 61.33%\n",
      "Epoch 1/3, Batch 23920, Loss: 1.4941, Acc: 61.33%\n",
      "Epoch 1/3, Batch 23930, Loss: 0.5920, Acc: 61.33%\n",
      "Epoch 1/3, Batch 23940, Loss: 0.0657, Acc: 61.35%\n",
      "Epoch 1/3, Batch 23950, Loss: 1.4198, Acc: 61.35%\n",
      "Epoch 1/3, Batch 23960, Loss: 1.8993, Acc: 61.35%\n",
      "Epoch 1/3, Batch 23970, Loss: 0.3710, Acc: 61.35%\n",
      "Epoch 1/3, Batch 23980, Loss: 0.0322, Acc: 61.36%\n",
      "Epoch 1/3, Batch 23990, Loss: 5.1650, Acc: 61.36%\n",
      "Epoch 1/3, Batch 24000, Loss: 0.6315, Acc: 61.37%\n",
      "Epoch 1/3, Batch 24010, Loss: 0.0964, Acc: 61.38%\n",
      "Epoch 1/3, Batch 24020, Loss: 0.8838, Acc: 61.37%\n",
      "Epoch 1/3, Batch 24030, Loss: 0.6825, Acc: 61.37%\n",
      "Epoch 1/3, Batch 24040, Loss: 1.6816, Acc: 61.37%\n",
      "Epoch 1/3, Batch 24050, Loss: 0.7599, Acc: 61.36%\n",
      "Epoch 1/3, Batch 24060, Loss: 0.6053, Acc: 61.36%\n",
      "Epoch 1/3, Batch 24070, Loss: 1.9830, Acc: 61.36%\n",
      "Epoch 1/3, Batch 24080, Loss: 1.5776, Acc: 61.34%\n",
      "Epoch 1/3, Batch 24090, Loss: 0.8528, Acc: 61.34%\n",
      "Epoch 1/3, Batch 24100, Loss: 0.6495, Acc: 61.34%\n",
      "Epoch 1/3, Batch 24110, Loss: 1.2447, Acc: 61.34%\n",
      "Epoch 1/3, Batch 24120, Loss: 0.9821, Acc: 61.33%\n",
      "Epoch 1/3, Batch 24130, Loss: 0.0515, Acc: 61.34%\n",
      "Epoch 1/3, Batch 24140, Loss: 3.2287, Acc: 61.33%\n",
      "Epoch 1/3, Batch 24150, Loss: 0.1783, Acc: 61.33%\n",
      "Epoch 1/3, Batch 24160, Loss: 0.0177, Acc: 61.34%\n",
      "Epoch 1/3, Batch 24170, Loss: 0.9770, Acc: 61.33%\n",
      "Epoch 1/3, Batch 24180, Loss: 1.1586, Acc: 61.34%\n",
      "Epoch 1/3, Batch 24190, Loss: 0.0061, Acc: 61.35%\n",
      "Epoch 1/3, Batch 24200, Loss: 0.7428, Acc: 61.35%\n",
      "Epoch 1/3, Batch 24210, Loss: 1.8874, Acc: 61.35%\n",
      "Epoch 1/3, Batch 24220, Loss: 0.0698, Acc: 61.35%\n",
      "Epoch 1/3, Batch 24230, Loss: 0.0206, Acc: 61.34%\n",
      "Epoch 1/3, Batch 24240, Loss: 2.3606, Acc: 61.34%\n",
      "Epoch 1/3, Batch 24250, Loss: 0.9567, Acc: 61.33%\n",
      "Epoch 1/3, Batch 24260, Loss: 1.0666, Acc: 61.33%\n",
      "Epoch 1/3, Batch 24270, Loss: 2.0622, Acc: 61.32%\n",
      "Epoch 1/3, Batch 24280, Loss: 1.2579, Acc: 61.32%\n",
      "Epoch 1/3, Batch 24290, Loss: 0.4291, Acc: 61.32%\n",
      "Epoch 1/3, Batch 24300, Loss: 0.3067, Acc: 61.33%\n",
      "Epoch 1/3, Batch 24310, Loss: 1.0834, Acc: 61.33%\n",
      "Epoch 1/3, Batch 24320, Loss: 0.1506, Acc: 61.33%\n",
      "Epoch 1/3, Batch 24330, Loss: 0.1146, Acc: 61.33%\n",
      "Epoch 1/3, Batch 24340, Loss: 0.0478, Acc: 61.34%\n",
      "Epoch 1/3, Batch 24350, Loss: 0.0037, Acc: 61.35%\n",
      "Epoch 1/3, Batch 24360, Loss: 0.0026, Acc: 61.34%\n",
      "Epoch 1/3, Batch 24370, Loss: 0.0571, Acc: 61.35%\n",
      "Epoch 1/3, Batch 24380, Loss: 0.3328, Acc: 61.36%\n",
      "Epoch 1/3, Batch 24390, Loss: 0.7894, Acc: 61.35%\n",
      "Epoch 1/3, Batch 24400, Loss: 1.3079, Acc: 61.35%\n",
      "Epoch 1/3, Batch 24410, Loss: 0.2473, Acc: 61.36%\n",
      "Epoch 1/3, Batch 24420, Loss: 0.2032, Acc: 61.35%\n",
      "Epoch 1/3, Batch 24430, Loss: 0.3093, Acc: 61.36%\n",
      "Epoch 1/3, Batch 24440, Loss: 0.0050, Acc: 61.36%\n",
      "Epoch 1/3, Batch 24450, Loss: 0.2765, Acc: 61.37%\n",
      "Epoch 1/3, Batch 24460, Loss: 0.0020, Acc: 61.36%\n",
      "Epoch 1/3, Batch 24470, Loss: 0.3487, Acc: 61.36%\n",
      "Epoch 1/3, Batch 24480, Loss: 0.9783, Acc: 61.35%\n",
      "Epoch 1/3, Batch 24490, Loss: 3.2348, Acc: 61.35%\n",
      "Epoch 1/3, Batch 24500, Loss: 0.8032, Acc: 61.34%\n",
      "Epoch 1/3, Batch 24510, Loss: 0.7505, Acc: 61.34%\n",
      "Epoch 1/3, Batch 24520, Loss: 0.0373, Acc: 61.35%\n",
      "Epoch 1/3, Batch 24530, Loss: 0.5874, Acc: 61.36%\n",
      "Epoch 1/3, Batch 24540, Loss: 0.2224, Acc: 61.37%\n",
      "Epoch 1/3, Batch 24550, Loss: 3.1899, Acc: 61.37%\n",
      "Epoch 1/3, Batch 24560, Loss: 0.0276, Acc: 61.37%\n",
      "Epoch 1/3, Batch 24570, Loss: 0.1652, Acc: 61.37%\n",
      "Epoch 1/3, Batch 24580, Loss: 0.4859, Acc: 61.37%\n",
      "Epoch 1/3, Batch 24590, Loss: 0.5457, Acc: 61.38%\n",
      "Epoch 1/3, Batch 24600, Loss: 0.2911, Acc: 61.38%\n",
      "Epoch 1/3, Batch 24610, Loss: 2.4595, Acc: 61.39%\n",
      "Epoch 1/3, Batch 24620, Loss: 0.0105, Acc: 61.39%\n",
      "Epoch 1/3, Batch 24630, Loss: 0.0352, Acc: 61.39%\n",
      "Epoch 1/3, Batch 24640, Loss: 0.0114, Acc: 61.39%\n",
      "Epoch 1/3, Batch 24650, Loss: 0.0176, Acc: 61.38%\n",
      "Epoch 1/3, Batch 24660, Loss: 0.9299, Acc: 61.38%\n",
      "Epoch 1/3, Batch 24670, Loss: 0.2307, Acc: 61.39%\n",
      "Epoch 1/3, Batch 24680, Loss: 0.3980, Acc: 61.40%\n",
      "Epoch 1/3, Batch 24690, Loss: 0.5054, Acc: 61.40%\n",
      "Epoch 1/3, Batch 24700, Loss: 1.3645, Acc: 61.40%\n",
      "Epoch 1/3, Batch 24710, Loss: 0.0260, Acc: 61.40%\n",
      "Epoch 1/3, Batch 24720, Loss: 0.7999, Acc: 61.39%\n",
      "Epoch 1/3, Batch 24730, Loss: 0.5223, Acc: 61.40%\n",
      "Epoch 1/3, Batch 24740, Loss: 0.8568, Acc: 61.39%\n",
      "Epoch 1/3, Batch 24750, Loss: 0.9756, Acc: 61.39%\n",
      "Epoch 1/3, Batch 24760, Loss: 1.7835, Acc: 61.39%\n",
      "Epoch 1/3, Batch 24770, Loss: 1.1851, Acc: 61.40%\n",
      "Epoch 1/3, Batch 24780, Loss: 0.0337, Acc: 61.40%\n",
      "Epoch 1/3, Batch 24790, Loss: 0.5012, Acc: 61.40%\n",
      "Epoch 1/3, Batch 24800, Loss: 0.0024, Acc: 61.40%\n",
      "Epoch 1/3, Batch 24810, Loss: 0.0563, Acc: 61.41%\n",
      "Epoch 1/3, Batch 24820, Loss: 2.3276, Acc: 61.39%\n",
      "Epoch 1/3, Batch 24830, Loss: 0.0311, Acc: 61.38%\n",
      "Epoch 1/3, Batch 24840, Loss: 0.0633, Acc: 61.39%\n",
      "Epoch 1/3, Batch 24850, Loss: 0.8926, Acc: 61.39%\n",
      "Epoch 1/3, Batch 24860, Loss: 0.0745, Acc: 61.39%\n",
      "Epoch 1/3, Batch 24870, Loss: 0.0050, Acc: 61.39%\n",
      "Epoch 1/3, Batch 24880, Loss: 0.2371, Acc: 61.40%\n",
      "Epoch 1/3, Batch 24890, Loss: 1.1028, Acc: 61.40%\n",
      "Epoch 1/3, Batch 24900, Loss: 0.8949, Acc: 61.39%\n",
      "Epoch 1/3, Batch 24910, Loss: 0.6943, Acc: 61.39%\n",
      "Epoch 1/3, Batch 24920, Loss: 0.0923, Acc: 61.38%\n",
      "Epoch 1/3, Batch 24930, Loss: 0.6561, Acc: 61.39%\n",
      "Epoch 1/3, Batch 24940, Loss: 0.0087, Acc: 61.39%\n",
      "Epoch 1/3, Batch 24950, Loss: 0.6938, Acc: 61.40%\n",
      "Epoch 1/3, Batch 24960, Loss: 0.1818, Acc: 61.40%\n",
      "Epoch 1/3, Batch 24970, Loss: 0.0240, Acc: 61.40%\n",
      "Epoch 1/3, Batch 24980, Loss: 0.6502, Acc: 61.41%\n",
      "Epoch 1/3, Batch 24990, Loss: 0.0175, Acc: 61.42%\n",
      "Epoch 1/3, Batch 25000, Loss: 0.9428, Acc: 61.42%\n",
      "Epoch 1/3, Batch 25010, Loss: 0.2330, Acc: 61.42%\n",
      "Epoch 1/3, Batch 25020, Loss: 0.3269, Acc: 61.43%\n",
      "Epoch 1/3, Batch 25030, Loss: 0.0191, Acc: 61.43%\n",
      "Epoch 1/3, Batch 25040, Loss: 0.0499, Acc: 61.42%\n",
      "Epoch 1/3, Batch 25050, Loss: 1.6391, Acc: 61.43%\n",
      "Epoch 1/3, Batch 25060, Loss: 0.6130, Acc: 61.43%\n",
      "Epoch 1/3, Batch 25070, Loss: 0.4378, Acc: 61.44%\n",
      "Epoch 1/3, Batch 25080, Loss: 0.0346, Acc: 61.44%\n",
      "Epoch 1/3, Batch 25090, Loss: 0.0193, Acc: 61.44%\n",
      "Epoch 1/3, Batch 25100, Loss: 0.1394, Acc: 61.44%\n",
      "Epoch 1/3, Batch 25110, Loss: 0.5576, Acc: 61.44%\n",
      "Epoch 1/3, Batch 25120, Loss: 0.0157, Acc: 61.44%\n",
      "Epoch 1/3, Batch 25130, Loss: 0.9248, Acc: 61.44%\n",
      "Epoch 1/3, Batch 25140, Loss: 2.7396, Acc: 61.44%\n",
      "Epoch 1/3, Batch 25150, Loss: 1.7664, Acc: 61.44%\n",
      "Epoch 1/3, Batch 25160, Loss: 0.5970, Acc: 61.44%\n",
      "Epoch 1/3, Batch 25170, Loss: 0.2345, Acc: 61.44%\n",
      "Epoch 1/3, Batch 25180, Loss: 1.9298, Acc: 61.45%\n",
      "Epoch 1/3, Batch 25190, Loss: 1.8054, Acc: 61.45%\n",
      "Epoch 1/3, Batch 25200, Loss: 0.9075, Acc: 61.45%\n",
      "Epoch 1/3, Batch 25210, Loss: 0.1657, Acc: 61.46%\n",
      "Epoch 1/3, Batch 25220, Loss: 0.0023, Acc: 61.46%\n",
      "Epoch 1/3, Batch 25230, Loss: 1.0836, Acc: 61.46%\n",
      "Epoch 1/3, Batch 25240, Loss: 0.1997, Acc: 61.46%\n",
      "Epoch 1/3, Batch 25250, Loss: 0.1256, Acc: 61.46%\n",
      "Epoch 1/3, Batch 25260, Loss: 0.6584, Acc: 61.46%\n",
      "Epoch 1/3, Batch 25270, Loss: 0.7941, Acc: 61.46%\n",
      "Epoch 1/3, Batch 25280, Loss: 0.5439, Acc: 61.47%\n",
      "Epoch 1/3, Batch 25290, Loss: 0.3200, Acc: 61.47%\n",
      "Epoch 1/3, Batch 25300, Loss: 0.3349, Acc: 61.46%\n",
      "Epoch 1/3, Batch 25310, Loss: 0.1384, Acc: 61.46%\n",
      "Epoch 1/3, Batch 25320, Loss: 0.1141, Acc: 61.47%\n",
      "Epoch 1/3, Batch 25330, Loss: 0.0283, Acc: 61.47%\n",
      "Epoch 1/3, Batch 25340, Loss: 1.4370, Acc: 61.48%\n",
      "Epoch 1/3, Batch 25350, Loss: 0.4440, Acc: 61.48%\n",
      "Epoch 1/3, Batch 25360, Loss: 1.6356, Acc: 61.46%\n",
      "Epoch 1/3, Batch 25370, Loss: 0.9516, Acc: 61.46%\n",
      "Epoch 1/3, Batch 25380, Loss: 0.4306, Acc: 61.48%\n",
      "Epoch 1/3, Batch 25390, Loss: 0.0404, Acc: 61.48%\n",
      "Epoch 1/3, Batch 25400, Loss: 1.1753, Acc: 61.48%\n",
      "Epoch 1/3, Batch 25410, Loss: 0.0146, Acc: 61.48%\n",
      "Epoch 1/3, Batch 25420, Loss: 0.6739, Acc: 61.47%\n",
      "Epoch 1/3, Batch 25430, Loss: 0.4541, Acc: 61.48%\n",
      "Epoch 1/3, Batch 25440, Loss: 0.3127, Acc: 61.47%\n",
      "Epoch 1/3, Batch 25450, Loss: 0.9920, Acc: 61.47%\n",
      "Epoch 1/3, Batch 25460, Loss: 0.4111, Acc: 61.48%\n",
      "Epoch 1/3, Batch 25470, Loss: 0.5848, Acc: 61.48%\n",
      "Epoch 1/3, Batch 25480, Loss: 0.9707, Acc: 61.49%\n",
      "Epoch 1/3, Batch 25490, Loss: 0.6908, Acc: 61.48%\n",
      "Epoch 1/3, Batch 25500, Loss: 0.1588, Acc: 61.49%\n",
      "Epoch 1/3, Batch 25510, Loss: 0.0077, Acc: 61.48%\n",
      "Epoch 1/3, Batch 25520, Loss: 0.7753, Acc: 61.47%\n",
      "Epoch 1/3, Batch 25530, Loss: 0.6517, Acc: 61.49%\n",
      "Epoch 1/3, Batch 25540, Loss: 0.2800, Acc: 61.49%\n",
      "Epoch 1/3, Batch 25550, Loss: 1.7866, Acc: 61.49%\n",
      "Epoch 1/3, Batch 25560, Loss: 0.3528, Acc: 61.49%\n",
      "Epoch 1/3, Batch 25570, Loss: 0.0029, Acc: 61.49%\n",
      "Epoch 1/3, Batch 25580, Loss: 0.6862, Acc: 61.49%\n",
      "Epoch 1/3, Batch 25590, Loss: 1.0917, Acc: 61.49%\n",
      "Epoch 1/3, Batch 25600, Loss: 0.4421, Acc: 61.49%\n",
      "Epoch 1/3, Batch 25610, Loss: 0.0551, Acc: 61.50%\n",
      "Epoch 1/3, Batch 25620, Loss: 0.6339, Acc: 61.50%\n",
      "Epoch 1/3, Batch 25630, Loss: 0.0183, Acc: 61.50%\n",
      "Epoch 1/3, Batch 25640, Loss: 0.0531, Acc: 61.51%\n",
      "Epoch 1/3, Batch 25650, Loss: 0.1769, Acc: 61.51%\n",
      "Epoch 1/3, Batch 25660, Loss: 0.1913, Acc: 61.52%\n",
      "Epoch 1/3, Batch 25670, Loss: 2.0622, Acc: 61.52%\n",
      "Epoch 1/3, Batch 25680, Loss: 0.0189, Acc: 61.52%\n",
      "Epoch 1/3, Batch 25690, Loss: 0.1049, Acc: 61.53%\n",
      "Epoch 1/3, Batch 25700, Loss: 0.9558, Acc: 61.53%\n",
      "Epoch 1/3, Batch 25710, Loss: 0.3699, Acc: 61.53%\n",
      "Epoch 1/3, Batch 25720, Loss: 2.1380, Acc: 61.54%\n",
      "Epoch 1/3, Batch 25730, Loss: 0.5977, Acc: 61.54%\n",
      "Epoch 1/3, Batch 25740, Loss: 0.8221, Acc: 61.54%\n",
      "Epoch 1/3, Batch 25750, Loss: 1.3071, Acc: 61.53%\n",
      "Epoch 1/3, Batch 25760, Loss: 0.0756, Acc: 61.53%\n",
      "Epoch 1/3, Batch 25770, Loss: 0.4061, Acc: 61.53%\n",
      "Epoch 1/3, Batch 25780, Loss: 0.8516, Acc: 61.51%\n",
      "Epoch 1/3, Batch 25790, Loss: 1.0623, Acc: 61.52%\n",
      "Epoch 1/3, Batch 25800, Loss: 1.3675, Acc: 61.52%\n",
      "Epoch 1/3, Batch 25810, Loss: 2.2366, Acc: 61.52%\n",
      "Epoch 1/3, Batch 25820, Loss: 0.1816, Acc: 61.52%\n",
      "Epoch 1/3, Batch 25830, Loss: 0.3719, Acc: 61.52%\n",
      "Epoch 1/3, Batch 25840, Loss: 0.0157, Acc: 61.52%\n",
      "Epoch 1/3, Batch 25850, Loss: 0.5287, Acc: 61.54%\n",
      "Epoch 1/3, Batch 25860, Loss: 0.3864, Acc: 61.55%\n",
      "Epoch 1/3, Batch 25870, Loss: 0.5813, Acc: 61.55%\n",
      "Epoch 1/3, Batch 25880, Loss: 0.3849, Acc: 61.55%\n",
      "Epoch 1/3, Batch 25890, Loss: 2.6138, Acc: 61.55%\n",
      "Epoch 1/3, Batch 25900, Loss: 0.4529, Acc: 61.55%\n",
      "Epoch 1/3, Batch 25910, Loss: 0.0802, Acc: 61.56%\n",
      "Epoch 1/3, Batch 25920, Loss: 0.0214, Acc: 61.55%\n",
      "Epoch 1/3, Batch 25930, Loss: 0.6648, Acc: 61.56%\n",
      "Epoch 1/3, Batch 25940, Loss: 1.3350, Acc: 61.56%\n",
      "Epoch 1/3, Batch 25950, Loss: 0.2117, Acc: 61.55%\n",
      "Epoch 1/3, Batch 25960, Loss: 0.0018, Acc: 61.54%\n",
      "Epoch 1/3, Batch 25970, Loss: 0.0025, Acc: 61.53%\n",
      "Epoch 1/3, Batch 25980, Loss: 0.7196, Acc: 61.52%\n",
      "Epoch 1/3, Batch 25990, Loss: 0.8177, Acc: 61.52%\n",
      "Epoch 1/3, Batch 26000, Loss: 0.1047, Acc: 61.52%\n",
      "Epoch 1/3, Batch 26010, Loss: 0.0130, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26020, Loss: 0.3186, Acc: 61.52%\n",
      "Epoch 1/3, Batch 26030, Loss: 0.0357, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26040, Loss: 1.3967, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26050, Loss: 0.2661, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26060, Loss: 1.4995, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26070, Loss: 0.3958, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26080, Loss: 0.0058, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26090, Loss: 0.7186, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26100, Loss: 0.3393, Acc: 61.53%\n",
      "Epoch 1/3, Batch 26110, Loss: 0.0846, Acc: 61.53%\n",
      "Epoch 1/3, Batch 26120, Loss: 2.3121, Acc: 61.52%\n",
      "Epoch 1/3, Batch 26130, Loss: 0.6551, Acc: 61.52%\n",
      "Epoch 1/3, Batch 26140, Loss: 1.9075, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26150, Loss: 0.0428, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26160, Loss: 0.6120, Acc: 61.52%\n",
      "Epoch 1/3, Batch 26170, Loss: 2.2298, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26180, Loss: 0.8282, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26190, Loss: 0.4505, Acc: 61.50%\n",
      "Epoch 1/3, Batch 26200, Loss: 0.3643, Acc: 61.50%\n",
      "Epoch 1/3, Batch 26210, Loss: 0.8734, Acc: 61.49%\n",
      "Epoch 1/3, Batch 26220, Loss: 0.8183, Acc: 61.49%\n",
      "Epoch 1/3, Batch 26230, Loss: 0.1227, Acc: 61.50%\n",
      "Epoch 1/3, Batch 26240, Loss: 0.0775, Acc: 61.50%\n",
      "Epoch 1/3, Batch 26250, Loss: 0.1846, Acc: 61.49%\n",
      "Epoch 1/3, Batch 26260, Loss: 0.0464, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26270, Loss: 0.0470, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26280, Loss: 2.5825, Acc: 61.50%\n",
      "Epoch 1/3, Batch 26290, Loss: 0.3190, Acc: 61.50%\n",
      "Epoch 1/3, Batch 26300, Loss: 1.4897, Acc: 61.50%\n",
      "Epoch 1/3, Batch 26310, Loss: 0.4625, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26320, Loss: 0.0319, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26330, Loss: 0.0422, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26340, Loss: 0.8045, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26350, Loss: 0.3078, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26360, Loss: 1.1469, Acc: 61.50%\n",
      "Epoch 1/3, Batch 26370, Loss: 0.1135, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26380, Loss: 0.0007, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26390, Loss: 0.2727, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26400, Loss: 0.8581, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26410, Loss: 0.5150, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26420, Loss: 0.0195, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26430, Loss: 0.4287, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26440, Loss: 0.8103, Acc: 61.50%\n",
      "Epoch 1/3, Batch 26450, Loss: 0.3392, Acc: 61.50%\n",
      "Epoch 1/3, Batch 26460, Loss: 0.5795, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26470, Loss: 2.0747, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26480, Loss: 2.0334, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26490, Loss: 0.2917, Acc: 61.52%\n",
      "Epoch 1/3, Batch 26500, Loss: 0.4402, Acc: 61.52%\n",
      "Epoch 1/3, Batch 26510, Loss: 1.1756, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26520, Loss: 1.1929, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26530, Loss: 0.8821, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26540, Loss: 0.6892, Acc: 61.52%\n",
      "Epoch 1/3, Batch 26550, Loss: 0.6997, Acc: 61.52%\n",
      "Epoch 1/3, Batch 26560, Loss: 0.5519, Acc: 61.52%\n",
      "Epoch 1/3, Batch 26570, Loss: 0.2258, Acc: 61.52%\n",
      "Epoch 1/3, Batch 26580, Loss: 1.0239, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26590, Loss: 0.0384, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26600, Loss: 0.0341, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26610, Loss: 1.0130, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26620, Loss: 0.6348, Acc: 61.52%\n",
      "Epoch 1/3, Batch 26630, Loss: 0.6930, Acc: 61.52%\n",
      "Epoch 1/3, Batch 26640, Loss: 0.0732, Acc: 61.52%\n",
      "Epoch 1/3, Batch 26650, Loss: 1.2844, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26660, Loss: 0.0892, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26670, Loss: 0.2335, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26680, Loss: 0.9851, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26690, Loss: 2.3280, Acc: 61.50%\n",
      "Epoch 1/3, Batch 26700, Loss: 1.2643, Acc: 61.50%\n",
      "Epoch 1/3, Batch 26710, Loss: 0.0254, Acc: 61.50%\n",
      "Epoch 1/3, Batch 26720, Loss: 0.2776, Acc: 61.50%\n",
      "Epoch 1/3, Batch 26730, Loss: 0.3160, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26740, Loss: 0.0118, Acc: 61.50%\n",
      "Epoch 1/3, Batch 26750, Loss: 0.0024, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26760, Loss: 0.4861, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26770, Loss: 0.6219, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26780, Loss: 0.5378, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26790, Loss: 1.1352, Acc: 61.50%\n",
      "Epoch 1/3, Batch 26800, Loss: 0.0102, Acc: 61.50%\n",
      "Epoch 1/3, Batch 26810, Loss: 0.0114, Acc: 61.50%\n",
      "Epoch 1/3, Batch 26820, Loss: 0.6916, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26830, Loss: 0.1250, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26840, Loss: 0.4936, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26850, Loss: 0.2351, Acc: 61.52%\n",
      "Epoch 1/3, Batch 26860, Loss: 0.5588, Acc: 61.52%\n",
      "Epoch 1/3, Batch 26870, Loss: 0.0522, Acc: 61.53%\n",
      "Epoch 1/3, Batch 26880, Loss: 0.0070, Acc: 61.53%\n",
      "Epoch 1/3, Batch 26890, Loss: 0.5501, Acc: 61.53%\n",
      "Epoch 1/3, Batch 26900, Loss: 2.1040, Acc: 61.53%\n",
      "Epoch 1/3, Batch 26910, Loss: 2.1582, Acc: 61.53%\n",
      "Epoch 1/3, Batch 26920, Loss: 0.2671, Acc: 61.52%\n",
      "Epoch 1/3, Batch 26930, Loss: 0.1276, Acc: 61.52%\n",
      "Epoch 1/3, Batch 26940, Loss: 0.0834, Acc: 61.52%\n",
      "Epoch 1/3, Batch 26950, Loss: 0.1317, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26960, Loss: 0.4837, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26970, Loss: 1.9950, Acc: 61.51%\n",
      "Epoch 1/3, Batch 26980, Loss: 0.5957, Acc: 61.52%\n",
      "Epoch 1/3, Batch 26990, Loss: 0.3022, Acc: 61.52%\n",
      "Epoch 1/3, Batch 27000, Loss: 0.2714, Acc: 61.52%\n",
      "Epoch 1/3, Batch 27010, Loss: 0.6530, Acc: 61.52%\n",
      "Epoch 1/3, Batch 27020, Loss: 0.1187, Acc: 61.52%\n",
      "Epoch 1/3, Batch 27030, Loss: 0.0412, Acc: 61.51%\n",
      "Epoch 1/3, Batch 27040, Loss: 0.0301, Acc: 61.51%\n",
      "Epoch 1/3, Batch 27050, Loss: 0.6721, Acc: 61.51%\n",
      "Epoch 1/3, Batch 27060, Loss: 0.2124, Acc: 61.52%\n",
      "Epoch 1/3, Batch 27070, Loss: 1.3632, Acc: 61.50%\n",
      "Epoch 1/3, Batch 27080, Loss: 0.5051, Acc: 61.51%\n",
      "Epoch 1/3, Batch 27090, Loss: 1.2418, Acc: 61.51%\n",
      "Epoch 1/3, Batch 27100, Loss: 0.4914, Acc: 61.52%\n",
      "Epoch 1/3, Batch 27110, Loss: 0.1946, Acc: 61.52%\n",
      "Epoch 1/3, Batch 27120, Loss: 0.1017, Acc: 61.52%\n",
      "Epoch 1/3, Batch 27130, Loss: 0.1443, Acc: 61.52%\n",
      "Epoch 1/3, Batch 27140, Loss: 0.1972, Acc: 61.52%\n",
      "Epoch 1/3, Batch 27150, Loss: 0.0879, Acc: 61.52%\n",
      "Epoch 1/3, Batch 27160, Loss: 0.1578, Acc: 61.51%\n",
      "Epoch 1/3, Batch 27170, Loss: 1.8741, Acc: 61.51%\n",
      "Epoch 1/3, Batch 27180, Loss: 0.8577, Acc: 61.51%\n",
      "Epoch 1/3, Batch 27190, Loss: 0.2493, Acc: 61.50%\n",
      "Epoch 1/3, Batch 27200, Loss: 0.6180, Acc: 61.50%\n",
      "Epoch 1/3, Batch 27210, Loss: 0.4673, Acc: 61.50%\n",
      "Epoch 1/3, Batch 27220, Loss: 0.0309, Acc: 61.52%\n",
      "Epoch 1/3, Batch 27230, Loss: 0.2514, Acc: 61.51%\n",
      "Epoch 1/3, Batch 27240, Loss: 1.1353, Acc: 61.51%\n",
      "Epoch 1/3, Batch 27250, Loss: 1.2709, Acc: 61.51%\n",
      "Epoch 1/3, Batch 27260, Loss: 0.2068, Acc: 61.51%\n",
      "Epoch 1/3, Batch 27270, Loss: 0.6440, Acc: 61.52%\n",
      "Epoch 1/3, Batch 27280, Loss: 0.2394, Acc: 61.52%\n",
      "Epoch 1/3, Batch 27290, Loss: 1.9487, Acc: 61.52%\n",
      "Epoch 1/3, Batch 27300, Loss: 0.8035, Acc: 61.52%\n",
      "Epoch 1/3, Batch 27310, Loss: 0.1715, Acc: 61.52%\n",
      "Epoch 1/3, Batch 27320, Loss: 0.2667, Acc: 61.52%\n",
      "Epoch 1/3, Batch 27330, Loss: 0.3369, Acc: 61.52%\n",
      "Epoch 1/3, Batch 27340, Loss: 0.3210, Acc: 61.52%\n",
      "Epoch 1/3, Batch 27350, Loss: 0.3046, Acc: 61.52%\n",
      "Epoch 1/3, Batch 27360, Loss: 1.1739, Acc: 61.53%\n",
      "Epoch 1/3, Batch 27370, Loss: 0.4142, Acc: 61.52%\n",
      "Epoch 1/3, Batch 27380, Loss: 0.1756, Acc: 61.53%\n",
      "Epoch 1/3, Batch 27390, Loss: 0.0849, Acc: 61.54%\n",
      "Epoch 1/3, Batch 27400, Loss: 0.8776, Acc: 61.54%\n",
      "Epoch 1/3, Batch 27410, Loss: 0.0701, Acc: 61.55%\n",
      "Epoch 1/3, Batch 27420, Loss: 0.9444, Acc: 61.54%\n",
      "Epoch 1/3, Batch 27430, Loss: 0.2163, Acc: 61.54%\n",
      "Epoch 1/3, Batch 27440, Loss: 0.4040, Acc: 61.54%\n",
      "Epoch 1/3, Batch 27450, Loss: 0.4620, Acc: 61.54%\n",
      "Epoch 1/3, Batch 27460, Loss: 0.4245, Acc: 61.54%\n",
      "Epoch 1/3, Batch 27470, Loss: 0.2189, Acc: 61.54%\n",
      "Epoch 1/3, Batch 27480, Loss: 0.0661, Acc: 61.54%\n",
      "Epoch 1/3, Batch 27490, Loss: 0.0744, Acc: 61.53%\n",
      "Epoch 1/3, Batch 27500, Loss: 0.5543, Acc: 61.54%\n",
      "Epoch 1/3, Batch 27510, Loss: 2.3152, Acc: 61.54%\n",
      "Epoch 1/3, Batch 27520, Loss: 0.3644, Acc: 61.55%\n",
      "Epoch 1/3, Batch 27530, Loss: 0.1808, Acc: 61.56%\n",
      "Epoch 1/3, Batch 27540, Loss: 0.9398, Acc: 61.56%\n",
      "Epoch 1/3, Batch 27550, Loss: 0.0494, Acc: 61.55%\n",
      "Epoch 1/3, Batch 27560, Loss: 0.2267, Acc: 61.56%\n",
      "Epoch 1/3, Batch 27570, Loss: 0.0704, Acc: 61.57%\n",
      "Epoch 1/3, Batch 27580, Loss: 0.0362, Acc: 61.57%\n",
      "Epoch 1/3, Batch 27590, Loss: 1.0904, Acc: 61.57%\n",
      "Epoch 1/3, Batch 27600, Loss: 1.1208, Acc: 61.58%\n",
      "Epoch 1/3, Average Loss: 0.7165, Accuracy: 61.58%\n",
      "Epoch 2/3, Batch 0, Loss: 0.1448, Acc: 100.00%\n",
      "Epoch 2/3, Batch 10, Loss: 0.1775, Acc: 72.73%\n",
      "Epoch 2/3, Batch 20, Loss: 0.1609, Acc: 85.71%\n",
      "Epoch 2/3, Batch 30, Loss: 0.8162, Acc: 67.74%\n",
      "Epoch 2/3, Batch 40, Loss: 0.8843, Acc: 63.41%\n",
      "Epoch 2/3, Batch 50, Loss: 0.2076, Acc: 62.75%\n",
      "Epoch 2/3, Batch 60, Loss: 0.8715, Acc: 62.30%\n",
      "Epoch 2/3, Batch 70, Loss: 0.0753, Acc: 63.38%\n",
      "Epoch 2/3, Batch 80, Loss: 0.9579, Acc: 64.20%\n",
      "Epoch 2/3, Batch 90, Loss: 0.0418, Acc: 64.84%\n",
      "Epoch 2/3, Batch 100, Loss: 1.3333, Acc: 61.39%\n",
      "Epoch 2/3, Batch 110, Loss: 1.1297, Acc: 62.16%\n",
      "Epoch 2/3, Batch 120, Loss: 0.8299, Acc: 60.33%\n",
      "Epoch 2/3, Batch 130, Loss: 0.7832, Acc: 61.83%\n",
      "Epoch 2/3, Batch 140, Loss: 1.7892, Acc: 60.28%\n",
      "Epoch 2/3, Batch 150, Loss: 0.4646, Acc: 60.26%\n",
      "Epoch 2/3, Batch 160, Loss: 0.1775, Acc: 59.63%\n",
      "Epoch 2/3, Batch 170, Loss: 0.2345, Acc: 59.06%\n",
      "Epoch 2/3, Batch 180, Loss: 1.3245, Acc: 59.67%\n",
      "Epoch 2/3, Batch 190, Loss: 0.0772, Acc: 60.21%\n",
      "Epoch 2/3, Batch 200, Loss: 0.0182, Acc: 60.20%\n",
      "Epoch 2/3, Batch 210, Loss: 0.1732, Acc: 61.14%\n",
      "Epoch 2/3, Batch 220, Loss: 0.0002, Acc: 61.09%\n",
      "Epoch 2/3, Batch 230, Loss: 0.3870, Acc: 60.61%\n",
      "Epoch 2/3, Batch 240, Loss: 0.3205, Acc: 61.41%\n",
      "Epoch 2/3, Batch 250, Loss: 0.1780, Acc: 61.75%\n",
      "Epoch 2/3, Batch 260, Loss: 0.6386, Acc: 61.69%\n",
      "Epoch 2/3, Batch 270, Loss: 0.3099, Acc: 62.73%\n",
      "Epoch 2/3, Batch 280, Loss: 0.5682, Acc: 64.06%\n",
      "Epoch 2/3, Batch 290, Loss: 0.0098, Acc: 63.92%\n",
      "Epoch 2/3, Batch 300, Loss: 0.2363, Acc: 64.78%\n",
      "Epoch 2/3, Batch 310, Loss: 0.0774, Acc: 64.95%\n",
      "Epoch 2/3, Batch 320, Loss: 1.3464, Acc: 64.80%\n",
      "Epoch 2/3, Batch 330, Loss: 0.2287, Acc: 64.95%\n",
      "Epoch 2/3, Batch 340, Loss: 0.0707, Acc: 64.81%\n",
      "Epoch 2/3, Batch 350, Loss: 1.3341, Acc: 64.67%\n",
      "Epoch 2/3, Batch 360, Loss: 1.0752, Acc: 63.99%\n",
      "Epoch 2/3, Batch 370, Loss: 0.3321, Acc: 63.34%\n",
      "Epoch 2/3, Batch 380, Loss: 0.6930, Acc: 64.04%\n",
      "Epoch 2/3, Batch 390, Loss: 0.1674, Acc: 63.94%\n",
      "Epoch 2/3, Batch 400, Loss: 0.0704, Acc: 64.09%\n",
      "Epoch 2/3, Batch 410, Loss: 0.5556, Acc: 64.23%\n",
      "Epoch 2/3, Batch 420, Loss: 0.0764, Acc: 63.66%\n",
      "Epoch 2/3, Batch 430, Loss: 0.0023, Acc: 63.81%\n",
      "Epoch 2/3, Batch 440, Loss: 1.6128, Acc: 63.72%\n",
      "Epoch 2/3, Batch 450, Loss: 0.0206, Acc: 63.86%\n",
      "Epoch 2/3, Batch 460, Loss: 0.4724, Acc: 64.21%\n",
      "Epoch 2/3, Batch 470, Loss: 0.8458, Acc: 64.33%\n",
      "Epoch 2/3, Batch 480, Loss: 0.5948, Acc: 64.24%\n",
      "Epoch 2/3, Batch 490, Loss: 0.0230, Acc: 64.77%\n",
      "Epoch 2/3, Batch 500, Loss: 0.0564, Acc: 64.47%\n",
      "Epoch 2/3, Batch 510, Loss: 0.0098, Acc: 64.58%\n",
      "Epoch 2/3, Batch 520, Loss: 1.1367, Acc: 64.49%\n",
      "Epoch 2/3, Batch 530, Loss: 1.0769, Acc: 64.41%\n",
      "Epoch 2/3, Batch 540, Loss: 1.9167, Acc: 64.51%\n",
      "Epoch 2/3, Batch 550, Loss: 1.0478, Acc: 64.61%\n",
      "Epoch 2/3, Batch 560, Loss: 0.2369, Acc: 64.71%\n",
      "Epoch 2/3, Batch 570, Loss: 0.0038, Acc: 65.15%\n",
      "Epoch 2/3, Batch 580, Loss: 0.3810, Acc: 64.72%\n",
      "Epoch 2/3, Batch 590, Loss: 0.9857, Acc: 64.64%\n",
      "Epoch 2/3, Batch 600, Loss: 0.0982, Acc: 64.89%\n",
      "Epoch 2/3, Batch 610, Loss: 0.4184, Acc: 64.65%\n",
      "Epoch 2/3, Batch 620, Loss: 0.4977, Acc: 64.57%\n",
      "Epoch 2/3, Batch 630, Loss: 1.5406, Acc: 64.18%\n",
      "Epoch 2/3, Batch 640, Loss: 1.3213, Acc: 63.96%\n",
      "Epoch 2/3, Batch 650, Loss: 1.2941, Acc: 64.21%\n",
      "Epoch 2/3, Batch 660, Loss: 2.0563, Acc: 64.15%\n",
      "Epoch 2/3, Batch 670, Loss: 0.0325, Acc: 64.23%\n",
      "Epoch 2/3, Batch 680, Loss: 0.0527, Acc: 64.46%\n",
      "Epoch 2/3, Batch 690, Loss: 0.0362, Acc: 64.25%\n",
      "Epoch 2/3, Batch 700, Loss: 1.6622, Acc: 64.19%\n",
      "Epoch 2/3, Batch 710, Loss: 0.0340, Acc: 64.56%\n",
      "Epoch 2/3, Batch 720, Loss: 0.3162, Acc: 64.49%\n",
      "Epoch 2/3, Batch 730, Loss: 0.6982, Acc: 64.16%\n",
      "Epoch 2/3, Batch 740, Loss: 0.0315, Acc: 64.24%\n",
      "Epoch 2/3, Batch 750, Loss: 0.0296, Acc: 64.45%\n",
      "Epoch 2/3, Batch 760, Loss: 1.0697, Acc: 64.39%\n",
      "Epoch 2/3, Batch 770, Loss: 0.1944, Acc: 64.33%\n",
      "Epoch 2/3, Batch 780, Loss: 0.5017, Acc: 64.28%\n",
      "Epoch 2/3, Batch 790, Loss: 0.5108, Acc: 64.22%\n",
      "Epoch 2/3, Batch 800, Loss: 0.4035, Acc: 64.29%\n",
      "Epoch 2/3, Batch 810, Loss: 0.5809, Acc: 64.36%\n",
      "Epoch 2/3, Batch 820, Loss: 0.7754, Acc: 64.43%\n",
      "Epoch 2/3, Batch 830, Loss: 0.7183, Acc: 64.62%\n",
      "Epoch 2/3, Batch 840, Loss: 0.0118, Acc: 64.33%\n",
      "Epoch 2/3, Batch 850, Loss: 0.7654, Acc: 64.39%\n",
      "Epoch 2/3, Batch 860, Loss: 0.2392, Acc: 64.34%\n",
      "Epoch 2/3, Batch 870, Loss: 0.9588, Acc: 64.29%\n",
      "Epoch 2/3, Batch 880, Loss: 0.0077, Acc: 64.36%\n",
      "Epoch 2/3, Batch 890, Loss: 0.0181, Acc: 64.53%\n",
      "Epoch 2/3, Batch 900, Loss: 1.0630, Acc: 64.04%\n",
      "Epoch 2/3, Batch 910, Loss: 0.6667, Acc: 64.32%\n",
      "Epoch 2/3, Batch 920, Loss: 0.5157, Acc: 64.28%\n",
      "Epoch 2/3, Batch 930, Loss: 0.8545, Acc: 64.12%\n",
      "Epoch 2/3, Batch 940, Loss: 0.4704, Acc: 64.40%\n",
      "Epoch 2/3, Batch 950, Loss: 0.5517, Acc: 64.56%\n",
      "Epoch 2/3, Batch 960, Loss: 0.0894, Acc: 64.31%\n",
      "Epoch 2/3, Batch 970, Loss: 0.2861, Acc: 64.26%\n",
      "Epoch 2/3, Batch 980, Loss: 0.9289, Acc: 64.42%\n",
      "Epoch 2/3, Batch 990, Loss: 1.6306, Acc: 64.48%\n",
      "Epoch 2/3, Batch 1000, Loss: 0.0661, Acc: 64.54%\n",
      "Epoch 2/3, Batch 1010, Loss: 0.0985, Acc: 64.79%\n",
      "Epoch 2/3, Batch 1020, Loss: 0.9696, Acc: 64.74%\n",
      "Epoch 2/3, Batch 1030, Loss: 1.2013, Acc: 64.99%\n",
      "Epoch 2/3, Batch 1040, Loss: 1.6191, Acc: 65.13%\n",
      "Epoch 2/3, Batch 1050, Loss: 0.8173, Acc: 65.18%\n",
      "Epoch 2/3, Batch 1060, Loss: 0.0039, Acc: 65.13%\n",
      "Epoch 2/3, Batch 1070, Loss: 0.0604, Acc: 65.17%\n",
      "Epoch 2/3, Batch 1080, Loss: 0.0815, Acc: 65.12%\n",
      "Epoch 2/3, Batch 1090, Loss: 0.0169, Acc: 65.17%\n",
      "Epoch 2/3, Batch 1100, Loss: 0.1371, Acc: 65.40%\n",
      "Epoch 2/3, Batch 1110, Loss: 0.0157, Acc: 65.17%\n",
      "Epoch 2/3, Batch 1120, Loss: 0.8999, Acc: 65.21%\n",
      "Epoch 2/3, Batch 1130, Loss: 0.0492, Acc: 65.43%\n",
      "Epoch 2/3, Batch 1140, Loss: 0.2548, Acc: 65.64%\n",
      "Epoch 2/3, Batch 1150, Loss: 0.5791, Acc: 65.68%\n",
      "Epoch 2/3, Batch 1160, Loss: 0.5727, Acc: 65.81%\n",
      "Epoch 2/3, Batch 1170, Loss: 0.3104, Acc: 65.58%\n",
      "Epoch 2/3, Batch 1180, Loss: 0.0597, Acc: 65.54%\n",
      "Epoch 2/3, Batch 1190, Loss: 0.2188, Acc: 65.32%\n",
      "Epoch 2/3, Batch 1200, Loss: 0.0904, Acc: 65.28%\n",
      "Epoch 2/3, Batch 1210, Loss: 2.5679, Acc: 65.15%\n",
      "Epoch 2/3, Batch 1220, Loss: 2.0006, Acc: 65.03%\n",
      "Epoch 2/3, Batch 1230, Loss: 0.5105, Acc: 64.91%\n",
      "Epoch 2/3, Batch 1240, Loss: 1.2295, Acc: 64.95%\n",
      "Epoch 2/3, Batch 1250, Loss: 0.4572, Acc: 64.83%\n",
      "Epoch 2/3, Batch 1260, Loss: 1.0476, Acc: 64.71%\n",
      "Epoch 2/3, Batch 1270, Loss: 1.7128, Acc: 64.44%\n",
      "Epoch 2/3, Batch 1280, Loss: 0.0371, Acc: 64.32%\n",
      "Epoch 2/3, Batch 1290, Loss: 0.8331, Acc: 64.21%\n",
      "Epoch 2/3, Batch 1300, Loss: 1.7926, Acc: 64.26%\n",
      "Epoch 2/3, Batch 1310, Loss: 0.0486, Acc: 64.30%\n",
      "Epoch 2/3, Batch 1320, Loss: 1.3608, Acc: 64.27%\n",
      "Epoch 2/3, Batch 1330, Loss: 0.4690, Acc: 64.39%\n",
      "Epoch 2/3, Batch 1340, Loss: 0.1585, Acc: 64.43%\n",
      "Epoch 2/3, Batch 1350, Loss: 0.1953, Acc: 64.54%\n",
      "Epoch 2/3, Batch 1360, Loss: 0.1729, Acc: 64.44%\n",
      "Epoch 2/3, Batch 1370, Loss: 0.1628, Acc: 64.55%\n",
      "Epoch 2/3, Batch 1380, Loss: 1.0973, Acc: 64.59%\n",
      "Epoch 2/3, Batch 1390, Loss: 1.4873, Acc: 64.41%\n",
      "Epoch 2/3, Batch 1400, Loss: 0.2408, Acc: 64.38%\n",
      "Epoch 2/3, Batch 1410, Loss: 0.4408, Acc: 64.49%\n",
      "Epoch 2/3, Batch 1420, Loss: 0.2521, Acc: 64.60%\n",
      "Epoch 2/3, Batch 1430, Loss: 0.0176, Acc: 64.71%\n",
      "Epoch 2/3, Batch 1440, Loss: 3.3222, Acc: 64.75%\n",
      "Epoch 2/3, Batch 1450, Loss: 0.6446, Acc: 64.78%\n",
      "Epoch 2/3, Batch 1460, Loss: 0.0054, Acc: 64.82%\n",
      "Epoch 2/3, Batch 1470, Loss: 3.2170, Acc: 64.79%\n",
      "Epoch 2/3, Batch 1480, Loss: 0.5087, Acc: 64.89%\n",
      "Epoch 2/3, Batch 1490, Loss: 0.0302, Acc: 64.92%\n",
      "Epoch 2/3, Batch 1500, Loss: 0.2120, Acc: 64.82%\n",
      "Epoch 2/3, Batch 1510, Loss: 0.7527, Acc: 64.66%\n",
      "Epoch 2/3, Batch 1520, Loss: 0.8900, Acc: 64.63%\n",
      "Epoch 2/3, Batch 1530, Loss: 0.5904, Acc: 64.60%\n",
      "Epoch 2/3, Batch 1540, Loss: 0.0976, Acc: 64.57%\n",
      "Epoch 2/3, Batch 1550, Loss: 0.4817, Acc: 64.60%\n",
      "Epoch 2/3, Batch 1560, Loss: 0.8158, Acc: 64.51%\n",
      "Epoch 2/3, Batch 1570, Loss: 1.3576, Acc: 64.54%\n",
      "Epoch 2/3, Batch 1580, Loss: 0.0224, Acc: 64.52%\n",
      "Epoch 2/3, Batch 1590, Loss: 0.7638, Acc: 64.55%\n",
      "Epoch 2/3, Batch 1600, Loss: 0.2609, Acc: 64.58%\n",
      "Epoch 2/3, Batch 1610, Loss: 0.3650, Acc: 64.49%\n",
      "Epoch 2/3, Batch 1620, Loss: 0.0442, Acc: 64.47%\n",
      "Epoch 2/3, Batch 1630, Loss: 0.5871, Acc: 64.44%\n",
      "Epoch 2/3, Batch 1640, Loss: 0.1374, Acc: 64.47%\n",
      "Epoch 2/3, Batch 1650, Loss: 0.5388, Acc: 64.69%\n",
      "Epoch 2/3, Batch 1660, Loss: 0.8133, Acc: 64.48%\n",
      "Epoch 2/3, Batch 1670, Loss: 2.5717, Acc: 64.45%\n",
      "Epoch 2/3, Batch 1680, Loss: 0.2387, Acc: 64.60%\n",
      "Epoch 2/3, Batch 1690, Loss: 0.1590, Acc: 64.70%\n",
      "Epoch 2/3, Batch 1700, Loss: 1.3217, Acc: 64.73%\n",
      "Epoch 2/3, Batch 1710, Loss: 0.3510, Acc: 64.82%\n",
      "Epoch 2/3, Batch 1720, Loss: 0.0123, Acc: 64.85%\n",
      "Epoch 2/3, Batch 1730, Loss: 0.8277, Acc: 64.76%\n",
      "Epoch 2/3, Batch 1740, Loss: 0.8016, Acc: 64.68%\n",
      "Epoch 2/3, Batch 1750, Loss: 0.0765, Acc: 64.65%\n",
      "Epoch 2/3, Batch 1760, Loss: 0.3501, Acc: 64.68%\n",
      "Epoch 2/3, Batch 1770, Loss: 0.2480, Acc: 64.54%\n",
      "Epoch 2/3, Batch 1780, Loss: 0.8489, Acc: 64.57%\n",
      "Epoch 2/3, Batch 1790, Loss: 1.6099, Acc: 64.54%\n",
      "Epoch 2/3, Batch 1800, Loss: 1.6409, Acc: 64.58%\n",
      "Epoch 2/3, Batch 1810, Loss: 0.5111, Acc: 64.61%\n",
      "Epoch 2/3, Batch 1820, Loss: 0.0876, Acc: 64.58%\n",
      "Epoch 2/3, Batch 1830, Loss: 0.6914, Acc: 64.61%\n",
      "Epoch 2/3, Batch 1840, Loss: 1.0222, Acc: 64.64%\n",
      "Epoch 2/3, Batch 1850, Loss: 0.8796, Acc: 64.61%\n",
      "Epoch 2/3, Batch 1860, Loss: 0.3556, Acc: 64.59%\n",
      "Epoch 2/3, Batch 1870, Loss: 0.3010, Acc: 64.51%\n",
      "Epoch 2/3, Batch 1880, Loss: 0.9342, Acc: 64.59%\n",
      "Epoch 2/3, Batch 1890, Loss: 3.3464, Acc: 64.62%\n",
      "Epoch 2/3, Batch 1900, Loss: 0.6456, Acc: 64.70%\n",
      "Epoch 2/3, Batch 1910, Loss: 0.4175, Acc: 64.68%\n",
      "Epoch 2/3, Batch 1920, Loss: 0.9229, Acc: 64.76%\n",
      "Epoch 2/3, Batch 1930, Loss: 0.3731, Acc: 64.84%\n",
      "Epoch 2/3, Batch 1940, Loss: 0.0011, Acc: 64.86%\n",
      "Epoch 2/3, Batch 1950, Loss: 2.7173, Acc: 64.94%\n",
      "Epoch 2/3, Batch 1960, Loss: 0.6883, Acc: 64.97%\n",
      "Epoch 2/3, Batch 1970, Loss: 1.1467, Acc: 64.94%\n",
      "Epoch 2/3, Batch 1980, Loss: 1.0652, Acc: 64.97%\n",
      "Epoch 2/3, Batch 1990, Loss: 0.9687, Acc: 64.94%\n",
      "Epoch 2/3, Batch 2000, Loss: 1.6792, Acc: 64.97%\n",
      "Epoch 2/3, Batch 2010, Loss: 0.1268, Acc: 64.94%\n",
      "Epoch 2/3, Batch 2020, Loss: 0.0426, Acc: 65.02%\n",
      "Epoch 2/3, Batch 2030, Loss: 0.1438, Acc: 65.09%\n",
      "Epoch 2/3, Batch 2040, Loss: 0.5709, Acc: 65.16%\n",
      "Epoch 2/3, Batch 2050, Loss: 0.7084, Acc: 65.14%\n",
      "Epoch 2/3, Batch 2060, Loss: 0.6869, Acc: 65.21%\n",
      "Epoch 2/3, Batch 2070, Loss: 0.0479, Acc: 65.14%\n",
      "Epoch 2/3, Batch 2080, Loss: 0.0715, Acc: 65.16%\n",
      "Epoch 2/3, Batch 2090, Loss: 1.3128, Acc: 65.28%\n",
      "Epoch 2/3, Batch 2100, Loss: 0.5390, Acc: 65.30%\n",
      "Epoch 2/3, Batch 2110, Loss: 0.0020, Acc: 65.23%\n",
      "Epoch 2/3, Batch 2120, Loss: 0.5548, Acc: 65.30%\n",
      "Epoch 2/3, Batch 2130, Loss: 0.0201, Acc: 65.23%\n",
      "Epoch 2/3, Batch 2140, Loss: 0.2906, Acc: 65.25%\n",
      "Epoch 2/3, Batch 2150, Loss: 1.8387, Acc: 65.13%\n",
      "Epoch 2/3, Batch 2160, Loss: 0.0420, Acc: 65.06%\n",
      "Epoch 2/3, Batch 2170, Loss: 0.0044, Acc: 65.18%\n",
      "Epoch 2/3, Batch 2180, Loss: 0.1609, Acc: 65.20%\n",
      "Epoch 2/3, Batch 2190, Loss: 0.6575, Acc: 65.18%\n",
      "Epoch 2/3, Batch 2200, Loss: 1.2064, Acc: 65.15%\n",
      "Epoch 2/3, Batch 2210, Loss: 0.2430, Acc: 65.17%\n",
      "Epoch 2/3, Batch 2220, Loss: 0.5642, Acc: 65.29%\n",
      "Epoch 2/3, Batch 2230, Loss: 0.4001, Acc: 65.22%\n",
      "Epoch 2/3, Batch 2240, Loss: 1.6973, Acc: 65.19%\n",
      "Epoch 2/3, Batch 2250, Loss: 1.4887, Acc: 65.26%\n",
      "Epoch 2/3, Batch 2260, Loss: 0.9293, Acc: 65.15%\n",
      "Epoch 2/3, Batch 2270, Loss: 0.0131, Acc: 65.13%\n",
      "Epoch 2/3, Batch 2280, Loss: 0.7986, Acc: 65.06%\n",
      "Epoch 2/3, Batch 2290, Loss: 0.0436, Acc: 64.99%\n",
      "Epoch 2/3, Batch 2300, Loss: 0.3244, Acc: 65.02%\n",
      "Epoch 2/3, Batch 2310, Loss: 0.6715, Acc: 64.99%\n",
      "Epoch 2/3, Batch 2320, Loss: 0.2687, Acc: 65.02%\n",
      "Epoch 2/3, Batch 2330, Loss: 0.1095, Acc: 65.04%\n",
      "Epoch 2/3, Batch 2340, Loss: 0.8837, Acc: 65.06%\n",
      "Epoch 2/3, Batch 2350, Loss: 0.8036, Acc: 65.12%\n",
      "Epoch 2/3, Batch 2360, Loss: 0.0178, Acc: 65.10%\n",
      "Epoch 2/3, Batch 2370, Loss: 0.1535, Acc: 65.16%\n",
      "Epoch 2/3, Batch 2380, Loss: 0.3316, Acc: 65.22%\n",
      "Epoch 2/3, Batch 2390, Loss: 0.4573, Acc: 65.24%\n",
      "Epoch 2/3, Batch 2400, Loss: 0.8565, Acc: 65.26%\n",
      "Epoch 2/3, Batch 2410, Loss: 2.2440, Acc: 65.24%\n",
      "Epoch 2/3, Batch 2420, Loss: 0.3681, Acc: 65.30%\n",
      "Epoch 2/3, Batch 2430, Loss: 0.2828, Acc: 65.28%\n",
      "Epoch 2/3, Batch 2440, Loss: 0.2952, Acc: 65.30%\n",
      "Epoch 2/3, Batch 2450, Loss: 1.3836, Acc: 65.28%\n",
      "Epoch 2/3, Batch 2460, Loss: 0.6953, Acc: 65.30%\n",
      "Epoch 2/3, Batch 2470, Loss: 0.2896, Acc: 65.24%\n",
      "Epoch 2/3, Batch 2480, Loss: 0.8874, Acc: 65.30%\n",
      "Epoch 2/3, Batch 2490, Loss: 0.7927, Acc: 65.27%\n",
      "Epoch 2/3, Batch 2500, Loss: 0.9675, Acc: 65.21%\n",
      "Epoch 2/3, Batch 2510, Loss: 0.0178, Acc: 65.23%\n",
      "Epoch 2/3, Batch 2520, Loss: 0.9097, Acc: 65.29%\n",
      "Epoch 2/3, Batch 2530, Loss: 0.4367, Acc: 65.27%\n",
      "Epoch 2/3, Batch 2540, Loss: 0.8856, Acc: 65.29%\n",
      "Epoch 2/3, Batch 2550, Loss: 0.0343, Acc: 65.43%\n",
      "Epoch 2/3, Batch 2560, Loss: 0.5642, Acc: 65.40%\n",
      "Epoch 2/3, Batch 2570, Loss: 1.1473, Acc: 65.34%\n",
      "Epoch 2/3, Batch 2580, Loss: 0.3752, Acc: 65.40%\n",
      "Epoch 2/3, Batch 2590, Loss: 1.2504, Acc: 65.30%\n",
      "Epoch 2/3, Batch 2600, Loss: 0.1076, Acc: 65.40%\n",
      "Epoch 2/3, Batch 2610, Loss: 0.0893, Acc: 65.30%\n",
      "Epoch 2/3, Batch 2620, Loss: 0.0516, Acc: 65.39%\n",
      "Epoch 2/3, Batch 2630, Loss: 1.3996, Acc: 65.34%\n",
      "Epoch 2/3, Batch 2640, Loss: 0.6563, Acc: 65.39%\n",
      "Epoch 2/3, Batch 2650, Loss: 0.0033, Acc: 65.37%\n",
      "Epoch 2/3, Batch 2660, Loss: 0.7941, Acc: 65.35%\n",
      "Epoch 2/3, Batch 2670, Loss: 1.9471, Acc: 65.26%\n",
      "Epoch 2/3, Batch 2680, Loss: 0.1400, Acc: 65.35%\n",
      "Epoch 2/3, Batch 2690, Loss: 0.2458, Acc: 65.40%\n",
      "Epoch 2/3, Batch 2700, Loss: 0.3766, Acc: 65.31%\n",
      "Epoch 2/3, Batch 2710, Loss: 0.8605, Acc: 65.36%\n",
      "Epoch 2/3, Batch 2720, Loss: 0.2625, Acc: 65.42%\n",
      "Epoch 2/3, Batch 2730, Loss: 1.0715, Acc: 65.25%\n",
      "Epoch 2/3, Batch 2740, Loss: 0.0437, Acc: 65.27%\n",
      "Epoch 2/3, Batch 2750, Loss: 0.5862, Acc: 65.39%\n",
      "Epoch 2/3, Batch 2760, Loss: 0.3752, Acc: 65.41%\n",
      "Epoch 2/3, Batch 2770, Loss: 0.0341, Acc: 65.39%\n",
      "Epoch 2/3, Batch 2780, Loss: 1.1461, Acc: 65.37%\n",
      "Epoch 2/3, Batch 2790, Loss: 1.8337, Acc: 65.28%\n",
      "Epoch 2/3, Batch 2800, Loss: 0.3295, Acc: 65.33%\n",
      "Epoch 2/3, Batch 2810, Loss: 1.1856, Acc: 65.39%\n",
      "Epoch 2/3, Batch 2820, Loss: 0.0501, Acc: 65.40%\n",
      "Epoch 2/3, Batch 2830, Loss: 1.6419, Acc: 65.35%\n",
      "Epoch 2/3, Batch 2840, Loss: 0.6949, Acc: 65.33%\n",
      "Epoch 2/3, Batch 2850, Loss: 0.0234, Acc: 65.31%\n",
      "Epoch 2/3, Batch 2860, Loss: 0.8524, Acc: 65.29%\n",
      "Epoch 2/3, Batch 2870, Loss: 0.2449, Acc: 65.20%\n",
      "Epoch 2/3, Batch 2880, Loss: 0.3287, Acc: 65.29%\n",
      "Epoch 2/3, Batch 2890, Loss: 0.2398, Acc: 65.31%\n",
      "Epoch 2/3, Batch 2900, Loss: 0.4501, Acc: 65.29%\n",
      "Epoch 2/3, Batch 2910, Loss: 0.4512, Acc: 65.24%\n",
      "Epoch 2/3, Batch 2920, Loss: 0.0091, Acc: 65.25%\n",
      "Epoch 2/3, Batch 2930, Loss: 0.0344, Acc: 65.30%\n",
      "Epoch 2/3, Batch 2940, Loss: 0.9139, Acc: 65.32%\n",
      "Epoch 2/3, Batch 2950, Loss: 0.9234, Acc: 65.23%\n",
      "Epoch 2/3, Batch 2960, Loss: 0.6032, Acc: 65.21%\n",
      "Epoch 2/3, Batch 2970, Loss: 2.2162, Acc: 65.23%\n",
      "Epoch 2/3, Batch 2980, Loss: 0.0860, Acc: 65.28%\n",
      "Epoch 2/3, Batch 2990, Loss: 0.1187, Acc: 65.20%\n",
      "Epoch 2/3, Batch 3000, Loss: 0.4304, Acc: 65.24%\n",
      "Epoch 2/3, Batch 3010, Loss: 0.6666, Acc: 65.16%\n",
      "Epoch 2/3, Batch 3020, Loss: 0.0581, Acc: 65.18%\n",
      "Epoch 2/3, Batch 3030, Loss: 0.0685, Acc: 65.23%\n",
      "Epoch 2/3, Batch 3040, Loss: 0.3223, Acc: 65.21%\n",
      "Epoch 2/3, Batch 3050, Loss: 0.6270, Acc: 65.22%\n",
      "Epoch 2/3, Batch 3060, Loss: 0.0019, Acc: 65.24%\n",
      "Epoch 2/3, Batch 3070, Loss: 0.2998, Acc: 65.22%\n",
      "Epoch 2/3, Batch 3080, Loss: 0.3136, Acc: 65.11%\n",
      "Epoch 2/3, Batch 3090, Loss: 0.0176, Acc: 65.09%\n",
      "Epoch 2/3, Batch 3100, Loss: 0.0788, Acc: 65.11%\n",
      "Epoch 2/3, Batch 3110, Loss: 1.2554, Acc: 65.00%\n",
      "Epoch 2/3, Batch 3120, Loss: 0.9827, Acc: 64.98%\n",
      "Epoch 2/3, Batch 3130, Loss: 0.0063, Acc: 65.00%\n",
      "Epoch 2/3, Batch 3140, Loss: 0.2562, Acc: 65.01%\n",
      "Epoch 2/3, Batch 3150, Loss: 0.6847, Acc: 65.00%\n",
      "Epoch 2/3, Batch 3160, Loss: 0.0124, Acc: 65.04%\n",
      "Epoch 2/3, Batch 3170, Loss: 0.0101, Acc: 64.96%\n",
      "Epoch 2/3, Batch 3180, Loss: 0.5023, Acc: 64.98%\n",
      "Epoch 2/3, Batch 3190, Loss: 0.5388, Acc: 65.06%\n",
      "Epoch 2/3, Batch 3200, Loss: 0.5718, Acc: 65.10%\n",
      "Epoch 2/3, Batch 3210, Loss: 0.3069, Acc: 65.06%\n",
      "Epoch 2/3, Batch 3220, Loss: 0.1910, Acc: 65.14%\n",
      "Epoch 2/3, Batch 3230, Loss: 0.2665, Acc: 65.15%\n",
      "Epoch 2/3, Batch 3240, Loss: 0.1367, Acc: 65.23%\n",
      "Epoch 2/3, Batch 3250, Loss: 2.3940, Acc: 65.15%\n",
      "Epoch 2/3, Batch 3260, Loss: 0.0282, Acc: 65.07%\n",
      "Epoch 2/3, Batch 3270, Loss: 0.0512, Acc: 65.12%\n",
      "Epoch 2/3, Batch 3280, Loss: 0.0276, Acc: 65.10%\n",
      "Epoch 2/3, Batch 3290, Loss: 0.6917, Acc: 65.09%\n",
      "Epoch 2/3, Batch 3300, Loss: 2.1863, Acc: 65.07%\n",
      "Epoch 2/3, Batch 3310, Loss: 0.0691, Acc: 65.12%\n",
      "Epoch 2/3, Batch 3320, Loss: 0.0028, Acc: 65.19%\n",
      "Epoch 2/3, Batch 3330, Loss: 0.6250, Acc: 65.24%\n",
      "Epoch 2/3, Batch 3340, Loss: 0.0091, Acc: 65.25%\n",
      "Epoch 2/3, Batch 3350, Loss: 0.6224, Acc: 65.26%\n",
      "Epoch 2/3, Batch 3360, Loss: 0.4720, Acc: 65.16%\n",
      "Epoch 2/3, Batch 3370, Loss: 0.0721, Acc: 65.17%\n",
      "Epoch 2/3, Batch 3380, Loss: 0.6191, Acc: 65.16%\n",
      "Epoch 2/3, Batch 3390, Loss: 0.4955, Acc: 65.14%\n",
      "Epoch 2/3, Batch 3400, Loss: 1.8215, Acc: 65.16%\n",
      "Epoch 2/3, Batch 3410, Loss: 0.1646, Acc: 65.20%\n",
      "Epoch 2/3, Batch 3420, Loss: 0.4501, Acc: 65.24%\n",
      "Epoch 2/3, Batch 3430, Loss: 0.5111, Acc: 65.26%\n",
      "Epoch 2/3, Batch 3440, Loss: 0.5631, Acc: 65.27%\n",
      "Epoch 2/3, Batch 3450, Loss: 0.2483, Acc: 65.26%\n",
      "Epoch 2/3, Batch 3460, Loss: 0.3807, Acc: 65.24%\n",
      "Epoch 2/3, Batch 3470, Loss: 0.1730, Acc: 65.20%\n",
      "Epoch 2/3, Batch 3480, Loss: 0.9873, Acc: 65.21%\n",
      "Epoch 2/3, Batch 3490, Loss: 2.1319, Acc: 65.20%\n",
      "Epoch 2/3, Batch 3500, Loss: 1.2436, Acc: 65.15%\n",
      "Epoch 2/3, Batch 3510, Loss: 1.8983, Acc: 65.20%\n",
      "Epoch 2/3, Batch 3520, Loss: 0.5446, Acc: 65.24%\n",
      "Epoch 2/3, Batch 3530, Loss: 0.8188, Acc: 65.25%\n",
      "Epoch 2/3, Batch 3540, Loss: 0.0063, Acc: 65.26%\n",
      "Epoch 2/3, Batch 3550, Loss: 0.0324, Acc: 65.22%\n",
      "Epoch 2/3, Batch 3560, Loss: 0.1290, Acc: 65.15%\n",
      "Epoch 2/3, Batch 3570, Loss: 0.0322, Acc: 65.19%\n",
      "Epoch 2/3, Batch 3580, Loss: 0.4438, Acc: 65.21%\n",
      "Epoch 2/3, Batch 3590, Loss: 0.7285, Acc: 65.25%\n",
      "Epoch 2/3, Batch 3600, Loss: 0.1696, Acc: 65.26%\n",
      "Epoch 2/3, Batch 3610, Loss: 0.0507, Acc: 65.30%\n",
      "Epoch 2/3, Batch 3620, Loss: 0.6476, Acc: 65.26%\n",
      "Epoch 2/3, Batch 3630, Loss: 2.6603, Acc: 65.19%\n",
      "Epoch 2/3, Batch 3640, Loss: 0.2263, Acc: 65.20%\n",
      "Epoch 2/3, Batch 3650, Loss: 1.0891, Acc: 65.16%\n",
      "Epoch 2/3, Batch 3660, Loss: 0.0478, Acc: 65.20%\n",
      "Epoch 2/3, Batch 3670, Loss: 0.3757, Acc: 65.21%\n",
      "Epoch 2/3, Batch 3680, Loss: 0.0099, Acc: 65.17%\n",
      "Epoch 2/3, Batch 3690, Loss: 1.8505, Acc: 65.16%\n",
      "Epoch 2/3, Batch 3700, Loss: 0.3681, Acc: 65.20%\n",
      "Epoch 2/3, Batch 3710, Loss: 1.0029, Acc: 65.21%\n",
      "Epoch 2/3, Batch 3720, Loss: 0.2071, Acc: 65.25%\n",
      "Epoch 2/3, Batch 3730, Loss: 0.0891, Acc: 65.26%\n",
      "Epoch 2/3, Batch 3740, Loss: 0.9594, Acc: 65.17%\n",
      "Epoch 2/3, Batch 3750, Loss: 0.8816, Acc: 65.16%\n",
      "Epoch 2/3, Batch 3760, Loss: 1.0298, Acc: 65.09%\n",
      "Epoch 2/3, Batch 3770, Loss: 1.0865, Acc: 65.08%\n",
      "Epoch 2/3, Batch 3780, Loss: 0.4416, Acc: 65.09%\n",
      "Epoch 2/3, Batch 3790, Loss: 0.0028, Acc: 65.13%\n",
      "Epoch 2/3, Batch 3800, Loss: 3.3348, Acc: 65.14%\n",
      "Epoch 2/3, Batch 3810, Loss: 0.0944, Acc: 65.18%\n",
      "Epoch 2/3, Batch 3820, Loss: 1.3077, Acc: 65.11%\n",
      "Epoch 2/3, Batch 3830, Loss: 0.2482, Acc: 65.05%\n",
      "Epoch 2/3, Batch 3840, Loss: 0.6998, Acc: 65.06%\n",
      "Epoch 2/3, Batch 3850, Loss: 0.2869, Acc: 65.07%\n",
      "Epoch 2/3, Batch 3860, Loss: 0.0248, Acc: 65.03%\n",
      "Epoch 2/3, Batch 3870, Loss: 0.3329, Acc: 65.00%\n",
      "Epoch 2/3, Batch 3880, Loss: 0.3205, Acc: 65.01%\n",
      "Epoch 2/3, Batch 3890, Loss: 0.2711, Acc: 64.97%\n",
      "Epoch 2/3, Batch 3900, Loss: 0.0273, Acc: 64.96%\n",
      "Epoch 2/3, Batch 3910, Loss: 1.3868, Acc: 64.97%\n",
      "Epoch 2/3, Batch 3920, Loss: 0.3229, Acc: 65.01%\n",
      "Epoch 2/3, Batch 3930, Loss: 0.3957, Acc: 64.95%\n",
      "Epoch 2/3, Batch 3940, Loss: 1.0922, Acc: 64.91%\n",
      "Epoch 2/3, Batch 3950, Loss: 0.2994, Acc: 64.95%\n",
      "Epoch 2/3, Batch 3960, Loss: 0.1395, Acc: 64.93%\n",
      "Epoch 2/3, Batch 3970, Loss: 0.0956, Acc: 64.92%\n",
      "Epoch 2/3, Batch 3980, Loss: 0.9809, Acc: 64.93%\n",
      "Epoch 2/3, Batch 3990, Loss: 0.8879, Acc: 64.95%\n",
      "Epoch 2/3, Batch 4000, Loss: 1.9358, Acc: 64.93%\n",
      "Epoch 2/3, Batch 4010, Loss: 0.5176, Acc: 64.97%\n",
      "Epoch 2/3, Batch 4020, Loss: 1.3838, Acc: 64.93%\n",
      "Epoch 2/3, Batch 4030, Loss: 1.2296, Acc: 64.90%\n",
      "Epoch 2/3, Batch 4040, Loss: 0.1959, Acc: 64.91%\n",
      "Epoch 2/3, Batch 4050, Loss: 0.0876, Acc: 64.85%\n",
      "Epoch 2/3, Batch 4060, Loss: 0.2760, Acc: 64.91%\n",
      "Epoch 2/3, Batch 4070, Loss: 0.3096, Acc: 64.85%\n",
      "Epoch 2/3, Batch 4080, Loss: 1.0542, Acc: 64.84%\n",
      "Epoch 2/3, Batch 4090, Loss: 0.5201, Acc: 64.85%\n",
      "Epoch 2/3, Batch 4100, Loss: 0.8859, Acc: 64.86%\n",
      "Epoch 2/3, Batch 4110, Loss: 0.1875, Acc: 64.90%\n",
      "Epoch 2/3, Batch 4120, Loss: 0.6944, Acc: 64.94%\n",
      "Epoch 2/3, Batch 4130, Loss: 0.2107, Acc: 64.92%\n",
      "Epoch 2/3, Batch 4140, Loss: 1.6191, Acc: 64.84%\n",
      "Epoch 2/3, Batch 4150, Loss: 0.7473, Acc: 64.78%\n",
      "Epoch 2/3, Batch 4160, Loss: 0.0112, Acc: 64.82%\n",
      "Epoch 2/3, Batch 4170, Loss: 0.5867, Acc: 64.88%\n",
      "Epoch 2/3, Batch 4180, Loss: 0.1931, Acc: 64.89%\n",
      "Epoch 2/3, Batch 4190, Loss: 0.7104, Acc: 64.90%\n",
      "Epoch 2/3, Batch 4200, Loss: 0.7491, Acc: 64.89%\n",
      "Epoch 2/3, Batch 4210, Loss: 2.6876, Acc: 64.88%\n",
      "Epoch 2/3, Batch 4220, Loss: 1.0483, Acc: 64.82%\n",
      "Epoch 2/3, Batch 4230, Loss: 1.3705, Acc: 64.81%\n",
      "Epoch 2/3, Batch 4240, Loss: 0.6755, Acc: 64.80%\n",
      "Epoch 2/3, Batch 4250, Loss: 0.4719, Acc: 64.78%\n",
      "Epoch 2/3, Batch 4260, Loss: 0.3564, Acc: 64.70%\n",
      "Epoch 2/3, Batch 4270, Loss: 0.1074, Acc: 64.69%\n",
      "Epoch 2/3, Batch 4280, Loss: 0.4766, Acc: 64.73%\n",
      "Epoch 2/3, Batch 4290, Loss: 0.7477, Acc: 64.72%\n",
      "Epoch 2/3, Batch 4300, Loss: 0.0008, Acc: 64.66%\n",
      "Epoch 2/3, Batch 4310, Loss: 0.2012, Acc: 64.65%\n",
      "Epoch 2/3, Batch 4320, Loss: 0.0042, Acc: 64.64%\n",
      "Epoch 2/3, Batch 4330, Loss: 0.3949, Acc: 64.63%\n",
      "Epoch 2/3, Batch 4340, Loss: 0.0305, Acc: 64.66%\n",
      "Epoch 2/3, Batch 4350, Loss: 0.6323, Acc: 64.63%\n",
      "Epoch 2/3, Batch 4360, Loss: 0.7193, Acc: 64.62%\n",
      "Epoch 2/3, Batch 4370, Loss: 0.1241, Acc: 64.58%\n",
      "Epoch 2/3, Batch 4380, Loss: 0.4988, Acc: 64.60%\n",
      "Epoch 2/3, Batch 4390, Loss: 0.0184, Acc: 64.63%\n",
      "Epoch 2/3, Batch 4400, Loss: 0.9121, Acc: 64.60%\n",
      "Epoch 2/3, Batch 4410, Loss: 1.6305, Acc: 64.52%\n",
      "Epoch 2/3, Batch 4420, Loss: 0.2605, Acc: 64.51%\n",
      "Epoch 2/3, Batch 4430, Loss: 2.2473, Acc: 64.50%\n",
      "Epoch 2/3, Batch 4440, Loss: 0.2751, Acc: 64.54%\n",
      "Epoch 2/3, Batch 4450, Loss: 0.0552, Acc: 64.59%\n",
      "Epoch 2/3, Batch 4460, Loss: 0.8241, Acc: 64.56%\n",
      "Epoch 2/3, Batch 4470, Loss: 0.2399, Acc: 64.59%\n",
      "Epoch 2/3, Batch 4480, Loss: 0.1244, Acc: 64.61%\n",
      "Epoch 2/3, Batch 4490, Loss: 0.4869, Acc: 64.60%\n",
      "Epoch 2/3, Batch 4500, Loss: 0.5074, Acc: 64.59%\n",
      "Epoch 2/3, Batch 4510, Loss: 0.1347, Acc: 64.62%\n",
      "Epoch 2/3, Batch 4520, Loss: 2.2322, Acc: 64.61%\n",
      "Epoch 2/3, Batch 4530, Loss: 0.0042, Acc: 64.60%\n",
      "Epoch 2/3, Batch 4540, Loss: 0.0608, Acc: 64.59%\n",
      "Epoch 2/3, Batch 4550, Loss: 0.1449, Acc: 64.60%\n",
      "Epoch 2/3, Batch 4560, Loss: 0.2844, Acc: 64.63%\n",
      "Epoch 2/3, Batch 4570, Loss: 1.4616, Acc: 64.56%\n",
      "Epoch 2/3, Batch 4580, Loss: 0.0067, Acc: 64.53%\n",
      "Epoch 2/3, Batch 4590, Loss: 0.0012, Acc: 64.54%\n",
      "Epoch 2/3, Batch 4600, Loss: 0.3204, Acc: 64.49%\n",
      "Epoch 2/3, Batch 4610, Loss: 0.3922, Acc: 64.45%\n",
      "Epoch 2/3, Batch 4620, Loss: 0.3575, Acc: 64.49%\n",
      "Epoch 2/3, Batch 4630, Loss: 0.9688, Acc: 64.46%\n",
      "Epoch 2/3, Batch 4640, Loss: 0.3842, Acc: 64.40%\n",
      "Epoch 2/3, Batch 4650, Loss: 0.5687, Acc: 64.46%\n",
      "Epoch 2/3, Batch 4660, Loss: 0.5961, Acc: 64.43%\n",
      "Epoch 2/3, Batch 4670, Loss: 0.8837, Acc: 64.38%\n",
      "Epoch 2/3, Batch 4680, Loss: 0.7994, Acc: 64.35%\n",
      "Epoch 2/3, Batch 4690, Loss: 1.0027, Acc: 64.34%\n",
      "Epoch 2/3, Batch 4700, Loss: 0.2681, Acc: 64.31%\n",
      "Epoch 2/3, Batch 4710, Loss: 0.7663, Acc: 64.25%\n",
      "Epoch 2/3, Batch 4720, Loss: 0.1421, Acc: 64.27%\n",
      "Epoch 2/3, Batch 4730, Loss: 1.1732, Acc: 64.21%\n",
      "Epoch 2/3, Batch 4740, Loss: 0.0040, Acc: 64.23%\n",
      "Epoch 2/3, Batch 4750, Loss: 0.6195, Acc: 64.26%\n",
      "Epoch 2/3, Batch 4760, Loss: 1.0446, Acc: 64.25%\n",
      "Epoch 2/3, Batch 4770, Loss: 0.0863, Acc: 64.24%\n",
      "Epoch 2/3, Batch 4780, Loss: 0.1566, Acc: 64.28%\n",
      "Epoch 2/3, Batch 4790, Loss: 0.6537, Acc: 64.31%\n",
      "Epoch 2/3, Batch 4800, Loss: 0.3683, Acc: 64.28%\n",
      "Epoch 2/3, Batch 4810, Loss: 1.2138, Acc: 64.25%\n",
      "Epoch 2/3, Batch 4820, Loss: 0.7299, Acc: 64.22%\n",
      "Epoch 2/3, Batch 4830, Loss: 3.6260, Acc: 64.23%\n",
      "Epoch 2/3, Batch 4840, Loss: 1.4005, Acc: 64.22%\n",
      "Epoch 2/3, Batch 4850, Loss: 1.0309, Acc: 64.17%\n",
      "Epoch 2/3, Batch 4860, Loss: 0.2392, Acc: 64.16%\n",
      "Epoch 2/3, Batch 4870, Loss: 0.5222, Acc: 64.18%\n",
      "Epoch 2/3, Batch 4880, Loss: 0.9354, Acc: 64.15%\n",
      "Epoch 2/3, Batch 4890, Loss: 0.2606, Acc: 64.18%\n",
      "Epoch 2/3, Batch 4900, Loss: 0.9879, Acc: 64.17%\n",
      "Epoch 2/3, Batch 4910, Loss: 0.1762, Acc: 64.12%\n",
      "Epoch 2/3, Batch 4920, Loss: 0.1772, Acc: 64.15%\n",
      "Epoch 2/3, Batch 4930, Loss: 2.8896, Acc: 64.12%\n",
      "Epoch 2/3, Batch 4940, Loss: 0.2192, Acc: 64.10%\n",
      "Epoch 2/3, Batch 4950, Loss: 1.4139, Acc: 64.03%\n",
      "Epoch 2/3, Batch 4960, Loss: 0.1918, Acc: 63.98%\n",
      "Epoch 2/3, Batch 4970, Loss: 0.3887, Acc: 64.01%\n",
      "Epoch 2/3, Batch 4980, Loss: 0.0061, Acc: 64.02%\n",
      "Epoch 2/3, Batch 4990, Loss: 0.3086, Acc: 64.02%\n",
      "Epoch 2/3, Batch 5000, Loss: 1.1258, Acc: 64.01%\n",
      "Epoch 2/3, Batch 5010, Loss: 0.1038, Acc: 63.96%\n",
      "Epoch 2/3, Batch 5020, Loss: 1.8166, Acc: 63.97%\n",
      "Epoch 2/3, Batch 5030, Loss: 1.0981, Acc: 63.94%\n",
      "Epoch 2/3, Batch 5040, Loss: 0.7542, Acc: 63.96%\n",
      "Epoch 2/3, Batch 5050, Loss: 0.0538, Acc: 63.95%\n",
      "Epoch 2/3, Batch 5060, Loss: 0.0623, Acc: 64.00%\n",
      "Epoch 2/3, Batch 5070, Loss: 1.0034, Acc: 64.01%\n",
      "Epoch 2/3, Batch 5080, Loss: 0.3807, Acc: 64.04%\n",
      "Epoch 2/3, Batch 5090, Loss: 1.1159, Acc: 64.01%\n",
      "Epoch 2/3, Batch 5100, Loss: 0.6373, Acc: 64.01%\n",
      "Epoch 2/3, Batch 5110, Loss: 0.7411, Acc: 63.98%\n",
      "Epoch 2/3, Batch 5120, Loss: 1.0145, Acc: 63.93%\n",
      "Epoch 2/3, Batch 5130, Loss: 1.3719, Acc: 63.93%\n",
      "Epoch 2/3, Batch 5140, Loss: 0.2871, Acc: 63.96%\n",
      "Epoch 2/3, Batch 5150, Loss: 0.0405, Acc: 63.93%\n",
      "Epoch 2/3, Batch 5160, Loss: 1.2591, Acc: 63.90%\n",
      "Epoch 2/3, Batch 5170, Loss: 0.8966, Acc: 63.86%\n",
      "Epoch 2/3, Batch 5180, Loss: 0.3420, Acc: 63.87%\n",
      "Epoch 2/3, Batch 5190, Loss: 0.2388, Acc: 63.86%\n",
      "Epoch 2/3, Batch 5200, Loss: 1.5764, Acc: 63.80%\n",
      "Epoch 2/3, Batch 5210, Loss: 1.5516, Acc: 63.77%\n",
      "Epoch 2/3, Batch 5220, Loss: 0.4202, Acc: 63.78%\n",
      "Epoch 2/3, Batch 5230, Loss: 2.5504, Acc: 63.79%\n",
      "Epoch 2/3, Batch 5240, Loss: 0.0107, Acc: 63.80%\n",
      "Epoch 2/3, Batch 5250, Loss: 0.5716, Acc: 63.82%\n",
      "Epoch 2/3, Batch 5260, Loss: 1.5835, Acc: 63.83%\n",
      "Epoch 2/3, Batch 5270, Loss: 0.0719, Acc: 63.84%\n",
      "Epoch 2/3, Batch 5280, Loss: 0.1629, Acc: 63.87%\n",
      "Epoch 2/3, Batch 5290, Loss: 0.7739, Acc: 63.86%\n",
      "Epoch 2/3, Batch 5300, Loss: 0.5581, Acc: 63.87%\n",
      "Epoch 2/3, Batch 5310, Loss: 0.1327, Acc: 63.85%\n",
      "Epoch 2/3, Batch 5320, Loss: 0.5836, Acc: 63.84%\n",
      "Epoch 2/3, Batch 5330, Loss: 0.0568, Acc: 63.85%\n",
      "Epoch 2/3, Batch 5340, Loss: 1.5556, Acc: 63.86%\n",
      "Epoch 2/3, Batch 5350, Loss: 1.2130, Acc: 63.89%\n",
      "Epoch 2/3, Batch 5360, Loss: 0.9824, Acc: 63.85%\n",
      "Epoch 2/3, Batch 5370, Loss: 0.6118, Acc: 63.92%\n",
      "Epoch 2/3, Batch 5380, Loss: 0.0263, Acc: 63.93%\n",
      "Epoch 2/3, Batch 5390, Loss: 0.0125, Acc: 63.94%\n",
      "Epoch 2/3, Batch 5400, Loss: 0.7190, Acc: 63.95%\n",
      "Epoch 2/3, Batch 5410, Loss: 0.1434, Acc: 63.98%\n",
      "Epoch 2/3, Batch 5420, Loss: 0.5077, Acc: 63.99%\n",
      "Epoch 2/3, Batch 5430, Loss: 0.0034, Acc: 64.00%\n",
      "Epoch 2/3, Batch 5440, Loss: 0.0399, Acc: 64.01%\n",
      "Epoch 2/3, Batch 5450, Loss: 0.1853, Acc: 64.01%\n",
      "Epoch 2/3, Batch 5460, Loss: 0.9536, Acc: 64.02%\n",
      "Epoch 2/3, Batch 5470, Loss: 1.1919, Acc: 63.99%\n",
      "Epoch 2/3, Batch 5480, Loss: 0.0897, Acc: 63.98%\n",
      "Epoch 2/3, Batch 5490, Loss: 0.1528, Acc: 63.98%\n",
      "Epoch 2/3, Batch 5500, Loss: 1.6816, Acc: 63.97%\n",
      "Epoch 2/3, Batch 5510, Loss: 0.2830, Acc: 64.00%\n",
      "Epoch 2/3, Batch 5520, Loss: 0.0846, Acc: 64.01%\n",
      "Epoch 2/3, Batch 5530, Loss: 0.0863, Acc: 64.00%\n",
      "Epoch 2/3, Batch 5540, Loss: 2.2664, Acc: 64.01%\n",
      "Epoch 2/3, Batch 5550, Loss: 0.6950, Acc: 64.01%\n",
      "Epoch 2/3, Batch 5560, Loss: 2.3261, Acc: 64.00%\n",
      "Epoch 2/3, Batch 5570, Loss: 1.1748, Acc: 63.97%\n",
      "Epoch 2/3, Batch 5580, Loss: 0.2517, Acc: 64.00%\n",
      "Epoch 2/3, Batch 5590, Loss: 0.0580, Acc: 63.98%\n",
      "Epoch 2/3, Batch 5600, Loss: 1.6281, Acc: 63.97%\n",
      "Epoch 2/3, Batch 5610, Loss: 0.2394, Acc: 64.02%\n",
      "Epoch 2/3, Batch 5620, Loss: 0.9720, Acc: 63.96%\n",
      "Epoch 2/3, Batch 5630, Loss: 0.4236, Acc: 63.97%\n",
      "Epoch 2/3, Batch 5640, Loss: 0.0119, Acc: 63.94%\n",
      "Epoch 2/3, Batch 5650, Loss: 1.1517, Acc: 63.94%\n",
      "Epoch 2/3, Batch 5660, Loss: 0.4814, Acc: 63.95%\n",
      "Epoch 2/3, Batch 5670, Loss: 1.3922, Acc: 63.96%\n",
      "Epoch 2/3, Batch 5680, Loss: 0.5069, Acc: 63.97%\n",
      "Epoch 2/3, Batch 5690, Loss: 0.1685, Acc: 63.96%\n",
      "Epoch 2/3, Batch 5700, Loss: 0.6125, Acc: 64.01%\n",
      "Epoch 2/3, Batch 5710, Loss: 0.0481, Acc: 64.02%\n",
      "Epoch 2/3, Batch 5720, Loss: 0.2103, Acc: 64.04%\n",
      "Epoch 2/3, Batch 5730, Loss: 0.8561, Acc: 64.02%\n",
      "Epoch 2/3, Batch 5740, Loss: 0.2893, Acc: 64.00%\n",
      "Epoch 2/3, Batch 5750, Loss: 0.6535, Acc: 64.01%\n",
      "Epoch 2/3, Batch 5760, Loss: 0.1673, Acc: 64.03%\n",
      "Epoch 2/3, Batch 5770, Loss: 1.7353, Acc: 64.01%\n",
      "Epoch 2/3, Batch 5780, Loss: 0.7954, Acc: 64.00%\n",
      "Epoch 2/3, Batch 5790, Loss: 0.9017, Acc: 63.98%\n",
      "Epoch 2/3, Batch 5800, Loss: 1.3971, Acc: 63.99%\n",
      "Epoch 2/3, Batch 5810, Loss: 0.5548, Acc: 64.00%\n",
      "Epoch 2/3, Batch 5820, Loss: 0.3154, Acc: 63.99%\n",
      "Epoch 2/3, Batch 5830, Loss: 1.1042, Acc: 63.99%\n",
      "Epoch 2/3, Batch 5840, Loss: 0.3625, Acc: 64.00%\n",
      "Epoch 2/3, Batch 5850, Loss: 0.4530, Acc: 63.99%\n",
      "Epoch 2/3, Batch 5860, Loss: 1.1177, Acc: 63.97%\n",
      "Epoch 2/3, Batch 5870, Loss: 2.2496, Acc: 63.92%\n",
      "Epoch 2/3, Batch 5880, Loss: 0.3406, Acc: 63.92%\n",
      "Epoch 2/3, Batch 5890, Loss: 1.4151, Acc: 63.91%\n",
      "Epoch 2/3, Batch 5900, Loss: 0.7810, Acc: 63.85%\n",
      "Epoch 2/3, Batch 5910, Loss: 0.5547, Acc: 63.86%\n",
      "Epoch 2/3, Batch 5920, Loss: 0.3115, Acc: 63.91%\n",
      "Epoch 2/3, Batch 5930, Loss: 0.1984, Acc: 63.92%\n",
      "Epoch 2/3, Batch 5940, Loss: 0.0026, Acc: 63.89%\n",
      "Epoch 2/3, Batch 5950, Loss: 0.2105, Acc: 63.91%\n",
      "Epoch 2/3, Batch 5960, Loss: 0.3920, Acc: 63.93%\n",
      "Epoch 2/3, Batch 5970, Loss: 0.1158, Acc: 63.93%\n",
      "Epoch 2/3, Batch 5980, Loss: 1.8394, Acc: 63.90%\n",
      "Epoch 2/3, Batch 5990, Loss: 0.0083, Acc: 63.93%\n",
      "Epoch 2/3, Batch 6000, Loss: 0.1999, Acc: 63.91%\n",
      "Epoch 2/3, Batch 6010, Loss: 0.0894, Acc: 63.88%\n",
      "Epoch 2/3, Batch 6020, Loss: 0.5849, Acc: 63.89%\n",
      "Epoch 2/3, Batch 6030, Loss: 0.1827, Acc: 63.92%\n",
      "Epoch 2/3, Batch 6040, Loss: 0.1031, Acc: 63.90%\n",
      "Epoch 2/3, Batch 6050, Loss: 0.0371, Acc: 63.92%\n",
      "Epoch 2/3, Batch 6060, Loss: 0.2533, Acc: 63.95%\n",
      "Epoch 2/3, Batch 6070, Loss: 0.0346, Acc: 63.98%\n",
      "Epoch 2/3, Batch 6080, Loss: 1.3584, Acc: 63.95%\n",
      "Epoch 2/3, Batch 6090, Loss: 0.0013, Acc: 63.93%\n",
      "Epoch 2/3, Batch 6100, Loss: 0.9236, Acc: 63.94%\n",
      "Epoch 2/3, Batch 6110, Loss: 1.1612, Acc: 63.98%\n",
      "Epoch 2/3, Batch 6120, Loss: 1.2415, Acc: 63.98%\n",
      "Epoch 2/3, Batch 6130, Loss: 0.4198, Acc: 64.00%\n",
      "Epoch 2/3, Batch 6140, Loss: 0.2109, Acc: 64.01%\n",
      "Epoch 2/3, Batch 6150, Loss: 0.7305, Acc: 63.97%\n",
      "Epoch 2/3, Batch 6160, Loss: 0.5251, Acc: 63.98%\n",
      "Epoch 2/3, Batch 6170, Loss: 1.1977, Acc: 63.98%\n",
      "Epoch 2/3, Batch 6180, Loss: 0.0160, Acc: 64.00%\n",
      "Epoch 2/3, Batch 6190, Loss: 0.6133, Acc: 64.01%\n",
      "Epoch 2/3, Batch 6200, Loss: 0.0514, Acc: 64.01%\n",
      "Epoch 2/3, Batch 6210, Loss: 0.4732, Acc: 64.03%\n",
      "Epoch 2/3, Batch 6220, Loss: 1.2773, Acc: 64.01%\n",
      "Epoch 2/3, Batch 6230, Loss: 0.1794, Acc: 64.05%\n",
      "Epoch 2/3, Batch 6240, Loss: 0.2950, Acc: 64.08%\n",
      "Epoch 2/3, Batch 6250, Loss: 1.5905, Acc: 64.04%\n",
      "Epoch 2/3, Batch 6260, Loss: 1.2747, Acc: 63.98%\n",
      "Epoch 2/3, Batch 6270, Loss: 0.9289, Acc: 63.98%\n",
      "Epoch 2/3, Batch 6280, Loss: 1.5444, Acc: 63.95%\n",
      "Epoch 2/3, Batch 6290, Loss: 0.2524, Acc: 64.00%\n",
      "Epoch 2/3, Batch 6300, Loss: 0.4466, Acc: 64.02%\n",
      "Epoch 2/3, Batch 6310, Loss: 0.0007, Acc: 64.03%\n",
      "Epoch 2/3, Batch 6320, Loss: 0.0941, Acc: 64.02%\n",
      "Epoch 2/3, Batch 6330, Loss: 0.7845, Acc: 63.99%\n",
      "Epoch 2/3, Batch 6340, Loss: 0.0181, Acc: 63.96%\n",
      "Epoch 2/3, Batch 6350, Loss: 0.1428, Acc: 63.96%\n",
      "Epoch 2/3, Batch 6360, Loss: 1.7455, Acc: 63.95%\n",
      "Epoch 2/3, Batch 6370, Loss: 1.0086, Acc: 63.93%\n",
      "Epoch 2/3, Batch 6380, Loss: 0.3561, Acc: 63.92%\n",
      "Epoch 2/3, Batch 6390, Loss: 0.0255, Acc: 63.95%\n",
      "Epoch 2/3, Batch 6400, Loss: 0.2051, Acc: 63.97%\n",
      "Epoch 2/3, Batch 6410, Loss: 0.0998, Acc: 63.98%\n",
      "Epoch 2/3, Batch 6420, Loss: 0.0175, Acc: 63.99%\n",
      "Epoch 2/3, Batch 6430, Loss: 0.8098, Acc: 63.97%\n",
      "Epoch 2/3, Batch 6440, Loss: 0.8985, Acc: 63.97%\n",
      "Epoch 2/3, Batch 6450, Loss: 0.7155, Acc: 63.96%\n",
      "Epoch 2/3, Batch 6460, Loss: 0.4046, Acc: 63.95%\n",
      "Epoch 2/3, Batch 6470, Loss: 1.1157, Acc: 63.96%\n",
      "Epoch 2/3, Batch 6480, Loss: 1.0951, Acc: 63.94%\n",
      "Epoch 2/3, Batch 6490, Loss: 0.4278, Acc: 63.98%\n",
      "Epoch 2/3, Batch 6500, Loss: 0.6053, Acc: 63.99%\n",
      "Epoch 2/3, Batch 6510, Loss: 0.0431, Acc: 63.98%\n",
      "Epoch 2/3, Batch 6520, Loss: 0.0132, Acc: 63.95%\n",
      "Epoch 2/3, Batch 6530, Loss: 1.1216, Acc: 63.93%\n",
      "Epoch 2/3, Batch 6540, Loss: 1.6809, Acc: 63.90%\n",
      "Epoch 2/3, Batch 6550, Loss: 0.0180, Acc: 63.93%\n",
      "Epoch 2/3, Batch 6560, Loss: 0.0278, Acc: 63.94%\n",
      "Epoch 2/3, Batch 6570, Loss: 0.4840, Acc: 63.95%\n",
      "Epoch 2/3, Batch 6580, Loss: 0.0021, Acc: 63.99%\n",
      "Epoch 2/3, Batch 6590, Loss: 0.8587, Acc: 63.97%\n",
      "Epoch 2/3, Batch 6600, Loss: 0.0276, Acc: 63.98%\n",
      "Epoch 2/3, Batch 6610, Loss: 1.4246, Acc: 64.00%\n",
      "Epoch 2/3, Batch 6620, Loss: 0.6625, Acc: 63.99%\n",
      "Epoch 2/3, Batch 6630, Loss: 0.6464, Acc: 64.02%\n",
      "Epoch 2/3, Batch 6640, Loss: 0.3346, Acc: 64.03%\n",
      "Epoch 2/3, Batch 6650, Loss: 0.4853, Acc: 64.04%\n",
      "Epoch 2/3, Batch 6660, Loss: 1.9765, Acc: 64.04%\n",
      "Epoch 2/3, Batch 6670, Loss: 1.3737, Acc: 64.04%\n",
      "Epoch 2/3, Batch 6680, Loss: 0.9149, Acc: 64.03%\n",
      "Epoch 2/3, Batch 6690, Loss: 0.0041, Acc: 64.07%\n",
      "Epoch 2/3, Batch 6700, Loss: 0.4712, Acc: 64.09%\n",
      "Epoch 2/3, Batch 6710, Loss: 0.9128, Acc: 64.10%\n",
      "Epoch 2/3, Batch 6720, Loss: 0.0198, Acc: 64.11%\n",
      "Epoch 2/3, Batch 6730, Loss: 0.0946, Acc: 64.15%\n",
      "Epoch 2/3, Batch 6740, Loss: 0.7320, Acc: 64.17%\n",
      "Epoch 2/3, Batch 6750, Loss: 1.4398, Acc: 64.15%\n",
      "Epoch 2/3, Batch 6760, Loss: 0.0558, Acc: 64.15%\n",
      "Epoch 2/3, Batch 6770, Loss: 2.5150, Acc: 64.16%\n",
      "Epoch 2/3, Batch 6780, Loss: 0.5180, Acc: 64.16%\n",
      "Epoch 2/3, Batch 6790, Loss: 1.3418, Acc: 64.14%\n",
      "Epoch 2/3, Batch 6800, Loss: 0.1422, Acc: 64.14%\n",
      "Epoch 2/3, Batch 6810, Loss: 0.5691, Acc: 64.15%\n",
      "Epoch 2/3, Batch 6820, Loss: 1.2678, Acc: 64.13%\n",
      "Epoch 2/3, Batch 6830, Loss: 1.4823, Acc: 64.13%\n",
      "Epoch 2/3, Batch 6840, Loss: 0.1589, Acc: 64.14%\n",
      "Epoch 2/3, Batch 6850, Loss: 0.2750, Acc: 64.14%\n",
      "Epoch 2/3, Batch 6860, Loss: 1.7902, Acc: 64.12%\n",
      "Epoch 2/3, Batch 6870, Loss: 0.0522, Acc: 64.12%\n",
      "Epoch 2/3, Batch 6880, Loss: 1.4006, Acc: 64.10%\n",
      "Epoch 2/3, Batch 6890, Loss: 0.1296, Acc: 64.16%\n",
      "Epoch 2/3, Batch 6900, Loss: 0.2633, Acc: 64.16%\n",
      "Epoch 2/3, Batch 6910, Loss: 0.8530, Acc: 64.13%\n",
      "Epoch 2/3, Batch 6920, Loss: 0.0025, Acc: 64.14%\n",
      "Epoch 2/3, Batch 6930, Loss: 1.5162, Acc: 64.12%\n",
      "Epoch 2/3, Batch 6940, Loss: 0.5946, Acc: 64.10%\n",
      "Epoch 2/3, Batch 6950, Loss: 0.4775, Acc: 64.09%\n",
      "Epoch 2/3, Batch 6960, Loss: 2.3302, Acc: 64.06%\n",
      "Epoch 2/3, Batch 6970, Loss: 2.1320, Acc: 64.04%\n",
      "Epoch 2/3, Batch 6980, Loss: 0.3038, Acc: 64.03%\n",
      "Epoch 2/3, Batch 6990, Loss: 0.0170, Acc: 64.07%\n",
      "Epoch 2/3, Batch 7000, Loss: 0.5042, Acc: 64.09%\n",
      "Epoch 2/3, Batch 7010, Loss: 0.0340, Acc: 64.11%\n",
      "Epoch 2/3, Batch 7020, Loss: 0.0384, Acc: 64.15%\n",
      "Epoch 2/3, Batch 7030, Loss: 0.0021, Acc: 64.13%\n",
      "Epoch 2/3, Batch 7040, Loss: 0.9413, Acc: 64.14%\n",
      "Epoch 2/3, Batch 7050, Loss: 0.0092, Acc: 64.19%\n",
      "Epoch 2/3, Batch 7060, Loss: 0.3230, Acc: 64.21%\n",
      "Epoch 2/3, Batch 7070, Loss: 1.2480, Acc: 64.19%\n",
      "Epoch 2/3, Batch 7080, Loss: 0.0236, Acc: 64.21%\n",
      "Epoch 2/3, Batch 7090, Loss: 0.9318, Acc: 64.19%\n",
      "Epoch 2/3, Batch 7100, Loss: 0.9672, Acc: 64.19%\n",
      "Epoch 2/3, Batch 7110, Loss: 1.0226, Acc: 64.17%\n",
      "Epoch 2/3, Batch 7120, Loss: 0.0179, Acc: 64.19%\n",
      "Epoch 2/3, Batch 7130, Loss: 0.4456, Acc: 64.18%\n",
      "Epoch 2/3, Batch 7140, Loss: 0.0478, Acc: 64.16%\n",
      "Epoch 2/3, Batch 7150, Loss: 0.5576, Acc: 64.19%\n",
      "Epoch 2/3, Batch 7160, Loss: 0.2366, Acc: 64.18%\n",
      "Epoch 2/3, Batch 7170, Loss: 0.1885, Acc: 64.16%\n",
      "Epoch 2/3, Batch 7180, Loss: 0.3674, Acc: 64.18%\n",
      "Epoch 2/3, Batch 7190, Loss: 0.0015, Acc: 64.18%\n",
      "Epoch 2/3, Batch 7200, Loss: 0.3565, Acc: 64.19%\n",
      "Epoch 2/3, Batch 7210, Loss: 0.0033, Acc: 64.18%\n",
      "Epoch 2/3, Batch 7220, Loss: 0.0890, Acc: 64.16%\n",
      "Epoch 2/3, Batch 7230, Loss: 1.1968, Acc: 64.15%\n",
      "Epoch 2/3, Batch 7240, Loss: 1.1314, Acc: 64.13%\n",
      "Epoch 2/3, Batch 7250, Loss: 1.3451, Acc: 64.14%\n",
      "Epoch 2/3, Batch 7260, Loss: 0.4515, Acc: 64.14%\n",
      "Epoch 2/3, Batch 7270, Loss: 0.7099, Acc: 64.09%\n",
      "Epoch 2/3, Batch 7280, Loss: 0.0483, Acc: 64.07%\n",
      "Epoch 2/3, Batch 7290, Loss: 1.0292, Acc: 64.04%\n",
      "Epoch 2/3, Batch 7300, Loss: 0.0220, Acc: 64.06%\n",
      "Epoch 2/3, Batch 7310, Loss: 0.6601, Acc: 64.07%\n",
      "Epoch 2/3, Batch 7320, Loss: 0.5899, Acc: 64.03%\n",
      "Epoch 2/3, Batch 7330, Loss: 1.3335, Acc: 64.04%\n",
      "Epoch 2/3, Batch 7340, Loss: 0.1155, Acc: 64.04%\n",
      "Epoch 2/3, Batch 7350, Loss: 0.0396, Acc: 64.05%\n",
      "Epoch 2/3, Batch 7360, Loss: 0.8525, Acc: 64.03%\n",
      "Epoch 2/3, Batch 7370, Loss: 1.4317, Acc: 64.02%\n",
      "Epoch 2/3, Batch 7380, Loss: 1.2963, Acc: 64.04%\n",
      "Epoch 2/3, Batch 7390, Loss: 2.0830, Acc: 64.05%\n",
      "Epoch 2/3, Batch 7400, Loss: 0.7870, Acc: 64.07%\n",
      "Epoch 2/3, Batch 7410, Loss: 0.4184, Acc: 64.07%\n",
      "Epoch 2/3, Batch 7420, Loss: 0.0450, Acc: 64.07%\n",
      "Epoch 2/3, Batch 7430, Loss: 0.0162, Acc: 64.11%\n",
      "Epoch 2/3, Batch 7440, Loss: 0.4743, Acc: 64.09%\n",
      "Epoch 2/3, Batch 7450, Loss: 1.9924, Acc: 64.09%\n",
      "Epoch 2/3, Batch 7460, Loss: 0.9465, Acc: 64.07%\n",
      "Epoch 2/3, Batch 7470, Loss: 1.3562, Acc: 64.05%\n",
      "Epoch 2/3, Batch 7480, Loss: 1.7463, Acc: 64.04%\n",
      "Epoch 2/3, Batch 7490, Loss: 2.3317, Acc: 64.04%\n",
      "Epoch 2/3, Batch 7500, Loss: 1.3080, Acc: 64.06%\n",
      "Epoch 2/3, Batch 7510, Loss: 2.1882, Acc: 64.03%\n",
      "Epoch 2/3, Batch 7520, Loss: 0.0026, Acc: 64.05%\n",
      "Epoch 2/3, Batch 7530, Loss: 0.6551, Acc: 64.08%\n",
      "Epoch 2/3, Batch 7540, Loss: 0.9181, Acc: 64.06%\n",
      "Epoch 2/3, Batch 7550, Loss: 3.4015, Acc: 64.04%\n",
      "Epoch 2/3, Batch 7560, Loss: 0.5499, Acc: 64.03%\n",
      "Epoch 2/3, Batch 7570, Loss: 1.0216, Acc: 64.01%\n",
      "Epoch 2/3, Batch 7580, Loss: 1.2551, Acc: 63.99%\n",
      "Epoch 2/3, Batch 7590, Loss: 0.3186, Acc: 64.00%\n",
      "Epoch 2/3, Batch 7600, Loss: 0.2714, Acc: 64.02%\n",
      "Epoch 2/3, Batch 7610, Loss: 1.6998, Acc: 64.04%\n",
      "Epoch 2/3, Batch 7620, Loss: 0.1575, Acc: 64.06%\n",
      "Epoch 2/3, Batch 7630, Loss: 0.5514, Acc: 64.08%\n",
      "Epoch 2/3, Batch 7640, Loss: 0.0010, Acc: 64.09%\n",
      "Epoch 2/3, Batch 7650, Loss: 0.1748, Acc: 64.08%\n",
      "Epoch 2/3, Batch 7660, Loss: 0.5254, Acc: 64.12%\n",
      "Epoch 2/3, Batch 7670, Loss: 0.3788, Acc: 64.15%\n",
      "Epoch 2/3, Batch 7680, Loss: 1.0610, Acc: 64.13%\n",
      "Epoch 2/3, Batch 7690, Loss: 0.8959, Acc: 64.11%\n",
      "Epoch 2/3, Batch 7700, Loss: 0.3211, Acc: 64.15%\n",
      "Epoch 2/3, Batch 7710, Loss: 0.9314, Acc: 64.13%\n",
      "Epoch 2/3, Batch 7720, Loss: 0.6700, Acc: 64.12%\n",
      "Epoch 2/3, Batch 7730, Loss: 0.6482, Acc: 64.16%\n",
      "Epoch 2/3, Batch 7740, Loss: 0.2962, Acc: 64.11%\n",
      "Epoch 2/3, Batch 7750, Loss: 1.0215, Acc: 64.07%\n",
      "Epoch 2/3, Batch 7760, Loss: 1.3266, Acc: 64.04%\n",
      "Epoch 2/3, Batch 7770, Loss: 0.9071, Acc: 63.99%\n",
      "Epoch 2/3, Batch 7780, Loss: 0.0138, Acc: 64.01%\n",
      "Epoch 2/3, Batch 7790, Loss: 0.0969, Acc: 64.01%\n",
      "Epoch 2/3, Batch 7800, Loss: 0.4477, Acc: 64.00%\n",
      "Epoch 2/3, Batch 7810, Loss: 0.0925, Acc: 64.01%\n",
      "Epoch 2/3, Batch 7820, Loss: 0.7216, Acc: 64.02%\n",
      "Epoch 2/3, Batch 7830, Loss: 1.4891, Acc: 64.03%\n",
      "Epoch 2/3, Batch 7840, Loss: 0.6366, Acc: 64.04%\n",
      "Epoch 2/3, Batch 7850, Loss: 0.4433, Acc: 64.02%\n",
      "Epoch 2/3, Batch 7860, Loss: 1.1331, Acc: 64.05%\n",
      "Epoch 2/3, Batch 7870, Loss: 0.5194, Acc: 64.07%\n",
      "Epoch 2/3, Batch 7880, Loss: 0.9669, Acc: 64.07%\n",
      "Epoch 2/3, Batch 7890, Loss: 0.4286, Acc: 64.10%\n",
      "Epoch 2/3, Batch 7900, Loss: 0.1902, Acc: 64.11%\n",
      "Epoch 2/3, Batch 7910, Loss: 0.0587, Acc: 64.11%\n",
      "Epoch 2/3, Batch 7920, Loss: 1.3822, Acc: 64.10%\n",
      "Epoch 2/3, Batch 7930, Loss: 1.4077, Acc: 64.10%\n",
      "Epoch 2/3, Batch 7940, Loss: 1.1465, Acc: 64.09%\n",
      "Epoch 2/3, Batch 7950, Loss: 0.0190, Acc: 64.08%\n",
      "Epoch 2/3, Batch 7960, Loss: 0.7834, Acc: 64.06%\n",
      "Epoch 2/3, Batch 7970, Loss: 0.9148, Acc: 64.06%\n",
      "Epoch 2/3, Batch 7980, Loss: 0.3119, Acc: 64.05%\n",
      "Epoch 2/3, Batch 7990, Loss: 0.1644, Acc: 64.03%\n",
      "Epoch 2/3, Batch 8000, Loss: 1.5993, Acc: 64.04%\n",
      "Epoch 2/3, Batch 8010, Loss: 0.2188, Acc: 64.06%\n",
      "Epoch 2/3, Batch 8020, Loss: 0.1178, Acc: 64.09%\n",
      "Epoch 2/3, Batch 8030, Loss: 0.4098, Acc: 64.09%\n",
      "Epoch 2/3, Batch 8040, Loss: 1.0107, Acc: 64.12%\n",
      "Epoch 2/3, Batch 8050, Loss: 1.9639, Acc: 64.13%\n",
      "Epoch 2/3, Batch 8060, Loss: 0.7418, Acc: 64.14%\n",
      "Epoch 2/3, Batch 8070, Loss: 0.0053, Acc: 64.13%\n",
      "Epoch 2/3, Batch 8080, Loss: 0.4175, Acc: 64.13%\n",
      "Epoch 2/3, Batch 8090, Loss: 0.2897, Acc: 64.12%\n",
      "Epoch 2/3, Batch 8100, Loss: 0.8577, Acc: 64.10%\n",
      "Epoch 2/3, Batch 8110, Loss: 0.0756, Acc: 64.10%\n",
      "Epoch 2/3, Batch 8120, Loss: 0.7965, Acc: 64.07%\n",
      "Epoch 2/3, Batch 8130, Loss: 0.3558, Acc: 64.10%\n",
      "Epoch 2/3, Batch 8140, Loss: 0.2552, Acc: 64.10%\n",
      "Epoch 2/3, Batch 8150, Loss: 0.0996, Acc: 64.10%\n",
      "Epoch 2/3, Batch 8160, Loss: 0.5708, Acc: 64.11%\n",
      "Epoch 2/3, Batch 8170, Loss: 1.3284, Acc: 64.10%\n",
      "Epoch 2/3, Batch 8180, Loss: 0.8216, Acc: 64.12%\n",
      "Epoch 2/3, Batch 8190, Loss: 0.2891, Acc: 64.12%\n",
      "Epoch 2/3, Batch 8200, Loss: 1.1651, Acc: 64.10%\n",
      "Epoch 2/3, Batch 8210, Loss: 1.1199, Acc: 64.07%\n",
      "Epoch 2/3, Batch 8220, Loss: 0.0493, Acc: 64.07%\n",
      "Epoch 2/3, Batch 8230, Loss: 1.5982, Acc: 64.04%\n",
      "Epoch 2/3, Batch 8240, Loss: 0.0028, Acc: 64.05%\n",
      "Epoch 2/3, Batch 8250, Loss: 0.5111, Acc: 64.02%\n",
      "Epoch 2/3, Batch 8260, Loss: 1.8833, Acc: 64.00%\n",
      "Epoch 2/3, Batch 8270, Loss: 0.4707, Acc: 64.03%\n",
      "Epoch 2/3, Batch 8280, Loss: 1.0207, Acc: 64.05%\n",
      "Epoch 2/3, Batch 8290, Loss: 0.1099, Acc: 64.06%\n",
      "Epoch 2/3, Batch 8300, Loss: 1.0698, Acc: 64.04%\n",
      "Epoch 2/3, Batch 8310, Loss: 0.9520, Acc: 64.02%\n",
      "Epoch 2/3, Batch 8320, Loss: 1.6332, Acc: 64.01%\n",
      "Epoch 2/3, Batch 8330, Loss: 1.2677, Acc: 64.01%\n",
      "Epoch 2/3, Batch 8340, Loss: 0.2878, Acc: 64.01%\n",
      "Epoch 2/3, Batch 8350, Loss: 0.5058, Acc: 64.03%\n",
      "Epoch 2/3, Batch 8360, Loss: 0.5036, Acc: 64.01%\n",
      "Epoch 2/3, Batch 8370, Loss: 0.6906, Acc: 64.04%\n",
      "Epoch 2/3, Batch 8380, Loss: 0.3013, Acc: 64.04%\n",
      "Epoch 2/3, Batch 8390, Loss: 0.8363, Acc: 64.00%\n",
      "Epoch 2/3, Batch 8400, Loss: 1.0201, Acc: 63.97%\n",
      "Epoch 2/3, Batch 8410, Loss: 1.1707, Acc: 63.94%\n",
      "Epoch 2/3, Batch 8420, Loss: 0.0019, Acc: 63.95%\n",
      "Epoch 2/3, Batch 8430, Loss: 0.7032, Acc: 63.94%\n",
      "Epoch 2/3, Batch 8440, Loss: 0.0418, Acc: 63.93%\n",
      "Epoch 2/3, Batch 8450, Loss: 0.0296, Acc: 63.97%\n",
      "Epoch 2/3, Batch 8460, Loss: 0.0552, Acc: 63.96%\n",
      "Epoch 2/3, Batch 8470, Loss: 0.0177, Acc: 63.95%\n",
      "Epoch 2/3, Batch 8480, Loss: 3.1192, Acc: 63.92%\n",
      "Epoch 2/3, Batch 8490, Loss: 0.0232, Acc: 63.91%\n",
      "Epoch 2/3, Batch 8500, Loss: 0.0376, Acc: 63.93%\n",
      "Epoch 2/3, Batch 8510, Loss: 2.7158, Acc: 63.93%\n",
      "Epoch 2/3, Batch 8520, Loss: 0.8886, Acc: 63.90%\n",
      "Epoch 2/3, Batch 8530, Loss: 0.7803, Acc: 63.90%\n",
      "Epoch 2/3, Batch 8540, Loss: 0.8297, Acc: 63.89%\n",
      "Epoch 2/3, Batch 8550, Loss: 0.0256, Acc: 63.91%\n",
      "Epoch 2/3, Batch 8560, Loss: 1.5990, Acc: 63.91%\n",
      "Epoch 2/3, Batch 8570, Loss: 0.0150, Acc: 63.94%\n",
      "Epoch 2/3, Batch 8580, Loss: 0.5831, Acc: 63.97%\n",
      "Epoch 2/3, Batch 8590, Loss: 1.3552, Acc: 63.94%\n",
      "Epoch 2/3, Batch 8600, Loss: 1.3732, Acc: 63.95%\n",
      "Epoch 2/3, Batch 8610, Loss: 0.0150, Acc: 63.93%\n",
      "Epoch 2/3, Batch 8620, Loss: 0.6048, Acc: 63.94%\n",
      "Epoch 2/3, Batch 8630, Loss: 0.2172, Acc: 63.94%\n",
      "Epoch 2/3, Batch 8640, Loss: 0.2781, Acc: 63.95%\n",
      "Epoch 2/3, Batch 8650, Loss: 0.2803, Acc: 63.95%\n",
      "Epoch 2/3, Batch 8660, Loss: 0.2407, Acc: 63.94%\n",
      "Epoch 2/3, Batch 8670, Loss: 0.1202, Acc: 63.95%\n",
      "Epoch 2/3, Batch 8680, Loss: 0.3041, Acc: 63.98%\n",
      "Epoch 2/3, Batch 8690, Loss: 0.0088, Acc: 63.97%\n",
      "Epoch 2/3, Batch 8700, Loss: 1.2136, Acc: 63.98%\n",
      "Epoch 2/3, Batch 8710, Loss: 0.0029, Acc: 63.99%\n",
      "Epoch 2/3, Batch 8720, Loss: 0.3481, Acc: 64.02%\n",
      "Epoch 2/3, Batch 8730, Loss: 0.1318, Acc: 64.01%\n",
      "Epoch 2/3, Batch 8740, Loss: 1.4625, Acc: 63.99%\n",
      "Epoch 2/3, Batch 8750, Loss: 0.8966, Acc: 63.96%\n",
      "Epoch 2/3, Batch 8760, Loss: 0.3454, Acc: 63.98%\n",
      "Epoch 2/3, Batch 8770, Loss: 0.2351, Acc: 63.99%\n",
      "Epoch 2/3, Batch 8780, Loss: 0.3734, Acc: 64.01%\n",
      "Epoch 2/3, Batch 8790, Loss: 0.0977, Acc: 64.00%\n",
      "Epoch 2/3, Batch 8800, Loss: 1.1133, Acc: 63.98%\n",
      "Epoch 2/3, Batch 8810, Loss: 1.1365, Acc: 63.97%\n",
      "Epoch 2/3, Batch 8820, Loss: 2.0075, Acc: 63.95%\n",
      "Epoch 2/3, Batch 8830, Loss: 0.5277, Acc: 63.96%\n",
      "Epoch 2/3, Batch 8840, Loss: 0.7624, Acc: 63.94%\n",
      "Epoch 2/3, Batch 8850, Loss: 0.0038, Acc: 63.94%\n",
      "Epoch 2/3, Batch 8860, Loss: 0.2966, Acc: 63.94%\n",
      "Epoch 2/3, Batch 8870, Loss: 0.3990, Acc: 63.96%\n",
      "Epoch 2/3, Batch 8880, Loss: 1.4254, Acc: 63.97%\n",
      "Epoch 2/3, Batch 8890, Loss: 0.5163, Acc: 63.99%\n",
      "Epoch 2/3, Batch 8900, Loss: 0.4086, Acc: 64.00%\n",
      "Epoch 2/3, Batch 8910, Loss: 1.1266, Acc: 63.99%\n",
      "Epoch 2/3, Batch 8920, Loss: 0.4569, Acc: 63.98%\n",
      "Epoch 2/3, Batch 8930, Loss: 1.3237, Acc: 63.98%\n",
      "Epoch 2/3, Batch 8940, Loss: 0.3296, Acc: 63.99%\n",
      "Epoch 2/3, Batch 8950, Loss: 0.6463, Acc: 63.97%\n",
      "Epoch 2/3, Batch 8960, Loss: 0.3906, Acc: 64.01%\n",
      "Epoch 2/3, Batch 8970, Loss: 0.0023, Acc: 64.01%\n",
      "Epoch 2/3, Batch 8980, Loss: 1.1344, Acc: 64.00%\n",
      "Epoch 2/3, Batch 8990, Loss: 0.1827, Acc: 64.00%\n",
      "Epoch 2/3, Batch 9000, Loss: 0.0485, Acc: 63.99%\n",
      "Epoch 2/3, Batch 9010, Loss: 0.7531, Acc: 63.98%\n",
      "Epoch 2/3, Batch 9020, Loss: 0.5310, Acc: 64.00%\n",
      "Epoch 2/3, Batch 9030, Loss: 0.1198, Acc: 64.01%\n",
      "Epoch 2/3, Batch 9040, Loss: 0.3344, Acc: 64.04%\n",
      "Epoch 2/3, Batch 9050, Loss: 1.4253, Acc: 64.00%\n",
      "Epoch 2/3, Batch 9060, Loss: 1.6228, Acc: 64.00%\n",
      "Epoch 2/3, Batch 9070, Loss: 0.2956, Acc: 64.02%\n",
      "Epoch 2/3, Batch 9080, Loss: 0.2100, Acc: 64.00%\n",
      "Epoch 2/3, Batch 9090, Loss: 0.3013, Acc: 64.01%\n",
      "Epoch 2/3, Batch 9100, Loss: 0.3418, Acc: 64.00%\n",
      "Epoch 2/3, Batch 9110, Loss: 0.7114, Acc: 63.97%\n",
      "Epoch 2/3, Batch 9120, Loss: 1.1507, Acc: 63.95%\n",
      "Epoch 2/3, Batch 9130, Loss: 0.0630, Acc: 63.96%\n",
      "Epoch 2/3, Batch 9140, Loss: 0.9518, Acc: 63.93%\n",
      "Epoch 2/3, Batch 9150, Loss: 0.2435, Acc: 63.94%\n",
      "Epoch 2/3, Batch 9160, Loss: 1.2563, Acc: 63.92%\n",
      "Epoch 2/3, Batch 9170, Loss: 0.0452, Acc: 63.93%\n",
      "Epoch 2/3, Batch 9180, Loss: 0.3763, Acc: 63.94%\n",
      "Epoch 2/3, Batch 9190, Loss: 0.0316, Acc: 63.92%\n",
      "Epoch 2/3, Batch 9200, Loss: 0.3678, Acc: 63.92%\n",
      "Epoch 2/3, Batch 9210, Loss: 1.7521, Acc: 63.92%\n",
      "Epoch 2/3, Batch 9220, Loss: 0.2238, Acc: 63.92%\n",
      "Epoch 2/3, Batch 9230, Loss: 0.5952, Acc: 63.92%\n",
      "Epoch 2/3, Batch 9240, Loss: 0.9072, Acc: 63.90%\n",
      "Epoch 2/3, Batch 9250, Loss: 0.0383, Acc: 63.86%\n",
      "Epoch 2/3, Batch 9260, Loss: 0.0901, Acc: 63.86%\n",
      "Epoch 2/3, Batch 9270, Loss: 0.0565, Acc: 63.87%\n",
      "Epoch 2/3, Batch 9280, Loss: 0.0141, Acc: 63.86%\n",
      "Epoch 2/3, Batch 9290, Loss: 0.4669, Acc: 63.86%\n",
      "Epoch 2/3, Batch 9300, Loss: 0.6579, Acc: 63.84%\n",
      "Epoch 2/3, Batch 9310, Loss: 0.0713, Acc: 63.84%\n",
      "Epoch 2/3, Batch 9320, Loss: 0.2797, Acc: 63.88%\n",
      "Epoch 2/3, Batch 9330, Loss: 0.0092, Acc: 63.88%\n",
      "Epoch 2/3, Batch 9340, Loss: 0.3071, Acc: 63.90%\n",
      "Epoch 2/3, Batch 9350, Loss: 1.0903, Acc: 63.89%\n",
      "Epoch 2/3, Batch 9360, Loss: 0.5827, Acc: 63.91%\n",
      "Epoch 2/3, Batch 9370, Loss: 2.7067, Acc: 63.90%\n",
      "Epoch 2/3, Batch 9380, Loss: 0.2017, Acc: 63.92%\n",
      "Epoch 2/3, Batch 9390, Loss: 0.0667, Acc: 63.93%\n",
      "Epoch 2/3, Batch 9400, Loss: 0.5844, Acc: 63.94%\n",
      "Epoch 2/3, Batch 9410, Loss: 0.0108, Acc: 63.95%\n",
      "Epoch 2/3, Batch 9420, Loss: 1.0780, Acc: 63.92%\n",
      "Epoch 2/3, Batch 9430, Loss: 0.3744, Acc: 63.94%\n",
      "Epoch 2/3, Batch 9440, Loss: 0.1949, Acc: 63.94%\n",
      "Epoch 2/3, Batch 9450, Loss: 0.2418, Acc: 63.94%\n",
      "Epoch 2/3, Batch 9460, Loss: 0.0380, Acc: 63.96%\n",
      "Epoch 2/3, Batch 9470, Loss: 0.9913, Acc: 63.93%\n",
      "Epoch 2/3, Batch 9480, Loss: 1.0522, Acc: 63.91%\n",
      "Epoch 2/3, Batch 9490, Loss: 0.5108, Acc: 63.88%\n",
      "Epoch 2/3, Batch 9500, Loss: 1.2748, Acc: 63.89%\n",
      "Epoch 2/3, Batch 9510, Loss: 0.7572, Acc: 63.88%\n",
      "Epoch 2/3, Batch 9520, Loss: 0.8814, Acc: 63.87%\n",
      "Epoch 2/3, Batch 9530, Loss: 0.0245, Acc: 63.91%\n",
      "Epoch 2/3, Batch 9540, Loss: 0.6745, Acc: 63.91%\n",
      "Epoch 2/3, Batch 9550, Loss: 0.1855, Acc: 63.92%\n",
      "Epoch 2/3, Batch 9560, Loss: 2.0923, Acc: 63.93%\n",
      "Epoch 2/3, Batch 9570, Loss: 0.4832, Acc: 63.93%\n",
      "Epoch 2/3, Batch 9580, Loss: 1.8503, Acc: 63.90%\n",
      "Epoch 2/3, Batch 9590, Loss: 0.7066, Acc: 63.88%\n",
      "Epoch 2/3, Batch 9600, Loss: 1.3059, Acc: 63.88%\n",
      "Epoch 2/3, Batch 9610, Loss: 0.9028, Acc: 63.85%\n",
      "Epoch 2/3, Batch 9620, Loss: 0.2177, Acc: 63.82%\n",
      "Epoch 2/3, Batch 9630, Loss: 0.7417, Acc: 63.84%\n",
      "Epoch 2/3, Batch 9640, Loss: 0.1567, Acc: 63.84%\n",
      "Epoch 2/3, Batch 9650, Loss: 0.5916, Acc: 63.82%\n",
      "Epoch 2/3, Batch 9660, Loss: 0.5415, Acc: 63.83%\n",
      "Epoch 2/3, Batch 9670, Loss: 0.6496, Acc: 63.83%\n",
      "Epoch 2/3, Batch 9680, Loss: 0.5051, Acc: 63.83%\n",
      "Epoch 2/3, Batch 9690, Loss: 0.3799, Acc: 63.83%\n",
      "Epoch 2/3, Batch 9700, Loss: 0.0406, Acc: 63.85%\n",
      "Epoch 2/3, Batch 9710, Loss: 0.8709, Acc: 63.82%\n",
      "Epoch 2/3, Batch 9720, Loss: 0.1778, Acc: 63.84%\n",
      "Epoch 2/3, Batch 9730, Loss: 0.0175, Acc: 63.85%\n",
      "Epoch 2/3, Batch 9740, Loss: 0.0210, Acc: 63.84%\n",
      "Epoch 2/3, Batch 9750, Loss: 1.1738, Acc: 63.84%\n",
      "Epoch 2/3, Batch 9760, Loss: 0.4711, Acc: 63.85%\n",
      "Epoch 2/3, Batch 9770, Loss: 0.0056, Acc: 63.82%\n",
      "Epoch 2/3, Batch 9780, Loss: 0.6397, Acc: 63.84%\n",
      "Epoch 2/3, Batch 9790, Loss: 0.5090, Acc: 63.84%\n",
      "Epoch 2/3, Batch 9800, Loss: 0.0566, Acc: 63.85%\n",
      "Epoch 2/3, Batch 9810, Loss: 0.8715, Acc: 63.87%\n",
      "Epoch 2/3, Batch 9820, Loss: 0.3174, Acc: 63.86%\n",
      "Epoch 2/3, Batch 9830, Loss: 0.0179, Acc: 63.87%\n",
      "Epoch 2/3, Batch 9840, Loss: 1.1350, Acc: 63.88%\n",
      "Epoch 2/3, Batch 9850, Loss: 0.7820, Acc: 63.90%\n",
      "Epoch 2/3, Batch 9860, Loss: 0.0639, Acc: 63.93%\n",
      "Epoch 2/3, Batch 9870, Loss: 0.3229, Acc: 63.93%\n",
      "Epoch 2/3, Batch 9880, Loss: 1.0897, Acc: 63.91%\n",
      "Epoch 2/3, Batch 9890, Loss: 0.0974, Acc: 63.90%\n",
      "Epoch 2/3, Batch 9900, Loss: 1.4851, Acc: 63.85%\n",
      "Epoch 2/3, Batch 9910, Loss: 0.6627, Acc: 63.87%\n",
      "Epoch 2/3, Batch 9920, Loss: 0.0402, Acc: 63.88%\n",
      "Epoch 2/3, Batch 9930, Loss: 0.0100, Acc: 63.88%\n",
      "Epoch 2/3, Batch 9940, Loss: 0.0014, Acc: 63.91%\n",
      "Epoch 2/3, Batch 9950, Loss: 1.3401, Acc: 63.89%\n",
      "Epoch 2/3, Batch 9960, Loss: 0.7056, Acc: 63.89%\n",
      "Epoch 2/3, Batch 9970, Loss: 0.8423, Acc: 63.87%\n",
      "Epoch 2/3, Batch 9980, Loss: 0.0117, Acc: 63.89%\n",
      "Epoch 2/3, Batch 9990, Loss: 0.3181, Acc: 63.90%\n",
      "Epoch 2/3, Batch 10000, Loss: 0.0381, Acc: 63.87%\n",
      "Epoch 2/3, Batch 10010, Loss: 0.8307, Acc: 63.86%\n",
      "Epoch 2/3, Batch 10020, Loss: 1.8941, Acc: 63.83%\n",
      "Epoch 2/3, Batch 10030, Loss: 0.4568, Acc: 63.82%\n",
      "Epoch 2/3, Batch 10040, Loss: 0.1766, Acc: 63.83%\n",
      "Epoch 2/3, Batch 10050, Loss: 0.0102, Acc: 63.83%\n",
      "Epoch 2/3, Batch 10060, Loss: 0.1004, Acc: 63.85%\n",
      "Epoch 2/3, Batch 10070, Loss: 0.5242, Acc: 63.86%\n",
      "Epoch 2/3, Batch 10080, Loss: 0.2743, Acc: 63.86%\n",
      "Epoch 2/3, Batch 10090, Loss: 0.5640, Acc: 63.89%\n",
      "Epoch 2/3, Batch 10100, Loss: 1.1117, Acc: 63.88%\n",
      "Epoch 2/3, Batch 10110, Loss: 1.2081, Acc: 63.88%\n",
      "Epoch 2/3, Batch 10120, Loss: 0.0534, Acc: 63.86%\n",
      "Epoch 2/3, Batch 10130, Loss: 0.1294, Acc: 63.86%\n",
      "Epoch 2/3, Batch 10140, Loss: 0.1296, Acc: 63.88%\n",
      "Epoch 2/3, Batch 10150, Loss: 1.1108, Acc: 63.88%\n",
      "Epoch 2/3, Batch 10160, Loss: 0.6392, Acc: 63.87%\n",
      "Epoch 2/3, Batch 10170, Loss: 0.2638, Acc: 63.85%\n",
      "Epoch 2/3, Batch 10180, Loss: 1.3459, Acc: 63.86%\n",
      "Epoch 2/3, Batch 10190, Loss: 0.0682, Acc: 63.87%\n",
      "Epoch 2/3, Batch 10200, Loss: 0.1005, Acc: 63.90%\n",
      "Epoch 2/3, Batch 10210, Loss: 1.0477, Acc: 63.89%\n",
      "Epoch 2/3, Batch 10220, Loss: 0.0825, Acc: 63.90%\n",
      "Epoch 2/3, Batch 10230, Loss: 0.8925, Acc: 63.92%\n",
      "Epoch 2/3, Batch 10240, Loss: 0.7355, Acc: 63.91%\n",
      "Epoch 2/3, Batch 10250, Loss: 0.0414, Acc: 63.94%\n",
      "Epoch 2/3, Batch 10260, Loss: 0.0158, Acc: 63.93%\n",
      "Epoch 2/3, Batch 10270, Loss: 0.6188, Acc: 63.93%\n",
      "Epoch 2/3, Batch 10280, Loss: 0.1730, Acc: 63.94%\n",
      "Epoch 2/3, Batch 10290, Loss: 0.2319, Acc: 63.94%\n",
      "Epoch 2/3, Batch 10300, Loss: 1.1083, Acc: 63.94%\n",
      "Epoch 2/3, Batch 10310, Loss: 1.0269, Acc: 63.94%\n",
      "Epoch 2/3, Batch 10320, Loss: 0.6985, Acc: 63.94%\n",
      "Epoch 2/3, Batch 10330, Loss: 0.7525, Acc: 63.92%\n",
      "Epoch 2/3, Batch 10340, Loss: 0.7474, Acc: 63.91%\n",
      "Epoch 2/3, Batch 10350, Loss: 0.5360, Acc: 63.90%\n",
      "Epoch 2/3, Batch 10360, Loss: 0.9821, Acc: 63.89%\n",
      "Epoch 2/3, Batch 10370, Loss: 0.0643, Acc: 63.91%\n",
      "Epoch 2/3, Batch 10380, Loss: 0.1466, Acc: 63.93%\n",
      "Epoch 2/3, Batch 10390, Loss: 0.6069, Acc: 63.93%\n",
      "Epoch 2/3, Batch 10400, Loss: 0.4248, Acc: 63.94%\n",
      "Epoch 2/3, Batch 10410, Loss: 0.0450, Acc: 63.95%\n",
      "Epoch 2/3, Batch 10420, Loss: 0.0025, Acc: 63.95%\n",
      "Epoch 2/3, Batch 10430, Loss: 1.7145, Acc: 63.92%\n",
      "Epoch 2/3, Batch 10440, Loss: 0.0334, Acc: 63.94%\n",
      "Epoch 2/3, Batch 10450, Loss: 0.0850, Acc: 63.95%\n",
      "Epoch 2/3, Batch 10460, Loss: 0.0185, Acc: 63.96%\n",
      "Epoch 2/3, Batch 10470, Loss: 0.9478, Acc: 63.94%\n",
      "Epoch 2/3, Batch 10480, Loss: 0.9920, Acc: 63.93%\n",
      "Epoch 2/3, Batch 10490, Loss: 0.7091, Acc: 63.92%\n",
      "Epoch 2/3, Batch 10500, Loss: 0.2012, Acc: 63.94%\n",
      "Epoch 2/3, Batch 10510, Loss: 0.1786, Acc: 63.95%\n",
      "Epoch 2/3, Batch 10520, Loss: 0.8447, Acc: 63.94%\n",
      "Epoch 2/3, Batch 10530, Loss: 0.0203, Acc: 63.94%\n",
      "Epoch 2/3, Batch 10540, Loss: 2.0208, Acc: 63.91%\n",
      "Epoch 2/3, Batch 10550, Loss: 1.9021, Acc: 63.88%\n",
      "Epoch 2/3, Batch 10560, Loss: 0.1373, Acc: 63.87%\n",
      "Epoch 2/3, Batch 10570, Loss: 0.0115, Acc: 63.87%\n",
      "Epoch 2/3, Batch 10580, Loss: 0.0230, Acc: 63.88%\n",
      "Epoch 2/3, Batch 10590, Loss: 1.5028, Acc: 63.85%\n",
      "Epoch 2/3, Batch 10600, Loss: 0.7477, Acc: 63.82%\n",
      "Epoch 2/3, Batch 10610, Loss: 1.2359, Acc: 63.82%\n",
      "Epoch 2/3, Batch 10620, Loss: 0.2841, Acc: 63.82%\n",
      "Epoch 2/3, Batch 10630, Loss: 1.4940, Acc: 63.82%\n",
      "Epoch 2/3, Batch 10640, Loss: 0.6982, Acc: 63.80%\n",
      "Epoch 2/3, Batch 10650, Loss: 0.1027, Acc: 63.82%\n",
      "Epoch 2/3, Batch 10660, Loss: 0.0736, Acc: 63.84%\n",
      "Epoch 2/3, Batch 10670, Loss: 1.1611, Acc: 63.85%\n",
      "Epoch 2/3, Batch 10680, Loss: 1.0974, Acc: 63.82%\n",
      "Epoch 2/3, Batch 10690, Loss: 1.9964, Acc: 63.79%\n",
      "Epoch 2/3, Batch 10700, Loss: 0.0585, Acc: 63.80%\n",
      "Epoch 2/3, Batch 10710, Loss: 1.2163, Acc: 63.78%\n",
      "Epoch 2/3, Batch 10720, Loss: 0.0656, Acc: 63.77%\n",
      "Epoch 2/3, Batch 10730, Loss: 0.5984, Acc: 63.78%\n",
      "Epoch 2/3, Batch 10740, Loss: 0.4705, Acc: 63.79%\n",
      "Epoch 2/3, Batch 10750, Loss: 0.0369, Acc: 63.82%\n",
      "Epoch 2/3, Batch 10760, Loss: 0.0259, Acc: 63.81%\n",
      "Epoch 2/3, Batch 10770, Loss: 0.0626, Acc: 63.81%\n",
      "Epoch 2/3, Batch 10780, Loss: 0.4069, Acc: 63.80%\n",
      "Epoch 2/3, Batch 10790, Loss: 0.0140, Acc: 63.78%\n",
      "Epoch 2/3, Batch 10800, Loss: 1.0261, Acc: 63.75%\n",
      "Epoch 2/3, Batch 10810, Loss: 0.0259, Acc: 63.73%\n",
      "Epoch 2/3, Batch 10820, Loss: 0.8749, Acc: 63.71%\n",
      "Epoch 2/3, Batch 10830, Loss: 0.0229, Acc: 63.70%\n",
      "Epoch 2/3, Batch 10840, Loss: 0.3016, Acc: 63.70%\n",
      "Epoch 2/3, Batch 10850, Loss: 0.2002, Acc: 63.70%\n",
      "Epoch 2/3, Batch 10860, Loss: 1.0706, Acc: 63.69%\n",
      "Epoch 2/3, Batch 10870, Loss: 0.0564, Acc: 63.68%\n",
      "Epoch 2/3, Batch 10880, Loss: 0.0561, Acc: 63.70%\n",
      "Epoch 2/3, Batch 10890, Loss: 0.0097, Acc: 63.69%\n",
      "Epoch 2/3, Batch 10900, Loss: 0.0627, Acc: 63.70%\n",
      "Epoch 2/3, Batch 10910, Loss: 0.0295, Acc: 63.70%\n",
      "Epoch 2/3, Batch 10920, Loss: 1.9735, Acc: 63.70%\n",
      "Epoch 2/3, Batch 10930, Loss: 0.1940, Acc: 63.71%\n",
      "Epoch 2/3, Batch 10940, Loss: 0.4397, Acc: 63.71%\n",
      "Epoch 2/3, Batch 10950, Loss: 0.0183, Acc: 63.68%\n",
      "Epoch 2/3, Batch 10960, Loss: 1.2067, Acc: 63.70%\n",
      "Epoch 2/3, Batch 10970, Loss: 0.4835, Acc: 63.71%\n",
      "Epoch 2/3, Batch 10980, Loss: 2.0472, Acc: 63.73%\n",
      "Epoch 2/3, Batch 10990, Loss: 1.4100, Acc: 63.71%\n",
      "Epoch 2/3, Batch 11000, Loss: 0.3291, Acc: 63.73%\n",
      "Epoch 2/3, Batch 11010, Loss: 0.0027, Acc: 63.72%\n",
      "Epoch 2/3, Batch 11020, Loss: 0.4050, Acc: 63.71%\n",
      "Epoch 2/3, Batch 11030, Loss: 0.0026, Acc: 63.70%\n",
      "Epoch 2/3, Batch 11040, Loss: 0.7748, Acc: 63.71%\n",
      "Epoch 2/3, Batch 11050, Loss: 0.2111, Acc: 63.70%\n",
      "Epoch 2/3, Batch 11060, Loss: 0.5038, Acc: 63.69%\n",
      "Epoch 2/3, Batch 11070, Loss: 1.1540, Acc: 63.71%\n",
      "Epoch 2/3, Batch 11080, Loss: 2.7559, Acc: 63.69%\n",
      "Epoch 2/3, Batch 11090, Loss: 0.4151, Acc: 63.68%\n",
      "Epoch 2/3, Batch 11100, Loss: 0.8870, Acc: 63.67%\n",
      "Epoch 2/3, Batch 11110, Loss: 0.3505, Acc: 63.70%\n",
      "Epoch 2/3, Batch 11120, Loss: 0.0066, Acc: 63.71%\n",
      "Epoch 2/3, Batch 11130, Loss: 0.5951, Acc: 63.72%\n",
      "Epoch 2/3, Batch 11140, Loss: 0.1489, Acc: 63.73%\n",
      "Epoch 2/3, Batch 11150, Loss: 0.2158, Acc: 63.74%\n",
      "Epoch 2/3, Batch 11160, Loss: 0.6151, Acc: 63.72%\n",
      "Epoch 2/3, Batch 11170, Loss: 0.1419, Acc: 63.74%\n",
      "Epoch 2/3, Batch 11180, Loss: 0.1442, Acc: 63.72%\n",
      "Epoch 2/3, Batch 11190, Loss: 0.3351, Acc: 63.75%\n",
      "Epoch 2/3, Batch 11200, Loss: 0.2480, Acc: 63.74%\n",
      "Epoch 2/3, Batch 11210, Loss: 1.1290, Acc: 63.73%\n",
      "Epoch 2/3, Batch 11220, Loss: 0.3524, Acc: 63.74%\n",
      "Epoch 2/3, Batch 11230, Loss: 0.3360, Acc: 63.75%\n",
      "Epoch 2/3, Batch 11240, Loss: 0.0344, Acc: 63.73%\n",
      "Epoch 2/3, Batch 11250, Loss: 0.3971, Acc: 63.73%\n",
      "Epoch 2/3, Batch 11260, Loss: 0.2687, Acc: 63.72%\n",
      "Epoch 2/3, Batch 11270, Loss: 0.5316, Acc: 63.73%\n",
      "Epoch 2/3, Batch 11280, Loss: 1.6968, Acc: 63.73%\n",
      "Epoch 2/3, Batch 11290, Loss: 0.0097, Acc: 63.73%\n",
      "Epoch 2/3, Batch 11300, Loss: 0.4286, Acc: 63.74%\n",
      "Epoch 2/3, Batch 11310, Loss: 1.1984, Acc: 63.73%\n",
      "Epoch 2/3, Batch 11320, Loss: 1.7100, Acc: 63.74%\n",
      "Epoch 2/3, Batch 11330, Loss: 0.1736, Acc: 63.74%\n",
      "Epoch 2/3, Batch 11340, Loss: 0.0088, Acc: 63.76%\n",
      "Epoch 2/3, Batch 11350, Loss: 0.3754, Acc: 63.76%\n",
      "Epoch 2/3, Batch 11360, Loss: 0.2249, Acc: 63.77%\n",
      "Epoch 2/3, Batch 11370, Loss: 0.4445, Acc: 63.78%\n",
      "Epoch 2/3, Batch 11380, Loss: 0.0216, Acc: 63.77%\n",
      "Epoch 2/3, Batch 11390, Loss: 0.4649, Acc: 63.77%\n",
      "Epoch 2/3, Batch 11400, Loss: 0.6860, Acc: 63.77%\n",
      "Epoch 2/3, Batch 11410, Loss: 1.6303, Acc: 63.76%\n",
      "Epoch 2/3, Batch 11420, Loss: 0.2938, Acc: 63.78%\n",
      "Epoch 2/3, Batch 11430, Loss: 0.8268, Acc: 63.76%\n",
      "Epoch 2/3, Batch 11440, Loss: 0.0011, Acc: 63.77%\n",
      "Epoch 2/3, Batch 11450, Loss: 0.5995, Acc: 63.78%\n",
      "Epoch 2/3, Batch 11460, Loss: 0.0068, Acc: 63.78%\n",
      "Epoch 2/3, Batch 11470, Loss: 3.0764, Acc: 63.78%\n",
      "Epoch 2/3, Batch 11480, Loss: 0.2612, Acc: 63.77%\n",
      "Epoch 2/3, Batch 11490, Loss: 0.4658, Acc: 63.78%\n",
      "Epoch 2/3, Batch 11500, Loss: 1.4860, Acc: 63.77%\n",
      "Epoch 2/3, Batch 11510, Loss: 0.5952, Acc: 63.76%\n",
      "Epoch 2/3, Batch 11520, Loss: 0.0036, Acc: 63.78%\n",
      "Epoch 2/3, Batch 11530, Loss: 0.0246, Acc: 63.79%\n",
      "Epoch 2/3, Batch 11540, Loss: 0.1860, Acc: 63.81%\n",
      "Epoch 2/3, Batch 11550, Loss: 0.0206, Acc: 63.83%\n",
      "Epoch 2/3, Batch 11560, Loss: 0.0008, Acc: 63.83%\n",
      "Epoch 2/3, Batch 11570, Loss: 1.2113, Acc: 63.84%\n",
      "Epoch 2/3, Batch 11580, Loss: 0.4099, Acc: 63.85%\n",
      "Epoch 2/3, Batch 11590, Loss: 1.1279, Acc: 63.83%\n",
      "Epoch 2/3, Batch 11600, Loss: 0.9569, Acc: 63.81%\n",
      "Epoch 2/3, Batch 11610, Loss: 1.3187, Acc: 63.80%\n",
      "Epoch 2/3, Batch 11620, Loss: 0.0011, Acc: 63.82%\n",
      "Epoch 2/3, Batch 11630, Loss: 0.0031, Acc: 63.82%\n",
      "Epoch 2/3, Batch 11640, Loss: 0.4287, Acc: 63.81%\n",
      "Epoch 2/3, Batch 11650, Loss: 0.5747, Acc: 63.82%\n",
      "Epoch 2/3, Batch 11660, Loss: 0.0843, Acc: 63.85%\n",
      "Epoch 2/3, Batch 11670, Loss: 0.0009, Acc: 63.86%\n",
      "Epoch 2/3, Batch 11680, Loss: 0.4247, Acc: 63.86%\n",
      "Epoch 2/3, Batch 11690, Loss: 1.0749, Acc: 63.88%\n",
      "Epoch 2/3, Batch 11700, Loss: 0.6045, Acc: 63.87%\n",
      "Epoch 2/3, Batch 11710, Loss: 0.7144, Acc: 63.88%\n",
      "Epoch 2/3, Batch 11720, Loss: 0.4026, Acc: 63.88%\n",
      "Epoch 2/3, Batch 11730, Loss: 0.6420, Acc: 63.87%\n",
      "Epoch 2/3, Batch 11740, Loss: 0.0380, Acc: 63.86%\n",
      "Epoch 2/3, Batch 11750, Loss: 1.3239, Acc: 63.86%\n",
      "Epoch 2/3, Batch 11760, Loss: 0.7268, Acc: 63.85%\n",
      "Epoch 2/3, Batch 11770, Loss: 0.4159, Acc: 63.87%\n",
      "Epoch 2/3, Batch 11780, Loss: 1.0912, Acc: 63.88%\n",
      "Epoch 2/3, Batch 11790, Loss: 0.2176, Acc: 63.89%\n",
      "Epoch 2/3, Batch 11800, Loss: 1.1252, Acc: 63.88%\n",
      "Epoch 2/3, Batch 11810, Loss: 2.3203, Acc: 63.87%\n",
      "Epoch 2/3, Batch 11820, Loss: 0.6058, Acc: 63.86%\n",
      "Epoch 2/3, Batch 11830, Loss: 0.4239, Acc: 63.88%\n",
      "Epoch 2/3, Batch 11840, Loss: 0.5790, Acc: 63.91%\n",
      "Epoch 2/3, Batch 11850, Loss: 0.5045, Acc: 63.90%\n",
      "Epoch 2/3, Batch 11860, Loss: 0.5912, Acc: 63.92%\n",
      "Epoch 2/3, Batch 11870, Loss: 0.2573, Acc: 63.92%\n",
      "Epoch 2/3, Batch 11880, Loss: 0.9329, Acc: 63.91%\n",
      "Epoch 2/3, Batch 11890, Loss: 0.0279, Acc: 63.91%\n",
      "Epoch 2/3, Batch 11900, Loss: 0.7796, Acc: 63.92%\n",
      "Epoch 2/3, Batch 11910, Loss: 0.3008, Acc: 63.93%\n",
      "Epoch 2/3, Batch 11920, Loss: 0.8914, Acc: 63.90%\n",
      "Epoch 2/3, Batch 11930, Loss: 0.6112, Acc: 63.89%\n",
      "Epoch 2/3, Batch 11940, Loss: 0.0878, Acc: 63.89%\n",
      "Epoch 2/3, Batch 11950, Loss: 0.0034, Acc: 63.91%\n",
      "Epoch 2/3, Batch 11960, Loss: 0.2946, Acc: 63.91%\n",
      "Epoch 2/3, Batch 11970, Loss: 0.3392, Acc: 63.92%\n",
      "Epoch 2/3, Batch 11980, Loss: 0.5768, Acc: 63.93%\n",
      "Epoch 2/3, Batch 11990, Loss: 0.4810, Acc: 63.94%\n",
      "Epoch 2/3, Batch 12000, Loss: 0.2112, Acc: 63.94%\n",
      "Epoch 2/3, Batch 12010, Loss: 0.3011, Acc: 63.92%\n",
      "Epoch 2/3, Batch 12020, Loss: 1.5479, Acc: 63.90%\n",
      "Epoch 2/3, Batch 12030, Loss: 0.9505, Acc: 63.89%\n",
      "Epoch 2/3, Batch 12040, Loss: 0.2744, Acc: 63.90%\n",
      "Epoch 2/3, Batch 12050, Loss: 1.6212, Acc: 63.89%\n",
      "Epoch 2/3, Batch 12060, Loss: 0.6818, Acc: 63.88%\n",
      "Epoch 2/3, Batch 12070, Loss: 1.0298, Acc: 63.87%\n",
      "Epoch 2/3, Batch 12080, Loss: 0.3710, Acc: 63.88%\n",
      "Epoch 2/3, Batch 12090, Loss: 0.2990, Acc: 63.89%\n",
      "Epoch 2/3, Batch 12100, Loss: 1.3294, Acc: 63.90%\n",
      "Epoch 2/3, Batch 12110, Loss: 1.0843, Acc: 63.88%\n",
      "Epoch 2/3, Batch 12120, Loss: 0.4855, Acc: 63.89%\n",
      "Epoch 2/3, Batch 12130, Loss: 0.5406, Acc: 63.90%\n",
      "Epoch 2/3, Batch 12140, Loss: 0.1583, Acc: 63.91%\n",
      "Epoch 2/3, Batch 12150, Loss: 0.8332, Acc: 63.91%\n",
      "Epoch 2/3, Batch 12160, Loss: 0.0030, Acc: 63.93%\n",
      "Epoch 2/3, Batch 12170, Loss: 0.6345, Acc: 63.94%\n",
      "Epoch 2/3, Batch 12180, Loss: 0.1787, Acc: 63.95%\n",
      "Epoch 2/3, Batch 12190, Loss: 0.3678, Acc: 63.97%\n",
      "Epoch 2/3, Batch 12200, Loss: 0.2547, Acc: 63.97%\n",
      "Epoch 2/3, Batch 12210, Loss: 0.2571, Acc: 63.98%\n",
      "Epoch 2/3, Batch 12220, Loss: 0.5742, Acc: 63.99%\n",
      "Epoch 2/3, Batch 12230, Loss: 1.1374, Acc: 63.99%\n",
      "Epoch 2/3, Batch 12240, Loss: 1.6120, Acc: 64.00%\n",
      "Epoch 2/3, Batch 12250, Loss: 0.3529, Acc: 64.00%\n",
      "Epoch 2/3, Batch 12260, Loss: 0.2541, Acc: 64.00%\n",
      "Epoch 2/3, Batch 12270, Loss: 1.9848, Acc: 64.00%\n",
      "Epoch 2/3, Batch 12280, Loss: 0.0256, Acc: 63.98%\n",
      "Epoch 2/3, Batch 12290, Loss: 0.2653, Acc: 63.98%\n",
      "Epoch 2/3, Batch 12300, Loss: 0.7548, Acc: 63.98%\n",
      "Epoch 2/3, Batch 12310, Loss: 1.5560, Acc: 63.98%\n",
      "Epoch 2/3, Batch 12320, Loss: 0.1064, Acc: 63.99%\n",
      "Epoch 2/3, Batch 12330, Loss: 0.0274, Acc: 63.99%\n",
      "Epoch 2/3, Batch 12340, Loss: 1.3070, Acc: 63.98%\n",
      "Epoch 2/3, Batch 12350, Loss: 0.2985, Acc: 63.99%\n",
      "Epoch 2/3, Batch 12360, Loss: 0.0059, Acc: 64.00%\n",
      "Epoch 2/3, Batch 12370, Loss: 0.0478, Acc: 64.01%\n",
      "Epoch 2/3, Batch 12380, Loss: 0.1333, Acc: 64.00%\n",
      "Epoch 2/3, Batch 12390, Loss: 0.1739, Acc: 64.01%\n",
      "Epoch 2/3, Batch 12400, Loss: 0.0035, Acc: 64.03%\n",
      "Epoch 2/3, Batch 12410, Loss: 0.0417, Acc: 64.02%\n",
      "Epoch 2/3, Batch 12420, Loss: 0.2069, Acc: 64.02%\n",
      "Epoch 2/3, Batch 12430, Loss: 0.0227, Acc: 64.03%\n",
      "Epoch 2/3, Batch 12440, Loss: 0.3245, Acc: 64.04%\n",
      "Epoch 2/3, Batch 12450, Loss: 0.0172, Acc: 64.04%\n",
      "Epoch 2/3, Batch 12460, Loss: 0.8288, Acc: 64.02%\n",
      "Epoch 2/3, Batch 12470, Loss: 0.0715, Acc: 64.05%\n",
      "Epoch 2/3, Batch 12480, Loss: 0.8012, Acc: 64.04%\n",
      "Epoch 2/3, Batch 12490, Loss: 0.2002, Acc: 64.06%\n",
      "Epoch 2/3, Batch 12500, Loss: 0.9580, Acc: 64.07%\n",
      "Epoch 2/3, Batch 12510, Loss: 1.1036, Acc: 64.06%\n",
      "Epoch 2/3, Batch 12520, Loss: 0.2301, Acc: 64.04%\n",
      "Epoch 2/3, Batch 12530, Loss: 0.0071, Acc: 64.03%\n",
      "Epoch 2/3, Batch 12540, Loss: 2.2961, Acc: 64.02%\n",
      "Epoch 2/3, Batch 12550, Loss: 0.4977, Acc: 64.00%\n",
      "Epoch 2/3, Batch 12560, Loss: 0.1590, Acc: 64.01%\n",
      "Epoch 2/3, Batch 12570, Loss: 0.0336, Acc: 64.01%\n",
      "Epoch 2/3, Batch 12580, Loss: 0.5669, Acc: 64.00%\n",
      "Epoch 2/3, Batch 12590, Loss: 0.6841, Acc: 64.01%\n",
      "Epoch 2/3, Batch 12600, Loss: 0.0510, Acc: 63.99%\n",
      "Epoch 2/3, Batch 12610, Loss: 1.0065, Acc: 63.98%\n",
      "Epoch 2/3, Batch 12620, Loss: 0.9672, Acc: 63.96%\n",
      "Epoch 2/3, Batch 12630, Loss: 0.4557, Acc: 63.96%\n",
      "Epoch 2/3, Batch 12640, Loss: 1.1766, Acc: 63.97%\n",
      "Epoch 2/3, Batch 12650, Loss: 0.7324, Acc: 63.96%\n",
      "Epoch 2/3, Batch 12660, Loss: 0.5874, Acc: 63.94%\n",
      "Epoch 2/3, Batch 12670, Loss: 1.0648, Acc: 63.94%\n",
      "Epoch 2/3, Batch 12680, Loss: 0.2472, Acc: 63.94%\n",
      "Epoch 2/3, Batch 12690, Loss: 1.5719, Acc: 63.94%\n",
      "Epoch 2/3, Batch 12700, Loss: 0.0066, Acc: 63.92%\n",
      "Epoch 2/3, Batch 12710, Loss: 0.5376, Acc: 63.91%\n",
      "Epoch 2/3, Batch 12720, Loss: 0.0042, Acc: 63.93%\n",
      "Epoch 2/3, Batch 12730, Loss: 0.4407, Acc: 63.95%\n",
      "Epoch 2/3, Batch 12740, Loss: 0.5558, Acc: 63.95%\n",
      "Epoch 2/3, Batch 12750, Loss: 0.0177, Acc: 63.96%\n",
      "Epoch 2/3, Batch 12760, Loss: 0.0366, Acc: 63.94%\n",
      "Epoch 2/3, Batch 12770, Loss: 1.1116, Acc: 63.94%\n",
      "Epoch 2/3, Batch 12780, Loss: 0.0996, Acc: 63.96%\n",
      "Epoch 2/3, Batch 12790, Loss: 0.7893, Acc: 63.96%\n",
      "Epoch 2/3, Batch 12800, Loss: 0.2101, Acc: 63.97%\n",
      "Epoch 2/3, Batch 12810, Loss: 0.3422, Acc: 64.00%\n",
      "Epoch 2/3, Batch 12820, Loss: 0.0051, Acc: 64.01%\n",
      "Epoch 2/3, Batch 12830, Loss: 0.9101, Acc: 64.01%\n",
      "Epoch 2/3, Batch 12840, Loss: 0.1857, Acc: 64.03%\n",
      "Epoch 2/3, Batch 12850, Loss: 0.8234, Acc: 64.03%\n",
      "Epoch 2/3, Batch 12860, Loss: 1.7518, Acc: 64.02%\n",
      "Epoch 2/3, Batch 12870, Loss: 0.0011, Acc: 64.01%\n",
      "Epoch 2/3, Batch 12880, Loss: 0.4842, Acc: 64.00%\n",
      "Epoch 2/3, Batch 12890, Loss: 0.4450, Acc: 64.00%\n",
      "Epoch 2/3, Batch 12900, Loss: 0.5695, Acc: 64.00%\n",
      "Epoch 2/3, Batch 12910, Loss: 0.0127, Acc: 64.00%\n",
      "Epoch 2/3, Batch 12920, Loss: 0.0421, Acc: 64.00%\n",
      "Epoch 2/3, Batch 12930, Loss: 0.0415, Acc: 64.02%\n",
      "Epoch 2/3, Batch 12940, Loss: 0.2897, Acc: 64.02%\n",
      "Epoch 2/3, Batch 12950, Loss: 0.1586, Acc: 64.04%\n",
      "Epoch 2/3, Batch 12960, Loss: 1.8791, Acc: 64.04%\n",
      "Epoch 2/3, Batch 12970, Loss: 0.3584, Acc: 64.05%\n",
      "Epoch 2/3, Batch 12980, Loss: 0.0119, Acc: 64.06%\n",
      "Epoch 2/3, Batch 12990, Loss: 2.0237, Acc: 64.04%\n",
      "Epoch 2/3, Batch 13000, Loss: 0.0316, Acc: 64.04%\n",
      "Epoch 2/3, Batch 13010, Loss: 2.0654, Acc: 64.05%\n",
      "Epoch 2/3, Batch 13020, Loss: 0.0273, Acc: 64.04%\n",
      "Epoch 2/3, Batch 13030, Loss: 0.1631, Acc: 64.05%\n",
      "Epoch 2/3, Batch 13040, Loss: 0.0501, Acc: 64.07%\n",
      "Epoch 2/3, Batch 13050, Loss: 0.7826, Acc: 64.05%\n",
      "Epoch 2/3, Batch 13060, Loss: 0.2453, Acc: 64.06%\n",
      "Epoch 2/3, Batch 13070, Loss: 0.0695, Acc: 64.07%\n",
      "Epoch 2/3, Batch 13080, Loss: 0.0828, Acc: 64.08%\n",
      "Epoch 2/3, Batch 13090, Loss: 0.1503, Acc: 64.08%\n",
      "Epoch 2/3, Batch 13100, Loss: 1.1888, Acc: 64.08%\n",
      "Epoch 2/3, Batch 13110, Loss: 0.5850, Acc: 64.08%\n",
      "Epoch 2/3, Batch 13120, Loss: 1.6459, Acc: 64.07%\n",
      "Epoch 2/3, Batch 13130, Loss: 0.0081, Acc: 64.08%\n",
      "Epoch 2/3, Batch 13140, Loss: 0.3177, Acc: 64.09%\n",
      "Epoch 2/3, Batch 13150, Loss: 0.6426, Acc: 64.10%\n",
      "Epoch 2/3, Batch 13160, Loss: 0.5064, Acc: 64.11%\n",
      "Epoch 2/3, Batch 13170, Loss: 0.3721, Acc: 64.12%\n",
      "Epoch 2/3, Batch 13180, Loss: 0.0041, Acc: 64.11%\n",
      "Epoch 2/3, Batch 13190, Loss: 0.6385, Acc: 64.11%\n",
      "Epoch 2/3, Batch 13200, Loss: 0.0303, Acc: 64.10%\n",
      "Epoch 2/3, Batch 13210, Loss: 0.9200, Acc: 64.11%\n",
      "Epoch 2/3, Batch 13220, Loss: 0.4002, Acc: 64.11%\n",
      "Epoch 2/3, Batch 13230, Loss: 0.0006, Acc: 64.11%\n",
      "Epoch 2/3, Batch 13240, Loss: 0.3457, Acc: 64.13%\n",
      "Epoch 2/3, Batch 13250, Loss: 0.6579, Acc: 64.13%\n",
      "Epoch 2/3, Batch 13260, Loss: 0.2712, Acc: 64.12%\n",
      "Epoch 2/3, Batch 13270, Loss: 0.0143, Acc: 64.12%\n",
      "Epoch 2/3, Batch 13280, Loss: 3.6498, Acc: 64.11%\n",
      "Epoch 2/3, Batch 13290, Loss: 0.8166, Acc: 64.10%\n",
      "Epoch 2/3, Batch 13300, Loss: 0.5371, Acc: 64.11%\n",
      "Epoch 2/3, Batch 13310, Loss: 0.0082, Acc: 64.12%\n",
      "Epoch 2/3, Batch 13320, Loss: 0.2913, Acc: 64.12%\n",
      "Epoch 2/3, Batch 13330, Loss: 1.7500, Acc: 64.10%\n",
      "Epoch 2/3, Batch 13340, Loss: 0.2252, Acc: 64.10%\n",
      "Epoch 2/3, Batch 13350, Loss: 1.9118, Acc: 64.09%\n",
      "Epoch 2/3, Batch 13360, Loss: 1.0184, Acc: 64.08%\n",
      "Epoch 2/3, Batch 13370, Loss: 0.2443, Acc: 64.11%\n",
      "Epoch 2/3, Batch 13380, Loss: 0.7734, Acc: 64.11%\n",
      "Epoch 2/3, Batch 13390, Loss: 0.5349, Acc: 64.10%\n",
      "Epoch 2/3, Batch 13400, Loss: 0.5957, Acc: 64.08%\n",
      "Epoch 2/3, Batch 13410, Loss: 0.0285, Acc: 64.08%\n",
      "Epoch 2/3, Batch 13420, Loss: 1.1567, Acc: 64.09%\n",
      "Epoch 2/3, Batch 13430, Loss: 0.4167, Acc: 64.07%\n",
      "Epoch 2/3, Batch 13440, Loss: 0.2551, Acc: 64.07%\n",
      "Epoch 2/3, Batch 13450, Loss: 1.1429, Acc: 64.08%\n",
      "Epoch 2/3, Batch 13460, Loss: 1.3979, Acc: 64.07%\n",
      "Epoch 2/3, Batch 13470, Loss: 1.0592, Acc: 64.07%\n",
      "Epoch 2/3, Batch 13480, Loss: 0.7529, Acc: 64.06%\n",
      "Epoch 2/3, Batch 13490, Loss: 0.0137, Acc: 64.05%\n",
      "Epoch 2/3, Batch 13500, Loss: 0.5080, Acc: 64.05%\n",
      "Epoch 2/3, Batch 13510, Loss: 0.2907, Acc: 64.05%\n",
      "Epoch 2/3, Batch 13520, Loss: 1.0714, Acc: 64.06%\n",
      "Epoch 2/3, Batch 13530, Loss: 0.1113, Acc: 64.06%\n",
      "Epoch 2/3, Batch 13540, Loss: 0.0025, Acc: 64.04%\n",
      "Epoch 2/3, Batch 13550, Loss: 0.0023, Acc: 64.05%\n",
      "Epoch 2/3, Batch 13560, Loss: 0.9892, Acc: 64.04%\n",
      "Epoch 2/3, Batch 13570, Loss: 1.2520, Acc: 64.05%\n",
      "Epoch 2/3, Batch 13580, Loss: 1.4019, Acc: 64.05%\n",
      "Epoch 2/3, Batch 13590, Loss: 0.1182, Acc: 64.05%\n",
      "Epoch 2/3, Batch 13600, Loss: 0.6743, Acc: 64.03%\n",
      "Epoch 2/3, Batch 13610, Loss: 0.2327, Acc: 64.04%\n",
      "Epoch 2/3, Batch 13620, Loss: 1.6221, Acc: 64.04%\n",
      "Epoch 2/3, Batch 13630, Loss: 0.1441, Acc: 64.02%\n",
      "Epoch 2/3, Batch 13640, Loss: 1.0308, Acc: 64.01%\n",
      "Epoch 2/3, Batch 13650, Loss: 0.3307, Acc: 64.02%\n",
      "Epoch 2/3, Batch 13660, Loss: 1.2519, Acc: 64.01%\n",
      "Epoch 2/3, Batch 13670, Loss: 0.7415, Acc: 64.00%\n",
      "Epoch 2/3, Batch 13680, Loss: 0.7815, Acc: 64.00%\n",
      "Epoch 2/3, Batch 13690, Loss: 0.1342, Acc: 64.01%\n",
      "Epoch 2/3, Batch 13700, Loss: 0.5270, Acc: 64.02%\n",
      "Epoch 2/3, Batch 13710, Loss: 0.0067, Acc: 64.00%\n",
      "Epoch 2/3, Batch 13720, Loss: 0.4347, Acc: 64.01%\n",
      "Epoch 2/3, Batch 13730, Loss: 0.7736, Acc: 64.03%\n",
      "Epoch 2/3, Batch 13740, Loss: 0.4713, Acc: 64.03%\n",
      "Epoch 2/3, Batch 13750, Loss: 1.3184, Acc: 64.02%\n",
      "Epoch 2/3, Batch 13760, Loss: 0.4338, Acc: 64.04%\n",
      "Epoch 2/3, Batch 13770, Loss: 0.0446, Acc: 64.03%\n",
      "Epoch 2/3, Batch 13780, Loss: 0.4234, Acc: 64.03%\n",
      "Epoch 2/3, Batch 13790, Loss: 1.6027, Acc: 64.02%\n",
      "Epoch 2/3, Batch 13800, Loss: 0.6980, Acc: 64.03%\n",
      "Epoch 2/3, Batch 13810, Loss: 0.2987, Acc: 64.04%\n",
      "Epoch 2/3, Batch 13820, Loss: 0.2211, Acc: 64.03%\n",
      "Epoch 2/3, Batch 13830, Loss: 0.1212, Acc: 64.03%\n",
      "Epoch 2/3, Batch 13840, Loss: 0.0747, Acc: 64.03%\n",
      "Epoch 2/3, Batch 13850, Loss: 0.8517, Acc: 64.05%\n",
      "Epoch 2/3, Batch 13860, Loss: 0.7656, Acc: 64.06%\n",
      "Epoch 2/3, Batch 13870, Loss: 0.0687, Acc: 64.06%\n",
      "Epoch 2/3, Batch 13880, Loss: 0.2419, Acc: 64.07%\n",
      "Epoch 2/3, Batch 13890, Loss: 1.1369, Acc: 64.08%\n",
      "Epoch 2/3, Batch 13900, Loss: 0.6852, Acc: 64.07%\n",
      "Epoch 2/3, Batch 13910, Loss: 3.0621, Acc: 64.06%\n",
      "Epoch 2/3, Batch 13920, Loss: 1.2710, Acc: 64.05%\n",
      "Epoch 2/3, Batch 13930, Loss: 2.7664, Acc: 64.04%\n",
      "Epoch 2/3, Batch 13940, Loss: 0.0567, Acc: 64.06%\n",
      "Epoch 2/3, Batch 13950, Loss: 0.6754, Acc: 64.07%\n",
      "Epoch 2/3, Batch 13960, Loss: 0.0007, Acc: 64.06%\n",
      "Epoch 2/3, Batch 13970, Loss: 0.1724, Acc: 64.08%\n",
      "Epoch 2/3, Batch 13980, Loss: 0.0501, Acc: 64.07%\n",
      "Epoch 2/3, Batch 13990, Loss: 1.1234, Acc: 64.06%\n",
      "Epoch 2/3, Batch 14000, Loss: 1.1822, Acc: 64.06%\n",
      "Epoch 2/3, Batch 14010, Loss: 0.4383, Acc: 64.06%\n",
      "Epoch 2/3, Batch 14020, Loss: 0.0320, Acc: 64.05%\n",
      "Epoch 2/3, Batch 14030, Loss: 0.7932, Acc: 64.06%\n",
      "Epoch 2/3, Batch 14040, Loss: 0.0705, Acc: 64.06%\n",
      "Epoch 2/3, Batch 14050, Loss: 0.4919, Acc: 64.07%\n",
      "Epoch 2/3, Batch 14060, Loss: 0.8728, Acc: 64.06%\n",
      "Epoch 2/3, Batch 14070, Loss: 0.0491, Acc: 64.05%\n",
      "Epoch 2/3, Batch 14080, Loss: 0.6557, Acc: 64.05%\n",
      "Epoch 2/3, Batch 14090, Loss: 0.0175, Acc: 64.06%\n",
      "Epoch 2/3, Batch 14100, Loss: 0.0360, Acc: 64.04%\n",
      "Epoch 2/3, Batch 14110, Loss: 0.0882, Acc: 64.06%\n",
      "Epoch 2/3, Batch 14120, Loss: 0.0305, Acc: 64.06%\n",
      "Epoch 2/3, Batch 14130, Loss: 0.0031, Acc: 64.05%\n",
      "Epoch 2/3, Batch 14140, Loss: 1.6452, Acc: 64.05%\n",
      "Epoch 2/3, Batch 14150, Loss: 0.9364, Acc: 64.04%\n",
      "Epoch 2/3, Batch 14160, Loss: 0.4892, Acc: 64.04%\n",
      "Epoch 2/3, Batch 14170, Loss: 0.4364, Acc: 64.04%\n",
      "Epoch 2/3, Batch 14180, Loss: 0.0701, Acc: 64.03%\n",
      "Epoch 2/3, Batch 14190, Loss: 1.6203, Acc: 64.03%\n",
      "Epoch 2/3, Batch 14200, Loss: 0.4645, Acc: 64.04%\n",
      "Epoch 2/3, Batch 14210, Loss: 0.3205, Acc: 64.03%\n",
      "Epoch 2/3, Batch 14220, Loss: 1.0229, Acc: 64.05%\n",
      "Epoch 2/3, Batch 14230, Loss: 0.1769, Acc: 64.05%\n",
      "Epoch 2/3, Batch 14240, Loss: 0.1501, Acc: 64.05%\n",
      "Epoch 2/3, Batch 14250, Loss: 0.1092, Acc: 64.06%\n",
      "Epoch 2/3, Batch 14260, Loss: 0.5319, Acc: 64.06%\n",
      "Epoch 2/3, Batch 14270, Loss: 0.0474, Acc: 64.06%\n",
      "Epoch 2/3, Batch 14280, Loss: 0.3124, Acc: 64.06%\n",
      "Epoch 2/3, Batch 14290, Loss: 0.5626, Acc: 64.05%\n",
      "Epoch 2/3, Batch 14300, Loss: 0.2008, Acc: 64.06%\n",
      "Epoch 2/3, Batch 14310, Loss: 0.6473, Acc: 64.08%\n",
      "Epoch 2/3, Batch 14320, Loss: 1.0448, Acc: 64.06%\n",
      "Epoch 2/3, Batch 14330, Loss: 0.0297, Acc: 64.07%\n",
      "Epoch 2/3, Batch 14340, Loss: 0.1304, Acc: 64.07%\n",
      "Epoch 2/3, Batch 14350, Loss: 1.6101, Acc: 64.05%\n",
      "Epoch 2/3, Batch 14360, Loss: 0.9124, Acc: 64.05%\n",
      "Epoch 2/3, Batch 14370, Loss: 0.3327, Acc: 64.06%\n",
      "Epoch 2/3, Batch 14380, Loss: 0.2162, Acc: 64.06%\n",
      "Epoch 2/3, Batch 14390, Loss: 1.0241, Acc: 64.07%\n",
      "Epoch 2/3, Batch 14400, Loss: 0.3904, Acc: 64.06%\n",
      "Epoch 2/3, Batch 14410, Loss: 0.4597, Acc: 64.07%\n",
      "Epoch 2/3, Batch 14420, Loss: 0.8456, Acc: 64.07%\n",
      "Epoch 2/3, Batch 14430, Loss: 1.7336, Acc: 64.05%\n",
      "Epoch 2/3, Batch 14440, Loss: 0.0015, Acc: 64.07%\n",
      "Epoch 2/3, Batch 14450, Loss: 0.6120, Acc: 64.05%\n",
      "Epoch 2/3, Batch 14460, Loss: 0.0730, Acc: 64.06%\n",
      "Epoch 2/3, Batch 14470, Loss: 0.3431, Acc: 64.07%\n",
      "Epoch 2/3, Batch 14480, Loss: 1.4803, Acc: 64.08%\n",
      "Epoch 2/3, Batch 14490, Loss: 1.1410, Acc: 64.06%\n",
      "Epoch 2/3, Batch 14500, Loss: 0.0046, Acc: 64.07%\n",
      "Epoch 2/3, Batch 14510, Loss: 0.2689, Acc: 64.08%\n",
      "Epoch 2/3, Batch 14520, Loss: 0.0433, Acc: 64.09%\n",
      "Epoch 2/3, Batch 14530, Loss: 0.2433, Acc: 64.10%\n",
      "Epoch 2/3, Batch 14540, Loss: 0.7364, Acc: 64.09%\n",
      "Epoch 2/3, Batch 14550, Loss: 0.1101, Acc: 64.09%\n",
      "Epoch 2/3, Batch 14560, Loss: 0.0951, Acc: 64.10%\n",
      "Epoch 2/3, Batch 14570, Loss: 0.3977, Acc: 64.10%\n",
      "Epoch 2/3, Batch 14580, Loss: 0.4204, Acc: 64.11%\n",
      "Epoch 2/3, Batch 14590, Loss: 0.3193, Acc: 64.11%\n",
      "Epoch 2/3, Batch 14600, Loss: 1.3885, Acc: 64.12%\n",
      "Epoch 2/3, Batch 14610, Loss: 0.5600, Acc: 64.14%\n",
      "Epoch 2/3, Batch 14620, Loss: 0.3665, Acc: 64.15%\n",
      "Epoch 2/3, Batch 14630, Loss: 1.0964, Acc: 64.15%\n",
      "Epoch 2/3, Batch 14640, Loss: 1.2168, Acc: 64.11%\n",
      "Epoch 2/3, Batch 14650, Loss: 1.2666, Acc: 64.10%\n",
      "Epoch 2/3, Batch 14660, Loss: 0.1165, Acc: 64.10%\n",
      "Epoch 2/3, Batch 14670, Loss: 0.4610, Acc: 64.11%\n",
      "Epoch 2/3, Batch 14680, Loss: 0.0346, Acc: 64.12%\n",
      "Epoch 2/3, Batch 14690, Loss: 0.9198, Acc: 64.12%\n",
      "Epoch 2/3, Batch 14700, Loss: 0.0940, Acc: 64.12%\n",
      "Epoch 2/3, Batch 14710, Loss: 0.2403, Acc: 64.12%\n",
      "Epoch 2/3, Batch 14720, Loss: 0.0146, Acc: 64.13%\n",
      "Epoch 2/3, Batch 14730, Loss: 0.3068, Acc: 64.13%\n",
      "Epoch 2/3, Batch 14740, Loss: 1.0270, Acc: 64.13%\n",
      "Epoch 2/3, Batch 14750, Loss: 0.8635, Acc: 64.11%\n",
      "Epoch 2/3, Batch 14760, Loss: 1.4200, Acc: 64.11%\n",
      "Epoch 2/3, Batch 14770, Loss: 0.1433, Acc: 64.12%\n",
      "Epoch 2/3, Batch 14780, Loss: 0.5233, Acc: 64.11%\n",
      "Epoch 2/3, Batch 14790, Loss: 0.0794, Acc: 64.13%\n",
      "Epoch 2/3, Batch 14800, Loss: 1.0217, Acc: 64.10%\n",
      "Epoch 2/3, Batch 14810, Loss: 2.2424, Acc: 64.11%\n",
      "Epoch 2/3, Batch 14820, Loss: 1.1585, Acc: 64.11%\n",
      "Epoch 2/3, Batch 14830, Loss: 0.7332, Acc: 64.12%\n",
      "Epoch 2/3, Batch 14840, Loss: 0.0040, Acc: 64.11%\n",
      "Epoch 2/3, Batch 14850, Loss: 0.2714, Acc: 64.12%\n",
      "Epoch 2/3, Batch 14860, Loss: 0.0615, Acc: 64.11%\n",
      "Epoch 2/3, Batch 14870, Loss: 0.0630, Acc: 64.10%\n",
      "Epoch 2/3, Batch 14880, Loss: 0.2737, Acc: 64.11%\n",
      "Epoch 2/3, Batch 14890, Loss: 1.2177, Acc: 64.11%\n",
      "Epoch 2/3, Batch 14900, Loss: 0.4465, Acc: 64.11%\n",
      "Epoch 2/3, Batch 14910, Loss: 1.2077, Acc: 64.11%\n",
      "Epoch 2/3, Batch 14920, Loss: 0.2625, Acc: 64.12%\n",
      "Epoch 2/3, Batch 14930, Loss: 0.6428, Acc: 64.11%\n",
      "Epoch 2/3, Batch 14940, Loss: 0.4712, Acc: 64.10%\n",
      "Epoch 2/3, Batch 14950, Loss: 0.6290, Acc: 64.09%\n",
      "Epoch 2/3, Batch 14960, Loss: 2.0689, Acc: 64.09%\n",
      "Epoch 2/3, Batch 14970, Loss: 0.6295, Acc: 64.10%\n",
      "Epoch 2/3, Batch 14980, Loss: 0.7782, Acc: 64.11%\n",
      "Epoch 2/3, Batch 14990, Loss: 0.2577, Acc: 64.11%\n",
      "Epoch 2/3, Batch 15000, Loss: 0.8855, Acc: 64.10%\n",
      "Epoch 2/3, Batch 15010, Loss: 0.0142, Acc: 64.11%\n",
      "Epoch 2/3, Batch 15020, Loss: 0.7952, Acc: 64.10%\n",
      "Epoch 2/3, Batch 15030, Loss: 1.9859, Acc: 64.10%\n",
      "Epoch 2/3, Batch 15040, Loss: 1.3693, Acc: 64.10%\n",
      "Epoch 2/3, Batch 15050, Loss: 0.9580, Acc: 64.09%\n",
      "Epoch 2/3, Batch 15060, Loss: 0.7647, Acc: 64.08%\n",
      "Epoch 2/3, Batch 15070, Loss: 2.4966, Acc: 64.08%\n",
      "Epoch 2/3, Batch 15080, Loss: 0.1710, Acc: 64.07%\n",
      "Epoch 2/3, Batch 15090, Loss: 0.0120, Acc: 64.08%\n",
      "Epoch 2/3, Batch 15100, Loss: 0.0518, Acc: 64.10%\n",
      "Epoch 2/3, Batch 15110, Loss: 0.0351, Acc: 64.09%\n",
      "Epoch 2/3, Batch 15120, Loss: 0.8497, Acc: 64.10%\n",
      "Epoch 2/3, Batch 15130, Loss: 2.2160, Acc: 64.11%\n",
      "Epoch 2/3, Batch 15140, Loss: 1.9419, Acc: 64.10%\n",
      "Epoch 2/3, Batch 15150, Loss: 1.6003, Acc: 64.10%\n",
      "Epoch 2/3, Batch 15160, Loss: 0.3854, Acc: 64.09%\n",
      "Epoch 2/3, Batch 15170, Loss: 0.0230, Acc: 64.10%\n",
      "Epoch 2/3, Batch 15180, Loss: 0.9589, Acc: 64.08%\n",
      "Epoch 2/3, Batch 15190, Loss: 2.2763, Acc: 64.08%\n",
      "Epoch 2/3, Batch 15200, Loss: 0.5820, Acc: 64.08%\n",
      "Epoch 2/3, Batch 15210, Loss: 0.8528, Acc: 64.09%\n",
      "Epoch 2/3, Batch 15220, Loss: 0.8093, Acc: 64.10%\n",
      "Epoch 2/3, Batch 15230, Loss: 0.8548, Acc: 64.11%\n",
      "Epoch 2/3, Batch 15240, Loss: 0.0052, Acc: 64.10%\n",
      "Epoch 2/3, Batch 15250, Loss: 0.2920, Acc: 64.10%\n",
      "Epoch 2/3, Batch 15260, Loss: 0.6945, Acc: 64.09%\n",
      "Epoch 2/3, Batch 15270, Loss: 1.6815, Acc: 64.10%\n",
      "Epoch 2/3, Batch 15280, Loss: 0.0127, Acc: 64.11%\n",
      "Epoch 2/3, Batch 15290, Loss: 2.3598, Acc: 64.10%\n",
      "Epoch 2/3, Batch 15300, Loss: 0.4283, Acc: 64.08%\n",
      "Epoch 2/3, Batch 15310, Loss: 0.0226, Acc: 64.07%\n",
      "Epoch 2/3, Batch 15320, Loss: 0.6916, Acc: 64.05%\n",
      "Epoch 2/3, Batch 15330, Loss: 0.3124, Acc: 64.04%\n",
      "Epoch 2/3, Batch 15340, Loss: 0.6330, Acc: 64.05%\n",
      "Epoch 2/3, Batch 15350, Loss: 1.3223, Acc: 64.05%\n",
      "Epoch 2/3, Batch 15360, Loss: 0.0137, Acc: 64.06%\n",
      "Epoch 2/3, Batch 15370, Loss: 0.0020, Acc: 64.06%\n",
      "Epoch 2/3, Batch 15380, Loss: 0.8040, Acc: 64.07%\n",
      "Epoch 2/3, Batch 15390, Loss: 0.0844, Acc: 64.08%\n",
      "Epoch 2/3, Batch 15400, Loss: 0.9195, Acc: 64.07%\n",
      "Epoch 2/3, Batch 15410, Loss: 1.2685, Acc: 64.08%\n",
      "Epoch 2/3, Batch 15420, Loss: 1.1674, Acc: 64.06%\n",
      "Epoch 2/3, Batch 15430, Loss: 0.2567, Acc: 64.07%\n",
      "Epoch 2/3, Batch 15440, Loss: 0.2429, Acc: 64.07%\n",
      "Epoch 2/3, Batch 15450, Loss: 1.5500, Acc: 64.07%\n",
      "Epoch 2/3, Batch 15460, Loss: 1.5064, Acc: 64.08%\n",
      "Epoch 2/3, Batch 15470, Loss: 0.5865, Acc: 64.09%\n",
      "Epoch 2/3, Batch 15480, Loss: 0.4647, Acc: 64.10%\n",
      "Epoch 2/3, Batch 15490, Loss: 0.1208, Acc: 64.11%\n",
      "Epoch 2/3, Batch 15500, Loss: 0.5618, Acc: 64.12%\n",
      "Epoch 2/3, Batch 15510, Loss: 0.0091, Acc: 64.11%\n",
      "Epoch 2/3, Batch 15520, Loss: 1.5219, Acc: 64.10%\n",
      "Epoch 2/3, Batch 15530, Loss: 0.8263, Acc: 64.09%\n",
      "Epoch 2/3, Batch 15540, Loss: 1.0301, Acc: 64.09%\n",
      "Epoch 2/3, Batch 15550, Loss: 0.2696, Acc: 64.09%\n",
      "Epoch 2/3, Batch 15560, Loss: 0.5001, Acc: 64.09%\n",
      "Epoch 2/3, Batch 15570, Loss: 0.4394, Acc: 64.08%\n",
      "Epoch 2/3, Batch 15580, Loss: 0.6815, Acc: 64.08%\n",
      "Epoch 2/3, Batch 15590, Loss: 0.0126, Acc: 64.08%\n",
      "Epoch 2/3, Batch 15600, Loss: 0.3900, Acc: 64.08%\n",
      "Epoch 2/3, Batch 15610, Loss: 0.4683, Acc: 64.07%\n",
      "Epoch 2/3, Batch 15620, Loss: 1.6674, Acc: 64.06%\n",
      "Epoch 2/3, Batch 15630, Loss: 0.0203, Acc: 64.07%\n",
      "Epoch 2/3, Batch 15640, Loss: 0.3818, Acc: 64.06%\n",
      "Epoch 2/3, Batch 15650, Loss: 0.9152, Acc: 64.05%\n",
      "Epoch 2/3, Batch 15660, Loss: 0.0300, Acc: 64.06%\n",
      "Epoch 2/3, Batch 15670, Loss: 1.0755, Acc: 64.05%\n",
      "Epoch 2/3, Batch 15680, Loss: 0.6275, Acc: 64.05%\n",
      "Epoch 2/3, Batch 15690, Loss: 0.3345, Acc: 64.04%\n",
      "Epoch 2/3, Batch 15700, Loss: 1.4865, Acc: 64.03%\n",
      "Epoch 2/3, Batch 15710, Loss: 0.4991, Acc: 64.04%\n",
      "Epoch 2/3, Batch 15720, Loss: 0.3535, Acc: 64.05%\n",
      "Epoch 2/3, Batch 15730, Loss: 0.4759, Acc: 64.06%\n",
      "Epoch 2/3, Batch 15740, Loss: 0.0701, Acc: 64.06%\n",
      "Epoch 2/3, Batch 15750, Loss: 0.1801, Acc: 64.06%\n",
      "Epoch 2/3, Batch 15760, Loss: 0.5023, Acc: 64.05%\n",
      "Epoch 2/3, Batch 15770, Loss: 0.1136, Acc: 64.07%\n",
      "Epoch 2/3, Batch 15780, Loss: 3.0249, Acc: 64.08%\n",
      "Epoch 2/3, Batch 15790, Loss: 0.0209, Acc: 64.08%\n",
      "Epoch 2/3, Batch 15800, Loss: 0.0379, Acc: 64.09%\n",
      "Epoch 2/3, Batch 15810, Loss: 0.0373, Acc: 64.09%\n",
      "Epoch 2/3, Batch 15820, Loss: 0.8998, Acc: 64.07%\n",
      "Epoch 2/3, Batch 15830, Loss: 1.3971, Acc: 64.06%\n",
      "Epoch 2/3, Batch 15840, Loss: 0.0027, Acc: 64.05%\n",
      "Epoch 2/3, Batch 15850, Loss: 1.4546, Acc: 64.04%\n",
      "Epoch 2/3, Batch 15860, Loss: 0.0320, Acc: 64.04%\n",
      "Epoch 2/3, Batch 15870, Loss: 1.9979, Acc: 64.04%\n",
      "Epoch 2/3, Batch 15880, Loss: 0.8599, Acc: 64.04%\n",
      "Epoch 2/3, Batch 15890, Loss: 0.7507, Acc: 64.04%\n",
      "Epoch 2/3, Batch 15900, Loss: 2.2513, Acc: 64.05%\n",
      "Epoch 2/3, Batch 15910, Loss: 1.5299, Acc: 64.04%\n",
      "Epoch 2/3, Batch 15920, Loss: 0.5133, Acc: 64.06%\n",
      "Epoch 2/3, Batch 15930, Loss: 0.6130, Acc: 64.07%\n",
      "Epoch 2/3, Batch 15940, Loss: 0.9925, Acc: 64.05%\n",
      "Epoch 2/3, Batch 15950, Loss: 0.3173, Acc: 64.06%\n",
      "Epoch 2/3, Batch 15960, Loss: 0.0025, Acc: 64.06%\n",
      "Epoch 2/3, Batch 15970, Loss: 0.1101, Acc: 64.07%\n",
      "Epoch 2/3, Batch 15980, Loss: 0.5834, Acc: 64.08%\n",
      "Epoch 2/3, Batch 15990, Loss: 1.8948, Acc: 64.07%\n",
      "Epoch 2/3, Batch 16000, Loss: 0.3413, Acc: 64.07%\n",
      "Epoch 2/3, Batch 16010, Loss: 0.9464, Acc: 64.06%\n",
      "Epoch 2/3, Batch 16020, Loss: 1.2758, Acc: 64.06%\n",
      "Epoch 2/3, Batch 16030, Loss: 0.4297, Acc: 64.08%\n",
      "Epoch 2/3, Batch 16040, Loss: 2.2793, Acc: 64.08%\n",
      "Epoch 2/3, Batch 16050, Loss: 0.5147, Acc: 64.08%\n",
      "Epoch 2/3, Batch 16060, Loss: 0.0336, Acc: 64.08%\n",
      "Epoch 2/3, Batch 16070, Loss: 0.8127, Acc: 64.08%\n",
      "Epoch 2/3, Batch 16080, Loss: 0.0435, Acc: 64.09%\n",
      "Epoch 2/3, Batch 16090, Loss: 0.9572, Acc: 64.10%\n",
      "Epoch 2/3, Batch 16100, Loss: 0.8694, Acc: 64.11%\n",
      "Epoch 2/3, Batch 16110, Loss: 0.5079, Acc: 64.12%\n",
      "Epoch 2/3, Batch 16120, Loss: 0.6009, Acc: 64.12%\n",
      "Epoch 2/3, Batch 16130, Loss: 0.0175, Acc: 64.12%\n",
      "Epoch 2/3, Batch 16140, Loss: 0.0225, Acc: 64.12%\n",
      "Epoch 2/3, Batch 16150, Loss: 0.0493, Acc: 64.11%\n",
      "Epoch 2/3, Batch 16160, Loss: 0.3034, Acc: 64.10%\n",
      "Epoch 2/3, Batch 16170, Loss: 0.4918, Acc: 64.11%\n",
      "Epoch 2/3, Batch 16180, Loss: 0.9543, Acc: 64.10%\n",
      "Epoch 2/3, Batch 16190, Loss: 0.4752, Acc: 64.11%\n",
      "Epoch 2/3, Batch 16200, Loss: 0.0609, Acc: 64.11%\n",
      "Epoch 2/3, Batch 16210, Loss: 0.0030, Acc: 64.11%\n",
      "Epoch 2/3, Batch 16220, Loss: 0.2218, Acc: 64.11%\n",
      "Epoch 2/3, Batch 16230, Loss: 0.3664, Acc: 64.11%\n",
      "Epoch 2/3, Batch 16240, Loss: 0.7647, Acc: 64.10%\n",
      "Epoch 2/3, Batch 16250, Loss: 0.9570, Acc: 64.11%\n",
      "Epoch 2/3, Batch 16260, Loss: 0.1891, Acc: 64.12%\n",
      "Epoch 2/3, Batch 16270, Loss: 0.4634, Acc: 64.13%\n",
      "Epoch 2/3, Batch 16280, Loss: 0.5193, Acc: 64.13%\n",
      "Epoch 2/3, Batch 16290, Loss: 1.2259, Acc: 64.12%\n",
      "Epoch 2/3, Batch 16300, Loss: 0.0388, Acc: 64.11%\n",
      "Epoch 2/3, Batch 16310, Loss: 1.3307, Acc: 64.12%\n",
      "Epoch 2/3, Batch 16320, Loss: 1.4528, Acc: 64.12%\n",
      "Epoch 2/3, Batch 16330, Loss: 0.4611, Acc: 64.13%\n",
      "Epoch 2/3, Batch 16340, Loss: 0.4482, Acc: 64.13%\n",
      "Epoch 2/3, Batch 16350, Loss: 0.0106, Acc: 64.12%\n",
      "Epoch 2/3, Batch 16360, Loss: 0.1256, Acc: 64.14%\n",
      "Epoch 2/3, Batch 16370, Loss: 1.1610, Acc: 64.13%\n",
      "Epoch 2/3, Batch 16380, Loss: 1.7312, Acc: 64.14%\n",
      "Epoch 2/3, Batch 16390, Loss: 0.7565, Acc: 64.14%\n",
      "Epoch 2/3, Batch 16400, Loss: 0.6123, Acc: 64.14%\n",
      "Epoch 2/3, Batch 16410, Loss: 0.3524, Acc: 64.13%\n",
      "Epoch 2/3, Batch 16420, Loss: 0.1098, Acc: 64.15%\n",
      "Epoch 2/3, Batch 16430, Loss: 0.5883, Acc: 64.15%\n",
      "Epoch 2/3, Batch 16440, Loss: 0.6239, Acc: 64.14%\n",
      "Epoch 2/3, Batch 16450, Loss: 0.1371, Acc: 64.15%\n",
      "Epoch 2/3, Batch 16460, Loss: 0.1618, Acc: 64.15%\n",
      "Epoch 2/3, Batch 16470, Loss: 0.8501, Acc: 64.15%\n",
      "Epoch 2/3, Batch 16480, Loss: 1.0753, Acc: 64.14%\n",
      "Epoch 2/3, Batch 16490, Loss: 1.3875, Acc: 64.13%\n",
      "Epoch 2/3, Batch 16500, Loss: 0.7108, Acc: 64.12%\n",
      "Epoch 2/3, Batch 16510, Loss: 1.1070, Acc: 64.11%\n",
      "Epoch 2/3, Batch 16520, Loss: 0.7156, Acc: 64.12%\n",
      "Epoch 2/3, Batch 16530, Loss: 0.6282, Acc: 64.14%\n",
      "Epoch 2/3, Batch 16540, Loss: 0.5946, Acc: 64.14%\n",
      "Epoch 2/3, Batch 16550, Loss: 0.2677, Acc: 64.15%\n",
      "Epoch 2/3, Batch 16560, Loss: 0.8880, Acc: 64.16%\n",
      "Epoch 2/3, Batch 16570, Loss: 0.9664, Acc: 64.17%\n",
      "Epoch 2/3, Batch 16580, Loss: 0.5255, Acc: 64.16%\n",
      "Epoch 2/3, Batch 16590, Loss: 0.4304, Acc: 64.18%\n",
      "Epoch 2/3, Batch 16600, Loss: 0.5428, Acc: 64.18%\n",
      "Epoch 2/3, Batch 16610, Loss: 1.5143, Acc: 64.19%\n",
      "Epoch 2/3, Batch 16620, Loss: 0.6297, Acc: 64.19%\n",
      "Epoch 2/3, Batch 16630, Loss: 0.8726, Acc: 64.19%\n",
      "Epoch 2/3, Batch 16640, Loss: 0.4090, Acc: 64.20%\n",
      "Epoch 2/3, Batch 16650, Loss: 0.8855, Acc: 64.19%\n",
      "Epoch 2/3, Batch 16660, Loss: 0.4359, Acc: 64.19%\n",
      "Epoch 2/3, Batch 16670, Loss: 0.0314, Acc: 64.20%\n",
      "Epoch 2/3, Batch 16680, Loss: 0.0212, Acc: 64.20%\n",
      "Epoch 2/3, Batch 16690, Loss: 0.1117, Acc: 64.19%\n",
      "Epoch 2/3, Batch 16700, Loss: 0.6473, Acc: 64.19%\n",
      "Epoch 2/3, Batch 16710, Loss: 0.4722, Acc: 64.19%\n",
      "Epoch 2/3, Batch 16720, Loss: 0.7580, Acc: 64.18%\n",
      "Epoch 2/3, Batch 16730, Loss: 0.7109, Acc: 64.18%\n",
      "Epoch 2/3, Batch 16740, Loss: 0.1284, Acc: 64.18%\n",
      "Epoch 2/3, Batch 16750, Loss: 0.2376, Acc: 64.16%\n",
      "Epoch 2/3, Batch 16760, Loss: 0.1389, Acc: 64.15%\n",
      "Epoch 2/3, Batch 16770, Loss: 0.6016, Acc: 64.15%\n",
      "Epoch 2/3, Batch 16780, Loss: 0.1385, Acc: 64.15%\n",
      "Epoch 2/3, Batch 16790, Loss: 0.5817, Acc: 64.15%\n",
      "Epoch 2/3, Batch 16800, Loss: 0.6023, Acc: 64.16%\n",
      "Epoch 2/3, Batch 16810, Loss: 1.2795, Acc: 64.14%\n",
      "Epoch 2/3, Batch 16820, Loss: 0.8627, Acc: 64.15%\n",
      "Epoch 2/3, Batch 16830, Loss: 0.4977, Acc: 64.16%\n",
      "Epoch 2/3, Batch 16840, Loss: 2.2854, Acc: 64.16%\n",
      "Epoch 2/3, Batch 16850, Loss: 0.4289, Acc: 64.16%\n",
      "Epoch 2/3, Batch 16860, Loss: 0.0277, Acc: 64.16%\n",
      "Epoch 2/3, Batch 16870, Loss: 0.8902, Acc: 64.16%\n",
      "Epoch 2/3, Batch 16880, Loss: 0.4271, Acc: 64.17%\n",
      "Epoch 2/3, Batch 16890, Loss: 0.1103, Acc: 64.16%\n",
      "Epoch 2/3, Batch 16900, Loss: 1.4481, Acc: 64.15%\n",
      "Epoch 2/3, Batch 16910, Loss: 1.2876, Acc: 64.14%\n",
      "Epoch 2/3, Batch 16920, Loss: 0.2245, Acc: 64.16%\n",
      "Epoch 2/3, Batch 16930, Loss: 0.6143, Acc: 64.16%\n",
      "Epoch 2/3, Batch 16940, Loss: 1.0426, Acc: 64.15%\n",
      "Epoch 2/3, Batch 16950, Loss: 1.3264, Acc: 64.15%\n",
      "Epoch 2/3, Batch 16960, Loss: 2.1434, Acc: 64.15%\n",
      "Epoch 2/3, Batch 16970, Loss: 0.8980, Acc: 64.15%\n",
      "Epoch 2/3, Batch 16980, Loss: 0.4367, Acc: 64.15%\n",
      "Epoch 2/3, Batch 16990, Loss: 0.0196, Acc: 64.15%\n",
      "Epoch 2/3, Batch 17000, Loss: 0.8875, Acc: 64.15%\n",
      "Epoch 2/3, Batch 17010, Loss: 0.2677, Acc: 64.15%\n",
      "Epoch 2/3, Batch 17020, Loss: 0.4992, Acc: 64.15%\n",
      "Epoch 2/3, Batch 17030, Loss: 0.7484, Acc: 64.16%\n",
      "Epoch 2/3, Batch 17040, Loss: 0.4201, Acc: 64.17%\n",
      "Epoch 2/3, Batch 17050, Loss: 0.0105, Acc: 64.18%\n",
      "Epoch 2/3, Batch 17060, Loss: 0.0036, Acc: 64.18%\n",
      "Epoch 2/3, Batch 17070, Loss: 0.5479, Acc: 64.18%\n",
      "Epoch 2/3, Batch 17080, Loss: 2.2244, Acc: 64.17%\n",
      "Epoch 2/3, Batch 17090, Loss: 0.9568, Acc: 64.17%\n",
      "Epoch 2/3, Batch 17100, Loss: 0.0387, Acc: 64.15%\n",
      "Epoch 2/3, Batch 17110, Loss: 0.5629, Acc: 64.17%\n",
      "Epoch 2/3, Batch 17120, Loss: 1.2352, Acc: 64.17%\n",
      "Epoch 2/3, Batch 17130, Loss: 0.3395, Acc: 64.16%\n",
      "Epoch 2/3, Batch 17140, Loss: 0.6941, Acc: 64.14%\n",
      "Epoch 2/3, Batch 17150, Loss: 0.6331, Acc: 64.14%\n",
      "Epoch 2/3, Batch 17160, Loss: 0.0409, Acc: 64.13%\n",
      "Epoch 2/3, Batch 17170, Loss: 0.6332, Acc: 64.11%\n",
      "Epoch 2/3, Batch 17180, Loss: 0.7388, Acc: 64.11%\n",
      "Epoch 2/3, Batch 17190, Loss: 0.9168, Acc: 64.09%\n",
      "Epoch 2/3, Batch 17200, Loss: 0.2729, Acc: 64.09%\n",
      "Epoch 2/3, Batch 17210, Loss: 1.1036, Acc: 64.08%\n",
      "Epoch 2/3, Batch 17220, Loss: 0.6979, Acc: 64.07%\n",
      "Epoch 2/3, Batch 17230, Loss: 0.6848, Acc: 64.08%\n",
      "Epoch 2/3, Batch 17240, Loss: 0.6748, Acc: 64.07%\n",
      "Epoch 2/3, Batch 17250, Loss: 0.6459, Acc: 64.08%\n",
      "Epoch 2/3, Batch 17260, Loss: 0.9412, Acc: 64.06%\n",
      "Epoch 2/3, Batch 17270, Loss: 0.3149, Acc: 64.06%\n",
      "Epoch 2/3, Batch 17280, Loss: 0.9319, Acc: 64.08%\n",
      "Epoch 2/3, Batch 17290, Loss: 0.9280, Acc: 64.06%\n",
      "Epoch 2/3, Batch 17300, Loss: 0.0039, Acc: 64.07%\n",
      "Epoch 2/3, Batch 17310, Loss: 0.7915, Acc: 64.06%\n",
      "Epoch 2/3, Batch 17320, Loss: 0.5267, Acc: 64.04%\n",
      "Epoch 2/3, Batch 17330, Loss: 0.9736, Acc: 64.04%\n",
      "Epoch 2/3, Batch 17340, Loss: 1.3294, Acc: 64.03%\n",
      "Epoch 2/3, Batch 17350, Loss: 0.0008, Acc: 64.03%\n",
      "Epoch 2/3, Batch 17360, Loss: 0.7447, Acc: 64.02%\n",
      "Epoch 2/3, Batch 17370, Loss: 0.6453, Acc: 64.03%\n",
      "Epoch 2/3, Batch 17380, Loss: 0.5501, Acc: 64.02%\n",
      "Epoch 2/3, Batch 17390, Loss: 1.0066, Acc: 64.01%\n",
      "Epoch 2/3, Batch 17400, Loss: 1.1192, Acc: 64.00%\n",
      "Epoch 2/3, Batch 17410, Loss: 1.2498, Acc: 64.00%\n",
      "Epoch 2/3, Batch 17420, Loss: 0.4144, Acc: 64.01%\n",
      "Epoch 2/3, Batch 17430, Loss: 3.4113, Acc: 64.01%\n",
      "Epoch 2/3, Batch 17440, Loss: 2.5136, Acc: 64.00%\n",
      "Epoch 2/3, Batch 17450, Loss: 0.3403, Acc: 64.00%\n",
      "Epoch 2/3, Batch 17460, Loss: 0.4272, Acc: 63.99%\n",
      "Epoch 2/3, Batch 17470, Loss: 2.1985, Acc: 64.00%\n",
      "Epoch 2/3, Batch 17480, Loss: 0.6956, Acc: 63.98%\n",
      "Epoch 2/3, Batch 17490, Loss: 1.6721, Acc: 63.98%\n",
      "Epoch 2/3, Batch 17500, Loss: 0.5395, Acc: 63.99%\n",
      "Epoch 2/3, Batch 17510, Loss: 0.7952, Acc: 63.97%\n",
      "Epoch 2/3, Batch 17520, Loss: 1.6036, Acc: 63.96%\n",
      "Epoch 2/3, Batch 17530, Loss: 1.7207, Acc: 63.96%\n",
      "Epoch 2/3, Batch 17540, Loss: 0.1520, Acc: 63.96%\n",
      "Epoch 2/3, Batch 17550, Loss: 1.0913, Acc: 63.97%\n",
      "Epoch 2/3, Batch 17560, Loss: 0.1960, Acc: 63.99%\n",
      "Epoch 2/3, Batch 17570, Loss: 0.0842, Acc: 64.00%\n",
      "Epoch 2/3, Batch 17580, Loss: 0.4236, Acc: 64.01%\n",
      "Epoch 2/3, Batch 17590, Loss: 0.3295, Acc: 63.99%\n",
      "Epoch 2/3, Batch 17600, Loss: 0.6003, Acc: 63.99%\n",
      "Epoch 2/3, Batch 17610, Loss: 1.5657, Acc: 63.99%\n",
      "Epoch 2/3, Batch 17620, Loss: 0.1497, Acc: 63.98%\n",
      "Epoch 2/3, Batch 17630, Loss: 0.2650, Acc: 63.98%\n",
      "Epoch 2/3, Batch 17640, Loss: 0.0904, Acc: 63.98%\n",
      "Epoch 2/3, Batch 17650, Loss: 0.7524, Acc: 63.98%\n",
      "Epoch 2/3, Batch 17660, Loss: 0.3876, Acc: 63.99%\n",
      "Epoch 2/3, Batch 17670, Loss: 0.3174, Acc: 63.99%\n",
      "Epoch 2/3, Batch 17680, Loss: 0.1795, Acc: 63.96%\n",
      "Epoch 2/3, Batch 17690, Loss: 1.2743, Acc: 63.97%\n",
      "Epoch 2/3, Batch 17700, Loss: 0.7195, Acc: 63.97%\n",
      "Epoch 2/3, Batch 17710, Loss: 0.6339, Acc: 63.97%\n",
      "Epoch 2/3, Batch 17720, Loss: 0.4678, Acc: 63.97%\n",
      "Epoch 2/3, Batch 17730, Loss: 1.6115, Acc: 63.97%\n",
      "Epoch 2/3, Batch 17740, Loss: 0.0257, Acc: 63.96%\n",
      "Epoch 2/3, Batch 17750, Loss: 0.9472, Acc: 63.96%\n",
      "Epoch 2/3, Batch 17760, Loss: 0.0035, Acc: 63.94%\n",
      "Epoch 2/3, Batch 17770, Loss: 2.0738, Acc: 63.93%\n",
      "Epoch 2/3, Batch 17780, Loss: 1.2155, Acc: 63.94%\n",
      "Epoch 2/3, Batch 17790, Loss: 0.5940, Acc: 63.94%\n",
      "Epoch 2/3, Batch 17800, Loss: 2.0784, Acc: 63.94%\n",
      "Epoch 2/3, Batch 17810, Loss: 0.3897, Acc: 63.94%\n",
      "Epoch 2/3, Batch 17820, Loss: 0.2021, Acc: 63.95%\n",
      "Epoch 2/3, Batch 17830, Loss: 0.0409, Acc: 63.96%\n",
      "Epoch 2/3, Batch 17840, Loss: 1.2746, Acc: 63.95%\n",
      "Epoch 2/3, Batch 17850, Loss: 0.3483, Acc: 63.96%\n",
      "Epoch 2/3, Batch 17860, Loss: 0.5690, Acc: 63.97%\n",
      "Epoch 2/3, Batch 17870, Loss: 1.7761, Acc: 63.98%\n",
      "Epoch 2/3, Batch 17880, Loss: 0.4810, Acc: 63.97%\n",
      "Epoch 2/3, Batch 17890, Loss: 0.0543, Acc: 63.98%\n",
      "Epoch 2/3, Batch 17900, Loss: 0.8528, Acc: 63.97%\n",
      "Epoch 2/3, Batch 17910, Loss: 0.4421, Acc: 63.99%\n",
      "Epoch 2/3, Batch 17920, Loss: 0.0220, Acc: 63.99%\n",
      "Epoch 2/3, Batch 17930, Loss: 0.3635, Acc: 63.99%\n",
      "Epoch 2/3, Batch 17940, Loss: 0.4799, Acc: 63.99%\n",
      "Epoch 2/3, Batch 17950, Loss: 1.2742, Acc: 63.99%\n",
      "Epoch 2/3, Batch 17960, Loss: 0.6213, Acc: 63.99%\n",
      "Epoch 2/3, Batch 17970, Loss: 0.0416, Acc: 63.99%\n",
      "Epoch 2/3, Batch 17980, Loss: 0.1210, Acc: 64.00%\n",
      "Epoch 2/3, Batch 17990, Loss: 0.6313, Acc: 63.99%\n",
      "Epoch 2/3, Batch 18000, Loss: 0.0631, Acc: 63.99%\n",
      "Epoch 2/3, Batch 18010, Loss: 1.0630, Acc: 63.98%\n",
      "Epoch 2/3, Batch 18020, Loss: 1.0295, Acc: 63.96%\n",
      "Epoch 2/3, Batch 18030, Loss: 1.1664, Acc: 63.95%\n",
      "Epoch 2/3, Batch 18040, Loss: 0.6728, Acc: 63.96%\n",
      "Epoch 2/3, Batch 18050, Loss: 0.0178, Acc: 63.97%\n",
      "Epoch 2/3, Batch 18060, Loss: 0.8196, Acc: 63.96%\n",
      "Epoch 2/3, Batch 18070, Loss: 0.1031, Acc: 63.96%\n",
      "Epoch 2/3, Batch 18080, Loss: 0.1428, Acc: 63.98%\n",
      "Epoch 2/3, Batch 18090, Loss: 0.3825, Acc: 63.99%\n",
      "Epoch 2/3, Batch 18100, Loss: 0.9147, Acc: 63.99%\n",
      "Epoch 2/3, Batch 18110, Loss: 1.1795, Acc: 63.99%\n",
      "Epoch 2/3, Batch 18120, Loss: 0.0179, Acc: 63.99%\n",
      "Epoch 2/3, Batch 18130, Loss: 0.2003, Acc: 64.00%\n",
      "Epoch 2/3, Batch 18140, Loss: 0.1052, Acc: 64.01%\n",
      "Epoch 2/3, Batch 18150, Loss: 0.3103, Acc: 64.01%\n",
      "Epoch 2/3, Batch 18160, Loss: 0.0472, Acc: 64.01%\n",
      "Epoch 2/3, Batch 18170, Loss: 0.5671, Acc: 64.00%\n",
      "Epoch 2/3, Batch 18180, Loss: 1.6865, Acc: 64.00%\n",
      "Epoch 2/3, Batch 18190, Loss: 1.2676, Acc: 63.98%\n",
      "Epoch 2/3, Batch 18200, Loss: 0.6959, Acc: 63.98%\n",
      "Epoch 2/3, Batch 18210, Loss: 0.0349, Acc: 63.97%\n",
      "Epoch 2/3, Batch 18220, Loss: 0.7351, Acc: 63.96%\n",
      "Epoch 2/3, Batch 18230, Loss: 1.8392, Acc: 63.96%\n",
      "Epoch 2/3, Batch 18240, Loss: 0.4802, Acc: 63.96%\n",
      "Epoch 2/3, Batch 18250, Loss: 0.4984, Acc: 63.96%\n",
      "Epoch 2/3, Batch 18260, Loss: 0.8833, Acc: 63.95%\n",
      "Epoch 2/3, Batch 18270, Loss: 1.0745, Acc: 63.94%\n",
      "Epoch 2/3, Batch 18280, Loss: 0.0081, Acc: 63.94%\n",
      "Epoch 2/3, Batch 18290, Loss: 1.9340, Acc: 63.92%\n",
      "Epoch 2/3, Batch 18300, Loss: 0.0980, Acc: 63.92%\n",
      "Epoch 2/3, Batch 18310, Loss: 0.6860, Acc: 63.91%\n",
      "Epoch 2/3, Batch 18320, Loss: 0.5403, Acc: 63.92%\n",
      "Epoch 2/3, Batch 18330, Loss: 1.5886, Acc: 63.91%\n",
      "Epoch 2/3, Batch 18340, Loss: 0.3173, Acc: 63.91%\n",
      "Epoch 2/3, Batch 18350, Loss: 0.0229, Acc: 63.91%\n",
      "Epoch 2/3, Batch 18360, Loss: 0.5807, Acc: 63.90%\n",
      "Epoch 2/3, Batch 18370, Loss: 0.0052, Acc: 63.91%\n",
      "Epoch 2/3, Batch 18380, Loss: 0.6014, Acc: 63.91%\n",
      "Epoch 2/3, Batch 18390, Loss: 0.0307, Acc: 63.92%\n",
      "Epoch 2/3, Batch 18400, Loss: 0.3739, Acc: 63.93%\n",
      "Epoch 2/3, Batch 18410, Loss: 0.2351, Acc: 63.92%\n",
      "Epoch 2/3, Batch 18420, Loss: 1.0349, Acc: 63.92%\n",
      "Epoch 2/3, Batch 18430, Loss: 0.4098, Acc: 63.92%\n",
      "Epoch 2/3, Batch 18440, Loss: 0.5289, Acc: 63.93%\n",
      "Epoch 2/3, Batch 18450, Loss: 0.0354, Acc: 63.94%\n",
      "Epoch 2/3, Batch 18460, Loss: 0.9178, Acc: 63.94%\n",
      "Epoch 2/3, Batch 18470, Loss: 0.3900, Acc: 63.93%\n",
      "Epoch 2/3, Batch 18480, Loss: 0.0217, Acc: 63.92%\n",
      "Epoch 2/3, Batch 18490, Loss: 1.0116, Acc: 63.90%\n",
      "Epoch 2/3, Batch 18500, Loss: 0.0521, Acc: 63.90%\n",
      "Epoch 2/3, Batch 18510, Loss: 0.6018, Acc: 63.90%\n",
      "Epoch 2/3, Batch 18520, Loss: 0.6038, Acc: 63.90%\n",
      "Epoch 2/3, Batch 18530, Loss: 0.0014, Acc: 63.89%\n",
      "Epoch 2/3, Batch 18540, Loss: 0.2226, Acc: 63.91%\n",
      "Epoch 2/3, Batch 18550, Loss: 0.1895, Acc: 63.91%\n",
      "Epoch 2/3, Batch 18560, Loss: 0.1883, Acc: 63.91%\n",
      "Epoch 2/3, Batch 18570, Loss: 0.9348, Acc: 63.91%\n",
      "Epoch 2/3, Batch 18580, Loss: 1.6681, Acc: 63.90%\n",
      "Epoch 2/3, Batch 18590, Loss: 0.0753, Acc: 63.89%\n",
      "Epoch 2/3, Batch 18600, Loss: 0.3154, Acc: 63.89%\n",
      "Epoch 2/3, Batch 18610, Loss: 0.9187, Acc: 63.89%\n",
      "Epoch 2/3, Batch 18620, Loss: 0.0012, Acc: 63.88%\n",
      "Epoch 2/3, Batch 18630, Loss: 0.7803, Acc: 63.88%\n",
      "Epoch 2/3, Batch 18640, Loss: 0.2174, Acc: 63.89%\n",
      "Epoch 2/3, Batch 18650, Loss: 1.5111, Acc: 63.88%\n",
      "Epoch 2/3, Batch 18660, Loss: 1.3044, Acc: 63.88%\n",
      "Epoch 2/3, Batch 18670, Loss: 0.9674, Acc: 63.87%\n",
      "Epoch 2/3, Batch 18680, Loss: 0.3238, Acc: 63.88%\n",
      "Epoch 2/3, Batch 18690, Loss: 0.8903, Acc: 63.88%\n",
      "Epoch 2/3, Batch 18700, Loss: 1.1621, Acc: 63.88%\n",
      "Epoch 2/3, Batch 18710, Loss: 1.3842, Acc: 63.88%\n",
      "Epoch 2/3, Batch 18720, Loss: 0.1236, Acc: 63.89%\n",
      "Epoch 2/3, Batch 18730, Loss: 0.1188, Acc: 63.89%\n",
      "Epoch 2/3, Batch 18740, Loss: 0.4068, Acc: 63.90%\n",
      "Epoch 2/3, Batch 18750, Loss: 0.1364, Acc: 63.89%\n",
      "Epoch 2/3, Batch 18760, Loss: 0.8220, Acc: 63.88%\n",
      "Epoch 2/3, Batch 18770, Loss: 0.1801, Acc: 63.88%\n",
      "Epoch 2/3, Batch 18780, Loss: 0.3546, Acc: 63.88%\n",
      "Epoch 2/3, Batch 18790, Loss: 1.3056, Acc: 63.88%\n",
      "Epoch 2/3, Batch 18800, Loss: 1.5954, Acc: 63.87%\n",
      "Epoch 2/3, Batch 18810, Loss: 0.3685, Acc: 63.87%\n",
      "Epoch 2/3, Batch 18820, Loss: 0.3614, Acc: 63.85%\n",
      "Epoch 2/3, Batch 18830, Loss: 1.2623, Acc: 63.84%\n",
      "Epoch 2/3, Batch 18840, Loss: 0.0063, Acc: 63.84%\n",
      "Epoch 2/3, Batch 18850, Loss: 0.8019, Acc: 63.84%\n",
      "Epoch 2/3, Batch 18860, Loss: 1.0530, Acc: 63.85%\n",
      "Epoch 2/3, Batch 18870, Loss: 0.0369, Acc: 63.85%\n",
      "Epoch 2/3, Batch 18880, Loss: 0.3193, Acc: 63.85%\n",
      "Epoch 2/3, Batch 18890, Loss: 1.3513, Acc: 63.84%\n",
      "Epoch 2/3, Batch 18900, Loss: 0.7811, Acc: 63.83%\n",
      "Epoch 2/3, Batch 18910, Loss: 0.7865, Acc: 63.82%\n",
      "Epoch 2/3, Batch 18920, Loss: 0.7745, Acc: 63.82%\n",
      "Epoch 2/3, Batch 18930, Loss: 0.4622, Acc: 63.83%\n",
      "Epoch 2/3, Batch 18940, Loss: 2.2839, Acc: 63.83%\n",
      "Epoch 2/3, Batch 18950, Loss: 1.1429, Acc: 63.81%\n",
      "Epoch 2/3, Batch 18960, Loss: 0.0144, Acc: 63.82%\n",
      "Epoch 2/3, Batch 18970, Loss: 1.1196, Acc: 63.82%\n",
      "Epoch 2/3, Batch 18980, Loss: 0.7715, Acc: 63.83%\n",
      "Epoch 2/3, Batch 18990, Loss: 0.9373, Acc: 63.84%\n",
      "Epoch 2/3, Batch 19000, Loss: 0.9672, Acc: 63.84%\n",
      "Epoch 2/3, Batch 19010, Loss: 0.4112, Acc: 63.84%\n",
      "Epoch 2/3, Batch 19020, Loss: 0.6597, Acc: 63.85%\n",
      "Epoch 2/3, Batch 19030, Loss: 0.4048, Acc: 63.84%\n",
      "Epoch 2/3, Batch 19040, Loss: 0.7279, Acc: 63.84%\n",
      "Epoch 2/3, Batch 19050, Loss: 0.2961, Acc: 63.84%\n",
      "Epoch 2/3, Batch 19060, Loss: 1.7366, Acc: 63.84%\n",
      "Epoch 2/3, Batch 19070, Loss: 0.0136, Acc: 63.84%\n",
      "Epoch 2/3, Batch 19080, Loss: 0.2657, Acc: 63.84%\n",
      "Epoch 2/3, Batch 19090, Loss: 0.5719, Acc: 63.86%\n",
      "Epoch 2/3, Batch 19100, Loss: 1.1812, Acc: 63.86%\n",
      "Epoch 2/3, Batch 19110, Loss: 1.2820, Acc: 63.85%\n",
      "Epoch 2/3, Batch 19120, Loss: 0.0005, Acc: 63.85%\n",
      "Epoch 2/3, Batch 19130, Loss: 0.8519, Acc: 63.85%\n",
      "Epoch 2/3, Batch 19140, Loss: 0.0605, Acc: 63.86%\n",
      "Epoch 2/3, Batch 19150, Loss: 0.9090, Acc: 63.85%\n",
      "Epoch 2/3, Batch 19160, Loss: 0.4291, Acc: 63.85%\n",
      "Epoch 2/3, Batch 19170, Loss: 2.3802, Acc: 63.85%\n",
      "Epoch 2/3, Batch 19180, Loss: 0.0056, Acc: 63.85%\n",
      "Epoch 2/3, Batch 19190, Loss: 1.5492, Acc: 63.84%\n",
      "Epoch 2/3, Batch 19200, Loss: 0.0056, Acc: 63.86%\n",
      "Epoch 2/3, Batch 19210, Loss: 0.8286, Acc: 63.86%\n",
      "Epoch 2/3, Batch 19220, Loss: 0.1060, Acc: 63.85%\n",
      "Epoch 2/3, Batch 19230, Loss: 0.2628, Acc: 63.86%\n",
      "Epoch 2/3, Batch 19240, Loss: 0.2692, Acc: 63.85%\n",
      "Epoch 2/3, Batch 19250, Loss: 0.5271, Acc: 63.86%\n",
      "Epoch 2/3, Batch 19260, Loss: 0.5729, Acc: 63.86%\n",
      "Epoch 2/3, Batch 19270, Loss: 0.4611, Acc: 63.85%\n",
      "Epoch 2/3, Batch 19280, Loss: 0.0434, Acc: 63.87%\n",
      "Epoch 2/3, Batch 19290, Loss: 1.6261, Acc: 63.85%\n",
      "Epoch 2/3, Batch 19300, Loss: 1.5820, Acc: 63.86%\n",
      "Epoch 2/3, Batch 19310, Loss: 0.1983, Acc: 63.85%\n",
      "Epoch 2/3, Batch 19320, Loss: 1.1907, Acc: 63.86%\n",
      "Epoch 2/3, Batch 19330, Loss: 1.2153, Acc: 63.85%\n",
      "Epoch 2/3, Batch 19340, Loss: 0.1305, Acc: 63.85%\n",
      "Epoch 2/3, Batch 19350, Loss: 0.3919, Acc: 63.86%\n",
      "Epoch 2/3, Batch 19360, Loss: 0.0025, Acc: 63.86%\n",
      "Epoch 2/3, Batch 19370, Loss: 1.4956, Acc: 63.85%\n",
      "Epoch 2/3, Batch 19380, Loss: 0.1282, Acc: 63.85%\n",
      "Epoch 2/3, Batch 19390, Loss: 0.0269, Acc: 63.84%\n",
      "Epoch 2/3, Batch 19400, Loss: 0.0825, Acc: 63.86%\n",
      "Epoch 2/3, Batch 19410, Loss: 0.3927, Acc: 63.87%\n",
      "Epoch 2/3, Batch 19420, Loss: 0.2480, Acc: 63.88%\n",
      "Epoch 2/3, Batch 19430, Loss: 0.6225, Acc: 63.88%\n",
      "Epoch 2/3, Batch 19440, Loss: 0.1427, Acc: 63.89%\n",
      "Epoch 2/3, Batch 19450, Loss: 0.2753, Acc: 63.88%\n",
      "Epoch 2/3, Batch 19460, Loss: 0.8938, Acc: 63.89%\n",
      "Epoch 2/3, Batch 19470, Loss: 0.2541, Acc: 63.89%\n",
      "Epoch 2/3, Batch 19480, Loss: 0.5837, Acc: 63.89%\n",
      "Epoch 2/3, Batch 19490, Loss: 0.3375, Acc: 63.89%\n",
      "Epoch 2/3, Batch 19500, Loss: 0.6443, Acc: 63.89%\n",
      "Epoch 2/3, Batch 19510, Loss: 0.1142, Acc: 63.90%\n",
      "Epoch 2/3, Batch 19520, Loss: 0.9528, Acc: 63.91%\n",
      "Epoch 2/3, Batch 19530, Loss: 1.1660, Acc: 63.91%\n",
      "Epoch 2/3, Batch 19540, Loss: 0.6315, Acc: 63.91%\n",
      "Epoch 2/3, Batch 19550, Loss: 1.4243, Acc: 63.91%\n",
      "Epoch 2/3, Batch 19560, Loss: 0.0294, Acc: 63.89%\n",
      "Epoch 2/3, Batch 19570, Loss: 0.2243, Acc: 63.89%\n",
      "Epoch 2/3, Batch 19580, Loss: 0.0264, Acc: 63.89%\n",
      "Epoch 2/3, Batch 19590, Loss: 1.3804, Acc: 63.89%\n",
      "Epoch 2/3, Batch 19600, Loss: 0.5759, Acc: 63.89%\n",
      "Epoch 2/3, Batch 19610, Loss: 0.6506, Acc: 63.89%\n",
      "Epoch 2/3, Batch 19620, Loss: 0.0158, Acc: 63.90%\n",
      "Epoch 2/3, Batch 19630, Loss: 0.2523, Acc: 63.89%\n",
      "Epoch 2/3, Batch 19640, Loss: 0.4904, Acc: 63.90%\n",
      "Epoch 2/3, Batch 19650, Loss: 0.6715, Acc: 63.89%\n",
      "Epoch 2/3, Batch 19660, Loss: 0.7227, Acc: 63.91%\n",
      "Epoch 2/3, Batch 19670, Loss: 0.3692, Acc: 63.90%\n",
      "Epoch 2/3, Batch 19680, Loss: 0.0222, Acc: 63.91%\n",
      "Epoch 2/3, Batch 19690, Loss: 0.6319, Acc: 63.90%\n",
      "Epoch 2/3, Batch 19700, Loss: 0.5152, Acc: 63.91%\n",
      "Epoch 2/3, Batch 19710, Loss: 0.2792, Acc: 63.91%\n",
      "Epoch 2/3, Batch 19720, Loss: 0.0178, Acc: 63.92%\n",
      "Epoch 2/3, Batch 19730, Loss: 0.3870, Acc: 63.91%\n",
      "Epoch 2/3, Batch 19740, Loss: 0.0235, Acc: 63.91%\n",
      "Epoch 2/3, Batch 19750, Loss: 0.0902, Acc: 63.91%\n",
      "Epoch 2/3, Batch 19760, Loss: 0.9189, Acc: 63.91%\n",
      "Epoch 2/3, Batch 19770, Loss: 0.0602, Acc: 63.91%\n",
      "Epoch 2/3, Batch 19780, Loss: 0.2949, Acc: 63.90%\n",
      "Epoch 2/3, Batch 19790, Loss: 1.0494, Acc: 63.90%\n",
      "Epoch 2/3, Batch 19800, Loss: 1.6120, Acc: 63.90%\n",
      "Epoch 2/3, Batch 19810, Loss: 0.0397, Acc: 63.90%\n",
      "Epoch 2/3, Batch 19820, Loss: 1.6331, Acc: 63.89%\n",
      "Epoch 2/3, Batch 19830, Loss: 0.1949, Acc: 63.89%\n",
      "Epoch 2/3, Batch 19840, Loss: 0.4322, Acc: 63.89%\n",
      "Epoch 2/3, Batch 19850, Loss: 1.0346, Acc: 63.90%\n",
      "Epoch 2/3, Batch 19860, Loss: 0.5974, Acc: 63.89%\n",
      "Epoch 2/3, Batch 19870, Loss: 0.0487, Acc: 63.90%\n",
      "Epoch 2/3, Batch 19880, Loss: 0.1794, Acc: 63.90%\n",
      "Epoch 2/3, Batch 19890, Loss: 0.1222, Acc: 63.88%\n",
      "Epoch 2/3, Batch 19900, Loss: 0.0825, Acc: 63.89%\n",
      "Epoch 2/3, Batch 19910, Loss: 0.4457, Acc: 63.87%\n",
      "Epoch 2/3, Batch 19920, Loss: 0.2673, Acc: 63.86%\n",
      "Epoch 2/3, Batch 19930, Loss: 0.9340, Acc: 63.86%\n",
      "Epoch 2/3, Batch 19940, Loss: 0.7013, Acc: 63.85%\n",
      "Epoch 2/3, Batch 19950, Loss: 0.9238, Acc: 63.84%\n",
      "Epoch 2/3, Batch 19960, Loss: 0.7620, Acc: 63.84%\n",
      "Epoch 2/3, Batch 19970, Loss: 0.4884, Acc: 63.85%\n",
      "Epoch 2/3, Batch 19980, Loss: 0.4863, Acc: 63.85%\n",
      "Epoch 2/3, Batch 19990, Loss: 0.5207, Acc: 63.85%\n",
      "Epoch 2/3, Batch 20000, Loss: 0.1813, Acc: 63.85%\n",
      "Epoch 2/3, Batch 20010, Loss: 0.2155, Acc: 63.85%\n",
      "Epoch 2/3, Batch 20020, Loss: 0.7093, Acc: 63.85%\n",
      "Epoch 2/3, Batch 20030, Loss: 1.2114, Acc: 63.84%\n",
      "Epoch 2/3, Batch 20040, Loss: 0.0055, Acc: 63.84%\n",
      "Epoch 2/3, Batch 20050, Loss: 1.8779, Acc: 63.83%\n",
      "Epoch 2/3, Batch 20060, Loss: 0.2611, Acc: 63.82%\n",
      "Epoch 2/3, Batch 20070, Loss: 0.0468, Acc: 63.82%\n",
      "Epoch 2/3, Batch 20080, Loss: 0.7008, Acc: 63.83%\n",
      "Epoch 2/3, Batch 20090, Loss: 0.8014, Acc: 63.83%\n",
      "Epoch 2/3, Batch 20100, Loss: 1.0107, Acc: 63.82%\n",
      "Epoch 2/3, Batch 20110, Loss: 0.8223, Acc: 63.82%\n",
      "Epoch 2/3, Batch 20120, Loss: 0.3490, Acc: 63.82%\n",
      "Epoch 2/3, Batch 20130, Loss: 0.7173, Acc: 63.82%\n",
      "Epoch 2/3, Batch 20140, Loss: 0.8590, Acc: 63.80%\n",
      "Epoch 2/3, Batch 20150, Loss: 0.1549, Acc: 63.80%\n",
      "Epoch 2/3, Batch 20160, Loss: 0.0341, Acc: 63.81%\n",
      "Epoch 2/3, Batch 20170, Loss: 1.5242, Acc: 63.81%\n",
      "Epoch 2/3, Batch 20180, Loss: 0.4339, Acc: 63.80%\n",
      "Epoch 2/3, Batch 20190, Loss: 0.8048, Acc: 63.79%\n",
      "Epoch 2/3, Batch 20200, Loss: 1.0012, Acc: 63.78%\n",
      "Epoch 2/3, Batch 20210, Loss: 0.6484, Acc: 63.79%\n",
      "Epoch 2/3, Batch 20220, Loss: 1.0615, Acc: 63.80%\n",
      "Epoch 2/3, Batch 20230, Loss: 1.0199, Acc: 63.81%\n",
      "Epoch 2/3, Batch 20240, Loss: 0.0308, Acc: 63.81%\n",
      "Epoch 2/3, Batch 20250, Loss: 0.8137, Acc: 63.80%\n",
      "Epoch 2/3, Batch 20260, Loss: 0.9555, Acc: 63.80%\n",
      "Epoch 2/3, Batch 20270, Loss: 0.0713, Acc: 63.81%\n",
      "Epoch 2/3, Batch 20280, Loss: 0.1450, Acc: 63.82%\n",
      "Epoch 2/3, Batch 20290, Loss: 0.3432, Acc: 63.83%\n",
      "Epoch 2/3, Batch 20300, Loss: 0.0092, Acc: 63.83%\n",
      "Epoch 2/3, Batch 20310, Loss: 0.0037, Acc: 63.84%\n",
      "Epoch 2/3, Batch 20320, Loss: 1.5561, Acc: 63.85%\n",
      "Epoch 2/3, Batch 20330, Loss: 0.0509, Acc: 63.84%\n",
      "Epoch 2/3, Batch 20340, Loss: 0.2510, Acc: 63.84%\n",
      "Epoch 2/3, Batch 20350, Loss: 0.0226, Acc: 63.83%\n",
      "Epoch 2/3, Batch 20360, Loss: 0.3548, Acc: 63.84%\n",
      "Epoch 2/3, Batch 20370, Loss: 0.2612, Acc: 63.84%\n",
      "Epoch 2/3, Batch 20380, Loss: 0.8757, Acc: 63.83%\n",
      "Epoch 2/3, Batch 20390, Loss: 0.3724, Acc: 63.84%\n",
      "Epoch 2/3, Batch 20400, Loss: 0.3250, Acc: 63.84%\n",
      "Epoch 2/3, Batch 20410, Loss: 0.6594, Acc: 63.84%\n",
      "Epoch 2/3, Batch 20420, Loss: 0.0332, Acc: 63.84%\n",
      "Epoch 2/3, Batch 20430, Loss: 0.5209, Acc: 63.85%\n",
      "Epoch 2/3, Batch 20440, Loss: 0.6853, Acc: 63.86%\n",
      "Epoch 2/3, Batch 20450, Loss: 0.6789, Acc: 63.85%\n",
      "Epoch 2/3, Batch 20460, Loss: 0.2016, Acc: 63.85%\n",
      "Epoch 2/3, Batch 20470, Loss: 0.0535, Acc: 63.85%\n",
      "Epoch 2/3, Batch 20480, Loss: 0.6756, Acc: 63.85%\n",
      "Epoch 2/3, Batch 20490, Loss: 0.3412, Acc: 63.87%\n",
      "Epoch 2/3, Batch 20500, Loss: 0.5462, Acc: 63.86%\n",
      "Epoch 2/3, Batch 20510, Loss: 1.4569, Acc: 63.85%\n",
      "Epoch 2/3, Batch 20520, Loss: 0.4812, Acc: 63.86%\n",
      "Epoch 2/3, Batch 20530, Loss: 1.1791, Acc: 63.85%\n",
      "Epoch 2/3, Batch 20540, Loss: 0.0388, Acc: 63.85%\n",
      "Epoch 2/3, Batch 20550, Loss: 0.0099, Acc: 63.86%\n",
      "Epoch 2/3, Batch 20560, Loss: 0.9299, Acc: 63.85%\n",
      "Epoch 2/3, Batch 20570, Loss: 0.4263, Acc: 63.86%\n",
      "Epoch 2/3, Batch 20580, Loss: 0.2249, Acc: 63.86%\n",
      "Epoch 2/3, Batch 20590, Loss: 0.4185, Acc: 63.87%\n",
      "Epoch 2/3, Batch 20600, Loss: 0.7366, Acc: 63.87%\n",
      "Epoch 2/3, Batch 20610, Loss: 0.8774, Acc: 63.85%\n",
      "Epoch 2/3, Batch 20620, Loss: 0.0724, Acc: 63.86%\n",
      "Epoch 2/3, Batch 20630, Loss: 0.3390, Acc: 63.87%\n",
      "Epoch 2/3, Batch 20640, Loss: 0.0597, Acc: 63.88%\n",
      "Epoch 2/3, Batch 20650, Loss: 0.0296, Acc: 63.88%\n",
      "Epoch 2/3, Batch 20660, Loss: 0.7298, Acc: 63.86%\n",
      "Epoch 2/3, Batch 20670, Loss: 0.3125, Acc: 63.86%\n",
      "Epoch 2/3, Batch 20680, Loss: 0.8415, Acc: 63.87%\n",
      "Epoch 2/3, Batch 20690, Loss: 0.0653, Acc: 63.85%\n",
      "Epoch 2/3, Batch 20700, Loss: 0.3401, Acc: 63.84%\n",
      "Epoch 2/3, Batch 20710, Loss: 0.9982, Acc: 63.85%\n",
      "Epoch 2/3, Batch 20720, Loss: 0.6347, Acc: 63.84%\n",
      "Epoch 2/3, Batch 20730, Loss: 0.5079, Acc: 63.83%\n",
      "Epoch 2/3, Batch 20740, Loss: 0.4077, Acc: 63.83%\n",
      "Epoch 2/3, Batch 20750, Loss: 0.0136, Acc: 63.83%\n",
      "Epoch 2/3, Batch 20760, Loss: 0.7382, Acc: 63.84%\n",
      "Epoch 2/3, Batch 20770, Loss: 0.4718, Acc: 63.85%\n",
      "Epoch 2/3, Batch 20780, Loss: 0.3551, Acc: 63.86%\n",
      "Epoch 2/3, Batch 20790, Loss: 0.0785, Acc: 63.86%\n",
      "Epoch 2/3, Batch 20800, Loss: 1.0404, Acc: 63.88%\n",
      "Epoch 2/3, Batch 20810, Loss: 0.5379, Acc: 63.88%\n",
      "Epoch 2/3, Batch 20820, Loss: 0.8283, Acc: 63.88%\n",
      "Epoch 2/3, Batch 20830, Loss: 2.7979, Acc: 63.87%\n",
      "Epoch 2/3, Batch 20840, Loss: 0.9617, Acc: 63.87%\n",
      "Epoch 2/3, Batch 20850, Loss: 0.6064, Acc: 63.87%\n",
      "Epoch 2/3, Batch 20860, Loss: 1.2729, Acc: 63.87%\n",
      "Epoch 2/3, Batch 20870, Loss: 1.1048, Acc: 63.86%\n",
      "Epoch 2/3, Batch 20880, Loss: 0.2051, Acc: 63.86%\n",
      "Epoch 2/3, Batch 20890, Loss: 0.0806, Acc: 63.85%\n",
      "Epoch 2/3, Batch 20900, Loss: 0.3570, Acc: 63.85%\n",
      "Epoch 2/3, Batch 20910, Loss: 0.0779, Acc: 63.86%\n",
      "Epoch 2/3, Batch 20920, Loss: 0.7801, Acc: 63.85%\n",
      "Epoch 2/3, Batch 20930, Loss: 0.7342, Acc: 63.84%\n",
      "Epoch 2/3, Batch 20940, Loss: 1.4488, Acc: 63.85%\n",
      "Epoch 2/3, Batch 20950, Loss: 1.5756, Acc: 63.85%\n",
      "Epoch 2/3, Batch 20960, Loss: 1.7142, Acc: 63.86%\n",
      "Epoch 2/3, Batch 20970, Loss: 0.0224, Acc: 63.86%\n",
      "Epoch 2/3, Batch 20980, Loss: 0.2480, Acc: 63.86%\n",
      "Epoch 2/3, Batch 20990, Loss: 0.4114, Acc: 63.87%\n",
      "Epoch 2/3, Batch 21000, Loss: 0.2028, Acc: 63.86%\n",
      "Epoch 2/3, Batch 21010, Loss: 0.0528, Acc: 63.87%\n",
      "Epoch 2/3, Batch 21020, Loss: 0.0514, Acc: 63.86%\n",
      "Epoch 2/3, Batch 21030, Loss: 1.2750, Acc: 63.86%\n",
      "Epoch 2/3, Batch 21040, Loss: 0.1786, Acc: 63.86%\n",
      "Epoch 2/3, Batch 21050, Loss: 0.4161, Acc: 63.86%\n",
      "Epoch 2/3, Batch 21060, Loss: 0.9012, Acc: 63.87%\n",
      "Epoch 2/3, Batch 21070, Loss: 0.5080, Acc: 63.87%\n",
      "Epoch 2/3, Batch 21080, Loss: 0.3426, Acc: 63.87%\n",
      "Epoch 2/3, Batch 21090, Loss: 1.3735, Acc: 63.87%\n",
      "Epoch 2/3, Batch 21100, Loss: 0.0293, Acc: 63.88%\n",
      "Epoch 2/3, Batch 21110, Loss: 2.0270, Acc: 63.87%\n",
      "Epoch 2/3, Batch 21120, Loss: 0.0845, Acc: 63.87%\n",
      "Epoch 2/3, Batch 21130, Loss: 0.8411, Acc: 63.85%\n",
      "Epoch 2/3, Batch 21140, Loss: 0.0228, Acc: 63.86%\n",
      "Epoch 2/3, Batch 21150, Loss: 0.0095, Acc: 63.86%\n",
      "Epoch 2/3, Batch 21160, Loss: 0.0162, Acc: 63.87%\n",
      "Epoch 2/3, Batch 21170, Loss: 0.6416, Acc: 63.88%\n",
      "Epoch 2/3, Batch 21180, Loss: 1.9414, Acc: 63.87%\n",
      "Epoch 2/3, Batch 21190, Loss: 0.1265, Acc: 63.87%\n",
      "Epoch 2/3, Batch 21200, Loss: 0.0224, Acc: 63.88%\n",
      "Epoch 2/3, Batch 21210, Loss: 0.0013, Acc: 63.89%\n",
      "Epoch 2/3, Batch 21220, Loss: 0.1921, Acc: 63.89%\n",
      "Epoch 2/3, Batch 21230, Loss: 0.3999, Acc: 63.91%\n",
      "Epoch 2/3, Batch 21240, Loss: 0.3315, Acc: 63.91%\n",
      "Epoch 2/3, Batch 21250, Loss: 0.7880, Acc: 63.90%\n",
      "Epoch 2/3, Batch 21260, Loss: 1.3855, Acc: 63.90%\n",
      "Epoch 2/3, Batch 21270, Loss: 0.1593, Acc: 63.90%\n",
      "Epoch 2/3, Batch 21280, Loss: 1.0979, Acc: 63.90%\n",
      "Epoch 2/3, Batch 21290, Loss: 0.5968, Acc: 63.90%\n",
      "Epoch 2/3, Batch 21300, Loss: 0.4152, Acc: 63.89%\n",
      "Epoch 2/3, Batch 21310, Loss: 0.0284, Acc: 63.90%\n",
      "Epoch 2/3, Batch 21320, Loss: 0.6751, Acc: 63.91%\n",
      "Epoch 2/3, Batch 21330, Loss: 0.5549, Acc: 63.91%\n",
      "Epoch 2/3, Batch 21340, Loss: 0.3774, Acc: 63.91%\n",
      "Epoch 2/3, Batch 21350, Loss: 0.9805, Acc: 63.91%\n",
      "Epoch 2/3, Batch 21360, Loss: 1.0823, Acc: 63.92%\n",
      "Epoch 2/3, Batch 21370, Loss: 0.4019, Acc: 63.91%\n",
      "Epoch 2/3, Batch 21380, Loss: 0.3824, Acc: 63.91%\n",
      "Epoch 2/3, Batch 21390, Loss: 0.2905, Acc: 63.91%\n",
      "Epoch 2/3, Batch 21400, Loss: 0.0032, Acc: 63.91%\n",
      "Epoch 2/3, Batch 21410, Loss: 0.3871, Acc: 63.91%\n",
      "Epoch 2/3, Batch 21420, Loss: 0.5901, Acc: 63.91%\n",
      "Epoch 2/3, Batch 21430, Loss: 0.5707, Acc: 63.92%\n",
      "Epoch 2/3, Batch 21440, Loss: 0.1985, Acc: 63.91%\n",
      "Epoch 2/3, Batch 21450, Loss: 0.5846, Acc: 63.92%\n",
      "Epoch 2/3, Batch 21460, Loss: 0.9947, Acc: 63.91%\n",
      "Epoch 2/3, Batch 21470, Loss: 0.1591, Acc: 63.91%\n",
      "Epoch 2/3, Batch 21480, Loss: 0.1038, Acc: 63.92%\n",
      "Epoch 2/3, Batch 21490, Loss: 0.0027, Acc: 63.92%\n",
      "Epoch 2/3, Batch 21500, Loss: 0.3389, Acc: 63.92%\n",
      "Epoch 2/3, Batch 21510, Loss: 0.4708, Acc: 63.92%\n",
      "Epoch 2/3, Batch 21520, Loss: 0.4244, Acc: 63.92%\n",
      "Epoch 2/3, Batch 21530, Loss: 0.0414, Acc: 63.92%\n",
      "Epoch 2/3, Batch 21540, Loss: 0.8875, Acc: 63.92%\n",
      "Epoch 2/3, Batch 21550, Loss: 0.5821, Acc: 63.91%\n",
      "Epoch 2/3, Batch 21560, Loss: 1.4229, Acc: 63.91%\n",
      "Epoch 2/3, Batch 21570, Loss: 0.8330, Acc: 63.91%\n",
      "Epoch 2/3, Batch 21580, Loss: 0.1319, Acc: 63.91%\n",
      "Epoch 2/3, Batch 21590, Loss: 0.5825, Acc: 63.92%\n",
      "Epoch 2/3, Batch 21600, Loss: 0.4819, Acc: 63.91%\n",
      "Epoch 2/3, Batch 21610, Loss: 0.8361, Acc: 63.91%\n",
      "Epoch 2/3, Batch 21620, Loss: 0.5543, Acc: 63.91%\n",
      "Epoch 2/3, Batch 21630, Loss: 0.3189, Acc: 63.91%\n",
      "Epoch 2/3, Batch 21640, Loss: 0.3482, Acc: 63.91%\n",
      "Epoch 2/3, Batch 21650, Loss: 0.1886, Acc: 63.90%\n",
      "Epoch 2/3, Batch 21660, Loss: 0.5724, Acc: 63.90%\n",
      "Epoch 2/3, Batch 21670, Loss: 0.1292, Acc: 63.91%\n",
      "Epoch 2/3, Batch 21680, Loss: 0.7072, Acc: 63.90%\n",
      "Epoch 2/3, Batch 21690, Loss: 0.8006, Acc: 63.90%\n",
      "Epoch 2/3, Batch 21700, Loss: 0.9090, Acc: 63.90%\n",
      "Epoch 2/3, Batch 21710, Loss: 0.9836, Acc: 63.89%\n",
      "Epoch 2/3, Batch 21720, Loss: 0.7356, Acc: 63.88%\n",
      "Epoch 2/3, Batch 21730, Loss: 0.7092, Acc: 63.89%\n",
      "Epoch 2/3, Batch 21740, Loss: 0.0362, Acc: 63.89%\n",
      "Epoch 2/3, Batch 21750, Loss: 0.0352, Acc: 63.91%\n",
      "Epoch 2/3, Batch 21760, Loss: 1.2199, Acc: 63.91%\n",
      "Epoch 2/3, Batch 21770, Loss: 0.8472, Acc: 63.91%\n",
      "Epoch 2/3, Batch 21780, Loss: 1.4597, Acc: 63.89%\n",
      "Epoch 2/3, Batch 21790, Loss: 0.9218, Acc: 63.88%\n",
      "Epoch 2/3, Batch 21800, Loss: 0.0093, Acc: 63.89%\n",
      "Epoch 2/3, Batch 21810, Loss: 0.4726, Acc: 63.88%\n",
      "Epoch 2/3, Batch 21820, Loss: 0.7803, Acc: 63.87%\n",
      "Epoch 2/3, Batch 21830, Loss: 0.1130, Acc: 63.87%\n",
      "Epoch 2/3, Batch 21840, Loss: 0.5620, Acc: 63.87%\n",
      "Epoch 2/3, Batch 21850, Loss: 1.0324, Acc: 63.87%\n",
      "Epoch 2/3, Batch 21860, Loss: 0.6386, Acc: 63.87%\n",
      "Epoch 2/3, Batch 21870, Loss: 0.7786, Acc: 63.87%\n",
      "Epoch 2/3, Batch 21880, Loss: 0.0090, Acc: 63.86%\n",
      "Epoch 2/3, Batch 21890, Loss: 1.0006, Acc: 63.85%\n",
      "Epoch 2/3, Batch 21900, Loss: 0.3297, Acc: 63.86%\n",
      "Epoch 2/3, Batch 21910, Loss: 0.4813, Acc: 63.86%\n",
      "Epoch 2/3, Batch 21920, Loss: 0.5625, Acc: 63.85%\n",
      "Epoch 2/3, Batch 21930, Loss: 0.0240, Acc: 63.85%\n",
      "Epoch 2/3, Batch 21940, Loss: 0.3020, Acc: 63.85%\n",
      "Epoch 2/3, Batch 21950, Loss: 0.0252, Acc: 63.85%\n",
      "Epoch 2/3, Batch 21960, Loss: 1.0273, Acc: 63.84%\n",
      "Epoch 2/3, Batch 21970, Loss: 0.9653, Acc: 63.83%\n",
      "Epoch 2/3, Batch 21980, Loss: 0.4041, Acc: 63.83%\n",
      "Epoch 2/3, Batch 21990, Loss: 1.2052, Acc: 63.83%\n",
      "Epoch 2/3, Batch 22000, Loss: 0.2457, Acc: 63.82%\n",
      "Epoch 2/3, Batch 22010, Loss: 0.0311, Acc: 63.82%\n",
      "Epoch 2/3, Batch 22020, Loss: 0.5876, Acc: 63.83%\n",
      "Epoch 2/3, Batch 22030, Loss: 0.2479, Acc: 63.84%\n",
      "Epoch 2/3, Batch 22040, Loss: 0.4288, Acc: 63.85%\n",
      "Epoch 2/3, Batch 22050, Loss: 0.9090, Acc: 63.86%\n",
      "Epoch 2/3, Batch 22060, Loss: 0.2613, Acc: 63.85%\n",
      "Epoch 2/3, Batch 22070, Loss: 0.1042, Acc: 63.85%\n",
      "Epoch 2/3, Batch 22080, Loss: 2.0918, Acc: 63.85%\n",
      "Epoch 2/3, Batch 22090, Loss: 0.2195, Acc: 63.85%\n",
      "Epoch 2/3, Batch 22100, Loss: 0.0170, Acc: 63.86%\n",
      "Epoch 2/3, Batch 22110, Loss: 0.9951, Acc: 63.85%\n",
      "Epoch 2/3, Batch 22120, Loss: 0.4271, Acc: 63.85%\n",
      "Epoch 2/3, Batch 22130, Loss: 0.3306, Acc: 63.86%\n",
      "Epoch 2/3, Batch 22140, Loss: 0.3768, Acc: 63.85%\n",
      "Epoch 2/3, Batch 22150, Loss: 0.6130, Acc: 63.86%\n",
      "Epoch 2/3, Batch 22160, Loss: 0.0087, Acc: 63.86%\n",
      "Epoch 2/3, Batch 22170, Loss: 2.0619, Acc: 63.86%\n",
      "Epoch 2/3, Batch 22180, Loss: 0.5396, Acc: 63.87%\n",
      "Epoch 2/3, Batch 22190, Loss: 0.1795, Acc: 63.85%\n",
      "Epoch 2/3, Batch 22200, Loss: 0.1038, Acc: 63.85%\n",
      "Epoch 2/3, Batch 22210, Loss: 0.9543, Acc: 63.86%\n",
      "Epoch 2/3, Batch 22220, Loss: 0.2464, Acc: 63.85%\n",
      "Epoch 2/3, Batch 22230, Loss: 0.1950, Acc: 63.86%\n",
      "Epoch 2/3, Batch 22240, Loss: 0.3181, Acc: 63.86%\n",
      "Epoch 2/3, Batch 22250, Loss: 0.6450, Acc: 63.87%\n",
      "Epoch 2/3, Batch 22260, Loss: 2.6076, Acc: 63.88%\n",
      "Epoch 2/3, Batch 22270, Loss: 2.7762, Acc: 63.88%\n",
      "Epoch 2/3, Batch 22280, Loss: 1.4027, Acc: 63.87%\n",
      "Epoch 2/3, Batch 22290, Loss: 1.8621, Acc: 63.87%\n",
      "Epoch 2/3, Batch 22300, Loss: 1.9003, Acc: 63.87%\n",
      "Epoch 2/3, Batch 22310, Loss: 0.3703, Acc: 63.88%\n",
      "Epoch 2/3, Batch 22320, Loss: 0.9881, Acc: 63.88%\n",
      "Epoch 2/3, Batch 22330, Loss: 0.2462, Acc: 63.88%\n",
      "Epoch 2/3, Batch 22340, Loss: 0.0617, Acc: 63.89%\n",
      "Epoch 2/3, Batch 22350, Loss: 0.0683, Acc: 63.88%\n",
      "Epoch 2/3, Batch 22360, Loss: 0.2531, Acc: 63.87%\n",
      "Epoch 2/3, Batch 22370, Loss: 0.6413, Acc: 63.89%\n",
      "Epoch 2/3, Batch 22380, Loss: 0.0201, Acc: 63.89%\n",
      "Epoch 2/3, Batch 22390, Loss: 0.3339, Acc: 63.89%\n",
      "Epoch 2/3, Batch 22400, Loss: 0.0041, Acc: 63.89%\n",
      "Epoch 2/3, Batch 22410, Loss: 0.3050, Acc: 63.88%\n",
      "Epoch 2/3, Batch 22420, Loss: 0.7073, Acc: 63.89%\n",
      "Epoch 2/3, Batch 22430, Loss: 0.0217, Acc: 63.89%\n",
      "Epoch 2/3, Batch 22440, Loss: 0.3361, Acc: 63.89%\n",
      "Epoch 2/3, Batch 22450, Loss: 2.3908, Acc: 63.89%\n",
      "Epoch 2/3, Batch 22460, Loss: 0.4511, Acc: 63.89%\n",
      "Epoch 2/3, Batch 22470, Loss: 1.6653, Acc: 63.88%\n",
      "Epoch 2/3, Batch 22480, Loss: 0.2127, Acc: 63.88%\n",
      "Epoch 2/3, Batch 22490, Loss: 0.4956, Acc: 63.89%\n",
      "Epoch 2/3, Batch 22500, Loss: 0.0186, Acc: 63.89%\n",
      "Epoch 2/3, Batch 22510, Loss: 0.3273, Acc: 63.88%\n",
      "Epoch 2/3, Batch 22520, Loss: 0.1361, Acc: 63.88%\n",
      "Epoch 2/3, Batch 22530, Loss: 0.0572, Acc: 63.89%\n",
      "Epoch 2/3, Batch 22540, Loss: 1.1505, Acc: 63.88%\n",
      "Epoch 2/3, Batch 22550, Loss: 0.1042, Acc: 63.89%\n",
      "Epoch 2/3, Batch 22560, Loss: 0.7066, Acc: 63.89%\n",
      "Epoch 2/3, Batch 22570, Loss: 1.6025, Acc: 63.88%\n",
      "Epoch 2/3, Batch 22580, Loss: 0.0075, Acc: 63.89%\n",
      "Epoch 2/3, Batch 22590, Loss: 0.3816, Acc: 63.90%\n",
      "Epoch 2/3, Batch 22600, Loss: 0.0157, Acc: 63.90%\n",
      "Epoch 2/3, Batch 22610, Loss: 0.5477, Acc: 63.90%\n",
      "Epoch 2/3, Batch 22620, Loss: 0.3809, Acc: 63.90%\n",
      "Epoch 2/3, Batch 22630, Loss: 0.2338, Acc: 63.89%\n",
      "Epoch 2/3, Batch 22640, Loss: 0.6351, Acc: 63.89%\n",
      "Epoch 2/3, Batch 22650, Loss: 1.3379, Acc: 63.88%\n",
      "Epoch 2/3, Batch 22660, Loss: 0.0506, Acc: 63.88%\n",
      "Epoch 2/3, Batch 22670, Loss: 0.6611, Acc: 63.88%\n",
      "Epoch 2/3, Batch 22680, Loss: 2.4943, Acc: 63.88%\n",
      "Epoch 2/3, Batch 22690, Loss: 0.5654, Acc: 63.89%\n",
      "Epoch 2/3, Batch 22700, Loss: 0.7363, Acc: 63.89%\n",
      "Epoch 2/3, Batch 22710, Loss: 1.0044, Acc: 63.89%\n",
      "Epoch 2/3, Batch 22720, Loss: 0.1178, Acc: 63.89%\n",
      "Epoch 2/3, Batch 22730, Loss: 0.0777, Acc: 63.90%\n",
      "Epoch 2/3, Batch 22740, Loss: 0.2981, Acc: 63.90%\n",
      "Epoch 2/3, Batch 22750, Loss: 0.0002, Acc: 63.90%\n",
      "Epoch 2/3, Batch 22760, Loss: 0.9611, Acc: 63.90%\n",
      "Epoch 2/3, Batch 22770, Loss: 0.7556, Acc: 63.90%\n",
      "Epoch 2/3, Batch 22780, Loss: 0.2879, Acc: 63.90%\n",
      "Epoch 2/3, Batch 22790, Loss: 1.0921, Acc: 63.88%\n",
      "Epoch 2/3, Batch 22800, Loss: 1.4745, Acc: 63.88%\n",
      "Epoch 2/3, Batch 22810, Loss: 0.5985, Acc: 63.88%\n",
      "Epoch 2/3, Batch 22820, Loss: 0.0198, Acc: 63.89%\n",
      "Epoch 2/3, Batch 22830, Loss: 0.8875, Acc: 63.89%\n",
      "Epoch 2/3, Batch 22840, Loss: 1.1048, Acc: 63.89%\n",
      "Epoch 2/3, Batch 22850, Loss: 0.4601, Acc: 63.90%\n",
      "Epoch 2/3, Batch 22860, Loss: 0.7962, Acc: 63.90%\n",
      "Epoch 2/3, Batch 22870, Loss: 0.0021, Acc: 63.91%\n",
      "Epoch 2/3, Batch 22880, Loss: 0.4782, Acc: 63.92%\n",
      "Epoch 2/3, Batch 22890, Loss: 1.2363, Acc: 63.92%\n",
      "Epoch 2/3, Batch 22900, Loss: 0.0343, Acc: 63.93%\n",
      "Epoch 2/3, Batch 22910, Loss: 0.5467, Acc: 63.93%\n",
      "Epoch 2/3, Batch 22920, Loss: 1.2210, Acc: 63.93%\n",
      "Epoch 2/3, Batch 22930, Loss: 0.5676, Acc: 63.94%\n",
      "Epoch 2/3, Batch 22940, Loss: 0.0355, Acc: 63.94%\n",
      "Epoch 2/3, Batch 22950, Loss: 0.6523, Acc: 63.94%\n",
      "Epoch 2/3, Batch 22960, Loss: 0.0302, Acc: 63.94%\n",
      "Epoch 2/3, Batch 22970, Loss: 0.5482, Acc: 63.95%\n",
      "Epoch 2/3, Batch 22980, Loss: 0.0372, Acc: 63.95%\n",
      "Epoch 2/3, Batch 22990, Loss: 0.5595, Acc: 63.95%\n",
      "Epoch 2/3, Batch 23000, Loss: 0.4322, Acc: 63.95%\n",
      "Epoch 2/3, Batch 23010, Loss: 1.3469, Acc: 63.94%\n",
      "Epoch 2/3, Batch 23020, Loss: 0.6851, Acc: 63.94%\n",
      "Epoch 2/3, Batch 23030, Loss: 0.2879, Acc: 63.94%\n",
      "Epoch 2/3, Batch 23040, Loss: 0.5316, Acc: 63.95%\n",
      "Epoch 2/3, Batch 23050, Loss: 0.6860, Acc: 63.95%\n",
      "Epoch 2/3, Batch 23060, Loss: 0.1438, Acc: 63.96%\n",
      "Epoch 2/3, Batch 23070, Loss: 0.1885, Acc: 63.96%\n",
      "Epoch 2/3, Batch 23080, Loss: 0.5712, Acc: 63.97%\n",
      "Epoch 2/3, Batch 23090, Loss: 0.3708, Acc: 63.98%\n",
      "Epoch 2/3, Batch 23100, Loss: 0.0160, Acc: 63.98%\n",
      "Epoch 2/3, Batch 23110, Loss: 1.0019, Acc: 63.97%\n",
      "Epoch 2/3, Batch 23120, Loss: 0.1516, Acc: 63.95%\n",
      "Epoch 2/3, Batch 23130, Loss: 1.0358, Acc: 63.95%\n",
      "Epoch 2/3, Batch 23140, Loss: 0.2467, Acc: 63.96%\n",
      "Epoch 2/3, Batch 23150, Loss: 1.2217, Acc: 63.95%\n",
      "Epoch 2/3, Batch 23160, Loss: 0.3464, Acc: 63.94%\n",
      "Epoch 2/3, Batch 23170, Loss: 0.0004, Acc: 63.95%\n",
      "Epoch 2/3, Batch 23180, Loss: 0.3069, Acc: 63.96%\n",
      "Epoch 2/3, Batch 23190, Loss: 0.2634, Acc: 63.96%\n",
      "Epoch 2/3, Batch 23200, Loss: 3.1221, Acc: 63.96%\n",
      "Epoch 2/3, Batch 23210, Loss: 0.0065, Acc: 63.96%\n",
      "Epoch 2/3, Batch 23220, Loss: 2.1192, Acc: 63.94%\n",
      "Epoch 2/3, Batch 23230, Loss: 0.5638, Acc: 63.94%\n",
      "Epoch 2/3, Batch 23240, Loss: 1.1403, Acc: 63.94%\n",
      "Epoch 2/3, Batch 23250, Loss: 0.3192, Acc: 63.94%\n",
      "Epoch 2/3, Batch 23260, Loss: 1.7625, Acc: 63.94%\n",
      "Epoch 2/3, Batch 23270, Loss: 0.4679, Acc: 63.95%\n",
      "Epoch 2/3, Batch 23280, Loss: 1.9095, Acc: 63.96%\n",
      "Epoch 2/3, Batch 23290, Loss: 0.4228, Acc: 63.97%\n",
      "Epoch 2/3, Batch 23300, Loss: 0.8746, Acc: 63.96%\n",
      "Epoch 2/3, Batch 23310, Loss: 0.0733, Acc: 63.96%\n",
      "Epoch 2/3, Batch 23320, Loss: 1.1375, Acc: 63.93%\n",
      "Epoch 2/3, Batch 23330, Loss: 0.3373, Acc: 63.93%\n",
      "Epoch 2/3, Batch 23340, Loss: 0.8254, Acc: 63.93%\n",
      "Epoch 2/3, Batch 23350, Loss: 0.6315, Acc: 63.94%\n",
      "Epoch 2/3, Batch 23360, Loss: 2.1643, Acc: 63.94%\n",
      "Epoch 2/3, Batch 23370, Loss: 0.3568, Acc: 63.93%\n",
      "Epoch 2/3, Batch 23380, Loss: 1.0897, Acc: 63.95%\n",
      "Epoch 2/3, Batch 23390, Loss: 0.1322, Acc: 63.95%\n",
      "Epoch 2/3, Batch 23400, Loss: 0.0771, Acc: 63.95%\n",
      "Epoch 2/3, Batch 23410, Loss: 0.2671, Acc: 63.95%\n",
      "Epoch 2/3, Batch 23420, Loss: 0.8828, Acc: 63.95%\n",
      "Epoch 2/3, Batch 23430, Loss: 0.0287, Acc: 63.94%\n",
      "Epoch 2/3, Batch 23440, Loss: 0.2084, Acc: 63.94%\n",
      "Epoch 2/3, Batch 23450, Loss: 0.5085, Acc: 63.95%\n",
      "Epoch 2/3, Batch 23460, Loss: 0.9888, Acc: 63.94%\n",
      "Epoch 2/3, Batch 23470, Loss: 0.7636, Acc: 63.94%\n",
      "Epoch 2/3, Batch 23480, Loss: 0.8943, Acc: 63.94%\n",
      "Epoch 2/3, Batch 23490, Loss: 0.7739, Acc: 63.93%\n",
      "Epoch 2/3, Batch 23500, Loss: 0.4037, Acc: 63.93%\n",
      "Epoch 2/3, Batch 23510, Loss: 0.5063, Acc: 63.94%\n",
      "Epoch 2/3, Batch 23520, Loss: 0.8598, Acc: 63.94%\n",
      "Epoch 2/3, Batch 23530, Loss: 0.3560, Acc: 63.93%\n",
      "Epoch 2/3, Batch 23540, Loss: 0.0401, Acc: 63.92%\n",
      "Epoch 2/3, Batch 23550, Loss: 1.4422, Acc: 63.93%\n",
      "Epoch 2/3, Batch 23560, Loss: 0.2378, Acc: 63.92%\n",
      "Epoch 2/3, Batch 23570, Loss: 0.4101, Acc: 63.92%\n",
      "Epoch 2/3, Batch 23580, Loss: 0.3727, Acc: 63.92%\n",
      "Epoch 2/3, Batch 23590, Loss: 0.6815, Acc: 63.92%\n",
      "Epoch 2/3, Batch 23600, Loss: 0.8407, Acc: 63.92%\n",
      "Epoch 2/3, Batch 23610, Loss: 0.3673, Acc: 63.90%\n",
      "Epoch 2/3, Batch 23620, Loss: 0.1001, Acc: 63.91%\n",
      "Epoch 2/3, Batch 23630, Loss: 0.8750, Acc: 63.91%\n",
      "Epoch 2/3, Batch 23640, Loss: 0.0432, Acc: 63.92%\n",
      "Epoch 2/3, Batch 23650, Loss: 1.3822, Acc: 63.93%\n",
      "Epoch 2/3, Batch 23660, Loss: 1.4329, Acc: 63.92%\n",
      "Epoch 2/3, Batch 23670, Loss: 0.4916, Acc: 63.93%\n",
      "Epoch 2/3, Batch 23680, Loss: 0.8865, Acc: 63.93%\n",
      "Epoch 2/3, Batch 23690, Loss: 0.0522, Acc: 63.93%\n",
      "Epoch 2/3, Batch 23700, Loss: 0.0030, Acc: 63.93%\n",
      "Epoch 2/3, Batch 23710, Loss: 0.8819, Acc: 63.92%\n",
      "Epoch 2/3, Batch 23720, Loss: 0.3873, Acc: 63.93%\n",
      "Epoch 2/3, Batch 23730, Loss: 0.6193, Acc: 63.94%\n",
      "Epoch 2/3, Batch 23740, Loss: 1.0497, Acc: 63.94%\n",
      "Epoch 2/3, Batch 23750, Loss: 0.2190, Acc: 63.95%\n",
      "Epoch 2/3, Batch 23760, Loss: 0.2049, Acc: 63.95%\n",
      "Epoch 2/3, Batch 23770, Loss: 0.0762, Acc: 63.95%\n",
      "Epoch 2/3, Batch 23780, Loss: 0.0062, Acc: 63.95%\n",
      "Epoch 2/3, Batch 23790, Loss: 0.9444, Acc: 63.94%\n",
      "Epoch 2/3, Batch 23800, Loss: 0.0038, Acc: 63.94%\n",
      "Epoch 2/3, Batch 23810, Loss: 1.2872, Acc: 63.95%\n",
      "Epoch 2/3, Batch 23820, Loss: 0.5968, Acc: 63.96%\n",
      "Epoch 2/3, Batch 23830, Loss: 0.1224, Acc: 63.96%\n",
      "Epoch 2/3, Batch 23840, Loss: 0.1974, Acc: 63.96%\n",
      "Epoch 2/3, Batch 23850, Loss: 0.7711, Acc: 63.96%\n",
      "Epoch 2/3, Batch 23860, Loss: 0.0456, Acc: 63.95%\n",
      "Epoch 2/3, Batch 23870, Loss: 0.0800, Acc: 63.96%\n",
      "Epoch 2/3, Batch 23880, Loss: 0.5971, Acc: 63.97%\n",
      "Epoch 2/3, Batch 23890, Loss: 0.7984, Acc: 63.97%\n",
      "Epoch 2/3, Batch 23900, Loss: 0.7885, Acc: 63.97%\n",
      "Epoch 2/3, Batch 23910, Loss: 0.8314, Acc: 63.97%\n",
      "Epoch 2/3, Batch 23920, Loss: 0.2455, Acc: 63.98%\n",
      "Epoch 2/3, Batch 23930, Loss: 0.0075, Acc: 63.98%\n",
      "Epoch 2/3, Batch 23940, Loss: 1.6145, Acc: 63.99%\n",
      "Epoch 2/3, Batch 23950, Loss: 0.2811, Acc: 63.98%\n",
      "Epoch 2/3, Batch 23960, Loss: 1.3594, Acc: 63.97%\n",
      "Epoch 2/3, Batch 23970, Loss: 0.8978, Acc: 63.96%\n",
      "Epoch 2/3, Batch 23980, Loss: 0.3755, Acc: 63.96%\n",
      "Epoch 2/3, Batch 23990, Loss: 1.2417, Acc: 63.96%\n",
      "Epoch 2/3, Batch 24000, Loss: 0.5470, Acc: 63.96%\n",
      "Epoch 2/3, Batch 24010, Loss: 1.2305, Acc: 63.97%\n",
      "Epoch 2/3, Batch 24020, Loss: 0.8663, Acc: 63.96%\n",
      "Epoch 2/3, Batch 24030, Loss: 0.5028, Acc: 63.95%\n",
      "Epoch 2/3, Batch 24040, Loss: 0.1958, Acc: 63.95%\n",
      "Epoch 2/3, Batch 24050, Loss: 1.4240, Acc: 63.95%\n",
      "Epoch 2/3, Batch 24060, Loss: 1.3118, Acc: 63.95%\n",
      "Epoch 2/3, Batch 24070, Loss: 0.0944, Acc: 63.95%\n",
      "Epoch 2/3, Batch 24080, Loss: 1.5065, Acc: 63.95%\n",
      "Epoch 2/3, Batch 24090, Loss: 0.8228, Acc: 63.94%\n",
      "Epoch 2/3, Batch 24100, Loss: 1.1036, Acc: 63.94%\n",
      "Epoch 2/3, Batch 24110, Loss: 0.1134, Acc: 63.94%\n",
      "Epoch 2/3, Batch 24120, Loss: 0.7060, Acc: 63.93%\n",
      "Epoch 2/3, Batch 24130, Loss: 0.0300, Acc: 63.93%\n",
      "Epoch 2/3, Batch 24140, Loss: 0.0098, Acc: 63.92%\n",
      "Epoch 2/3, Batch 24150, Loss: 1.2269, Acc: 63.92%\n",
      "Epoch 2/3, Batch 24160, Loss: 0.1167, Acc: 63.92%\n",
      "Epoch 2/3, Batch 24170, Loss: 0.8435, Acc: 63.92%\n",
      "Epoch 2/3, Batch 24180, Loss: 0.8304, Acc: 63.92%\n",
      "Epoch 2/3, Batch 24190, Loss: 0.5210, Acc: 63.93%\n",
      "Epoch 2/3, Batch 24200, Loss: 1.5196, Acc: 63.94%\n",
      "Epoch 2/3, Batch 24210, Loss: 1.6439, Acc: 63.93%\n",
      "Epoch 2/3, Batch 24220, Loss: 0.8573, Acc: 63.93%\n",
      "Epoch 2/3, Batch 24230, Loss: 0.3584, Acc: 63.94%\n",
      "Epoch 2/3, Batch 24240, Loss: 0.0006, Acc: 63.94%\n",
      "Epoch 2/3, Batch 24250, Loss: 0.0793, Acc: 63.94%\n",
      "Epoch 2/3, Batch 24260, Loss: 2.1332, Acc: 63.94%\n",
      "Epoch 2/3, Batch 24270, Loss: 0.8465, Acc: 63.94%\n",
      "Epoch 2/3, Batch 24280, Loss: 1.3980, Acc: 63.93%\n",
      "Epoch 2/3, Batch 24290, Loss: 0.0439, Acc: 63.94%\n",
      "Epoch 2/3, Batch 24300, Loss: 1.0337, Acc: 63.94%\n",
      "Epoch 2/3, Batch 24310, Loss: 1.1017, Acc: 63.94%\n",
      "Epoch 2/3, Batch 24320, Loss: 0.9307, Acc: 63.93%\n",
      "Epoch 2/3, Batch 24330, Loss: 0.0286, Acc: 63.92%\n",
      "Epoch 2/3, Batch 24340, Loss: 0.7689, Acc: 63.93%\n",
      "Epoch 2/3, Batch 24350, Loss: 0.6252, Acc: 63.92%\n",
      "Epoch 2/3, Batch 24360, Loss: 0.3175, Acc: 63.92%\n",
      "Epoch 2/3, Batch 24370, Loss: 0.4011, Acc: 63.93%\n",
      "Epoch 2/3, Batch 24380, Loss: 1.3991, Acc: 63.94%\n",
      "Epoch 2/3, Batch 24390, Loss: 0.9204, Acc: 63.94%\n",
      "Epoch 2/3, Batch 24400, Loss: 0.0206, Acc: 63.94%\n",
      "Epoch 2/3, Batch 24410, Loss: 1.1667, Acc: 63.94%\n",
      "Epoch 2/3, Batch 24420, Loss: 1.5382, Acc: 63.94%\n",
      "Epoch 2/3, Batch 24430, Loss: 1.1791, Acc: 63.94%\n",
      "Epoch 2/3, Batch 24440, Loss: 0.0194, Acc: 63.95%\n",
      "Epoch 2/3, Batch 24450, Loss: 0.1138, Acc: 63.95%\n",
      "Epoch 2/3, Batch 24460, Loss: 0.5633, Acc: 63.95%\n",
      "Epoch 2/3, Batch 24470, Loss: 0.7289, Acc: 63.94%\n",
      "Epoch 2/3, Batch 24480, Loss: 0.0387, Acc: 63.93%\n",
      "Epoch 2/3, Batch 24490, Loss: 0.4322, Acc: 63.92%\n",
      "Epoch 2/3, Batch 24500, Loss: 1.0835, Acc: 63.92%\n",
      "Epoch 2/3, Batch 24510, Loss: 0.1427, Acc: 63.92%\n",
      "Epoch 2/3, Batch 24520, Loss: 0.3219, Acc: 63.92%\n",
      "Epoch 2/3, Batch 24530, Loss: 0.2845, Acc: 63.93%\n",
      "Epoch 2/3, Batch 24540, Loss: 0.4597, Acc: 63.93%\n",
      "Epoch 2/3, Batch 24550, Loss: 0.5302, Acc: 63.93%\n",
      "Epoch 2/3, Batch 24560, Loss: 0.6219, Acc: 63.93%\n",
      "Epoch 2/3, Batch 24570, Loss: 1.0921, Acc: 63.92%\n",
      "Epoch 2/3, Batch 24580, Loss: 1.1306, Acc: 63.92%\n",
      "Epoch 2/3, Batch 24590, Loss: 0.0543, Acc: 63.92%\n",
      "Epoch 2/3, Batch 24600, Loss: 0.0616, Acc: 63.92%\n",
      "Epoch 2/3, Batch 24610, Loss: 0.4354, Acc: 63.92%\n",
      "Epoch 2/3, Batch 24620, Loss: 0.0557, Acc: 63.93%\n",
      "Epoch 2/3, Batch 24630, Loss: 1.1075, Acc: 63.92%\n",
      "Epoch 2/3, Batch 24640, Loss: 1.6490, Acc: 63.92%\n",
      "Epoch 2/3, Batch 24650, Loss: 0.1064, Acc: 63.92%\n",
      "Epoch 2/3, Batch 24660, Loss: 0.0328, Acc: 63.92%\n",
      "Epoch 2/3, Batch 24670, Loss: 0.5505, Acc: 63.92%\n",
      "Epoch 2/3, Batch 24680, Loss: 1.1422, Acc: 63.92%\n",
      "Epoch 2/3, Batch 24690, Loss: 0.4396, Acc: 63.93%\n",
      "Epoch 2/3, Batch 24700, Loss: 0.6974, Acc: 63.93%\n",
      "Epoch 2/3, Batch 24710, Loss: 0.2883, Acc: 63.94%\n",
      "Epoch 2/3, Batch 24720, Loss: 0.8651, Acc: 63.93%\n",
      "Epoch 2/3, Batch 24730, Loss: 0.0228, Acc: 63.94%\n",
      "Epoch 2/3, Batch 24740, Loss: 0.3079, Acc: 63.93%\n",
      "Epoch 2/3, Batch 24750, Loss: 0.2343, Acc: 63.93%\n",
      "Epoch 2/3, Batch 24760, Loss: 0.1077, Acc: 63.92%\n",
      "Epoch 2/3, Batch 24770, Loss: 0.9462, Acc: 63.92%\n",
      "Epoch 2/3, Batch 24780, Loss: 0.9249, Acc: 63.91%\n",
      "Epoch 2/3, Batch 24790, Loss: 0.5627, Acc: 63.92%\n",
      "Epoch 2/3, Batch 24800, Loss: 0.0436, Acc: 63.92%\n",
      "Epoch 2/3, Batch 24810, Loss: 0.7034, Acc: 63.92%\n",
      "Epoch 2/3, Batch 24820, Loss: 1.6239, Acc: 63.93%\n",
      "Epoch 2/3, Batch 24830, Loss: 1.6174, Acc: 63.93%\n",
      "Epoch 2/3, Batch 24840, Loss: 0.5376, Acc: 63.94%\n",
      "Epoch 2/3, Batch 24850, Loss: 0.0130, Acc: 63.96%\n",
      "Epoch 2/3, Batch 24860, Loss: 0.3095, Acc: 63.96%\n",
      "Epoch 2/3, Batch 24870, Loss: 0.0492, Acc: 63.96%\n",
      "Epoch 2/3, Batch 24880, Loss: 0.8340, Acc: 63.96%\n",
      "Epoch 2/3, Batch 24890, Loss: 1.0513, Acc: 63.96%\n",
      "Epoch 2/3, Batch 24900, Loss: 1.2116, Acc: 63.96%\n",
      "Epoch 2/3, Batch 24910, Loss: 0.9888, Acc: 63.96%\n",
      "Epoch 2/3, Batch 24920, Loss: 0.6281, Acc: 63.96%\n",
      "Epoch 2/3, Batch 24930, Loss: 0.1441, Acc: 63.96%\n",
      "Epoch 2/3, Batch 24940, Loss: 0.3468, Acc: 63.97%\n",
      "Epoch 2/3, Batch 24950, Loss: 0.5552, Acc: 63.97%\n",
      "Epoch 2/3, Batch 24960, Loss: 0.5243, Acc: 63.98%\n",
      "Epoch 2/3, Batch 24970, Loss: 0.0017, Acc: 63.97%\n",
      "Epoch 2/3, Batch 24980, Loss: 0.0006, Acc: 63.97%\n",
      "Epoch 2/3, Batch 24990, Loss: 0.4147, Acc: 63.97%\n",
      "Epoch 2/3, Batch 25000, Loss: 0.1182, Acc: 63.97%\n",
      "Epoch 2/3, Batch 25010, Loss: 0.0316, Acc: 63.97%\n",
      "Epoch 2/3, Batch 25020, Loss: 0.0374, Acc: 63.97%\n",
      "Epoch 2/3, Batch 25030, Loss: 0.6958, Acc: 63.98%\n",
      "Epoch 2/3, Batch 25040, Loss: 1.4170, Acc: 63.97%\n",
      "Epoch 2/3, Batch 25050, Loss: 0.6468, Acc: 63.97%\n",
      "Epoch 2/3, Batch 25060, Loss: 0.5788, Acc: 63.97%\n",
      "Epoch 2/3, Batch 25070, Loss: 0.9087, Acc: 63.97%\n",
      "Epoch 2/3, Batch 25080, Loss: 1.0205, Acc: 63.97%\n",
      "Epoch 2/3, Batch 25090, Loss: 1.4973, Acc: 63.97%\n",
      "Epoch 2/3, Batch 25100, Loss: 2.0107, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25110, Loss: 0.3454, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25120, Loss: 0.8692, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25130, Loss: 0.1607, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25140, Loss: 0.2634, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25150, Loss: 1.0274, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25160, Loss: 0.0652, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25170, Loss: 1.1591, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25180, Loss: 0.6386, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25190, Loss: 0.4240, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25200, Loss: 0.7058, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25210, Loss: 0.5167, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25220, Loss: 0.0144, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25230, Loss: 0.1555, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25240, Loss: 0.0275, Acc: 63.98%\n",
      "Epoch 2/3, Batch 25250, Loss: 0.0002, Acc: 63.99%\n",
      "Epoch 2/3, Batch 25260, Loss: 0.7136, Acc: 63.98%\n",
      "Epoch 2/3, Batch 25270, Loss: 0.2482, Acc: 63.98%\n",
      "Epoch 2/3, Batch 25280, Loss: 0.0972, Acc: 63.98%\n",
      "Epoch 2/3, Batch 25290, Loss: 0.0148, Acc: 63.97%\n",
      "Epoch 2/3, Batch 25300, Loss: 0.4958, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25310, Loss: 0.6768, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25320, Loss: 0.2869, Acc: 63.97%\n",
      "Epoch 2/3, Batch 25330, Loss: 0.5085, Acc: 63.98%\n",
      "Epoch 2/3, Batch 25340, Loss: 0.5216, Acc: 63.98%\n",
      "Epoch 2/3, Batch 25350, Loss: 1.0007, Acc: 63.98%\n",
      "Epoch 2/3, Batch 25360, Loss: 0.6392, Acc: 63.98%\n",
      "Epoch 2/3, Batch 25370, Loss: 0.0294, Acc: 63.97%\n",
      "Epoch 2/3, Batch 25380, Loss: 0.0244, Acc: 63.97%\n",
      "Epoch 2/3, Batch 25390, Loss: 0.5803, Acc: 63.98%\n",
      "Epoch 2/3, Batch 25400, Loss: 0.1252, Acc: 63.98%\n",
      "Epoch 2/3, Batch 25410, Loss: 0.0912, Acc: 63.97%\n",
      "Epoch 2/3, Batch 25420, Loss: 0.6339, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25430, Loss: 0.2733, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25440, Loss: 0.3873, Acc: 63.97%\n",
      "Epoch 2/3, Batch 25450, Loss: 0.1463, Acc: 63.97%\n",
      "Epoch 2/3, Batch 25460, Loss: 0.1345, Acc: 63.98%\n",
      "Epoch 2/3, Batch 25470, Loss: 0.6306, Acc: 63.97%\n",
      "Epoch 2/3, Batch 25480, Loss: 1.2132, Acc: 63.97%\n",
      "Epoch 2/3, Batch 25490, Loss: 0.0184, Acc: 63.97%\n",
      "Epoch 2/3, Batch 25500, Loss: 0.9851, Acc: 63.97%\n",
      "Epoch 2/3, Batch 25510, Loss: 0.8913, Acc: 63.97%\n",
      "Epoch 2/3, Batch 25520, Loss: 0.2209, Acc: 63.99%\n",
      "Epoch 2/3, Batch 25530, Loss: 0.0238, Acc: 63.98%\n",
      "Epoch 2/3, Batch 25540, Loss: 2.4733, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25550, Loss: 0.3476, Acc: 63.97%\n",
      "Epoch 2/3, Batch 25560, Loss: 1.5810, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25570, Loss: 0.3800, Acc: 63.97%\n",
      "Epoch 2/3, Batch 25580, Loss: 1.2269, Acc: 63.97%\n",
      "Epoch 2/3, Batch 25590, Loss: 0.2399, Acc: 63.97%\n",
      "Epoch 2/3, Batch 25600, Loss: 0.0930, Acc: 63.97%\n",
      "Epoch 2/3, Batch 25610, Loss: 0.9685, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25620, Loss: 0.0545, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25630, Loss: 0.6090, Acc: 63.97%\n",
      "Epoch 2/3, Batch 25640, Loss: 0.5447, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25650, Loss: 2.4090, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25660, Loss: 0.1450, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25670, Loss: 1.3345, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25680, Loss: 0.5057, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25690, Loss: 0.5134, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25700, Loss: 0.0252, Acc: 63.95%\n",
      "Epoch 2/3, Batch 25710, Loss: 0.4321, Acc: 63.95%\n",
      "Epoch 2/3, Batch 25720, Loss: 0.3649, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25730, Loss: 0.3062, Acc: 63.95%\n",
      "Epoch 2/3, Batch 25740, Loss: 0.4406, Acc: 63.95%\n",
      "Epoch 2/3, Batch 25750, Loss: 0.0539, Acc: 63.95%\n",
      "Epoch 2/3, Batch 25760, Loss: 0.1303, Acc: 63.95%\n",
      "Epoch 2/3, Batch 25770, Loss: 1.9024, Acc: 63.94%\n",
      "Epoch 2/3, Batch 25780, Loss: 0.8965, Acc: 63.94%\n",
      "Epoch 2/3, Batch 25790, Loss: 0.5233, Acc: 63.93%\n",
      "Epoch 2/3, Batch 25800, Loss: 0.1030, Acc: 63.93%\n",
      "Epoch 2/3, Batch 25810, Loss: 0.3620, Acc: 63.93%\n",
      "Epoch 2/3, Batch 25820, Loss: 1.1109, Acc: 63.93%\n",
      "Epoch 2/3, Batch 25830, Loss: 0.5906, Acc: 63.93%\n",
      "Epoch 2/3, Batch 25840, Loss: 1.4013, Acc: 63.93%\n",
      "Epoch 2/3, Batch 25850, Loss: 0.0740, Acc: 63.93%\n",
      "Epoch 2/3, Batch 25860, Loss: 0.1169, Acc: 63.92%\n",
      "Epoch 2/3, Batch 25870, Loss: 0.6118, Acc: 63.92%\n",
      "Epoch 2/3, Batch 25880, Loss: 0.1748, Acc: 63.93%\n",
      "Epoch 2/3, Batch 25890, Loss: 0.2469, Acc: 63.93%\n",
      "Epoch 2/3, Batch 25900, Loss: 0.0632, Acc: 63.93%\n",
      "Epoch 2/3, Batch 25910, Loss: 0.0746, Acc: 63.93%\n",
      "Epoch 2/3, Batch 25920, Loss: 0.0339, Acc: 63.93%\n",
      "Epoch 2/3, Batch 25930, Loss: 0.0298, Acc: 63.92%\n",
      "Epoch 2/3, Batch 25940, Loss: 0.6847, Acc: 63.93%\n",
      "Epoch 2/3, Batch 25950, Loss: 0.4802, Acc: 63.94%\n",
      "Epoch 2/3, Batch 25960, Loss: 0.0263, Acc: 63.95%\n",
      "Epoch 2/3, Batch 25970, Loss: 0.1002, Acc: 63.96%\n",
      "Epoch 2/3, Batch 25980, Loss: 0.0057, Acc: 63.97%\n",
      "Epoch 2/3, Batch 25990, Loss: 0.2603, Acc: 63.97%\n",
      "Epoch 2/3, Batch 26000, Loss: 0.2404, Acc: 63.97%\n",
      "Epoch 2/3, Batch 26010, Loss: 0.0725, Acc: 63.97%\n",
      "Epoch 2/3, Batch 26020, Loss: 0.0348, Acc: 63.98%\n",
      "Epoch 2/3, Batch 26030, Loss: 0.7736, Acc: 63.97%\n",
      "Epoch 2/3, Batch 26040, Loss: 0.4502, Acc: 63.98%\n",
      "Epoch 2/3, Batch 26050, Loss: 0.3112, Acc: 63.97%\n",
      "Epoch 2/3, Batch 26060, Loss: 0.4303, Acc: 63.98%\n",
      "Epoch 2/3, Batch 26070, Loss: 0.4353, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26080, Loss: 1.0329, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26090, Loss: 0.7800, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26100, Loss: 1.2304, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26110, Loss: 1.3222, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26120, Loss: 0.5517, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26130, Loss: 0.7824, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26140, Loss: 0.2882, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26150, Loss: 0.0313, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26160, Loss: 0.0054, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26170, Loss: 0.7116, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26180, Loss: 0.4710, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26190, Loss: 0.4408, Acc: 64.00%\n",
      "Epoch 2/3, Batch 26200, Loss: 0.3086, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26210, Loss: 0.8208, Acc: 63.98%\n",
      "Epoch 2/3, Batch 26220, Loss: 0.0017, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26230, Loss: 0.6612, Acc: 64.00%\n",
      "Epoch 2/3, Batch 26240, Loss: 0.2163, Acc: 64.00%\n",
      "Epoch 2/3, Batch 26250, Loss: 0.2922, Acc: 64.00%\n",
      "Epoch 2/3, Batch 26260, Loss: 0.3749, Acc: 64.00%\n",
      "Epoch 2/3, Batch 26270, Loss: 0.4946, Acc: 64.01%\n",
      "Epoch 2/3, Batch 26280, Loss: 0.1697, Acc: 64.01%\n",
      "Epoch 2/3, Batch 26290, Loss: 0.9168, Acc: 64.00%\n",
      "Epoch 2/3, Batch 26300, Loss: 0.9079, Acc: 64.01%\n",
      "Epoch 2/3, Batch 26310, Loss: 1.5179, Acc: 64.00%\n",
      "Epoch 2/3, Batch 26320, Loss: 1.0586, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26330, Loss: 0.5924, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26340, Loss: 0.4897, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26350, Loss: 0.1476, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26360, Loss: 1.4986, Acc: 63.98%\n",
      "Epoch 2/3, Batch 26370, Loss: 0.5753, Acc: 63.98%\n",
      "Epoch 2/3, Batch 26380, Loss: 0.1805, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26390, Loss: 0.6290, Acc: 64.00%\n",
      "Epoch 2/3, Batch 26400, Loss: 0.2790, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26410, Loss: 1.2395, Acc: 64.00%\n",
      "Epoch 2/3, Batch 26420, Loss: 0.3840, Acc: 64.00%\n",
      "Epoch 2/3, Batch 26430, Loss: 0.1444, Acc: 64.00%\n",
      "Epoch 2/3, Batch 26440, Loss: 0.5055, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26450, Loss: 0.2288, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26460, Loss: 0.0513, Acc: 63.98%\n",
      "Epoch 2/3, Batch 26470, Loss: 0.6770, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26480, Loss: 3.1806, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26490, Loss: 0.1762, Acc: 64.00%\n",
      "Epoch 2/3, Batch 26500, Loss: 1.0601, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26510, Loss: 0.6284, Acc: 64.00%\n",
      "Epoch 2/3, Batch 26520, Loss: 0.3497, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26530, Loss: 0.2368, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26540, Loss: 0.1528, Acc: 64.00%\n",
      "Epoch 2/3, Batch 26550, Loss: 1.0057, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26560, Loss: 0.9682, Acc: 63.97%\n",
      "Epoch 2/3, Batch 26570, Loss: 0.5058, Acc: 63.97%\n",
      "Epoch 2/3, Batch 26580, Loss: 0.0381, Acc: 63.97%\n",
      "Epoch 2/3, Batch 26590, Loss: 0.0089, Acc: 63.97%\n",
      "Epoch 2/3, Batch 26600, Loss: 0.9026, Acc: 63.98%\n",
      "Epoch 2/3, Batch 26610, Loss: 1.6096, Acc: 63.97%\n",
      "Epoch 2/3, Batch 26620, Loss: 0.0866, Acc: 63.98%\n",
      "Epoch 2/3, Batch 26630, Loss: 0.0264, Acc: 63.98%\n",
      "Epoch 2/3, Batch 26640, Loss: 0.3155, Acc: 63.98%\n",
      "Epoch 2/3, Batch 26650, Loss: 0.5929, Acc: 63.98%\n",
      "Epoch 2/3, Batch 26660, Loss: 0.1119, Acc: 63.98%\n",
      "Epoch 2/3, Batch 26670, Loss: 0.7286, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26680, Loss: 0.3768, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26690, Loss: 0.7291, Acc: 63.98%\n",
      "Epoch 2/3, Batch 26700, Loss: 0.9581, Acc: 63.98%\n",
      "Epoch 2/3, Batch 26710, Loss: 0.9656, Acc: 63.98%\n",
      "Epoch 2/3, Batch 26720, Loss: 1.1966, Acc: 63.98%\n",
      "Epoch 2/3, Batch 26730, Loss: 0.8891, Acc: 63.98%\n",
      "Epoch 2/3, Batch 26740, Loss: 0.6690, Acc: 63.97%\n",
      "Epoch 2/3, Batch 26750, Loss: 0.9721, Acc: 63.97%\n",
      "Epoch 2/3, Batch 26760, Loss: 0.7267, Acc: 63.97%\n",
      "Epoch 2/3, Batch 26770, Loss: 0.7689, Acc: 63.96%\n",
      "Epoch 2/3, Batch 26780, Loss: 1.5744, Acc: 63.95%\n",
      "Epoch 2/3, Batch 26790, Loss: 0.8450, Acc: 63.95%\n",
      "Epoch 2/3, Batch 26800, Loss: 0.7355, Acc: 63.96%\n",
      "Epoch 2/3, Batch 26810, Loss: 0.0153, Acc: 63.95%\n",
      "Epoch 2/3, Batch 26820, Loss: 0.3988, Acc: 63.95%\n",
      "Epoch 2/3, Batch 26830, Loss: 0.1124, Acc: 63.95%\n",
      "Epoch 2/3, Batch 26840, Loss: 0.2020, Acc: 63.95%\n",
      "Epoch 2/3, Batch 26850, Loss: 0.1848, Acc: 63.96%\n",
      "Epoch 2/3, Batch 26860, Loss: 1.3463, Acc: 63.96%\n",
      "Epoch 2/3, Batch 26870, Loss: 0.0313, Acc: 63.98%\n",
      "Epoch 2/3, Batch 26880, Loss: 0.2260, Acc: 63.97%\n",
      "Epoch 2/3, Batch 26890, Loss: 1.3280, Acc: 63.98%\n",
      "Epoch 2/3, Batch 26900, Loss: 0.4796, Acc: 63.98%\n",
      "Epoch 2/3, Batch 26910, Loss: 0.1375, Acc: 63.98%\n",
      "Epoch 2/3, Batch 26920, Loss: 0.3500, Acc: 63.99%\n",
      "Epoch 2/3, Batch 26930, Loss: 0.3608, Acc: 64.00%\n",
      "Epoch 2/3, Batch 26940, Loss: 1.2705, Acc: 64.00%\n",
      "Epoch 2/3, Batch 26950, Loss: 0.4078, Acc: 64.01%\n",
      "Epoch 2/3, Batch 26960, Loss: 0.3521, Acc: 64.00%\n",
      "Epoch 2/3, Batch 26970, Loss: 0.0499, Acc: 64.00%\n",
      "Epoch 2/3, Batch 26980, Loss: 0.4616, Acc: 64.00%\n",
      "Epoch 2/3, Batch 26990, Loss: 1.9379, Acc: 64.00%\n",
      "Epoch 2/3, Batch 27000, Loss: 0.0016, Acc: 64.01%\n",
      "Epoch 2/3, Batch 27010, Loss: 0.4371, Acc: 64.00%\n",
      "Epoch 2/3, Batch 27020, Loss: 0.0049, Acc: 64.01%\n",
      "Epoch 2/3, Batch 27030, Loss: 0.0323, Acc: 64.00%\n",
      "Epoch 2/3, Batch 27040, Loss: 0.3312, Acc: 64.01%\n",
      "Epoch 2/3, Batch 27050, Loss: 1.5308, Acc: 64.02%\n",
      "Epoch 2/3, Batch 27060, Loss: 0.6085, Acc: 64.03%\n",
      "Epoch 2/3, Batch 27070, Loss: 0.2397, Acc: 64.02%\n",
      "Epoch 2/3, Batch 27080, Loss: 1.1062, Acc: 64.02%\n",
      "Epoch 2/3, Batch 27090, Loss: 0.8691, Acc: 64.01%\n",
      "Epoch 2/3, Batch 27100, Loss: 1.0595, Acc: 64.01%\n",
      "Epoch 2/3, Batch 27110, Loss: 0.4788, Acc: 64.01%\n",
      "Epoch 2/3, Batch 27120, Loss: 0.5426, Acc: 64.01%\n",
      "Epoch 2/3, Batch 27130, Loss: 0.2216, Acc: 64.01%\n",
      "Epoch 2/3, Batch 27140, Loss: 0.5883, Acc: 64.01%\n",
      "Epoch 2/3, Batch 27150, Loss: 0.0194, Acc: 64.01%\n",
      "Epoch 2/3, Batch 27160, Loss: 0.9358, Acc: 64.01%\n",
      "Epoch 2/3, Batch 27170, Loss: 0.7165, Acc: 64.01%\n",
      "Epoch 2/3, Batch 27180, Loss: 0.0490, Acc: 64.01%\n",
      "Epoch 2/3, Batch 27190, Loss: 0.4477, Acc: 64.01%\n",
      "Epoch 2/3, Batch 27200, Loss: 0.0174, Acc: 64.00%\n",
      "Epoch 2/3, Batch 27210, Loss: 0.8368, Acc: 64.00%\n",
      "Epoch 2/3, Batch 27220, Loss: 1.1027, Acc: 63.99%\n",
      "Epoch 2/3, Batch 27230, Loss: 1.1302, Acc: 63.99%\n",
      "Epoch 2/3, Batch 27240, Loss: 0.2532, Acc: 63.99%\n",
      "Epoch 2/3, Batch 27250, Loss: 0.7532, Acc: 63.99%\n",
      "Epoch 2/3, Batch 27260, Loss: 0.2869, Acc: 64.00%\n",
      "Epoch 2/3, Batch 27270, Loss: 1.3634, Acc: 64.00%\n",
      "Epoch 2/3, Batch 27280, Loss: 0.9659, Acc: 64.00%\n",
      "Epoch 2/3, Batch 27290, Loss: 0.5482, Acc: 64.00%\n",
      "Epoch 2/3, Batch 27300, Loss: 0.0270, Acc: 64.01%\n",
      "Epoch 2/3, Batch 27310, Loss: 0.2168, Acc: 64.02%\n",
      "Epoch 2/3, Batch 27320, Loss: 0.2261, Acc: 64.02%\n",
      "Epoch 2/3, Batch 27330, Loss: 0.2355, Acc: 64.02%\n",
      "Epoch 2/3, Batch 27340, Loss: 1.6747, Acc: 64.01%\n",
      "Epoch 2/3, Batch 27350, Loss: 0.8018, Acc: 64.02%\n",
      "Epoch 2/3, Batch 27360, Loss: 0.3753, Acc: 64.03%\n",
      "Epoch 2/3, Batch 27370, Loss: 0.6183, Acc: 64.03%\n",
      "Epoch 2/3, Batch 27380, Loss: 1.0083, Acc: 64.03%\n",
      "Epoch 2/3, Batch 27390, Loss: 0.0843, Acc: 64.02%\n",
      "Epoch 2/3, Batch 27400, Loss: 0.9311, Acc: 64.02%\n",
      "Epoch 2/3, Batch 27410, Loss: 0.7246, Acc: 64.02%\n",
      "Epoch 2/3, Batch 27420, Loss: 0.2022, Acc: 64.02%\n",
      "Epoch 2/3, Batch 27430, Loss: 0.0023, Acc: 64.02%\n",
      "Epoch 2/3, Batch 27440, Loss: 0.0214, Acc: 64.02%\n",
      "Epoch 2/3, Batch 27450, Loss: 0.6204, Acc: 64.03%\n",
      "Epoch 2/3, Batch 27460, Loss: 0.5675, Acc: 64.04%\n",
      "Epoch 2/3, Batch 27470, Loss: 2.1660, Acc: 64.03%\n",
      "Epoch 2/3, Batch 27480, Loss: 0.5412, Acc: 64.04%\n",
      "Epoch 2/3, Batch 27490, Loss: 0.9670, Acc: 64.03%\n",
      "Epoch 2/3, Batch 27500, Loss: 1.1881, Acc: 64.04%\n",
      "Epoch 2/3, Batch 27510, Loss: 0.4420, Acc: 64.03%\n",
      "Epoch 2/3, Batch 27520, Loss: 0.4847, Acc: 64.02%\n",
      "Epoch 2/3, Batch 27530, Loss: 0.5233, Acc: 64.03%\n",
      "Epoch 2/3, Batch 27540, Loss: 0.2370, Acc: 64.02%\n",
      "Epoch 2/3, Batch 27550, Loss: 0.5612, Acc: 64.04%\n",
      "Epoch 2/3, Batch 27560, Loss: 0.0806, Acc: 64.05%\n",
      "Epoch 2/3, Batch 27570, Loss: 0.0983, Acc: 64.05%\n",
      "Epoch 2/3, Batch 27580, Loss: 0.9092, Acc: 64.05%\n",
      "Epoch 2/3, Batch 27590, Loss: 0.0702, Acc: 64.05%\n",
      "Epoch 2/3, Batch 27600, Loss: 1.7978, Acc: 64.05%\n",
      "Epoch 2/3, Average Loss: 0.6170, Accuracy: 64.05%\n",
      "Epoch 3/3, Batch 0, Loss: 0.1107, Acc: 100.00%\n",
      "Epoch 3/3, Batch 10, Loss: 1.1339, Acc: 72.73%\n",
      "Epoch 3/3, Batch 20, Loss: 0.7979, Acc: 57.14%\n",
      "Epoch 3/3, Batch 30, Loss: 0.0135, Acc: 54.84%\n",
      "Epoch 3/3, Batch 40, Loss: 0.0026, Acc: 60.98%\n",
      "Epoch 3/3, Batch 50, Loss: 0.3692, Acc: 68.63%\n",
      "Epoch 3/3, Batch 60, Loss: 0.3775, Acc: 72.13%\n",
      "Epoch 3/3, Batch 70, Loss: 0.0814, Acc: 71.83%\n",
      "Epoch 3/3, Batch 80, Loss: 0.1136, Acc: 69.14%\n",
      "Epoch 3/3, Batch 90, Loss: 0.8267, Acc: 65.93%\n",
      "Epoch 3/3, Batch 100, Loss: 1.2791, Acc: 66.34%\n",
      "Epoch 3/3, Batch 110, Loss: 0.6954, Acc: 64.86%\n",
      "Epoch 3/3, Batch 120, Loss: 0.0269, Acc: 66.12%\n",
      "Epoch 3/3, Batch 130, Loss: 0.9923, Acc: 65.65%\n",
      "Epoch 3/3, Batch 140, Loss: 0.3878, Acc: 66.67%\n",
      "Epoch 3/3, Batch 150, Loss: 0.4200, Acc: 66.89%\n",
      "Epoch 3/3, Batch 160, Loss: 0.7868, Acc: 65.22%\n",
      "Epoch 3/3, Batch 170, Loss: 0.3968, Acc: 63.74%\n",
      "Epoch 3/3, Batch 180, Loss: 0.6687, Acc: 62.98%\n",
      "Epoch 3/3, Batch 190, Loss: 0.4392, Acc: 63.35%\n",
      "Epoch 3/3, Batch 200, Loss: 1.7352, Acc: 64.18%\n",
      "Epoch 3/3, Batch 210, Loss: 0.5485, Acc: 63.51%\n",
      "Epoch 3/3, Batch 220, Loss: 0.0199, Acc: 63.80%\n",
      "Epoch 3/3, Batch 230, Loss: 0.2893, Acc: 64.50%\n",
      "Epoch 3/3, Batch 240, Loss: 0.3262, Acc: 63.49%\n",
      "Epoch 3/3, Batch 250, Loss: 0.0365, Acc: 63.35%\n",
      "Epoch 3/3, Batch 260, Loss: 0.7487, Acc: 61.69%\n",
      "Epoch 3/3, Batch 270, Loss: 0.7059, Acc: 61.99%\n",
      "Epoch 3/3, Batch 280, Loss: 0.6653, Acc: 62.28%\n",
      "Epoch 3/3, Batch 290, Loss: 1.1117, Acc: 62.54%\n",
      "Epoch 3/3, Batch 300, Loss: 0.0342, Acc: 61.79%\n",
      "Epoch 3/3, Batch 310, Loss: 0.2470, Acc: 61.74%\n",
      "Epoch 3/3, Batch 320, Loss: 0.9246, Acc: 61.37%\n",
      "Epoch 3/3, Batch 330, Loss: 0.0466, Acc: 61.63%\n",
      "Epoch 3/3, Batch 340, Loss: 0.4220, Acc: 61.29%\n",
      "Epoch 3/3, Batch 350, Loss: 0.2008, Acc: 61.54%\n",
      "Epoch 3/3, Batch 360, Loss: 0.1228, Acc: 62.05%\n",
      "Epoch 3/3, Batch 370, Loss: 0.0827, Acc: 62.53%\n",
      "Epoch 3/3, Batch 380, Loss: 2.4140, Acc: 62.73%\n",
      "Epoch 3/3, Batch 390, Loss: 0.6475, Acc: 63.17%\n",
      "Epoch 3/3, Batch 400, Loss: 0.0040, Acc: 63.34%\n",
      "Epoch 3/3, Batch 410, Loss: 0.0511, Acc: 62.77%\n",
      "Epoch 3/3, Batch 420, Loss: 0.0207, Acc: 62.71%\n",
      "Epoch 3/3, Batch 430, Loss: 0.5521, Acc: 62.65%\n",
      "Epoch 3/3, Batch 440, Loss: 0.9081, Acc: 62.59%\n",
      "Epoch 3/3, Batch 450, Loss: 0.5492, Acc: 62.75%\n",
      "Epoch 3/3, Batch 460, Loss: 0.1760, Acc: 62.69%\n",
      "Epoch 3/3, Batch 470, Loss: 1.0867, Acc: 62.85%\n",
      "Epoch 3/3, Batch 480, Loss: 0.0167, Acc: 62.58%\n",
      "Epoch 3/3, Batch 490, Loss: 0.5569, Acc: 62.93%\n",
      "Epoch 3/3, Batch 500, Loss: 2.1422, Acc: 62.48%\n",
      "Epoch 3/3, Batch 510, Loss: 0.4771, Acc: 62.43%\n",
      "Epoch 3/3, Batch 520, Loss: 0.6354, Acc: 62.76%\n",
      "Epoch 3/3, Batch 530, Loss: 0.7552, Acc: 62.52%\n",
      "Epoch 3/3, Batch 540, Loss: 0.0784, Acc: 62.48%\n",
      "Epoch 3/3, Batch 550, Loss: 0.0020, Acc: 62.79%\n",
      "Epoch 3/3, Batch 560, Loss: 0.0535, Acc: 62.92%\n",
      "Epoch 3/3, Batch 570, Loss: 0.5296, Acc: 62.52%\n",
      "Epoch 3/3, Batch 580, Loss: 1.2101, Acc: 62.31%\n",
      "Epoch 3/3, Batch 590, Loss: 0.5056, Acc: 62.77%\n",
      "Epoch 3/3, Batch 600, Loss: 0.0333, Acc: 63.06%\n",
      "Epoch 3/3, Batch 610, Loss: 0.0770, Acc: 63.01%\n",
      "Epoch 3/3, Batch 620, Loss: 0.8612, Acc: 62.80%\n",
      "Epoch 3/3, Batch 630, Loss: 0.0763, Acc: 62.92%\n",
      "Epoch 3/3, Batch 640, Loss: 0.2486, Acc: 62.87%\n",
      "Epoch 3/3, Batch 650, Loss: 0.0582, Acc: 62.67%\n",
      "Epoch 3/3, Batch 660, Loss: 0.4284, Acc: 62.63%\n",
      "Epoch 3/3, Batch 670, Loss: 1.7136, Acc: 62.59%\n",
      "Epoch 3/3, Batch 680, Loss: 0.7908, Acc: 62.70%\n",
      "Epoch 3/3, Batch 690, Loss: 0.0911, Acc: 62.52%\n",
      "Epoch 3/3, Batch 700, Loss: 0.6217, Acc: 62.77%\n",
      "Epoch 3/3, Batch 710, Loss: 0.3030, Acc: 62.73%\n",
      "Epoch 3/3, Batch 720, Loss: 0.4484, Acc: 62.97%\n",
      "Epoch 3/3, Batch 730, Loss: 0.0443, Acc: 63.20%\n",
      "Epoch 3/3, Batch 740, Loss: 2.1416, Acc: 63.43%\n",
      "Epoch 3/3, Batch 750, Loss: 0.0595, Acc: 63.38%\n",
      "Epoch 3/3, Batch 760, Loss: 0.3710, Acc: 63.21%\n",
      "Epoch 3/3, Batch 770, Loss: 1.0241, Acc: 63.29%\n",
      "Epoch 3/3, Batch 780, Loss: 0.9223, Acc: 63.38%\n",
      "Epoch 3/3, Batch 790, Loss: 0.3183, Acc: 63.21%\n",
      "Epoch 3/3, Batch 800, Loss: 0.8682, Acc: 63.17%\n",
      "Epoch 3/3, Batch 810, Loss: 0.4203, Acc: 63.13%\n",
      "Epoch 3/3, Batch 820, Loss: 0.0028, Acc: 63.09%\n",
      "Epoch 3/3, Batch 830, Loss: 0.5383, Acc: 63.30%\n",
      "Epoch 3/3, Batch 840, Loss: 0.6313, Acc: 63.50%\n",
      "Epoch 3/3, Batch 850, Loss: 0.5139, Acc: 63.45%\n",
      "Epoch 3/3, Batch 860, Loss: 1.3422, Acc: 63.53%\n",
      "Epoch 3/3, Batch 870, Loss: 1.5508, Acc: 63.49%\n",
      "Epoch 3/3, Batch 880, Loss: 0.7430, Acc: 63.34%\n",
      "Epoch 3/3, Batch 890, Loss: 0.4215, Acc: 63.41%\n",
      "Epoch 3/3, Batch 900, Loss: 0.9799, Acc: 63.37%\n",
      "Epoch 3/3, Batch 910, Loss: 1.8702, Acc: 63.45%\n",
      "Epoch 3/3, Batch 920, Loss: 0.9139, Acc: 63.52%\n",
      "Epoch 3/3, Batch 930, Loss: 0.3356, Acc: 63.48%\n",
      "Epoch 3/3, Batch 940, Loss: 0.0005, Acc: 63.34%\n",
      "Epoch 3/3, Batch 950, Loss: 1.8696, Acc: 63.30%\n",
      "Epoch 3/3, Batch 960, Loss: 0.5685, Acc: 63.16%\n",
      "Epoch 3/3, Batch 970, Loss: 0.8211, Acc: 63.03%\n",
      "Epoch 3/3, Batch 980, Loss: 0.0029, Acc: 62.90%\n",
      "Epoch 3/3, Batch 990, Loss: 0.2927, Acc: 62.97%\n",
      "Epoch 3/3, Batch 1000, Loss: 1.0120, Acc: 62.74%\n",
      "Epoch 3/3, Batch 1010, Loss: 0.0600, Acc: 62.51%\n",
      "Epoch 3/3, Batch 1020, Loss: 0.5735, Acc: 62.78%\n",
      "Epoch 3/3, Batch 1030, Loss: 0.0713, Acc: 62.75%\n",
      "Epoch 3/3, Batch 1040, Loss: 0.0467, Acc: 62.73%\n",
      "Epoch 3/3, Batch 1050, Loss: 0.6300, Acc: 62.70%\n",
      "Epoch 3/3, Batch 1060, Loss: 0.3969, Acc: 62.87%\n",
      "Epoch 3/3, Batch 1070, Loss: 0.5218, Acc: 63.03%\n",
      "Epoch 3/3, Batch 1080, Loss: 0.8785, Acc: 63.00%\n",
      "Epoch 3/3, Batch 1090, Loss: 0.4007, Acc: 62.97%\n",
      "Epoch 3/3, Batch 1100, Loss: 0.8655, Acc: 62.85%\n",
      "Epoch 3/3, Batch 1110, Loss: 0.1962, Acc: 63.01%\n",
      "Epoch 3/3, Batch 1120, Loss: 0.3611, Acc: 63.07%\n",
      "Epoch 3/3, Batch 1130, Loss: 2.6622, Acc: 63.13%\n",
      "Epoch 3/3, Batch 1140, Loss: 1.0885, Acc: 63.10%\n",
      "Epoch 3/3, Batch 1150, Loss: 0.1683, Acc: 63.25%\n",
      "Epoch 3/3, Batch 1160, Loss: 0.1198, Acc: 63.31%\n",
      "Epoch 3/3, Batch 1170, Loss: 0.9560, Acc: 63.28%\n",
      "Epoch 3/3, Batch 1180, Loss: 0.8999, Acc: 63.25%\n",
      "Epoch 3/3, Batch 1190, Loss: 1.5616, Acc: 63.14%\n",
      "Epoch 3/3, Batch 1200, Loss: 0.1219, Acc: 63.03%\n",
      "Epoch 3/3, Batch 1210, Loss: 0.9160, Acc: 62.92%\n",
      "Epoch 3/3, Batch 1220, Loss: 0.5953, Acc: 62.74%\n",
      "Epoch 3/3, Batch 1230, Loss: 0.1682, Acc: 62.88%\n",
      "Epoch 3/3, Batch 1240, Loss: 0.9499, Acc: 62.85%\n",
      "Epoch 3/3, Batch 1250, Loss: 0.0235, Acc: 62.83%\n",
      "Epoch 3/3, Batch 1260, Loss: 0.1114, Acc: 62.81%\n",
      "Epoch 3/3, Batch 1270, Loss: 1.0460, Acc: 62.86%\n",
      "Epoch 3/3, Batch 1280, Loss: 0.4138, Acc: 63.00%\n",
      "Epoch 3/3, Batch 1290, Loss: 0.0288, Acc: 63.05%\n",
      "Epoch 3/3, Batch 1300, Loss: 1.0531, Acc: 62.95%\n",
      "Epoch 3/3, Batch 1310, Loss: 0.1740, Acc: 63.16%\n",
      "Epoch 3/3, Batch 1320, Loss: 0.0054, Acc: 63.06%\n",
      "Epoch 3/3, Batch 1330, Loss: 0.2279, Acc: 63.11%\n",
      "Epoch 3/3, Batch 1340, Loss: 0.3181, Acc: 63.31%\n",
      "Epoch 3/3, Batch 1350, Loss: 0.0440, Acc: 63.43%\n",
      "Epoch 3/3, Batch 1360, Loss: 0.8766, Acc: 63.41%\n",
      "Epoch 3/3, Batch 1370, Loss: 0.4963, Acc: 63.60%\n",
      "Epoch 3/3, Batch 1380, Loss: 0.3593, Acc: 63.43%\n",
      "Epoch 3/3, Batch 1390, Loss: 0.2233, Acc: 63.48%\n",
      "Epoch 3/3, Batch 1400, Loss: 0.8763, Acc: 63.53%\n",
      "Epoch 3/3, Batch 1410, Loss: 2.6585, Acc: 63.43%\n",
      "Epoch 3/3, Batch 1420, Loss: 0.1475, Acc: 63.41%\n",
      "Epoch 3/3, Batch 1430, Loss: 0.1763, Acc: 63.52%\n",
      "Epoch 3/3, Batch 1440, Loss: 0.3732, Acc: 63.57%\n",
      "Epoch 3/3, Batch 1450, Loss: 1.1282, Acc: 63.61%\n",
      "Epoch 3/3, Batch 1460, Loss: 0.7326, Acc: 63.45%\n",
      "Epoch 3/3, Batch 1470, Loss: 0.0168, Acc: 63.56%\n",
      "Epoch 3/3, Batch 1480, Loss: 0.1673, Acc: 63.54%\n",
      "Epoch 3/3, Batch 1490, Loss: 0.3058, Acc: 63.51%\n",
      "Epoch 3/3, Batch 1500, Loss: 1.7168, Acc: 63.42%\n",
      "Epoch 3/3, Batch 1510, Loss: 0.5072, Acc: 63.53%\n",
      "Epoch 3/3, Batch 1520, Loss: 0.8032, Acc: 63.45%\n",
      "Epoch 3/3, Batch 1530, Loss: 0.0006, Acc: 63.55%\n",
      "Epoch 3/3, Batch 1540, Loss: 0.3803, Acc: 63.66%\n",
      "Epoch 3/3, Batch 1550, Loss: 0.5548, Acc: 63.70%\n",
      "Epoch 3/3, Batch 1560, Loss: 1.8421, Acc: 63.68%\n",
      "Epoch 3/3, Batch 1570, Loss: 0.4985, Acc: 63.65%\n",
      "Epoch 3/3, Batch 1580, Loss: 1.0181, Acc: 63.44%\n",
      "Epoch 3/3, Batch 1590, Loss: 1.2183, Acc: 63.54%\n",
      "Epoch 3/3, Batch 1600, Loss: 0.6104, Acc: 63.40%\n",
      "Epoch 3/3, Batch 1610, Loss: 0.2800, Acc: 63.50%\n",
      "Epoch 3/3, Batch 1620, Loss: 0.6854, Acc: 63.60%\n",
      "Epoch 3/3, Batch 1630, Loss: 0.5657, Acc: 63.58%\n",
      "Epoch 3/3, Batch 1640, Loss: 1.3198, Acc: 63.56%\n",
      "Epoch 3/3, Batch 1650, Loss: 0.8686, Acc: 63.60%\n",
      "Epoch 3/3, Batch 1660, Loss: 0.4906, Acc: 63.58%\n",
      "Epoch 3/3, Batch 1670, Loss: 0.6248, Acc: 63.55%\n",
      "Epoch 3/3, Batch 1680, Loss: 1.5161, Acc: 63.36%\n",
      "Epoch 3/3, Batch 1690, Loss: 0.3111, Acc: 63.28%\n",
      "Epoch 3/3, Batch 1700, Loss: 1.6672, Acc: 63.20%\n",
      "Epoch 3/3, Batch 1710, Loss: 0.6121, Acc: 63.12%\n",
      "Epoch 3/3, Batch 1720, Loss: 0.7317, Acc: 62.99%\n",
      "Epoch 3/3, Batch 1730, Loss: 0.3899, Acc: 63.03%\n",
      "Epoch 3/3, Batch 1740, Loss: 0.7756, Acc: 63.12%\n",
      "Epoch 3/3, Batch 1750, Loss: 0.0070, Acc: 62.99%\n",
      "Epoch 3/3, Batch 1760, Loss: 1.2683, Acc: 62.92%\n",
      "Epoch 3/3, Batch 1770, Loss: 0.2528, Acc: 62.90%\n",
      "Epoch 3/3, Batch 1780, Loss: 0.8817, Acc: 63.00%\n",
      "Epoch 3/3, Batch 1790, Loss: 0.0141, Acc: 63.09%\n",
      "Epoch 3/3, Batch 1800, Loss: 0.1811, Acc: 63.13%\n",
      "Epoch 3/3, Batch 1810, Loss: 0.0243, Acc: 63.22%\n",
      "Epoch 3/3, Batch 1820, Loss: 0.6781, Acc: 63.32%\n",
      "Epoch 3/3, Batch 1830, Loss: 0.1061, Acc: 63.24%\n",
      "Epoch 3/3, Batch 1840, Loss: 0.0369, Acc: 63.39%\n",
      "Epoch 3/3, Batch 1850, Loss: 0.5333, Acc: 63.43%\n",
      "Epoch 3/3, Batch 1860, Loss: 0.8422, Acc: 63.46%\n",
      "Epoch 3/3, Batch 1870, Loss: 0.0550, Acc: 63.44%\n",
      "Epoch 3/3, Batch 1880, Loss: 0.8989, Acc: 63.48%\n",
      "Epoch 3/3, Batch 1890, Loss: 0.0073, Acc: 63.41%\n",
      "Epoch 3/3, Batch 1900, Loss: 0.5120, Acc: 63.49%\n",
      "Epoch 3/3, Batch 1910, Loss: 0.7953, Acc: 63.53%\n",
      "Epoch 3/3, Batch 1920, Loss: 2.1159, Acc: 63.51%\n",
      "Epoch 3/3, Batch 1930, Loss: 0.3023, Acc: 63.59%\n",
      "Epoch 3/3, Batch 1940, Loss: 0.3804, Acc: 63.52%\n",
      "Epoch 3/3, Batch 1950, Loss: 2.6805, Acc: 63.56%\n",
      "Epoch 3/3, Batch 1960, Loss: 0.5745, Acc: 63.59%\n",
      "Epoch 3/3, Batch 1970, Loss: 0.3420, Acc: 63.72%\n",
      "Epoch 3/3, Batch 1980, Loss: 0.4542, Acc: 63.76%\n",
      "Epoch 3/3, Batch 1990, Loss: 1.0783, Acc: 63.69%\n",
      "Epoch 3/3, Batch 2000, Loss: 0.1639, Acc: 63.62%\n",
      "Epoch 3/3, Batch 2010, Loss: 0.0921, Acc: 63.65%\n",
      "Epoch 3/3, Batch 2020, Loss: 0.6535, Acc: 63.73%\n",
      "Epoch 3/3, Batch 2030, Loss: 0.5892, Acc: 63.86%\n",
      "Epoch 3/3, Batch 2040, Loss: 0.0576, Acc: 63.94%\n",
      "Epoch 3/3, Batch 2050, Loss: 0.0131, Acc: 63.92%\n",
      "Epoch 3/3, Batch 2060, Loss: 0.6035, Acc: 64.05%\n",
      "Epoch 3/3, Batch 2070, Loss: 0.3640, Acc: 64.08%\n",
      "Epoch 3/3, Batch 2080, Loss: 0.6956, Acc: 64.06%\n",
      "Epoch 3/3, Batch 2090, Loss: 0.0161, Acc: 64.04%\n",
      "Epoch 3/3, Batch 2100, Loss: 0.1042, Acc: 64.21%\n",
      "Epoch 3/3, Batch 2110, Loss: 1.1943, Acc: 64.23%\n",
      "Epoch 3/3, Batch 2120, Loss: 0.3605, Acc: 64.31%\n",
      "Epoch 3/3, Batch 2130, Loss: 0.4104, Acc: 64.43%\n",
      "Epoch 3/3, Batch 2140, Loss: 0.0856, Acc: 64.50%\n",
      "Epoch 3/3, Batch 2150, Loss: 0.3019, Acc: 64.57%\n",
      "Epoch 3/3, Batch 2160, Loss: 0.5042, Acc: 64.60%\n",
      "Epoch 3/3, Batch 2170, Loss: 0.0022, Acc: 64.67%\n",
      "Epoch 3/3, Batch 2180, Loss: 0.6326, Acc: 64.70%\n",
      "Epoch 3/3, Batch 2190, Loss: 1.4131, Acc: 64.72%\n",
      "Epoch 3/3, Batch 2200, Loss: 0.1902, Acc: 64.70%\n",
      "Epoch 3/3, Batch 2210, Loss: 1.1101, Acc: 64.68%\n",
      "Epoch 3/3, Batch 2220, Loss: 0.5631, Acc: 64.70%\n",
      "Epoch 3/3, Batch 2230, Loss: 1.1791, Acc: 64.77%\n",
      "Epoch 3/3, Batch 2240, Loss: 0.5305, Acc: 64.84%\n",
      "Epoch 3/3, Batch 2250, Loss: 1.1352, Acc: 64.77%\n",
      "Epoch 3/3, Batch 2260, Loss: 0.2445, Acc: 64.84%\n",
      "Epoch 3/3, Batch 2270, Loss: 0.0696, Acc: 64.86%\n",
      "Epoch 3/3, Batch 2280, Loss: 0.0300, Acc: 64.71%\n",
      "Epoch 3/3, Batch 2290, Loss: 0.8123, Acc: 64.69%\n",
      "Epoch 3/3, Batch 2300, Loss: 0.8296, Acc: 64.62%\n",
      "Epoch 3/3, Batch 2310, Loss: 0.6875, Acc: 64.65%\n",
      "Epoch 3/3, Batch 2320, Loss: 0.0395, Acc: 64.67%\n",
      "Epoch 3/3, Batch 2330, Loss: 0.2521, Acc: 64.78%\n",
      "Epoch 3/3, Batch 2340, Loss: 0.3456, Acc: 64.72%\n",
      "Epoch 3/3, Batch 2350, Loss: 0.3177, Acc: 64.74%\n",
      "Epoch 3/3, Batch 2360, Loss: 0.1520, Acc: 64.72%\n",
      "Epoch 3/3, Batch 2370, Loss: 0.0416, Acc: 64.78%\n",
      "Epoch 3/3, Batch 2380, Loss: 0.5243, Acc: 64.72%\n",
      "Epoch 3/3, Batch 2390, Loss: 1.2862, Acc: 64.74%\n",
      "Epoch 3/3, Batch 2400, Loss: 0.1826, Acc: 64.81%\n",
      "Epoch 3/3, Batch 2410, Loss: 0.5239, Acc: 64.83%\n",
      "Epoch 3/3, Batch 2420, Loss: 0.8353, Acc: 64.81%\n",
      "Epoch 3/3, Batch 2430, Loss: 0.1649, Acc: 64.79%\n",
      "Epoch 3/3, Batch 2440, Loss: 1.6000, Acc: 64.73%\n",
      "Epoch 3/3, Batch 2450, Loss: 0.0379, Acc: 64.75%\n",
      "Epoch 3/3, Batch 2460, Loss: 0.4418, Acc: 64.77%\n",
      "Epoch 3/3, Batch 2470, Loss: 0.0021, Acc: 64.83%\n",
      "Epoch 3/3, Batch 2480, Loss: 0.0166, Acc: 64.85%\n",
      "Epoch 3/3, Batch 2490, Loss: 0.9180, Acc: 64.79%\n",
      "Epoch 3/3, Batch 2500, Loss: 1.3179, Acc: 64.77%\n",
      "Epoch 3/3, Batch 2510, Loss: 0.0154, Acc: 64.76%\n",
      "Epoch 3/3, Batch 2520, Loss: 0.0086, Acc: 64.82%\n",
      "Epoch 3/3, Batch 2530, Loss: 0.4230, Acc: 64.76%\n",
      "Epoch 3/3, Batch 2540, Loss: 0.0221, Acc: 64.78%\n",
      "Epoch 3/3, Batch 2550, Loss: 0.3622, Acc: 64.76%\n",
      "Epoch 3/3, Batch 2560, Loss: 0.6723, Acc: 64.78%\n",
      "Epoch 3/3, Batch 2570, Loss: 0.0404, Acc: 64.84%\n",
      "Epoch 3/3, Batch 2580, Loss: 0.8246, Acc: 64.86%\n",
      "Epoch 3/3, Batch 2590, Loss: 0.1014, Acc: 64.92%\n",
      "Epoch 3/3, Batch 2600, Loss: 0.0783, Acc: 65.01%\n",
      "Epoch 3/3, Batch 2610, Loss: 0.8395, Acc: 64.88%\n",
      "Epoch 3/3, Batch 2620, Loss: 0.0057, Acc: 64.86%\n",
      "Epoch 3/3, Batch 2630, Loss: 0.8443, Acc: 64.84%\n",
      "Epoch 3/3, Batch 2640, Loss: 0.9539, Acc: 64.86%\n",
      "Epoch 3/3, Batch 2650, Loss: 0.0777, Acc: 64.81%\n",
      "Epoch 3/3, Batch 2660, Loss: 1.0091, Acc: 64.86%\n",
      "Epoch 3/3, Batch 2670, Loss: 0.6177, Acc: 64.96%\n",
      "Epoch 3/3, Batch 2680, Loss: 2.1699, Acc: 64.86%\n",
      "Epoch 3/3, Batch 2690, Loss: 1.5649, Acc: 64.85%\n",
      "Epoch 3/3, Batch 2700, Loss: 0.3127, Acc: 64.98%\n",
      "Epoch 3/3, Batch 2710, Loss: 0.9613, Acc: 64.92%\n",
      "Epoch 3/3, Batch 2720, Loss: 0.1135, Acc: 64.94%\n",
      "Epoch 3/3, Batch 2730, Loss: 0.0564, Acc: 64.96%\n",
      "Epoch 3/3, Batch 2740, Loss: 0.6605, Acc: 64.90%\n",
      "Epoch 3/3, Batch 2750, Loss: 0.9872, Acc: 64.96%\n",
      "Epoch 3/3, Batch 2760, Loss: 0.5771, Acc: 64.94%\n",
      "Epoch 3/3, Batch 2770, Loss: 1.0668, Acc: 64.89%\n",
      "Epoch 3/3, Batch 2780, Loss: 0.0856, Acc: 64.87%\n",
      "Epoch 3/3, Batch 2790, Loss: 0.3341, Acc: 64.89%\n",
      "Epoch 3/3, Batch 2800, Loss: 1.2051, Acc: 64.87%\n",
      "Epoch 3/3, Batch 2810, Loss: 1.6190, Acc: 64.89%\n",
      "Epoch 3/3, Batch 2820, Loss: 0.0301, Acc: 64.80%\n",
      "Epoch 3/3, Batch 2830, Loss: 0.0677, Acc: 64.78%\n",
      "Epoch 3/3, Batch 2840, Loss: 0.0693, Acc: 64.77%\n",
      "Epoch 3/3, Batch 2850, Loss: 0.5816, Acc: 64.78%\n",
      "Epoch 3/3, Batch 2860, Loss: 0.4177, Acc: 64.84%\n",
      "Epoch 3/3, Batch 2870, Loss: 0.4752, Acc: 64.82%\n",
      "Epoch 3/3, Batch 2880, Loss: 0.3918, Acc: 64.87%\n",
      "Epoch 3/3, Batch 2890, Loss: 0.0343, Acc: 64.89%\n",
      "Epoch 3/3, Batch 2900, Loss: 1.9663, Acc: 64.91%\n",
      "Epoch 3/3, Batch 2910, Loss: 0.4452, Acc: 64.86%\n",
      "Epoch 3/3, Batch 2920, Loss: 1.8301, Acc: 64.81%\n",
      "Epoch 3/3, Batch 2930, Loss: 0.5197, Acc: 64.79%\n",
      "Epoch 3/3, Batch 2940, Loss: 0.9884, Acc: 64.77%\n",
      "Epoch 3/3, Batch 2950, Loss: 0.3921, Acc: 64.83%\n",
      "Epoch 3/3, Batch 2960, Loss: 0.0005, Acc: 64.78%\n",
      "Epoch 3/3, Batch 2970, Loss: 0.4501, Acc: 64.86%\n",
      "Epoch 3/3, Batch 2980, Loss: 0.2297, Acc: 64.94%\n",
      "Epoch 3/3, Batch 2990, Loss: 0.1512, Acc: 64.99%\n",
      "Epoch 3/3, Batch 3000, Loss: 0.3922, Acc: 65.01%\n",
      "Epoch 3/3, Batch 3010, Loss: 0.3211, Acc: 65.00%\n",
      "Epoch 3/3, Batch 3020, Loss: 0.0233, Acc: 64.98%\n",
      "Epoch 3/3, Batch 3030, Loss: 0.0222, Acc: 65.03%\n",
      "Epoch 3/3, Batch 3040, Loss: 0.1256, Acc: 65.04%\n",
      "Epoch 3/3, Batch 3050, Loss: 0.3283, Acc: 65.13%\n",
      "Epoch 3/3, Batch 3060, Loss: 0.0264, Acc: 65.14%\n",
      "Epoch 3/3, Batch 3070, Loss: 0.6338, Acc: 65.16%\n",
      "Epoch 3/3, Batch 3080, Loss: 0.9540, Acc: 65.21%\n",
      "Epoch 3/3, Batch 3090, Loss: 0.0455, Acc: 65.19%\n",
      "Epoch 3/3, Batch 3100, Loss: 0.0522, Acc: 65.08%\n",
      "Epoch 3/3, Batch 3110, Loss: 0.0004, Acc: 65.03%\n",
      "Epoch 3/3, Batch 3120, Loss: 1.3252, Acc: 65.04%\n",
      "Epoch 3/3, Batch 3130, Loss: 0.7780, Acc: 65.03%\n",
      "Epoch 3/3, Batch 3140, Loss: 0.1315, Acc: 65.01%\n",
      "Epoch 3/3, Batch 3150, Loss: 0.1020, Acc: 65.03%\n",
      "Epoch 3/3, Batch 3160, Loss: 0.1189, Acc: 65.04%\n",
      "Epoch 3/3, Batch 3170, Loss: 0.0570, Acc: 65.03%\n",
      "Epoch 3/3, Batch 3180, Loss: 1.8972, Acc: 64.98%\n",
      "Epoch 3/3, Batch 3190, Loss: 0.0470, Acc: 64.93%\n",
      "Epoch 3/3, Batch 3200, Loss: 0.2029, Acc: 64.95%\n",
      "Epoch 3/3, Batch 3210, Loss: 0.1030, Acc: 64.96%\n",
      "Epoch 3/3, Batch 3220, Loss: 0.0722, Acc: 65.01%\n",
      "Epoch 3/3, Batch 3230, Loss: 0.9119, Acc: 65.03%\n",
      "Epoch 3/3, Batch 3240, Loss: 0.5789, Acc: 65.04%\n",
      "Epoch 3/3, Batch 3250, Loss: 0.5459, Acc: 65.09%\n",
      "Epoch 3/3, Batch 3260, Loss: 0.6956, Acc: 65.13%\n",
      "Epoch 3/3, Batch 3270, Loss: 0.0002, Acc: 65.18%\n",
      "Epoch 3/3, Batch 3280, Loss: 1.2159, Acc: 65.10%\n",
      "Epoch 3/3, Batch 3290, Loss: 0.1270, Acc: 65.12%\n",
      "Epoch 3/3, Batch 3300, Loss: 0.0006, Acc: 65.13%\n",
      "Epoch 3/3, Batch 3310, Loss: 0.7382, Acc: 65.06%\n",
      "Epoch 3/3, Batch 3320, Loss: 0.7219, Acc: 65.01%\n",
      "Epoch 3/3, Batch 3330, Loss: 1.0326, Acc: 64.91%\n",
      "Epoch 3/3, Batch 3340, Loss: 0.2466, Acc: 64.83%\n",
      "Epoch 3/3, Batch 3350, Loss: 0.4024, Acc: 64.88%\n",
      "Epoch 3/3, Batch 3360, Loss: 1.4415, Acc: 64.77%\n",
      "Epoch 3/3, Batch 3370, Loss: 0.0050, Acc: 64.76%\n",
      "Epoch 3/3, Batch 3380, Loss: 1.2531, Acc: 64.77%\n",
      "Epoch 3/3, Batch 3390, Loss: 0.0027, Acc: 64.82%\n",
      "Epoch 3/3, Batch 3400, Loss: 1.1430, Acc: 64.72%\n",
      "Epoch 3/3, Batch 3410, Loss: 0.7802, Acc: 64.70%\n",
      "Epoch 3/3, Batch 3420, Loss: 1.0035, Acc: 64.60%\n",
      "Epoch 3/3, Batch 3430, Loss: 0.4413, Acc: 64.62%\n",
      "Epoch 3/3, Batch 3440, Loss: 0.5616, Acc: 64.57%\n",
      "Epoch 3/3, Batch 3450, Loss: 0.0203, Acc: 64.68%\n",
      "Epoch 3/3, Batch 3460, Loss: 0.0368, Acc: 64.75%\n",
      "Epoch 3/3, Batch 3470, Loss: 0.8042, Acc: 64.79%\n",
      "Epoch 3/3, Batch 3480, Loss: 2.2131, Acc: 64.78%\n",
      "Epoch 3/3, Batch 3490, Loss: 0.0140, Acc: 64.80%\n",
      "Epoch 3/3, Batch 3500, Loss: 0.9133, Acc: 64.78%\n",
      "Epoch 3/3, Batch 3510, Loss: 0.0865, Acc: 64.77%\n",
      "Epoch 3/3, Batch 3520, Loss: 0.2314, Acc: 64.70%\n",
      "Epoch 3/3, Batch 3530, Loss: 0.5226, Acc: 64.68%\n",
      "Epoch 3/3, Batch 3540, Loss: 0.2738, Acc: 64.61%\n",
      "Epoch 3/3, Batch 3550, Loss: 1.2239, Acc: 64.60%\n",
      "Epoch 3/3, Batch 3560, Loss: 0.2908, Acc: 64.67%\n",
      "Epoch 3/3, Batch 3570, Loss: 0.0293, Acc: 64.69%\n",
      "Epoch 3/3, Batch 3580, Loss: 0.0189, Acc: 64.76%\n",
      "Epoch 3/3, Batch 3590, Loss: 0.4985, Acc: 64.77%\n",
      "Epoch 3/3, Batch 3600, Loss: 0.3604, Acc: 64.73%\n",
      "Epoch 3/3, Batch 3610, Loss: 0.8888, Acc: 64.69%\n",
      "Epoch 3/3, Batch 3620, Loss: 0.0514, Acc: 64.76%\n",
      "Epoch 3/3, Batch 3630, Loss: 0.2393, Acc: 64.80%\n",
      "Epoch 3/3, Batch 3640, Loss: 0.3086, Acc: 64.79%\n",
      "Epoch 3/3, Batch 3650, Loss: 0.9973, Acc: 64.78%\n",
      "Epoch 3/3, Batch 3660, Loss: 0.2693, Acc: 64.79%\n",
      "Epoch 3/3, Batch 3670, Loss: 0.1251, Acc: 64.75%\n",
      "Epoch 3/3, Batch 3680, Loss: 0.0036, Acc: 64.71%\n",
      "Epoch 3/3, Batch 3690, Loss: 0.1619, Acc: 64.70%\n",
      "Epoch 3/3, Batch 3700, Loss: 0.5338, Acc: 64.71%\n",
      "Epoch 3/3, Batch 3710, Loss: 0.4631, Acc: 64.75%\n",
      "Epoch 3/3, Batch 3720, Loss: 0.2970, Acc: 64.71%\n",
      "Epoch 3/3, Batch 3730, Loss: 1.2266, Acc: 64.67%\n",
      "Epoch 3/3, Batch 3740, Loss: 0.2430, Acc: 64.74%\n",
      "Epoch 3/3, Batch 3750, Loss: 1.5642, Acc: 64.73%\n",
      "Epoch 3/3, Batch 3760, Loss: 0.9404, Acc: 64.80%\n",
      "Epoch 3/3, Batch 3770, Loss: 1.0465, Acc: 64.78%\n",
      "Epoch 3/3, Batch 3780, Loss: 0.7480, Acc: 64.82%\n",
      "Epoch 3/3, Batch 3790, Loss: 0.7012, Acc: 64.84%\n",
      "Epoch 3/3, Batch 3800, Loss: 0.0000, Acc: 64.85%\n",
      "Epoch 3/3, Batch 3810, Loss: 1.5700, Acc: 64.76%\n",
      "Epoch 3/3, Batch 3820, Loss: 1.1421, Acc: 64.72%\n",
      "Epoch 3/3, Batch 3830, Loss: 0.0050, Acc: 64.79%\n",
      "Epoch 3/3, Batch 3840, Loss: 1.1263, Acc: 64.70%\n",
      "Epoch 3/3, Batch 3850, Loss: 0.7214, Acc: 64.74%\n",
      "Epoch 3/3, Batch 3860, Loss: 0.3826, Acc: 64.70%\n",
      "Epoch 3/3, Batch 3870, Loss: 0.0010, Acc: 64.74%\n",
      "Epoch 3/3, Batch 3880, Loss: 0.3796, Acc: 64.78%\n",
      "Epoch 3/3, Batch 3890, Loss: 1.5372, Acc: 64.74%\n",
      "Epoch 3/3, Batch 3900, Loss: 0.0003, Acc: 64.70%\n",
      "Epoch 3/3, Batch 3910, Loss: 0.4956, Acc: 64.71%\n",
      "Epoch 3/3, Batch 3920, Loss: 1.2383, Acc: 64.68%\n",
      "Epoch 3/3, Batch 3930, Loss: 0.9679, Acc: 64.74%\n",
      "Epoch 3/3, Batch 3940, Loss: 0.6190, Acc: 64.78%\n",
      "Epoch 3/3, Batch 3950, Loss: 0.7519, Acc: 64.79%\n",
      "Epoch 3/3, Batch 3960, Loss: 0.0322, Acc: 64.86%\n",
      "Epoch 3/3, Batch 3970, Loss: 1.1434, Acc: 64.82%\n",
      "Epoch 3/3, Batch 3980, Loss: 1.1056, Acc: 64.83%\n",
      "Epoch 3/3, Batch 3990, Loss: 0.2091, Acc: 64.80%\n",
      "Epoch 3/3, Batch 4000, Loss: 0.0142, Acc: 64.81%\n",
      "Epoch 3/3, Batch 4010, Loss: 0.5476, Acc: 64.82%\n",
      "Epoch 3/3, Batch 4020, Loss: 0.2559, Acc: 64.76%\n",
      "Epoch 3/3, Batch 4030, Loss: 0.2063, Acc: 64.80%\n",
      "Epoch 3/3, Batch 4040, Loss: 0.0426, Acc: 64.84%\n",
      "Epoch 3/3, Batch 4050, Loss: 1.3069, Acc: 64.85%\n",
      "Epoch 3/3, Batch 4060, Loss: 0.2748, Acc: 64.86%\n",
      "Epoch 3/3, Batch 4070, Loss: 0.5957, Acc: 64.87%\n",
      "Epoch 3/3, Batch 4080, Loss: 1.1569, Acc: 64.84%\n",
      "Epoch 3/3, Batch 4090, Loss: 1.6910, Acc: 64.83%\n",
      "Epoch 3/3, Batch 4100, Loss: 0.2676, Acc: 64.84%\n",
      "Epoch 3/3, Batch 4110, Loss: 2.2240, Acc: 64.80%\n",
      "Epoch 3/3, Batch 4120, Loss: 1.0864, Acc: 64.77%\n",
      "Epoch 3/3, Batch 4130, Loss: 1.0403, Acc: 64.75%\n",
      "Epoch 3/3, Batch 4140, Loss: 1.5099, Acc: 64.77%\n",
      "Epoch 3/3, Batch 4150, Loss: 0.2073, Acc: 64.80%\n",
      "Epoch 3/3, Batch 4160, Loss: 0.3961, Acc: 64.82%\n",
      "Epoch 3/3, Batch 4170, Loss: 1.2562, Acc: 64.83%\n",
      "Epoch 3/3, Batch 4180, Loss: 0.9461, Acc: 64.79%\n",
      "Epoch 3/3, Batch 4190, Loss: 0.8887, Acc: 64.85%\n",
      "Epoch 3/3, Batch 4200, Loss: 2.0124, Acc: 64.82%\n",
      "Epoch 3/3, Batch 4210, Loss: 0.8643, Acc: 64.81%\n",
      "Epoch 3/3, Batch 4220, Loss: 0.0738, Acc: 64.80%\n",
      "Epoch 3/3, Batch 4230, Loss: 0.9131, Acc: 64.78%\n",
      "Epoch 3/3, Batch 4240, Loss: 0.5810, Acc: 64.80%\n",
      "Epoch 3/3, Batch 4250, Loss: 0.6049, Acc: 64.86%\n",
      "Epoch 3/3, Batch 4260, Loss: 0.7173, Acc: 64.84%\n",
      "Epoch 3/3, Batch 4270, Loss: 0.4298, Acc: 64.90%\n",
      "Epoch 3/3, Batch 4280, Loss: 0.0927, Acc: 64.96%\n",
      "Epoch 3/3, Batch 4290, Loss: 2.6318, Acc: 64.93%\n",
      "Epoch 3/3, Batch 4300, Loss: 0.7493, Acc: 64.96%\n",
      "Epoch 3/3, Batch 4310, Loss: 1.0122, Acc: 64.90%\n",
      "Epoch 3/3, Batch 4320, Loss: 0.5436, Acc: 64.96%\n",
      "Epoch 3/3, Batch 4330, Loss: 0.9241, Acc: 65.00%\n",
      "Epoch 3/3, Batch 4340, Loss: 0.0205, Acc: 64.99%\n",
      "Epoch 3/3, Batch 4350, Loss: 0.1704, Acc: 65.00%\n",
      "Epoch 3/3, Batch 4360, Loss: 0.9009, Acc: 64.96%\n",
      "Epoch 3/3, Batch 4370, Loss: 0.8992, Acc: 64.93%\n",
      "Epoch 3/3, Batch 4380, Loss: 0.8537, Acc: 64.94%\n",
      "Epoch 3/3, Batch 4390, Loss: 2.9344, Acc: 64.95%\n",
      "Epoch 3/3, Batch 4400, Loss: 0.5832, Acc: 64.96%\n",
      "Epoch 3/3, Batch 4410, Loss: 0.8876, Acc: 64.97%\n",
      "Epoch 3/3, Batch 4420, Loss: 1.0162, Acc: 64.96%\n",
      "Epoch 3/3, Batch 4430, Loss: 0.7071, Acc: 64.93%\n",
      "Epoch 3/3, Batch 4440, Loss: 0.9234, Acc: 64.94%\n",
      "Epoch 3/3, Batch 4450, Loss: 0.1807, Acc: 64.86%\n",
      "Epoch 3/3, Batch 4460, Loss: 0.2288, Acc: 64.90%\n",
      "Epoch 3/3, Batch 4470, Loss: 0.9893, Acc: 64.91%\n",
      "Epoch 3/3, Batch 4480, Loss: 0.4184, Acc: 64.92%\n",
      "Epoch 3/3, Batch 4490, Loss: 0.0053, Acc: 64.95%\n",
      "Epoch 3/3, Batch 4500, Loss: 0.4562, Acc: 64.94%\n",
      "Epoch 3/3, Batch 4510, Loss: 0.9545, Acc: 64.95%\n",
      "Epoch 3/3, Batch 4520, Loss: 0.0193, Acc: 64.96%\n",
      "Epoch 3/3, Batch 4530, Loss: 0.3888, Acc: 65.00%\n",
      "Epoch 3/3, Batch 4540, Loss: 0.1448, Acc: 65.03%\n",
      "Epoch 3/3, Batch 4550, Loss: 1.8588, Acc: 65.00%\n",
      "Epoch 3/3, Batch 4560, Loss: 0.5465, Acc: 65.03%\n",
      "Epoch 3/3, Batch 4570, Loss: 0.5098, Acc: 65.04%\n",
      "Epoch 3/3, Batch 4580, Loss: 0.7138, Acc: 65.01%\n",
      "Epoch 3/3, Batch 4590, Loss: 0.8154, Acc: 65.00%\n",
      "Epoch 3/3, Batch 4600, Loss: 0.1591, Acc: 64.99%\n",
      "Epoch 3/3, Batch 4610, Loss: 0.6116, Acc: 65.06%\n",
      "Epoch 3/3, Batch 4620, Loss: 0.7352, Acc: 64.96%\n",
      "Epoch 3/3, Batch 4630, Loss: 0.0139, Acc: 64.98%\n",
      "Epoch 3/3, Batch 4640, Loss: 0.9817, Acc: 64.96%\n",
      "Epoch 3/3, Batch 4650, Loss: 0.6378, Acc: 64.98%\n",
      "Epoch 3/3, Batch 4660, Loss: 0.7428, Acc: 64.92%\n",
      "Epoch 3/3, Batch 4670, Loss: 0.5284, Acc: 64.91%\n",
      "Epoch 3/3, Batch 4680, Loss: 0.4605, Acc: 64.88%\n",
      "Epoch 3/3, Batch 4690, Loss: 0.0221, Acc: 64.93%\n",
      "Epoch 3/3, Batch 4700, Loss: 0.3338, Acc: 64.94%\n",
      "Epoch 3/3, Batch 4710, Loss: 1.2479, Acc: 64.93%\n",
      "Epoch 3/3, Batch 4720, Loss: 0.7849, Acc: 64.92%\n",
      "Epoch 3/3, Batch 4730, Loss: 0.9141, Acc: 64.89%\n",
      "Epoch 3/3, Batch 4740, Loss: 0.7945, Acc: 64.86%\n",
      "Epoch 3/3, Batch 4750, Loss: 0.3157, Acc: 64.83%\n",
      "Epoch 3/3, Batch 4760, Loss: 1.0715, Acc: 64.80%\n",
      "Epoch 3/3, Batch 4770, Loss: 0.5359, Acc: 64.85%\n",
      "Epoch 3/3, Batch 4780, Loss: 2.1446, Acc: 64.88%\n",
      "Epoch 3/3, Batch 4790, Loss: 0.0106, Acc: 64.89%\n",
      "Epoch 3/3, Batch 4800, Loss: 0.0154, Acc: 64.92%\n",
      "Epoch 3/3, Batch 4810, Loss: 0.0496, Acc: 64.96%\n",
      "Epoch 3/3, Batch 4820, Loss: 0.8430, Acc: 64.92%\n",
      "Epoch 3/3, Batch 4830, Loss: 0.2141, Acc: 64.96%\n",
      "Epoch 3/3, Batch 4840, Loss: 0.0210, Acc: 64.97%\n",
      "Epoch 3/3, Batch 4850, Loss: 0.2391, Acc: 64.98%\n",
      "Epoch 3/3, Batch 4860, Loss: 0.0306, Acc: 64.99%\n",
      "Epoch 3/3, Batch 4870, Loss: 0.0840, Acc: 65.02%\n",
      "Epoch 3/3, Batch 4880, Loss: 0.9140, Acc: 65.05%\n",
      "Epoch 3/3, Batch 4890, Loss: 0.0978, Acc: 65.08%\n",
      "Epoch 3/3, Batch 4900, Loss: 1.8638, Acc: 65.07%\n",
      "Epoch 3/3, Batch 4910, Loss: 0.0157, Acc: 65.10%\n",
      "Epoch 3/3, Batch 4920, Loss: 0.0486, Acc: 65.09%\n",
      "Epoch 3/3, Batch 4930, Loss: 0.5783, Acc: 65.12%\n",
      "Epoch 3/3, Batch 4940, Loss: 0.4751, Acc: 65.09%\n",
      "Epoch 3/3, Batch 4950, Loss: 0.1239, Acc: 65.10%\n",
      "Epoch 3/3, Batch 4960, Loss: 0.0168, Acc: 65.13%\n",
      "Epoch 3/3, Batch 4970, Loss: 0.1277, Acc: 65.14%\n",
      "Epoch 3/3, Batch 4980, Loss: 0.7594, Acc: 65.15%\n",
      "Epoch 3/3, Batch 4990, Loss: 0.4143, Acc: 65.16%\n",
      "Epoch 3/3, Batch 5000, Loss: 0.0298, Acc: 65.13%\n",
      "Epoch 3/3, Batch 5010, Loss: 0.2771, Acc: 65.12%\n",
      "Epoch 3/3, Batch 5020, Loss: 0.0034, Acc: 65.11%\n",
      "Epoch 3/3, Batch 5030, Loss: 0.0017, Acc: 65.10%\n",
      "Epoch 3/3, Batch 5040, Loss: 1.6553, Acc: 65.13%\n",
      "Epoch 3/3, Batch 5050, Loss: 0.4637, Acc: 65.10%\n",
      "Epoch 3/3, Batch 5060, Loss: 0.3275, Acc: 65.09%\n",
      "Epoch 3/3, Batch 5070, Loss: 0.2720, Acc: 65.10%\n",
      "Epoch 3/3, Batch 5080, Loss: 0.3367, Acc: 65.11%\n",
      "Epoch 3/3, Batch 5090, Loss: 1.0799, Acc: 65.08%\n",
      "Epoch 3/3, Batch 5100, Loss: 0.5522, Acc: 65.09%\n",
      "Epoch 3/3, Batch 5110, Loss: 1.4258, Acc: 65.02%\n",
      "Epoch 3/3, Batch 5120, Loss: 0.0192, Acc: 65.07%\n",
      "Epoch 3/3, Batch 5130, Loss: 0.1187, Acc: 65.04%\n",
      "Epoch 3/3, Batch 5140, Loss: 0.0240, Acc: 65.07%\n",
      "Epoch 3/3, Batch 5150, Loss: 0.2179, Acc: 65.07%\n",
      "Epoch 3/3, Batch 5160, Loss: 0.5106, Acc: 65.06%\n",
      "Epoch 3/3, Batch 5170, Loss: 0.0089, Acc: 65.09%\n",
      "Epoch 3/3, Batch 5180, Loss: 0.1489, Acc: 65.12%\n",
      "Epoch 3/3, Batch 5190, Loss: 0.5322, Acc: 65.17%\n",
      "Epoch 3/3, Batch 5200, Loss: 0.5129, Acc: 65.18%\n",
      "Epoch 3/3, Batch 5210, Loss: 0.6748, Acc: 65.23%\n",
      "Epoch 3/3, Batch 5220, Loss: 1.0065, Acc: 65.20%\n",
      "Epoch 3/3, Batch 5230, Loss: 0.9162, Acc: 65.23%\n",
      "Epoch 3/3, Batch 5240, Loss: 0.4999, Acc: 65.27%\n",
      "Epoch 3/3, Batch 5250, Loss: 2.0703, Acc: 65.26%\n",
      "Epoch 3/3, Batch 5260, Loss: 0.0059, Acc: 65.25%\n",
      "Epoch 3/3, Batch 5270, Loss: 0.6442, Acc: 65.30%\n",
      "Epoch 3/3, Batch 5280, Loss: 0.5747, Acc: 65.29%\n",
      "Epoch 3/3, Batch 5290, Loss: 0.7576, Acc: 65.26%\n",
      "Epoch 3/3, Batch 5300, Loss: 0.1984, Acc: 65.23%\n",
      "Epoch 3/3, Batch 5310, Loss: 1.4743, Acc: 65.24%\n",
      "Epoch 3/3, Batch 5320, Loss: 0.9985, Acc: 65.23%\n",
      "Epoch 3/3, Batch 5330, Loss: 0.0493, Acc: 65.26%\n",
      "Epoch 3/3, Batch 5340, Loss: 0.0187, Acc: 65.25%\n",
      "Epoch 3/3, Batch 5350, Loss: 0.0941, Acc: 65.22%\n",
      "Epoch 3/3, Batch 5360, Loss: 0.8278, Acc: 65.23%\n",
      "Epoch 3/3, Batch 5370, Loss: 0.2819, Acc: 65.22%\n",
      "Epoch 3/3, Batch 5380, Loss: 0.0161, Acc: 65.23%\n",
      "Epoch 3/3, Batch 5390, Loss: 1.5320, Acc: 65.22%\n",
      "Epoch 3/3, Batch 5400, Loss: 1.7722, Acc: 65.21%\n",
      "Epoch 3/3, Batch 5410, Loss: 0.1956, Acc: 65.22%\n",
      "Epoch 3/3, Batch 5420, Loss: 0.0185, Acc: 65.23%\n",
      "Epoch 3/3, Batch 5430, Loss: 0.5907, Acc: 65.20%\n",
      "Epoch 3/3, Batch 5440, Loss: 0.5072, Acc: 65.23%\n",
      "Epoch 3/3, Batch 5450, Loss: 0.9344, Acc: 65.24%\n",
      "Epoch 3/3, Batch 5460, Loss: 0.0136, Acc: 65.23%\n",
      "Epoch 3/3, Batch 5470, Loss: 0.2181, Acc: 65.27%\n",
      "Epoch 3/3, Batch 5480, Loss: 0.0054, Acc: 65.24%\n",
      "Epoch 3/3, Batch 5490, Loss: 0.0072, Acc: 65.29%\n",
      "Epoch 3/3, Batch 5500, Loss: 0.7494, Acc: 65.30%\n",
      "Epoch 3/3, Batch 5510, Loss: 0.1366, Acc: 65.29%\n",
      "Epoch 3/3, Batch 5520, Loss: 1.1253, Acc: 65.26%\n",
      "Epoch 3/3, Batch 5530, Loss: 0.2153, Acc: 65.25%\n",
      "Epoch 3/3, Batch 5540, Loss: 0.2387, Acc: 65.28%\n",
      "Epoch 3/3, Batch 5550, Loss: 1.1016, Acc: 65.27%\n",
      "Epoch 3/3, Batch 5560, Loss: 0.1475, Acc: 65.28%\n",
      "Epoch 3/3, Batch 5570, Loss: 0.7548, Acc: 65.28%\n",
      "Epoch 3/3, Batch 5580, Loss: 0.4467, Acc: 65.28%\n",
      "Epoch 3/3, Batch 5590, Loss: 0.8426, Acc: 65.28%\n",
      "Epoch 3/3, Batch 5600, Loss: 0.9824, Acc: 65.24%\n",
      "Epoch 3/3, Batch 5610, Loss: 0.9525, Acc: 65.18%\n",
      "Epoch 3/3, Batch 5620, Loss: 0.0029, Acc: 65.15%\n",
      "Epoch 3/3, Batch 5630, Loss: 0.5217, Acc: 65.16%\n",
      "Epoch 3/3, Batch 5640, Loss: 1.1190, Acc: 65.11%\n",
      "Epoch 3/3, Batch 5650, Loss: 0.6532, Acc: 65.12%\n",
      "Epoch 3/3, Batch 5660, Loss: 0.8818, Acc: 65.15%\n",
      "Epoch 3/3, Batch 5670, Loss: 0.3272, Acc: 65.17%\n",
      "Epoch 3/3, Batch 5680, Loss: 0.5563, Acc: 65.16%\n",
      "Epoch 3/3, Batch 5690, Loss: 0.5667, Acc: 65.12%\n",
      "Epoch 3/3, Batch 5700, Loss: 1.9679, Acc: 65.08%\n",
      "Epoch 3/3, Batch 5710, Loss: 0.5205, Acc: 65.10%\n",
      "Epoch 3/3, Batch 5720, Loss: 0.5629, Acc: 65.08%\n",
      "Epoch 3/3, Batch 5730, Loss: 0.1148, Acc: 65.14%\n",
      "Epoch 3/3, Batch 5740, Loss: 0.7392, Acc: 65.11%\n",
      "Epoch 3/3, Batch 5750, Loss: 0.0411, Acc: 65.12%\n",
      "Epoch 3/3, Batch 5760, Loss: 0.1496, Acc: 65.13%\n",
      "Epoch 3/3, Batch 5770, Loss: 0.0161, Acc: 65.12%\n",
      "Epoch 3/3, Batch 5780, Loss: 0.3094, Acc: 65.13%\n",
      "Epoch 3/3, Batch 5790, Loss: 1.5791, Acc: 65.14%\n",
      "Epoch 3/3, Batch 5800, Loss: 0.0990, Acc: 65.14%\n",
      "Epoch 3/3, Batch 5810, Loss: 0.5835, Acc: 65.17%\n",
      "Epoch 3/3, Batch 5820, Loss: 0.0575, Acc: 65.18%\n",
      "Epoch 3/3, Batch 5830, Loss: 1.4324, Acc: 65.20%\n",
      "Epoch 3/3, Batch 5840, Loss: 1.2712, Acc: 65.18%\n",
      "Epoch 3/3, Batch 5850, Loss: 0.6356, Acc: 65.20%\n",
      "Epoch 3/3, Batch 5860, Loss: 0.1938, Acc: 65.19%\n",
      "Epoch 3/3, Batch 5870, Loss: 0.8196, Acc: 65.17%\n",
      "Epoch 3/3, Batch 5880, Loss: 0.1421, Acc: 65.19%\n",
      "Epoch 3/3, Batch 5890, Loss: 0.0539, Acc: 65.20%\n",
      "Epoch 3/3, Batch 5900, Loss: 0.3603, Acc: 65.23%\n",
      "Epoch 3/3, Batch 5910, Loss: 0.6192, Acc: 65.18%\n",
      "Epoch 3/3, Batch 5920, Loss: 1.0003, Acc: 65.23%\n",
      "Epoch 3/3, Batch 5930, Loss: 0.4433, Acc: 65.25%\n",
      "Epoch 3/3, Batch 5940, Loss: 0.1500, Acc: 65.24%\n",
      "Epoch 3/3, Batch 5950, Loss: 0.0242, Acc: 65.27%\n",
      "Epoch 3/3, Batch 5960, Loss: 0.1984, Acc: 65.29%\n",
      "Epoch 3/3, Batch 5970, Loss: 0.0057, Acc: 65.33%\n",
      "Epoch 3/3, Batch 5980, Loss: 1.0214, Acc: 65.32%\n",
      "Epoch 3/3, Batch 5990, Loss: 0.1370, Acc: 65.30%\n",
      "Epoch 3/3, Batch 6000, Loss: 0.0359, Acc: 65.29%\n",
      "Epoch 3/3, Batch 6010, Loss: 0.0149, Acc: 65.30%\n",
      "Epoch 3/3, Batch 6020, Loss: 0.7921, Acc: 65.24%\n",
      "Epoch 3/3, Batch 6030, Loss: 1.1312, Acc: 65.21%\n",
      "Epoch 3/3, Batch 6040, Loss: 0.8290, Acc: 65.24%\n",
      "Epoch 3/3, Batch 6050, Loss: 1.0562, Acc: 65.23%\n",
      "Epoch 3/3, Batch 6060, Loss: 0.5438, Acc: 65.25%\n",
      "Epoch 3/3, Batch 6070, Loss: 1.5786, Acc: 65.21%\n",
      "Epoch 3/3, Batch 6080, Loss: 0.3318, Acc: 65.24%\n",
      "Epoch 3/3, Batch 6090, Loss: 0.2334, Acc: 65.26%\n",
      "Epoch 3/3, Batch 6100, Loss: 1.3765, Acc: 65.25%\n",
      "Epoch 3/3, Batch 6110, Loss: 1.2995, Acc: 65.26%\n",
      "Epoch 3/3, Batch 6120, Loss: 1.1266, Acc: 65.27%\n",
      "Epoch 3/3, Batch 6130, Loss: 0.0371, Acc: 65.29%\n",
      "Epoch 3/3, Batch 6140, Loss: 0.3623, Acc: 65.28%\n",
      "Epoch 3/3, Batch 6150, Loss: 1.3096, Acc: 65.27%\n",
      "Epoch 3/3, Batch 6160, Loss: 0.0568, Acc: 65.30%\n",
      "Epoch 3/3, Batch 6170, Loss: 0.3660, Acc: 65.32%\n",
      "Epoch 3/3, Batch 6180, Loss: 0.3118, Acc: 65.26%\n",
      "Epoch 3/3, Batch 6190, Loss: 2.4976, Acc: 65.27%\n",
      "Epoch 3/3, Batch 6200, Loss: 2.3610, Acc: 65.30%\n",
      "Epoch 3/3, Batch 6210, Loss: 0.1855, Acc: 65.30%\n",
      "Epoch 3/3, Batch 6220, Loss: 0.0845, Acc: 65.29%\n",
      "Epoch 3/3, Batch 6230, Loss: 0.4684, Acc: 65.29%\n",
      "Epoch 3/3, Batch 6240, Loss: 1.2245, Acc: 65.29%\n",
      "Epoch 3/3, Batch 6250, Loss: 0.4750, Acc: 65.30%\n",
      "Epoch 3/3, Batch 6260, Loss: 0.2855, Acc: 65.29%\n",
      "Epoch 3/3, Batch 6270, Loss: 1.4611, Acc: 65.32%\n",
      "Epoch 3/3, Batch 6280, Loss: 0.9026, Acc: 65.31%\n",
      "Epoch 3/3, Batch 6290, Loss: 1.6905, Acc: 65.28%\n",
      "Epoch 3/3, Batch 6300, Loss: 0.0024, Acc: 65.26%\n",
      "Epoch 3/3, Batch 6310, Loss: 0.7362, Acc: 65.25%\n",
      "Epoch 3/3, Batch 6320, Loss: 0.1383, Acc: 65.24%\n",
      "Epoch 3/3, Batch 6330, Loss: 0.5364, Acc: 65.23%\n",
      "Epoch 3/3, Batch 6340, Loss: 0.0126, Acc: 65.24%\n",
      "Epoch 3/3, Batch 6350, Loss: 0.0158, Acc: 65.27%\n",
      "Epoch 3/3, Batch 6360, Loss: 0.4633, Acc: 65.27%\n",
      "Epoch 3/3, Batch 6370, Loss: 0.0836, Acc: 65.28%\n",
      "Epoch 3/3, Batch 6380, Loss: 0.0045, Acc: 65.26%\n",
      "Epoch 3/3, Batch 6390, Loss: 0.2938, Acc: 65.25%\n",
      "Epoch 3/3, Batch 6400, Loss: 0.0081, Acc: 65.27%\n",
      "Epoch 3/3, Batch 6410, Loss: 1.3187, Acc: 65.29%\n",
      "Epoch 3/3, Batch 6420, Loss: 0.4138, Acc: 65.32%\n",
      "Epoch 3/3, Batch 6430, Loss: 1.0551, Acc: 65.32%\n",
      "Epoch 3/3, Batch 6440, Loss: 0.5386, Acc: 65.28%\n",
      "Epoch 3/3, Batch 6450, Loss: 0.0274, Acc: 65.31%\n",
      "Epoch 3/3, Batch 6460, Loss: 0.1077, Acc: 65.31%\n",
      "Epoch 3/3, Batch 6470, Loss: 2.3836, Acc: 65.29%\n",
      "Epoch 3/3, Batch 6480, Loss: 0.1000, Acc: 65.30%\n",
      "Epoch 3/3, Batch 6490, Loss: 0.0062, Acc: 65.29%\n",
      "Epoch 3/3, Batch 6500, Loss: 0.0176, Acc: 65.28%\n",
      "Epoch 3/3, Batch 6510, Loss: 0.2435, Acc: 65.26%\n",
      "Epoch 3/3, Batch 6520, Loss: 0.2709, Acc: 65.25%\n",
      "Epoch 3/3, Batch 6530, Loss: 0.8196, Acc: 65.21%\n",
      "Epoch 3/3, Batch 6540, Loss: 0.6123, Acc: 65.25%\n",
      "Epoch 3/3, Batch 6550, Loss: 0.4392, Acc: 65.26%\n",
      "Epoch 3/3, Batch 6560, Loss: 0.3469, Acc: 65.23%\n",
      "Epoch 3/3, Batch 6570, Loss: 1.5583, Acc: 65.17%\n",
      "Epoch 3/3, Batch 6580, Loss: 1.4583, Acc: 65.17%\n",
      "Epoch 3/3, Batch 6590, Loss: 0.7436, Acc: 65.16%\n",
      "Epoch 3/3, Batch 6600, Loss: 0.7134, Acc: 65.17%\n",
      "Epoch 3/3, Batch 6610, Loss: 0.0166, Acc: 65.15%\n",
      "Epoch 3/3, Batch 6620, Loss: 0.0336, Acc: 65.13%\n",
      "Epoch 3/3, Batch 6630, Loss: 0.7308, Acc: 65.12%\n",
      "Epoch 3/3, Batch 6640, Loss: 1.0990, Acc: 65.13%\n",
      "Epoch 3/3, Batch 6650, Loss: 0.8919, Acc: 65.10%\n",
      "Epoch 3/3, Batch 6660, Loss: 1.0648, Acc: 65.13%\n",
      "Epoch 3/3, Batch 6670, Loss: 0.7393, Acc: 65.10%\n",
      "Epoch 3/3, Batch 6680, Loss: 0.0406, Acc: 65.12%\n",
      "Epoch 3/3, Batch 6690, Loss: 0.4025, Acc: 65.12%\n",
      "Epoch 3/3, Batch 6700, Loss: 0.6515, Acc: 65.12%\n",
      "Epoch 3/3, Batch 6710, Loss: 0.1446, Acc: 65.15%\n",
      "Epoch 3/3, Batch 6720, Loss: 1.0155, Acc: 65.17%\n",
      "Epoch 3/3, Batch 6730, Loss: 0.0720, Acc: 65.18%\n",
      "Epoch 3/3, Batch 6740, Loss: 0.0039, Acc: 65.14%\n",
      "Epoch 3/3, Batch 6750, Loss: 0.3657, Acc: 65.15%\n",
      "Epoch 3/3, Batch 6760, Loss: 0.6500, Acc: 65.18%\n",
      "Epoch 3/3, Batch 6770, Loss: 1.5201, Acc: 65.12%\n",
      "Epoch 3/3, Batch 6780, Loss: 0.7691, Acc: 65.08%\n",
      "Epoch 3/3, Batch 6790, Loss: 0.2002, Acc: 65.04%\n",
      "Epoch 3/3, Batch 6800, Loss: 0.6298, Acc: 65.05%\n",
      "Epoch 3/3, Batch 6810, Loss: 0.0451, Acc: 65.06%\n",
      "Epoch 3/3, Batch 6820, Loss: 0.0403, Acc: 65.05%\n",
      "Epoch 3/3, Batch 6830, Loss: 0.1221, Acc: 65.06%\n",
      "Epoch 3/3, Batch 6840, Loss: 0.0362, Acc: 65.05%\n",
      "Epoch 3/3, Batch 6850, Loss: 0.0641, Acc: 65.06%\n",
      "Epoch 3/3, Batch 6860, Loss: 0.0527, Acc: 65.09%\n",
      "Epoch 3/3, Batch 6870, Loss: 0.6129, Acc: 65.10%\n",
      "Epoch 3/3, Batch 6880, Loss: 0.7784, Acc: 65.09%\n",
      "Epoch 3/3, Batch 6890, Loss: 0.3281, Acc: 65.08%\n",
      "Epoch 3/3, Batch 6900, Loss: 0.3983, Acc: 65.09%\n",
      "Epoch 3/3, Batch 6910, Loss: 0.5023, Acc: 65.08%\n",
      "Epoch 3/3, Batch 6920, Loss: 0.6837, Acc: 65.06%\n",
      "Epoch 3/3, Batch 6930, Loss: 1.5006, Acc: 65.08%\n",
      "Epoch 3/3, Batch 6940, Loss: 0.3180, Acc: 65.08%\n",
      "Epoch 3/3, Batch 6950, Loss: 0.0095, Acc: 65.08%\n",
      "Epoch 3/3, Batch 6960, Loss: 0.0337, Acc: 65.06%\n",
      "Epoch 3/3, Batch 6970, Loss: 0.6398, Acc: 65.01%\n",
      "Epoch 3/3, Batch 6980, Loss: 0.0802, Acc: 64.98%\n",
      "Epoch 3/3, Batch 6990, Loss: 0.5965, Acc: 64.95%\n",
      "Epoch 3/3, Batch 7000, Loss: 1.0799, Acc: 64.95%\n",
      "Epoch 3/3, Batch 7010, Loss: 0.4986, Acc: 64.91%\n",
      "Epoch 3/3, Batch 7020, Loss: 0.0174, Acc: 64.89%\n",
      "Epoch 3/3, Batch 7030, Loss: 0.1625, Acc: 64.90%\n",
      "Epoch 3/3, Batch 7040, Loss: 0.5444, Acc: 64.89%\n",
      "Epoch 3/3, Batch 7050, Loss: 1.0529, Acc: 64.88%\n",
      "Epoch 3/3, Batch 7060, Loss: 0.9085, Acc: 64.88%\n",
      "Epoch 3/3, Batch 7070, Loss: 0.4151, Acc: 64.86%\n",
      "Epoch 3/3, Batch 7080, Loss: 0.4982, Acc: 64.82%\n",
      "Epoch 3/3, Batch 7090, Loss: 0.9634, Acc: 64.79%\n",
      "Epoch 3/3, Batch 7100, Loss: 0.2780, Acc: 64.79%\n",
      "Epoch 3/3, Batch 7110, Loss: 0.7759, Acc: 64.76%\n",
      "Epoch 3/3, Batch 7120, Loss: 1.1344, Acc: 64.77%\n",
      "Epoch 3/3, Batch 7130, Loss: 0.2988, Acc: 64.76%\n",
      "Epoch 3/3, Batch 7140, Loss: 0.1353, Acc: 64.78%\n",
      "Epoch 3/3, Batch 7150, Loss: 1.2374, Acc: 64.76%\n",
      "Epoch 3/3, Batch 7160, Loss: 1.1144, Acc: 64.74%\n",
      "Epoch 3/3, Batch 7170, Loss: 0.0007, Acc: 64.72%\n",
      "Epoch 3/3, Batch 7180, Loss: 0.3389, Acc: 64.74%\n",
      "Epoch 3/3, Batch 7190, Loss: 0.0129, Acc: 64.71%\n",
      "Epoch 3/3, Batch 7200, Loss: 0.9567, Acc: 64.69%\n",
      "Epoch 3/3, Batch 7210, Loss: 1.0731, Acc: 64.67%\n",
      "Epoch 3/3, Batch 7220, Loss: 0.4098, Acc: 64.66%\n",
      "Epoch 3/3, Batch 7230, Loss: 1.0010, Acc: 64.65%\n",
      "Epoch 3/3, Batch 7240, Loss: 0.0895, Acc: 64.63%\n",
      "Epoch 3/3, Batch 7250, Loss: 0.1332, Acc: 64.64%\n",
      "Epoch 3/3, Batch 7260, Loss: 0.2072, Acc: 64.63%\n",
      "Epoch 3/3, Batch 7270, Loss: 0.0241, Acc: 64.65%\n",
      "Epoch 3/3, Batch 7280, Loss: 1.1188, Acc: 64.62%\n",
      "Epoch 3/3, Batch 7290, Loss: 0.6691, Acc: 64.63%\n",
      "Epoch 3/3, Batch 7300, Loss: 0.1560, Acc: 64.59%\n",
      "Epoch 3/3, Batch 7310, Loss: 0.0744, Acc: 64.56%\n",
      "Epoch 3/3, Batch 7320, Loss: 0.9456, Acc: 64.55%\n",
      "Epoch 3/3, Batch 7330, Loss: 1.7809, Acc: 64.55%\n",
      "Epoch 3/3, Batch 7340, Loss: 0.1507, Acc: 64.54%\n",
      "Epoch 3/3, Batch 7350, Loss: 0.0373, Acc: 64.55%\n",
      "Epoch 3/3, Batch 7360, Loss: 0.8150, Acc: 64.54%\n",
      "Epoch 3/3, Batch 7370, Loss: 0.0112, Acc: 64.55%\n",
      "Epoch 3/3, Batch 7380, Loss: 0.0755, Acc: 64.56%\n",
      "Epoch 3/3, Batch 7390, Loss: 3.8751, Acc: 64.54%\n",
      "Epoch 3/3, Batch 7400, Loss: 0.5369, Acc: 64.53%\n",
      "Epoch 3/3, Batch 7410, Loss: 0.3613, Acc: 64.53%\n",
      "Epoch 3/3, Batch 7420, Loss: 1.5206, Acc: 64.49%\n",
      "Epoch 3/3, Batch 7430, Loss: 0.5362, Acc: 64.51%\n",
      "Epoch 3/3, Batch 7440, Loss: 1.1249, Acc: 64.49%\n",
      "Epoch 3/3, Batch 7450, Loss: 1.4479, Acc: 64.47%\n",
      "Epoch 3/3, Batch 7460, Loss: 1.0126, Acc: 64.50%\n",
      "Epoch 3/3, Batch 7470, Loss: 1.4189, Acc: 64.49%\n",
      "Epoch 3/3, Batch 7480, Loss: 1.1030, Acc: 64.46%\n",
      "Epoch 3/3, Batch 7490, Loss: 0.7962, Acc: 64.42%\n",
      "Epoch 3/3, Batch 7500, Loss: 0.6216, Acc: 64.44%\n",
      "Epoch 3/3, Batch 7510, Loss: 0.6645, Acc: 64.45%\n",
      "Epoch 3/3, Batch 7520, Loss: 0.3480, Acc: 64.47%\n",
      "Epoch 3/3, Batch 7530, Loss: 0.0015, Acc: 64.47%\n",
      "Epoch 3/3, Batch 7540, Loss: 0.0918, Acc: 64.46%\n",
      "Epoch 3/3, Batch 7550, Loss: 0.4814, Acc: 64.51%\n",
      "Epoch 3/3, Batch 7560, Loss: 0.6387, Acc: 64.50%\n",
      "Epoch 3/3, Batch 7570, Loss: 0.5923, Acc: 64.54%\n",
      "Epoch 3/3, Batch 7580, Loss: 0.7115, Acc: 64.52%\n",
      "Epoch 3/3, Batch 7590, Loss: 0.0212, Acc: 64.54%\n",
      "Epoch 3/3, Batch 7600, Loss: 0.1461, Acc: 64.53%\n",
      "Epoch 3/3, Batch 7610, Loss: 1.0024, Acc: 64.50%\n",
      "Epoch 3/3, Batch 7620, Loss: 0.3264, Acc: 64.51%\n",
      "Epoch 3/3, Batch 7630, Loss: 0.4261, Acc: 64.51%\n",
      "Epoch 3/3, Batch 7640, Loss: 0.1474, Acc: 64.52%\n",
      "Epoch 3/3, Batch 7650, Loss: 0.1639, Acc: 64.46%\n",
      "Epoch 3/3, Batch 7660, Loss: 0.4225, Acc: 64.47%\n",
      "Epoch 3/3, Batch 7670, Loss: 0.0129, Acc: 64.48%\n",
      "Epoch 3/3, Batch 7680, Loss: 0.0333, Acc: 64.46%\n",
      "Epoch 3/3, Batch 7690, Loss: 0.3866, Acc: 64.44%\n",
      "Epoch 3/3, Batch 7700, Loss: 0.8116, Acc: 64.42%\n",
      "Epoch 3/3, Batch 7710, Loss: 0.9541, Acc: 64.39%\n",
      "Epoch 3/3, Batch 7720, Loss: 0.4546, Acc: 64.38%\n",
      "Epoch 3/3, Batch 7730, Loss: 1.5700, Acc: 64.35%\n",
      "Epoch 3/3, Batch 7740, Loss: 1.0131, Acc: 64.36%\n",
      "Epoch 3/3, Batch 7750, Loss: 0.9214, Acc: 64.31%\n",
      "Epoch 3/3, Batch 7760, Loss: 0.0178, Acc: 64.33%\n",
      "Epoch 3/3, Batch 7770, Loss: 0.1375, Acc: 64.35%\n",
      "Epoch 3/3, Batch 7780, Loss: 0.6539, Acc: 64.40%\n",
      "Epoch 3/3, Batch 7790, Loss: 0.0251, Acc: 64.41%\n",
      "Epoch 3/3, Batch 7800, Loss: 1.1778, Acc: 64.41%\n",
      "Epoch 3/3, Batch 7810, Loss: 2.1181, Acc: 64.38%\n",
      "Epoch 3/3, Batch 7820, Loss: 0.0598, Acc: 64.40%\n",
      "Epoch 3/3, Batch 7830, Loss: 1.0148, Acc: 64.40%\n",
      "Epoch 3/3, Batch 7840, Loss: 0.2953, Acc: 64.39%\n",
      "Epoch 3/3, Batch 7850, Loss: 0.0261, Acc: 64.37%\n",
      "Epoch 3/3, Batch 7860, Loss: 1.1302, Acc: 64.38%\n",
      "Epoch 3/3, Batch 7870, Loss: 0.3671, Acc: 64.40%\n",
      "Epoch 3/3, Batch 7880, Loss: 2.2839, Acc: 64.38%\n",
      "Epoch 3/3, Batch 7890, Loss: 1.5720, Acc: 64.36%\n",
      "Epoch 3/3, Batch 7900, Loss: 1.0026, Acc: 64.38%\n",
      "Epoch 3/3, Batch 7910, Loss: 0.7797, Acc: 64.38%\n",
      "Epoch 3/3, Batch 7920, Loss: 1.2292, Acc: 64.40%\n",
      "Epoch 3/3, Batch 7930, Loss: 0.1217, Acc: 64.41%\n",
      "Epoch 3/3, Batch 7940, Loss: 0.6203, Acc: 64.39%\n",
      "Epoch 3/3, Batch 7950, Loss: 0.7801, Acc: 64.41%\n",
      "Epoch 3/3, Batch 7960, Loss: 1.2640, Acc: 64.41%\n",
      "Epoch 3/3, Batch 7970, Loss: 0.8936, Acc: 64.40%\n",
      "Epoch 3/3, Batch 7980, Loss: 0.3476, Acc: 64.39%\n",
      "Epoch 3/3, Batch 7990, Loss: 0.0847, Acc: 64.40%\n",
      "Epoch 3/3, Batch 8000, Loss: 0.7135, Acc: 64.43%\n",
      "Epoch 3/3, Batch 8010, Loss: 0.2860, Acc: 64.46%\n",
      "Epoch 3/3, Batch 8020, Loss: 1.4472, Acc: 64.47%\n",
      "Epoch 3/3, Batch 8030, Loss: 0.1894, Acc: 64.48%\n",
      "Epoch 3/3, Batch 8040, Loss: 0.7206, Acc: 64.46%\n",
      "Epoch 3/3, Batch 8050, Loss: 0.1688, Acc: 64.46%\n",
      "Epoch 3/3, Batch 8060, Loss: 0.0497, Acc: 64.46%\n",
      "Epoch 3/3, Batch 8070, Loss: 1.9111, Acc: 64.45%\n",
      "Epoch 3/3, Batch 8080, Loss: 0.0871, Acc: 64.47%\n",
      "Epoch 3/3, Batch 8090, Loss: 1.1433, Acc: 64.45%\n",
      "Epoch 3/3, Batch 8100, Loss: 1.6468, Acc: 64.47%\n",
      "Epoch 3/3, Batch 8110, Loss: 0.2650, Acc: 64.50%\n",
      "Epoch 3/3, Batch 8120, Loss: 1.5006, Acc: 64.49%\n",
      "Epoch 3/3, Batch 8130, Loss: 0.5288, Acc: 64.52%\n",
      "Epoch 3/3, Batch 8140, Loss: 1.2094, Acc: 64.49%\n",
      "Epoch 3/3, Batch 8150, Loss: 0.8219, Acc: 64.45%\n",
      "Epoch 3/3, Batch 8160, Loss: 2.6025, Acc: 64.43%\n",
      "Epoch 3/3, Batch 8170, Loss: 0.5908, Acc: 64.41%\n",
      "Epoch 3/3, Batch 8180, Loss: 0.9106, Acc: 64.38%\n",
      "Epoch 3/3, Batch 8190, Loss: 0.3282, Acc: 64.39%\n",
      "Epoch 3/3, Batch 8200, Loss: 2.0601, Acc: 64.36%\n",
      "Epoch 3/3, Batch 8210, Loss: 1.3482, Acc: 64.36%\n",
      "Epoch 3/3, Batch 8220, Loss: 0.5199, Acc: 64.37%\n",
      "Epoch 3/3, Batch 8230, Loss: 0.2058, Acc: 64.37%\n",
      "Epoch 3/3, Batch 8240, Loss: 0.7960, Acc: 64.35%\n",
      "Epoch 3/3, Batch 8250, Loss: 0.3102, Acc: 64.36%\n",
      "Epoch 3/3, Batch 8260, Loss: 0.7599, Acc: 64.35%\n",
      "Epoch 3/3, Batch 8270, Loss: 0.0555, Acc: 64.36%\n",
      "Epoch 3/3, Batch 8280, Loss: 0.7527, Acc: 64.35%\n",
      "Epoch 3/3, Batch 8290, Loss: 0.0182, Acc: 64.33%\n",
      "Epoch 3/3, Batch 8300, Loss: 0.0457, Acc: 64.35%\n",
      "Epoch 3/3, Batch 8310, Loss: 0.6147, Acc: 64.35%\n",
      "Epoch 3/3, Batch 8320, Loss: 0.6151, Acc: 64.38%\n",
      "Epoch 3/3, Batch 8330, Loss: 0.5689, Acc: 64.41%\n",
      "Epoch 3/3, Batch 8340, Loss: 0.0235, Acc: 64.43%\n",
      "Epoch 3/3, Batch 8350, Loss: 0.0079, Acc: 64.46%\n",
      "Epoch 3/3, Batch 8360, Loss: 0.3507, Acc: 64.45%\n",
      "Epoch 3/3, Batch 8370, Loss: 0.5894, Acc: 64.45%\n",
      "Epoch 3/3, Batch 8380, Loss: 0.0391, Acc: 64.44%\n",
      "Epoch 3/3, Batch 8390, Loss: 0.1028, Acc: 64.43%\n",
      "Epoch 3/3, Batch 8400, Loss: 0.3639, Acc: 64.46%\n",
      "Epoch 3/3, Batch 8410, Loss: 0.1307, Acc: 64.48%\n",
      "Epoch 3/3, Batch 8420, Loss: 0.1046, Acc: 64.47%\n",
      "Epoch 3/3, Batch 8430, Loss: 0.1808, Acc: 64.50%\n",
      "Epoch 3/3, Batch 8440, Loss: 0.6749, Acc: 64.51%\n",
      "Epoch 3/3, Batch 8450, Loss: 0.4897, Acc: 64.54%\n",
      "Epoch 3/3, Batch 8460, Loss: 0.3004, Acc: 64.52%\n",
      "Epoch 3/3, Batch 8470, Loss: 0.5844, Acc: 64.54%\n",
      "Epoch 3/3, Batch 8480, Loss: 0.0286, Acc: 64.53%\n",
      "Epoch 3/3, Batch 8490, Loss: 0.8079, Acc: 64.53%\n",
      "Epoch 3/3, Batch 8500, Loss: 0.4597, Acc: 64.52%\n",
      "Epoch 3/3, Batch 8510, Loss: 0.6315, Acc: 64.54%\n",
      "Epoch 3/3, Batch 8520, Loss: 0.0270, Acc: 64.57%\n",
      "Epoch 3/3, Batch 8530, Loss: 1.0974, Acc: 64.55%\n",
      "Epoch 3/3, Batch 8540, Loss: 0.0485, Acc: 64.55%\n",
      "Epoch 3/3, Batch 8550, Loss: 0.7404, Acc: 64.50%\n",
      "Epoch 3/3, Batch 8560, Loss: 0.1707, Acc: 64.49%\n",
      "Epoch 3/3, Batch 8570, Loss: 1.0161, Acc: 64.51%\n",
      "Epoch 3/3, Batch 8580, Loss: 1.1273, Acc: 64.51%\n",
      "Epoch 3/3, Batch 8590, Loss: 0.0026, Acc: 64.52%\n",
      "Epoch 3/3, Batch 8600, Loss: 1.1381, Acc: 64.48%\n",
      "Epoch 3/3, Batch 8610, Loss: 0.0051, Acc: 64.48%\n",
      "Epoch 3/3, Batch 8620, Loss: 0.3662, Acc: 64.47%\n",
      "Epoch 3/3, Batch 8630, Loss: 1.1971, Acc: 64.47%\n",
      "Epoch 3/3, Batch 8640, Loss: 0.7366, Acc: 64.46%\n",
      "Epoch 3/3, Batch 8650, Loss: 0.0424, Acc: 64.48%\n",
      "Epoch 3/3, Batch 8660, Loss: 0.1226, Acc: 64.46%\n",
      "Epoch 3/3, Batch 8670, Loss: 0.4919, Acc: 64.48%\n",
      "Epoch 3/3, Batch 8680, Loss: 0.0187, Acc: 64.51%\n",
      "Epoch 3/3, Batch 8690, Loss: 0.4202, Acc: 64.52%\n",
      "Epoch 3/3, Batch 8700, Loss: 0.0205, Acc: 64.52%\n",
      "Epoch 3/3, Batch 8710, Loss: 0.1940, Acc: 64.54%\n",
      "Epoch 3/3, Batch 8720, Loss: 0.9031, Acc: 64.55%\n",
      "Epoch 3/3, Batch 8730, Loss: 0.1189, Acc: 64.54%\n",
      "Epoch 3/3, Batch 8740, Loss: 0.6875, Acc: 64.56%\n",
      "Epoch 3/3, Batch 8750, Loss: 1.6590, Acc: 64.55%\n",
      "Epoch 3/3, Batch 8760, Loss: 1.4195, Acc: 64.57%\n",
      "Epoch 3/3, Batch 8770, Loss: 0.6594, Acc: 64.57%\n",
      "Epoch 3/3, Batch 8780, Loss: 1.0274, Acc: 64.57%\n",
      "Epoch 3/3, Batch 8790, Loss: 1.8809, Acc: 64.55%\n",
      "Epoch 3/3, Batch 8800, Loss: 0.6002, Acc: 64.58%\n",
      "Epoch 3/3, Batch 8810, Loss: 0.4878, Acc: 64.61%\n",
      "Epoch 3/3, Batch 8820, Loss: 0.6694, Acc: 64.62%\n",
      "Epoch 3/3, Batch 8830, Loss: 0.5441, Acc: 64.60%\n",
      "Epoch 3/3, Batch 8840, Loss: 1.3127, Acc: 64.59%\n",
      "Epoch 3/3, Batch 8850, Loss: 0.0513, Acc: 64.60%\n",
      "Epoch 3/3, Batch 8860, Loss: 0.2129, Acc: 64.63%\n",
      "Epoch 3/3, Batch 8870, Loss: 0.5101, Acc: 64.64%\n",
      "Epoch 3/3, Batch 8880, Loss: 0.0102, Acc: 64.63%\n",
      "Epoch 3/3, Batch 8890, Loss: 0.5013, Acc: 64.65%\n",
      "Epoch 3/3, Batch 8900, Loss: 0.0016, Acc: 64.64%\n",
      "Epoch 3/3, Batch 8910, Loss: 0.0304, Acc: 64.67%\n",
      "Epoch 3/3, Batch 8920, Loss: 0.8092, Acc: 64.68%\n",
      "Epoch 3/3, Batch 8930, Loss: 2.9050, Acc: 64.67%\n",
      "Epoch 3/3, Batch 8940, Loss: 0.0075, Acc: 64.70%\n",
      "Epoch 3/3, Batch 8950, Loss: 0.0360, Acc: 64.67%\n",
      "Epoch 3/3, Batch 8960, Loss: 0.2458, Acc: 64.70%\n",
      "Epoch 3/3, Batch 8970, Loss: 0.6364, Acc: 64.71%\n",
      "Epoch 3/3, Batch 8980, Loss: 0.0405, Acc: 64.73%\n",
      "Epoch 3/3, Batch 8990, Loss: 1.0735, Acc: 64.70%\n",
      "Epoch 3/3, Batch 9000, Loss: 0.1541, Acc: 64.67%\n",
      "Epoch 3/3, Batch 9010, Loss: 1.3215, Acc: 64.65%\n",
      "Epoch 3/3, Batch 9020, Loss: 0.1300, Acc: 64.66%\n",
      "Epoch 3/3, Batch 9030, Loss: 0.2443, Acc: 64.68%\n",
      "Epoch 3/3, Batch 9040, Loss: 0.0090, Acc: 64.68%\n",
      "Epoch 3/3, Batch 9050, Loss: 1.7809, Acc: 64.69%\n",
      "Epoch 3/3, Batch 9060, Loss: 0.8386, Acc: 64.69%\n",
      "Epoch 3/3, Batch 9070, Loss: 0.4710, Acc: 64.70%\n",
      "Epoch 3/3, Batch 9080, Loss: 0.5037, Acc: 64.71%\n",
      "Epoch 3/3, Batch 9090, Loss: 0.0097, Acc: 64.71%\n",
      "Epoch 3/3, Batch 9100, Loss: 0.3825, Acc: 64.74%\n",
      "Epoch 3/3, Batch 9110, Loss: 0.0150, Acc: 64.76%\n",
      "Epoch 3/3, Batch 9120, Loss: 0.2081, Acc: 64.77%\n",
      "Epoch 3/3, Batch 9130, Loss: 1.3583, Acc: 64.77%\n",
      "Epoch 3/3, Batch 9140, Loss: 0.7074, Acc: 64.76%\n",
      "Epoch 3/3, Batch 9150, Loss: 0.0333, Acc: 64.77%\n",
      "Epoch 3/3, Batch 9160, Loss: 0.0187, Acc: 64.76%\n",
      "Epoch 3/3, Batch 9170, Loss: 0.3076, Acc: 64.80%\n",
      "Epoch 3/3, Batch 9180, Loss: 0.0875, Acc: 64.84%\n",
      "Epoch 3/3, Batch 9190, Loss: 0.0090, Acc: 64.84%\n",
      "Epoch 3/3, Batch 9200, Loss: 1.7567, Acc: 64.85%\n",
      "Epoch 3/3, Batch 9210, Loss: 0.0927, Acc: 64.84%\n",
      "Epoch 3/3, Batch 9220, Loss: 0.3782, Acc: 64.86%\n",
      "Epoch 3/3, Batch 9230, Loss: 0.7096, Acc: 64.86%\n",
      "Epoch 3/3, Batch 9240, Loss: 0.6980, Acc: 64.85%\n",
      "Epoch 3/3, Batch 9250, Loss: 0.0274, Acc: 64.87%\n",
      "Epoch 3/3, Batch 9260, Loss: 0.9392, Acc: 64.87%\n",
      "Epoch 3/3, Batch 9270, Loss: 0.6380, Acc: 64.90%\n",
      "Epoch 3/3, Batch 9280, Loss: 0.9273, Acc: 64.90%\n",
      "Epoch 3/3, Batch 9290, Loss: 0.8147, Acc: 64.89%\n",
      "Epoch 3/3, Batch 9300, Loss: 1.0087, Acc: 64.92%\n",
      "Epoch 3/3, Batch 9310, Loss: 0.5152, Acc: 64.92%\n",
      "Epoch 3/3, Batch 9320, Loss: 0.6676, Acc: 64.93%\n",
      "Epoch 3/3, Batch 9330, Loss: 0.0003, Acc: 64.92%\n",
      "Epoch 3/3, Batch 9340, Loss: 0.0425, Acc: 64.95%\n",
      "Epoch 3/3, Batch 9350, Loss: 0.1067, Acc: 64.97%\n",
      "Epoch 3/3, Batch 9360, Loss: 0.0066, Acc: 64.96%\n",
      "Epoch 3/3, Batch 9370, Loss: 0.0059, Acc: 64.99%\n",
      "Epoch 3/3, Batch 9380, Loss: 0.5904, Acc: 64.99%\n",
      "Epoch 3/3, Batch 9390, Loss: 0.0058, Acc: 64.98%\n",
      "Epoch 3/3, Batch 9400, Loss: 1.2397, Acc: 64.98%\n",
      "Epoch 3/3, Batch 9410, Loss: 0.5268, Acc: 64.99%\n",
      "Epoch 3/3, Batch 9420, Loss: 0.9113, Acc: 64.99%\n",
      "Epoch 3/3, Batch 9430, Loss: 1.1848, Acc: 64.99%\n",
      "Epoch 3/3, Batch 9440, Loss: 0.3591, Acc: 65.00%\n",
      "Epoch 3/3, Batch 9450, Loss: 0.6565, Acc: 65.01%\n",
      "Epoch 3/3, Batch 9460, Loss: 0.1148, Acc: 65.02%\n",
      "Epoch 3/3, Batch 9470, Loss: 0.1792, Acc: 65.01%\n",
      "Epoch 3/3, Batch 9480, Loss: 0.0759, Acc: 65.02%\n",
      "Epoch 3/3, Batch 9490, Loss: 1.7045, Acc: 65.01%\n",
      "Epoch 3/3, Batch 9500, Loss: 0.2775, Acc: 65.01%\n",
      "Epoch 3/3, Batch 9510, Loss: 0.0214, Acc: 65.03%\n",
      "Epoch 3/3, Batch 9520, Loss: 1.1590, Acc: 65.02%\n",
      "Epoch 3/3, Batch 9530, Loss: 0.8179, Acc: 64.99%\n",
      "Epoch 3/3, Batch 9540, Loss: 1.2347, Acc: 64.99%\n",
      "Epoch 3/3, Batch 9550, Loss: 1.2174, Acc: 65.00%\n",
      "Epoch 3/3, Batch 9560, Loss: 0.0127, Acc: 65.02%\n",
      "Epoch 3/3, Batch 9570, Loss: 0.5309, Acc: 65.04%\n",
      "Epoch 3/3, Batch 9580, Loss: 0.6533, Acc: 65.02%\n",
      "Epoch 3/3, Batch 9590, Loss: 0.0234, Acc: 65.03%\n",
      "Epoch 3/3, Batch 9600, Loss: 0.4942, Acc: 65.01%\n",
      "Epoch 3/3, Batch 9610, Loss: 0.0384, Acc: 65.03%\n",
      "Epoch 3/3, Batch 9620, Loss: 0.6148, Acc: 65.03%\n",
      "Epoch 3/3, Batch 9630, Loss: 0.8858, Acc: 65.05%\n",
      "Epoch 3/3, Batch 9640, Loss: 0.8300, Acc: 65.05%\n",
      "Epoch 3/3, Batch 9650, Loss: 0.3595, Acc: 65.05%\n",
      "Epoch 3/3, Batch 9660, Loss: 1.0938, Acc: 65.05%\n",
      "Epoch 3/3, Batch 9670, Loss: 0.5562, Acc: 65.02%\n",
      "Epoch 3/3, Batch 9680, Loss: 0.7454, Acc: 65.02%\n",
      "Epoch 3/3, Batch 9690, Loss: 0.7400, Acc: 65.00%\n",
      "Epoch 3/3, Batch 9700, Loss: 0.0085, Acc: 64.99%\n",
      "Epoch 3/3, Batch 9710, Loss: 0.0251, Acc: 65.00%\n",
      "Epoch 3/3, Batch 9720, Loss: 1.3476, Acc: 64.96%\n",
      "Epoch 3/3, Batch 9730, Loss: 1.3195, Acc: 64.95%\n",
      "Epoch 3/3, Batch 9740, Loss: 0.6662, Acc: 64.94%\n",
      "Epoch 3/3, Batch 9750, Loss: 0.0857, Acc: 64.95%\n",
      "Epoch 3/3, Batch 9760, Loss: 1.1477, Acc: 64.93%\n",
      "Epoch 3/3, Batch 9770, Loss: 1.0996, Acc: 64.91%\n",
      "Epoch 3/3, Batch 9780, Loss: 0.2063, Acc: 64.90%\n",
      "Epoch 3/3, Batch 9790, Loss: 1.4076, Acc: 64.89%\n",
      "Epoch 3/3, Batch 9800, Loss: 0.5149, Acc: 64.91%\n",
      "Epoch 3/3, Batch 9810, Loss: 0.3112, Acc: 64.94%\n",
      "Epoch 3/3, Batch 9820, Loss: 0.7036, Acc: 64.92%\n",
      "Epoch 3/3, Batch 9830, Loss: 0.5928, Acc: 64.91%\n",
      "Epoch 3/3, Batch 9840, Loss: 0.8779, Acc: 64.91%\n",
      "Epoch 3/3, Batch 9850, Loss: 0.0682, Acc: 64.93%\n",
      "Epoch 3/3, Batch 9860, Loss: 1.1069, Acc: 64.93%\n",
      "Epoch 3/3, Batch 9870, Loss: 0.1664, Acc: 64.95%\n",
      "Epoch 3/3, Batch 9880, Loss: 0.0191, Acc: 64.94%\n",
      "Epoch 3/3, Batch 9890, Loss: 0.8242, Acc: 64.94%\n",
      "Epoch 3/3, Batch 9900, Loss: 0.4852, Acc: 64.96%\n",
      "Epoch 3/3, Batch 9910, Loss: 0.5733, Acc: 64.99%\n",
      "Epoch 3/3, Batch 9920, Loss: 0.3761, Acc: 65.01%\n",
      "Epoch 3/3, Batch 9930, Loss: 1.8549, Acc: 65.02%\n",
      "Epoch 3/3, Batch 9940, Loss: 0.4854, Acc: 65.01%\n",
      "Epoch 3/3, Batch 9950, Loss: 1.1248, Acc: 65.00%\n",
      "Epoch 3/3, Batch 9960, Loss: 0.0367, Acc: 64.99%\n",
      "Epoch 3/3, Batch 9970, Loss: 0.0009, Acc: 65.01%\n",
      "Epoch 3/3, Batch 9980, Loss: 1.1490, Acc: 65.00%\n",
      "Epoch 3/3, Batch 9990, Loss: 0.9220, Acc: 65.00%\n",
      "Epoch 3/3, Batch 10000, Loss: 0.6691, Acc: 65.01%\n",
      "Epoch 3/3, Batch 10010, Loss: 0.0691, Acc: 65.02%\n",
      "Epoch 3/3, Batch 10020, Loss: 0.9303, Acc: 65.02%\n",
      "Epoch 3/3, Batch 10030, Loss: 0.6317, Acc: 65.02%\n",
      "Epoch 3/3, Batch 10040, Loss: 0.0378, Acc: 65.01%\n",
      "Epoch 3/3, Batch 10050, Loss: 0.3911, Acc: 65.03%\n",
      "Epoch 3/3, Batch 10060, Loss: 1.9016, Acc: 65.01%\n",
      "Epoch 3/3, Batch 10070, Loss: 0.7317, Acc: 65.02%\n",
      "Epoch 3/3, Batch 10080, Loss: 1.7691, Acc: 65.01%\n",
      "Epoch 3/3, Batch 10090, Loss: 0.2970, Acc: 65.00%\n",
      "Epoch 3/3, Batch 10100, Loss: 1.2334, Acc: 64.99%\n",
      "Epoch 3/3, Batch 10110, Loss: 0.9053, Acc: 65.01%\n",
      "Epoch 3/3, Batch 10120, Loss: 0.1028, Acc: 65.00%\n",
      "Epoch 3/3, Batch 10130, Loss: 0.5749, Acc: 64.98%\n",
      "Epoch 3/3, Batch 10140, Loss: 0.7761, Acc: 64.98%\n",
      "Epoch 3/3, Batch 10150, Loss: 1.4368, Acc: 65.00%\n",
      "Epoch 3/3, Batch 10160, Loss: 0.0635, Acc: 64.99%\n",
      "Epoch 3/3, Batch 10170, Loss: 0.8563, Acc: 65.00%\n",
      "Epoch 3/3, Batch 10180, Loss: 0.3447, Acc: 65.01%\n",
      "Epoch 3/3, Batch 10190, Loss: 1.2077, Acc: 65.01%\n",
      "Epoch 3/3, Batch 10200, Loss: 0.2859, Acc: 65.01%\n",
      "Epoch 3/3, Batch 10210, Loss: 0.0201, Acc: 65.00%\n",
      "Epoch 3/3, Batch 10220, Loss: 0.1758, Acc: 64.99%\n",
      "Epoch 3/3, Batch 10230, Loss: 0.5480, Acc: 64.99%\n",
      "Epoch 3/3, Batch 10240, Loss: 1.0767, Acc: 64.97%\n",
      "Epoch 3/3, Batch 10250, Loss: 0.7552, Acc: 65.00%\n",
      "Epoch 3/3, Batch 10260, Loss: 0.9747, Acc: 64.98%\n",
      "Epoch 3/3, Batch 10270, Loss: 1.0963, Acc: 64.97%\n",
      "Epoch 3/3, Batch 10280, Loss: 0.0099, Acc: 64.98%\n",
      "Epoch 3/3, Batch 10290, Loss: 1.0174, Acc: 64.98%\n",
      "Epoch 3/3, Batch 10300, Loss: 0.0070, Acc: 64.95%\n",
      "Epoch 3/3, Batch 10310, Loss: 0.9128, Acc: 64.94%\n",
      "Epoch 3/3, Batch 10320, Loss: 0.3561, Acc: 64.95%\n",
      "Epoch 3/3, Batch 10330, Loss: 0.4827, Acc: 64.95%\n",
      "Epoch 3/3, Batch 10340, Loss: 0.0013, Acc: 64.96%\n",
      "Epoch 3/3, Batch 10350, Loss: 0.5474, Acc: 64.95%\n",
      "Epoch 3/3, Batch 10360, Loss: 1.3489, Acc: 64.94%\n",
      "Epoch 3/3, Batch 10370, Loss: 1.5714, Acc: 64.92%\n",
      "Epoch 3/3, Batch 10380, Loss: 0.4144, Acc: 64.92%\n",
      "Epoch 3/3, Batch 10390, Loss: 0.0750, Acc: 64.91%\n",
      "Epoch 3/3, Batch 10400, Loss: 2.0194, Acc: 64.90%\n",
      "Epoch 3/3, Batch 10410, Loss: 0.6064, Acc: 64.91%\n",
      "Epoch 3/3, Batch 10420, Loss: 0.3598, Acc: 64.92%\n",
      "Epoch 3/3, Batch 10430, Loss: 0.2356, Acc: 64.93%\n",
      "Epoch 3/3, Batch 10440, Loss: 0.0067, Acc: 64.91%\n",
      "Epoch 3/3, Batch 10450, Loss: 0.0385, Acc: 64.89%\n",
      "Epoch 3/3, Batch 10460, Loss: 0.0806, Acc: 64.87%\n",
      "Epoch 3/3, Batch 10470, Loss: 0.6537, Acc: 64.87%\n",
      "Epoch 3/3, Batch 10480, Loss: 1.3527, Acc: 64.89%\n",
      "Epoch 3/3, Batch 10490, Loss: 0.0089, Acc: 64.88%\n",
      "Epoch 3/3, Batch 10500, Loss: 0.8298, Acc: 64.85%\n",
      "Epoch 3/3, Batch 10510, Loss: 1.1936, Acc: 64.85%\n",
      "Epoch 3/3, Batch 10520, Loss: 0.3124, Acc: 64.85%\n",
      "Epoch 3/3, Batch 10530, Loss: 0.0255, Acc: 64.86%\n",
      "Epoch 3/3, Batch 10540, Loss: 0.9562, Acc: 64.87%\n",
      "Epoch 3/3, Batch 10550, Loss: 0.8974, Acc: 64.88%\n",
      "Epoch 3/3, Batch 10560, Loss: 0.0910, Acc: 64.86%\n",
      "Epoch 3/3, Batch 10570, Loss: 0.5055, Acc: 64.87%\n",
      "Epoch 3/3, Batch 10580, Loss: 0.0123, Acc: 64.87%\n",
      "Epoch 3/3, Batch 10590, Loss: 0.0150, Acc: 64.89%\n",
      "Epoch 3/3, Batch 10600, Loss: 1.3393, Acc: 64.90%\n",
      "Epoch 3/3, Batch 10610, Loss: 0.2459, Acc: 64.90%\n",
      "Epoch 3/3, Batch 10620, Loss: 1.1010, Acc: 64.89%\n",
      "Epoch 3/3, Batch 10630, Loss: 0.4184, Acc: 64.90%\n",
      "Epoch 3/3, Batch 10640, Loss: 0.2870, Acc: 64.90%\n",
      "Epoch 3/3, Batch 10650, Loss: 0.4084, Acc: 64.91%\n",
      "Epoch 3/3, Batch 10660, Loss: 0.6091, Acc: 64.91%\n",
      "Epoch 3/3, Batch 10670, Loss: 0.7126, Acc: 64.90%\n",
      "Epoch 3/3, Batch 10680, Loss: 0.1364, Acc: 64.88%\n",
      "Epoch 3/3, Batch 10690, Loss: 0.4204, Acc: 64.89%\n",
      "Epoch 3/3, Batch 10700, Loss: 0.6845, Acc: 64.90%\n",
      "Epoch 3/3, Batch 10710, Loss: 0.0303, Acc: 64.90%\n",
      "Epoch 3/3, Batch 10720, Loss: 1.0834, Acc: 64.91%\n",
      "Epoch 3/3, Batch 10730, Loss: 0.4308, Acc: 64.91%\n",
      "Epoch 3/3, Batch 10740, Loss: 0.8373, Acc: 64.89%\n",
      "Epoch 3/3, Batch 10750, Loss: 1.7668, Acc: 64.90%\n",
      "Epoch 3/3, Batch 10760, Loss: 0.3179, Acc: 64.89%\n",
      "Epoch 3/3, Batch 10770, Loss: 0.1534, Acc: 64.91%\n",
      "Epoch 3/3, Batch 10780, Loss: 0.8022, Acc: 64.87%\n",
      "Epoch 3/3, Batch 10790, Loss: 1.2660, Acc: 64.88%\n",
      "Epoch 3/3, Batch 10800, Loss: 0.9391, Acc: 64.87%\n",
      "Epoch 3/3, Batch 10810, Loss: 0.1442, Acc: 64.87%\n",
      "Epoch 3/3, Batch 10820, Loss: 0.8164, Acc: 64.86%\n",
      "Epoch 3/3, Batch 10830, Loss: 0.4453, Acc: 64.87%\n",
      "Epoch 3/3, Batch 10840, Loss: 0.6690, Acc: 64.89%\n",
      "Epoch 3/3, Batch 10850, Loss: 0.0026, Acc: 64.91%\n",
      "Epoch 3/3, Batch 10860, Loss: 0.9743, Acc: 64.89%\n",
      "Epoch 3/3, Batch 10870, Loss: 1.0092, Acc: 64.90%\n",
      "Epoch 3/3, Batch 10880, Loss: 1.7699, Acc: 64.89%\n",
      "Epoch 3/3, Batch 10890, Loss: 1.2435, Acc: 64.87%\n",
      "Epoch 3/3, Batch 10900, Loss: 0.6910, Acc: 64.88%\n",
      "Epoch 3/3, Batch 10910, Loss: 0.3626, Acc: 64.90%\n",
      "Epoch 3/3, Batch 10920, Loss: 0.0498, Acc: 64.89%\n",
      "Epoch 3/3, Batch 10930, Loss: 0.0711, Acc: 64.89%\n",
      "Epoch 3/3, Batch 10940, Loss: 0.3016, Acc: 64.89%\n",
      "Epoch 3/3, Batch 10950, Loss: 0.4303, Acc: 64.91%\n",
      "Epoch 3/3, Batch 10960, Loss: 0.0205, Acc: 64.89%\n",
      "Epoch 3/3, Batch 10970, Loss: 1.1019, Acc: 64.87%\n",
      "Epoch 3/3, Batch 10980, Loss: 0.4098, Acc: 64.88%\n",
      "Epoch 3/3, Batch 10990, Loss: 1.0258, Acc: 64.89%\n",
      "Epoch 3/3, Batch 11000, Loss: 0.5265, Acc: 64.86%\n",
      "Epoch 3/3, Batch 11010, Loss: 0.2760, Acc: 64.89%\n",
      "Epoch 3/3, Batch 11020, Loss: 0.5352, Acc: 64.89%\n",
      "Epoch 3/3, Batch 11030, Loss: 0.0134, Acc: 64.92%\n",
      "Epoch 3/3, Batch 11040, Loss: 0.4249, Acc: 64.91%\n",
      "Epoch 3/3, Batch 11050, Loss: 0.5158, Acc: 64.91%\n",
      "Epoch 3/3, Batch 11060, Loss: 0.4542, Acc: 64.89%\n",
      "Epoch 3/3, Batch 11070, Loss: 0.5402, Acc: 64.86%\n",
      "Epoch 3/3, Batch 11080, Loss: 0.0653, Acc: 64.86%\n",
      "Epoch 3/3, Batch 11090, Loss: 1.1533, Acc: 64.86%\n",
      "Epoch 3/3, Batch 11100, Loss: 2.0153, Acc: 64.86%\n",
      "Epoch 3/3, Batch 11110, Loss: 0.6477, Acc: 64.86%\n",
      "Epoch 3/3, Batch 11120, Loss: 0.6156, Acc: 64.89%\n",
      "Epoch 3/3, Batch 11130, Loss: 1.0558, Acc: 64.89%\n",
      "Epoch 3/3, Batch 11140, Loss: 1.4869, Acc: 64.86%\n",
      "Epoch 3/3, Batch 11150, Loss: 0.1461, Acc: 64.88%\n",
      "Epoch 3/3, Batch 11160, Loss: 0.0100, Acc: 64.89%\n",
      "Epoch 3/3, Batch 11170, Loss: 0.3640, Acc: 64.90%\n",
      "Epoch 3/3, Batch 11180, Loss: 0.3897, Acc: 64.90%\n",
      "Epoch 3/3, Batch 11190, Loss: 0.2720, Acc: 64.90%\n",
      "Epoch 3/3, Batch 11200, Loss: 0.0650, Acc: 64.90%\n",
      "Epoch 3/3, Batch 11210, Loss: 0.5566, Acc: 64.91%\n",
      "Epoch 3/3, Batch 11220, Loss: 0.0107, Acc: 64.91%\n",
      "Epoch 3/3, Batch 11230, Loss: 0.1553, Acc: 64.92%\n",
      "Epoch 3/3, Batch 11240, Loss: 0.8950, Acc: 64.91%\n",
      "Epoch 3/3, Batch 11250, Loss: 0.6220, Acc: 64.92%\n",
      "Epoch 3/3, Batch 11260, Loss: 0.4337, Acc: 64.89%\n",
      "Epoch 3/3, Batch 11270, Loss: 0.4300, Acc: 64.90%\n",
      "Epoch 3/3, Batch 11280, Loss: 0.0182, Acc: 64.90%\n",
      "Epoch 3/3, Batch 11290, Loss: 0.3332, Acc: 64.87%\n",
      "Epoch 3/3, Batch 11300, Loss: 0.9479, Acc: 64.86%\n",
      "Epoch 3/3, Batch 11310, Loss: 0.4499, Acc: 64.85%\n",
      "Epoch 3/3, Batch 11320, Loss: 0.2250, Acc: 64.84%\n",
      "Epoch 3/3, Batch 11330, Loss: 0.8688, Acc: 64.86%\n",
      "Epoch 3/3, Batch 11340, Loss: 1.0013, Acc: 64.85%\n",
      "Epoch 3/3, Batch 11350, Loss: 0.2686, Acc: 64.85%\n",
      "Epoch 3/3, Batch 11360, Loss: 0.4335, Acc: 64.84%\n",
      "Epoch 3/3, Batch 11370, Loss: 0.2807, Acc: 64.86%\n",
      "Epoch 3/3, Batch 11380, Loss: 0.9935, Acc: 64.84%\n",
      "Epoch 3/3, Batch 11390, Loss: 0.4682, Acc: 64.85%\n",
      "Epoch 3/3, Batch 11400, Loss: 0.3199, Acc: 64.85%\n",
      "Epoch 3/3, Batch 11410, Loss: 1.5125, Acc: 64.83%\n",
      "Epoch 3/3, Batch 11420, Loss: 1.2356, Acc: 64.81%\n",
      "Epoch 3/3, Batch 11430, Loss: 1.1928, Acc: 64.81%\n",
      "Epoch 3/3, Batch 11440, Loss: 0.8768, Acc: 64.81%\n",
      "Epoch 3/3, Batch 11450, Loss: 0.8409, Acc: 64.81%\n",
      "Epoch 3/3, Batch 11460, Loss: 0.8870, Acc: 64.80%\n",
      "Epoch 3/3, Batch 11470, Loss: 0.2383, Acc: 64.82%\n",
      "Epoch 3/3, Batch 11480, Loss: 0.7370, Acc: 64.80%\n",
      "Epoch 3/3, Batch 11490, Loss: 1.7122, Acc: 64.79%\n",
      "Epoch 3/3, Batch 11500, Loss: 0.9407, Acc: 64.80%\n",
      "Epoch 3/3, Batch 11510, Loss: 1.1183, Acc: 64.80%\n",
      "Epoch 3/3, Batch 11520, Loss: 0.3451, Acc: 64.81%\n",
      "Epoch 3/3, Batch 11530, Loss: 0.4738, Acc: 64.81%\n",
      "Epoch 3/3, Batch 11540, Loss: 0.7475, Acc: 64.79%\n",
      "Epoch 3/3, Batch 11550, Loss: 0.6863, Acc: 64.76%\n",
      "Epoch 3/3, Batch 11560, Loss: 0.3293, Acc: 64.79%\n",
      "Epoch 3/3, Batch 11570, Loss: 2.7577, Acc: 64.79%\n",
      "Epoch 3/3, Batch 11580, Loss: 0.5304, Acc: 64.79%\n",
      "Epoch 3/3, Batch 11590, Loss: 0.5529, Acc: 64.78%\n",
      "Epoch 3/3, Batch 11600, Loss: 0.5216, Acc: 64.80%\n",
      "Epoch 3/3, Batch 11610, Loss: 0.8151, Acc: 64.77%\n",
      "Epoch 3/3, Batch 11620, Loss: 0.0023, Acc: 64.80%\n",
      "Epoch 3/3, Batch 11630, Loss: 0.5063, Acc: 64.78%\n",
      "Epoch 3/3, Batch 11640, Loss: 0.4066, Acc: 64.79%\n",
      "Epoch 3/3, Batch 11650, Loss: 0.1255, Acc: 64.79%\n",
      "Epoch 3/3, Batch 11660, Loss: 1.0916, Acc: 64.80%\n",
      "Epoch 3/3, Batch 11670, Loss: 0.0043, Acc: 64.82%\n",
      "Epoch 3/3, Batch 11680, Loss: 1.2649, Acc: 64.83%\n",
      "Epoch 3/3, Batch 11690, Loss: 1.2907, Acc: 64.83%\n",
      "Epoch 3/3, Batch 11700, Loss: 0.4934, Acc: 64.85%\n",
      "Epoch 3/3, Batch 11710, Loss: 0.5335, Acc: 64.85%\n",
      "Epoch 3/3, Batch 11720, Loss: 0.0054, Acc: 64.86%\n",
      "Epoch 3/3, Batch 11730, Loss: 0.7861, Acc: 64.87%\n",
      "Epoch 3/3, Batch 11740, Loss: 1.2096, Acc: 64.88%\n",
      "Epoch 3/3, Batch 11750, Loss: 0.4818, Acc: 64.87%\n",
      "Epoch 3/3, Batch 11760, Loss: 0.3021, Acc: 64.88%\n",
      "Epoch 3/3, Batch 11770, Loss: 0.1772, Acc: 64.90%\n",
      "Epoch 3/3, Batch 11780, Loss: 0.0599, Acc: 64.90%\n",
      "Epoch 3/3, Batch 11790, Loss: 0.0762, Acc: 64.91%\n",
      "Epoch 3/3, Batch 11800, Loss: 1.0246, Acc: 64.91%\n",
      "Epoch 3/3, Batch 11810, Loss: 0.1915, Acc: 64.91%\n",
      "Epoch 3/3, Batch 11820, Loss: 0.8962, Acc: 64.91%\n",
      "Epoch 3/3, Batch 11830, Loss: 1.4793, Acc: 64.93%\n",
      "Epoch 3/3, Batch 11840, Loss: 0.0754, Acc: 64.94%\n",
      "Epoch 3/3, Batch 11850, Loss: 2.7000, Acc: 64.92%\n",
      "Epoch 3/3, Batch 11860, Loss: 0.1510, Acc: 64.93%\n",
      "Epoch 3/3, Batch 11870, Loss: 0.3821, Acc: 64.91%\n",
      "Epoch 3/3, Batch 11880, Loss: 0.8083, Acc: 64.92%\n",
      "Epoch 3/3, Batch 11890, Loss: 0.0452, Acc: 64.93%\n",
      "Epoch 3/3, Batch 11900, Loss: 0.2168, Acc: 64.94%\n",
      "Epoch 3/3, Batch 11910, Loss: 2.0040, Acc: 64.91%\n",
      "Epoch 3/3, Batch 11920, Loss: 0.0126, Acc: 64.89%\n",
      "Epoch 3/3, Batch 11930, Loss: 0.4405, Acc: 64.91%\n",
      "Epoch 3/3, Batch 11940, Loss: 0.3832, Acc: 64.92%\n",
      "Epoch 3/3, Batch 11950, Loss: 0.8318, Acc: 64.91%\n",
      "Epoch 3/3, Batch 11960, Loss: 0.0806, Acc: 64.91%\n",
      "Epoch 3/3, Batch 11970, Loss: 0.5352, Acc: 64.92%\n",
      "Epoch 3/3, Batch 11980, Loss: 0.6257, Acc: 64.92%\n",
      "Epoch 3/3, Batch 11990, Loss: 0.3487, Acc: 64.93%\n",
      "Epoch 3/3, Batch 12000, Loss: 0.0047, Acc: 64.93%\n",
      "Epoch 3/3, Batch 12010, Loss: 1.3180, Acc: 64.92%\n",
      "Epoch 3/3, Batch 12020, Loss: 0.0685, Acc: 64.92%\n",
      "Epoch 3/3, Batch 12030, Loss: 0.4048, Acc: 64.92%\n",
      "Epoch 3/3, Batch 12040, Loss: 0.5459, Acc: 64.90%\n",
      "Epoch 3/3, Batch 12050, Loss: 0.0511, Acc: 64.88%\n",
      "Epoch 3/3, Batch 12060, Loss: 0.7770, Acc: 64.90%\n",
      "Epoch 3/3, Batch 12070, Loss: 0.3409, Acc: 64.91%\n",
      "Epoch 3/3, Batch 12080, Loss: 0.9569, Acc: 64.92%\n",
      "Epoch 3/3, Batch 12090, Loss: 1.0093, Acc: 64.90%\n",
      "Epoch 3/3, Batch 12100, Loss: 0.0575, Acc: 64.90%\n",
      "Epoch 3/3, Batch 12110, Loss: 0.8285, Acc: 64.89%\n",
      "Epoch 3/3, Batch 12120, Loss: 0.1925, Acc: 64.88%\n",
      "Epoch 3/3, Batch 12130, Loss: 1.3077, Acc: 64.88%\n",
      "Epoch 3/3, Batch 12140, Loss: 0.5522, Acc: 64.89%\n",
      "Epoch 3/3, Batch 12150, Loss: 0.9007, Acc: 64.88%\n",
      "Epoch 3/3, Batch 12160, Loss: 0.2693, Acc: 64.89%\n",
      "Epoch 3/3, Batch 12170, Loss: 0.6423, Acc: 64.90%\n",
      "Epoch 3/3, Batch 12180, Loss: 0.6736, Acc: 64.92%\n",
      "Epoch 3/3, Batch 12190, Loss: 0.3706, Acc: 64.92%\n",
      "Epoch 3/3, Batch 12200, Loss: 0.1209, Acc: 64.93%\n",
      "Epoch 3/3, Batch 12210, Loss: 0.1693, Acc: 64.93%\n",
      "Epoch 3/3, Batch 12220, Loss: 1.6329, Acc: 64.91%\n",
      "Epoch 3/3, Batch 12230, Loss: 0.0364, Acc: 64.93%\n",
      "Epoch 3/3, Batch 12240, Loss: 0.5363, Acc: 64.94%\n",
      "Epoch 3/3, Batch 12250, Loss: 0.2709, Acc: 64.94%\n",
      "Epoch 3/3, Batch 12260, Loss: 1.2092, Acc: 64.95%\n",
      "Epoch 3/3, Batch 12270, Loss: 0.0908, Acc: 64.97%\n",
      "Epoch 3/3, Batch 12280, Loss: 0.0281, Acc: 64.97%\n",
      "Epoch 3/3, Batch 12290, Loss: 0.0973, Acc: 64.97%\n",
      "Epoch 3/3, Batch 12300, Loss: 0.6900, Acc: 64.98%\n",
      "Epoch 3/3, Batch 12310, Loss: 0.0124, Acc: 64.97%\n",
      "Epoch 3/3, Batch 12320, Loss: 0.3119, Acc: 64.97%\n",
      "Epoch 3/3, Batch 12330, Loss: 1.1751, Acc: 64.96%\n",
      "Epoch 3/3, Batch 12340, Loss: 0.3935, Acc: 64.96%\n",
      "Epoch 3/3, Batch 12350, Loss: 0.0147, Acc: 64.97%\n",
      "Epoch 3/3, Batch 12360, Loss: 0.7324, Acc: 64.95%\n",
      "Epoch 3/3, Batch 12370, Loss: 1.4088, Acc: 64.97%\n",
      "Epoch 3/3, Batch 12380, Loss: 0.5621, Acc: 64.98%\n",
      "Epoch 3/3, Batch 12390, Loss: 1.1962, Acc: 64.97%\n",
      "Epoch 3/3, Batch 12400, Loss: 0.5706, Acc: 64.97%\n",
      "Epoch 3/3, Batch 12410, Loss: 0.6167, Acc: 64.99%\n",
      "Epoch 3/3, Batch 12420, Loss: 0.0521, Acc: 64.99%\n",
      "Epoch 3/3, Batch 12430, Loss: 0.0368, Acc: 65.00%\n",
      "Epoch 3/3, Batch 12440, Loss: 1.2729, Acc: 64.99%\n",
      "Epoch 3/3, Batch 12450, Loss: 0.6151, Acc: 64.99%\n",
      "Epoch 3/3, Batch 12460, Loss: 1.9784, Acc: 64.99%\n",
      "Epoch 3/3, Batch 12470, Loss: 0.0051, Acc: 64.98%\n",
      "Epoch 3/3, Batch 12480, Loss: 0.0103, Acc: 64.98%\n",
      "Epoch 3/3, Batch 12490, Loss: 1.1693, Acc: 64.96%\n",
      "Epoch 3/3, Batch 12500, Loss: 0.2319, Acc: 64.97%\n",
      "Epoch 3/3, Batch 12510, Loss: 1.2584, Acc: 64.95%\n",
      "Epoch 3/3, Batch 12520, Loss: 0.6336, Acc: 64.94%\n",
      "Epoch 3/3, Batch 12530, Loss: 0.0603, Acc: 64.96%\n",
      "Epoch 3/3, Batch 12540, Loss: 0.2921, Acc: 64.97%\n",
      "Epoch 3/3, Batch 12550, Loss: 0.2085, Acc: 64.98%\n",
      "Epoch 3/3, Batch 12560, Loss: 0.0001, Acc: 64.98%\n",
      "Epoch 3/3, Batch 12570, Loss: 0.9741, Acc: 64.97%\n",
      "Epoch 3/3, Batch 12580, Loss: 0.2469, Acc: 64.98%\n",
      "Epoch 3/3, Batch 12590, Loss: 0.0623, Acc: 64.97%\n",
      "Epoch 3/3, Batch 12600, Loss: 0.5857, Acc: 64.98%\n",
      "Epoch 3/3, Batch 12610, Loss: 0.0443, Acc: 64.98%\n",
      "Epoch 3/3, Batch 12620, Loss: 0.1856, Acc: 64.99%\n",
      "Epoch 3/3, Batch 12630, Loss: 0.6592, Acc: 65.00%\n",
      "Epoch 3/3, Batch 12640, Loss: 0.1235, Acc: 65.00%\n",
      "Epoch 3/3, Batch 12650, Loss: 0.5913, Acc: 65.02%\n",
      "Epoch 3/3, Batch 12660, Loss: 1.0240, Acc: 65.00%\n",
      "Epoch 3/3, Batch 12670, Loss: 0.6961, Acc: 65.00%\n",
      "Epoch 3/3, Batch 12680, Loss: 0.0340, Acc: 65.03%\n",
      "Epoch 3/3, Batch 12690, Loss: 0.0426, Acc: 65.02%\n",
      "Epoch 3/3, Batch 12700, Loss: 0.7703, Acc: 65.02%\n",
      "Epoch 3/3, Batch 12710, Loss: 0.6590, Acc: 65.02%\n",
      "Epoch 3/3, Batch 12720, Loss: 0.5730, Acc: 65.03%\n",
      "Epoch 3/3, Batch 12730, Loss: 0.5349, Acc: 65.01%\n",
      "Epoch 3/3, Batch 12740, Loss: 0.1020, Acc: 65.03%\n",
      "Epoch 3/3, Batch 12750, Loss: 1.6196, Acc: 65.01%\n",
      "Epoch 3/3, Batch 12760, Loss: 0.0008, Acc: 65.02%\n",
      "Epoch 3/3, Batch 12770, Loss: 0.3371, Acc: 65.01%\n",
      "Epoch 3/3, Batch 12780, Loss: 0.0323, Acc: 65.02%\n",
      "Epoch 3/3, Batch 12790, Loss: 0.8502, Acc: 64.99%\n",
      "Epoch 3/3, Batch 12800, Loss: 0.0548, Acc: 64.98%\n",
      "Epoch 3/3, Batch 12810, Loss: 0.0389, Acc: 64.98%\n",
      "Epoch 3/3, Batch 12820, Loss: 0.0548, Acc: 64.97%\n",
      "Epoch 3/3, Batch 12830, Loss: 1.2345, Acc: 64.98%\n",
      "Epoch 3/3, Batch 12840, Loss: 0.4628, Acc: 64.99%\n",
      "Epoch 3/3, Batch 12850, Loss: 0.7386, Acc: 64.99%\n",
      "Epoch 3/3, Batch 12860, Loss: 0.3568, Acc: 64.99%\n",
      "Epoch 3/3, Batch 12870, Loss: 0.0082, Acc: 64.98%\n",
      "Epoch 3/3, Batch 12880, Loss: 0.0940, Acc: 64.99%\n",
      "Epoch 3/3, Batch 12890, Loss: 0.4626, Acc: 64.98%\n",
      "Epoch 3/3, Batch 12900, Loss: 1.2413, Acc: 64.99%\n",
      "Epoch 3/3, Batch 12910, Loss: 0.9159, Acc: 64.99%\n",
      "Epoch 3/3, Batch 12920, Loss: 1.1416, Acc: 64.99%\n",
      "Epoch 3/3, Batch 12930, Loss: 0.7014, Acc: 64.98%\n",
      "Epoch 3/3, Batch 12940, Loss: 0.0095, Acc: 64.96%\n",
      "Epoch 3/3, Batch 12950, Loss: 0.4317, Acc: 64.94%\n",
      "Epoch 3/3, Batch 12960, Loss: 0.2782, Acc: 64.93%\n",
      "Epoch 3/3, Batch 12970, Loss: 1.6284, Acc: 64.93%\n",
      "Epoch 3/3, Batch 12980, Loss: 0.0071, Acc: 64.96%\n",
      "Epoch 3/3, Batch 12990, Loss: 0.1251, Acc: 64.95%\n",
      "Epoch 3/3, Batch 13000, Loss: 0.9871, Acc: 64.96%\n",
      "Epoch 3/3, Batch 13010, Loss: 0.6856, Acc: 64.98%\n",
      "Epoch 3/3, Batch 13020, Loss: 0.2527, Acc: 65.00%\n",
      "Epoch 3/3, Batch 13030, Loss: 0.4865, Acc: 65.01%\n",
      "Epoch 3/3, Batch 13040, Loss: 0.5660, Acc: 65.00%\n",
      "Epoch 3/3, Batch 13050, Loss: 0.9128, Acc: 64.98%\n",
      "Epoch 3/3, Batch 13060, Loss: 0.0781, Acc: 64.97%\n",
      "Epoch 3/3, Batch 13070, Loss: 0.0011, Acc: 64.96%\n",
      "Epoch 3/3, Batch 13080, Loss: 0.3516, Acc: 64.95%\n",
      "Epoch 3/3, Batch 13090, Loss: 0.7152, Acc: 64.96%\n",
      "Epoch 3/3, Batch 13100, Loss: 1.5212, Acc: 64.95%\n",
      "Epoch 3/3, Batch 13110, Loss: 0.7595, Acc: 64.92%\n",
      "Epoch 3/3, Batch 13120, Loss: 0.2291, Acc: 64.93%\n",
      "Epoch 3/3, Batch 13130, Loss: 0.3926, Acc: 64.93%\n",
      "Epoch 3/3, Batch 13140, Loss: 0.4428, Acc: 64.93%\n",
      "Epoch 3/3, Batch 13150, Loss: 1.4065, Acc: 64.92%\n",
      "Epoch 3/3, Batch 13160, Loss: 0.0210, Acc: 64.92%\n",
      "Epoch 3/3, Batch 13170, Loss: 0.4119, Acc: 64.92%\n",
      "Epoch 3/3, Batch 13180, Loss: 0.4415, Acc: 64.93%\n",
      "Epoch 3/3, Batch 13190, Loss: 1.0455, Acc: 64.93%\n",
      "Epoch 3/3, Batch 13200, Loss: 0.7783, Acc: 64.91%\n",
      "Epoch 3/3, Batch 13210, Loss: 0.5992, Acc: 64.92%\n",
      "Epoch 3/3, Batch 13220, Loss: 1.2683, Acc: 64.93%\n",
      "Epoch 3/3, Batch 13230, Loss: 0.2677, Acc: 64.92%\n",
      "Epoch 3/3, Batch 13240, Loss: 0.0157, Acc: 64.93%\n",
      "Epoch 3/3, Batch 13250, Loss: 0.0366, Acc: 64.93%\n",
      "Epoch 3/3, Batch 13260, Loss: 0.4250, Acc: 64.93%\n",
      "Epoch 3/3, Batch 13270, Loss: 0.0004, Acc: 64.92%\n",
      "Epoch 3/3, Batch 13280, Loss: 0.4090, Acc: 64.93%\n",
      "Epoch 3/3, Batch 13290, Loss: 1.2351, Acc: 64.92%\n",
      "Epoch 3/3, Batch 13300, Loss: 1.3892, Acc: 64.93%\n",
      "Epoch 3/3, Batch 13310, Loss: 0.0033, Acc: 64.92%\n",
      "Epoch 3/3, Batch 13320, Loss: 0.0869, Acc: 64.92%\n",
      "Epoch 3/3, Batch 13330, Loss: 0.3674, Acc: 64.92%\n",
      "Epoch 3/3, Batch 13340, Loss: 0.7469, Acc: 64.91%\n",
      "Epoch 3/3, Batch 13350, Loss: 0.5991, Acc: 64.90%\n",
      "Epoch 3/3, Batch 13360, Loss: 1.8783, Acc: 64.90%\n",
      "Epoch 3/3, Batch 13370, Loss: 0.3894, Acc: 64.89%\n",
      "Epoch 3/3, Batch 13380, Loss: 0.2065, Acc: 64.91%\n",
      "Epoch 3/3, Batch 13390, Loss: 2.0400, Acc: 64.92%\n",
      "Epoch 3/3, Batch 13400, Loss: 2.4754, Acc: 64.91%\n",
      "Epoch 3/3, Batch 13410, Loss: 0.1962, Acc: 64.92%\n",
      "Epoch 3/3, Batch 13420, Loss: 1.0933, Acc: 64.91%\n",
      "Epoch 3/3, Batch 13430, Loss: 0.9262, Acc: 64.89%\n",
      "Epoch 3/3, Batch 13440, Loss: 0.1305, Acc: 64.88%\n",
      "Epoch 3/3, Batch 13450, Loss: 0.1992, Acc: 64.88%\n",
      "Epoch 3/3, Batch 13460, Loss: 0.6446, Acc: 64.89%\n",
      "Epoch 3/3, Batch 13470, Loss: 0.4185, Acc: 64.89%\n",
      "Epoch 3/3, Batch 13480, Loss: 0.1935, Acc: 64.88%\n",
      "Epoch 3/3, Batch 13490, Loss: 1.2064, Acc: 64.89%\n",
      "Epoch 3/3, Batch 13500, Loss: 0.0260, Acc: 64.87%\n",
      "Epoch 3/3, Batch 13510, Loss: 0.1001, Acc: 64.87%\n",
      "Epoch 3/3, Batch 13520, Loss: 0.6450, Acc: 64.86%\n",
      "Epoch 3/3, Batch 13530, Loss: 1.1525, Acc: 64.87%\n",
      "Epoch 3/3, Batch 13540, Loss: 0.0079, Acc: 64.86%\n",
      "Epoch 3/3, Batch 13550, Loss: 0.4753, Acc: 64.88%\n",
      "Epoch 3/3, Batch 13560, Loss: 0.8687, Acc: 64.88%\n",
      "Epoch 3/3, Batch 13570, Loss: 1.1338, Acc: 64.87%\n",
      "Epoch 3/3, Batch 13580, Loss: 0.5009, Acc: 64.87%\n",
      "Epoch 3/3, Batch 13590, Loss: 0.7580, Acc: 64.87%\n",
      "Epoch 3/3, Batch 13600, Loss: 0.8713, Acc: 64.85%\n",
      "Epoch 3/3, Batch 13610, Loss: 0.8470, Acc: 64.83%\n",
      "Epoch 3/3, Batch 13620, Loss: 0.2646, Acc: 64.84%\n",
      "Epoch 3/3, Batch 13630, Loss: 0.6117, Acc: 64.84%\n",
      "Epoch 3/3, Batch 13640, Loss: 0.0126, Acc: 64.84%\n",
      "Epoch 3/3, Batch 13650, Loss: 0.0219, Acc: 64.82%\n",
      "Epoch 3/3, Batch 13660, Loss: 0.0314, Acc: 64.81%\n",
      "Epoch 3/3, Batch 13670, Loss: 0.3116, Acc: 64.83%\n",
      "Epoch 3/3, Batch 13680, Loss: 1.5870, Acc: 64.85%\n",
      "Epoch 3/3, Batch 13690, Loss: 0.6303, Acc: 64.87%\n",
      "Epoch 3/3, Batch 13700, Loss: 0.0006, Acc: 64.87%\n",
      "Epoch 3/3, Batch 13710, Loss: 0.3537, Acc: 64.87%\n",
      "Epoch 3/3, Batch 13720, Loss: 0.0390, Acc: 64.88%\n",
      "Epoch 3/3, Batch 13730, Loss: 0.0224, Acc: 64.88%\n",
      "Epoch 3/3, Batch 13740, Loss: 0.5910, Acc: 64.88%\n",
      "Epoch 3/3, Batch 13750, Loss: 0.3645, Acc: 64.88%\n",
      "Epoch 3/3, Batch 13760, Loss: 0.3398, Acc: 64.90%\n",
      "Epoch 3/3, Batch 13770, Loss: 0.1579, Acc: 64.90%\n",
      "Epoch 3/3, Batch 13780, Loss: 1.2228, Acc: 64.88%\n",
      "Epoch 3/3, Batch 13790, Loss: 0.0720, Acc: 64.87%\n",
      "Epoch 3/3, Batch 13800, Loss: 1.0560, Acc: 64.85%\n",
      "Epoch 3/3, Batch 13810, Loss: 0.6231, Acc: 64.84%\n",
      "Epoch 3/3, Batch 13820, Loss: 0.6780, Acc: 64.86%\n",
      "Epoch 3/3, Batch 13830, Loss: 0.8641, Acc: 64.85%\n",
      "Epoch 3/3, Batch 13840, Loss: 0.7383, Acc: 64.86%\n",
      "Epoch 3/3, Batch 13850, Loss: 0.0345, Acc: 64.85%\n",
      "Epoch 3/3, Batch 13860, Loss: 0.6598, Acc: 64.86%\n",
      "Epoch 3/3, Batch 13870, Loss: 0.3177, Acc: 64.86%\n",
      "Epoch 3/3, Batch 13880, Loss: 0.6732, Acc: 64.86%\n",
      "Epoch 3/3, Batch 13890, Loss: 0.0437, Acc: 64.86%\n",
      "Epoch 3/3, Batch 13900, Loss: 0.0103, Acc: 64.86%\n",
      "Epoch 3/3, Batch 13910, Loss: 1.3857, Acc: 64.86%\n",
      "Epoch 3/3, Batch 13920, Loss: 0.1121, Acc: 64.86%\n",
      "Epoch 3/3, Batch 13930, Loss: 0.0053, Acc: 64.86%\n",
      "Epoch 3/3, Batch 13940, Loss: 1.3367, Acc: 64.85%\n",
      "Epoch 3/3, Batch 13950, Loss: 1.2653, Acc: 64.84%\n",
      "Epoch 3/3, Batch 13960, Loss: 0.6961, Acc: 64.84%\n",
      "Epoch 3/3, Batch 13970, Loss: 0.0170, Acc: 64.83%\n",
      "Epoch 3/3, Batch 13980, Loss: 0.8947, Acc: 64.80%\n",
      "Epoch 3/3, Batch 13990, Loss: 0.4144, Acc: 64.80%\n",
      "Epoch 3/3, Batch 14000, Loss: 0.4533, Acc: 64.80%\n",
      "Epoch 3/3, Batch 14010, Loss: 0.0350, Acc: 64.82%\n",
      "Epoch 3/3, Batch 14020, Loss: 0.8969, Acc: 64.80%\n",
      "Epoch 3/3, Batch 14030, Loss: 1.8405, Acc: 64.82%\n",
      "Epoch 3/3, Batch 14040, Loss: 1.1267, Acc: 64.82%\n",
      "Epoch 3/3, Batch 14050, Loss: 1.3140, Acc: 64.81%\n",
      "Epoch 3/3, Batch 14060, Loss: 0.0786, Acc: 64.82%\n",
      "Epoch 3/3, Batch 14070, Loss: 0.7882, Acc: 64.81%\n",
      "Epoch 3/3, Batch 14080, Loss: 0.0704, Acc: 64.81%\n",
      "Epoch 3/3, Batch 14090, Loss: 0.5792, Acc: 64.80%\n",
      "Epoch 3/3, Batch 14100, Loss: 0.8310, Acc: 64.79%\n",
      "Epoch 3/3, Batch 14110, Loss: 0.9589, Acc: 64.78%\n",
      "Epoch 3/3, Batch 14120, Loss: 1.3224, Acc: 64.80%\n",
      "Epoch 3/3, Batch 14130, Loss: 0.7642, Acc: 64.81%\n",
      "Epoch 3/3, Batch 14140, Loss: 0.4510, Acc: 64.81%\n",
      "Epoch 3/3, Batch 14150, Loss: 0.5717, Acc: 64.80%\n",
      "Epoch 3/3, Batch 14160, Loss: 0.1496, Acc: 64.80%\n",
      "Epoch 3/3, Batch 14170, Loss: 0.8035, Acc: 64.79%\n",
      "Epoch 3/3, Batch 14180, Loss: 0.0918, Acc: 64.79%\n",
      "Epoch 3/3, Batch 14190, Loss: 5.1040, Acc: 64.78%\n",
      "Epoch 3/3, Batch 14200, Loss: 0.5108, Acc: 64.78%\n",
      "Epoch 3/3, Batch 14210, Loss: 0.0155, Acc: 64.78%\n",
      "Epoch 3/3, Batch 14220, Loss: 0.9912, Acc: 64.77%\n",
      "Epoch 3/3, Batch 14230, Loss: 0.5943, Acc: 64.77%\n",
      "Epoch 3/3, Batch 14240, Loss: 0.5938, Acc: 64.78%\n",
      "Epoch 3/3, Batch 14250, Loss: 0.1766, Acc: 64.77%\n",
      "Epoch 3/3, Batch 14260, Loss: 0.0288, Acc: 64.75%\n",
      "Epoch 3/3, Batch 14270, Loss: 0.2385, Acc: 64.75%\n",
      "Epoch 3/3, Batch 14280, Loss: 0.5858, Acc: 64.76%\n",
      "Epoch 3/3, Batch 14290, Loss: 1.1324, Acc: 64.75%\n",
      "Epoch 3/3, Batch 14300, Loss: 1.1600, Acc: 64.75%\n",
      "Epoch 3/3, Batch 14310, Loss: 1.2304, Acc: 64.75%\n",
      "Epoch 3/3, Batch 14320, Loss: 0.2637, Acc: 64.76%\n",
      "Epoch 3/3, Batch 14330, Loss: 0.0532, Acc: 64.77%\n",
      "Epoch 3/3, Batch 14340, Loss: 0.0051, Acc: 64.76%\n",
      "Epoch 3/3, Batch 14350, Loss: 0.0495, Acc: 64.77%\n",
      "Epoch 3/3, Batch 14360, Loss: 0.0055, Acc: 64.77%\n",
      "Epoch 3/3, Batch 14370, Loss: 0.0187, Acc: 64.79%\n",
      "Epoch 3/3, Batch 14380, Loss: 0.2316, Acc: 64.79%\n",
      "Epoch 3/3, Batch 14390, Loss: 0.2600, Acc: 64.78%\n",
      "Epoch 3/3, Batch 14400, Loss: 0.3281, Acc: 64.80%\n",
      "Epoch 3/3, Batch 14410, Loss: 0.1778, Acc: 64.80%\n",
      "Epoch 3/3, Batch 14420, Loss: 1.8567, Acc: 64.79%\n",
      "Epoch 3/3, Batch 14430, Loss: 0.7037, Acc: 64.79%\n",
      "Epoch 3/3, Batch 14440, Loss: 0.6555, Acc: 64.77%\n",
      "Epoch 3/3, Batch 14450, Loss: 1.0529, Acc: 64.76%\n",
      "Epoch 3/3, Batch 14460, Loss: 0.2339, Acc: 64.75%\n",
      "Epoch 3/3, Batch 14470, Loss: 0.6097, Acc: 64.75%\n",
      "Epoch 3/3, Batch 14480, Loss: 0.2122, Acc: 64.75%\n",
      "Epoch 3/3, Batch 14490, Loss: 1.5516, Acc: 64.74%\n",
      "Epoch 3/3, Batch 14500, Loss: 0.0307, Acc: 64.75%\n",
      "Epoch 3/3, Batch 14510, Loss: 0.8638, Acc: 64.74%\n",
      "Epoch 3/3, Batch 14520, Loss: 0.4320, Acc: 64.75%\n",
      "Epoch 3/3, Batch 14530, Loss: 0.8061, Acc: 64.76%\n",
      "Epoch 3/3, Batch 14540, Loss: 0.2878, Acc: 64.78%\n",
      "Epoch 3/3, Batch 14550, Loss: 1.2314, Acc: 64.75%\n",
      "Epoch 3/3, Batch 14560, Loss: 0.7923, Acc: 64.75%\n",
      "Epoch 3/3, Batch 14570, Loss: 0.0195, Acc: 64.75%\n",
      "Epoch 3/3, Batch 14580, Loss: 0.8659, Acc: 64.73%\n",
      "Epoch 3/3, Batch 14590, Loss: 1.2799, Acc: 64.72%\n",
      "Epoch 3/3, Batch 14600, Loss: 0.3934, Acc: 64.72%\n",
      "Epoch 3/3, Batch 14610, Loss: 0.6936, Acc: 64.71%\n",
      "Epoch 3/3, Batch 14620, Loss: 0.2038, Acc: 64.71%\n",
      "Epoch 3/3, Batch 14630, Loss: 0.0355, Acc: 64.71%\n",
      "Epoch 3/3, Batch 14640, Loss: 0.4143, Acc: 64.71%\n",
      "Epoch 3/3, Batch 14650, Loss: 0.2812, Acc: 64.71%\n",
      "Epoch 3/3, Batch 14660, Loss: 0.4735, Acc: 64.72%\n",
      "Epoch 3/3, Batch 14670, Loss: 0.7156, Acc: 64.71%\n",
      "Epoch 3/3, Batch 14680, Loss: 1.4704, Acc: 64.73%\n",
      "Epoch 3/3, Batch 14690, Loss: 1.7729, Acc: 64.73%\n",
      "Epoch 3/3, Batch 14700, Loss: 0.8368, Acc: 64.72%\n",
      "Epoch 3/3, Batch 14710, Loss: 0.0276, Acc: 64.71%\n",
      "Epoch 3/3, Batch 14720, Loss: 1.0939, Acc: 64.70%\n",
      "Epoch 3/3, Batch 14730, Loss: 0.5484, Acc: 64.72%\n",
      "Epoch 3/3, Batch 14740, Loss: 1.2055, Acc: 64.70%\n",
      "Epoch 3/3, Batch 14750, Loss: 0.7558, Acc: 64.71%\n",
      "Epoch 3/3, Batch 14760, Loss: 1.0038, Acc: 64.71%\n",
      "Epoch 3/3, Batch 14770, Loss: 1.1501, Acc: 64.70%\n",
      "Epoch 3/3, Batch 14780, Loss: 1.1441, Acc: 64.69%\n",
      "Epoch 3/3, Batch 14790, Loss: 0.5661, Acc: 64.69%\n",
      "Epoch 3/3, Batch 14800, Loss: 0.6216, Acc: 64.71%\n",
      "Epoch 3/3, Batch 14810, Loss: 0.2209, Acc: 64.70%\n",
      "Epoch 3/3, Batch 14820, Loss: 0.0145, Acc: 64.70%\n",
      "Epoch 3/3, Batch 14830, Loss: 0.2186, Acc: 64.71%\n",
      "Epoch 3/3, Batch 14840, Loss: 0.5806, Acc: 64.71%\n",
      "Epoch 3/3, Batch 14850, Loss: 0.2733, Acc: 64.72%\n",
      "Epoch 3/3, Batch 14860, Loss: 0.4193, Acc: 64.72%\n",
      "Epoch 3/3, Batch 14870, Loss: 1.1694, Acc: 64.72%\n",
      "Epoch 3/3, Batch 14880, Loss: 0.0141, Acc: 64.74%\n",
      "Epoch 3/3, Batch 14890, Loss: 0.6071, Acc: 64.72%\n",
      "Epoch 3/3, Batch 14900, Loss: 1.3219, Acc: 64.72%\n",
      "Epoch 3/3, Batch 14910, Loss: 0.0511, Acc: 64.72%\n",
      "Epoch 3/3, Batch 14920, Loss: 1.5910, Acc: 64.71%\n",
      "Epoch 3/3, Batch 14930, Loss: 0.8231, Acc: 64.72%\n",
      "Epoch 3/3, Batch 14940, Loss: 0.4834, Acc: 64.70%\n",
      "Epoch 3/3, Batch 14950, Loss: 0.5671, Acc: 64.70%\n",
      "Epoch 3/3, Batch 14960, Loss: 1.9182, Acc: 64.69%\n",
      "Epoch 3/3, Batch 14970, Loss: 0.0287, Acc: 64.70%\n",
      "Epoch 3/3, Batch 14980, Loss: 0.6189, Acc: 64.70%\n",
      "Epoch 3/3, Batch 14990, Loss: 0.4901, Acc: 64.71%\n",
      "Epoch 3/3, Batch 15000, Loss: 1.2411, Acc: 64.71%\n",
      "Epoch 3/3, Batch 15010, Loss: 0.7413, Acc: 64.71%\n",
      "Epoch 3/3, Batch 15020, Loss: 0.5945, Acc: 64.71%\n",
      "Epoch 3/3, Batch 15030, Loss: 0.7986, Acc: 64.70%\n",
      "Epoch 3/3, Batch 15040, Loss: 0.3427, Acc: 64.69%\n",
      "Epoch 3/3, Batch 15050, Loss: 0.0961, Acc: 64.69%\n",
      "Epoch 3/3, Batch 15060, Loss: 0.7735, Acc: 64.70%\n",
      "Epoch 3/3, Batch 15070, Loss: 0.7221, Acc: 64.69%\n",
      "Epoch 3/3, Batch 15080, Loss: 0.4013, Acc: 64.68%\n",
      "Epoch 3/3, Batch 15090, Loss: 0.0938, Acc: 64.70%\n",
      "Epoch 3/3, Batch 15100, Loss: 0.3281, Acc: 64.71%\n",
      "Epoch 3/3, Batch 15110, Loss: 0.0174, Acc: 64.72%\n",
      "Epoch 3/3, Batch 15120, Loss: 1.2429, Acc: 64.70%\n",
      "Epoch 3/3, Batch 15130, Loss: 1.4503, Acc: 64.69%\n",
      "Epoch 3/3, Batch 15140, Loss: 0.0023, Acc: 64.69%\n",
      "Epoch 3/3, Batch 15150, Loss: 1.1444, Acc: 64.69%\n",
      "Epoch 3/3, Batch 15160, Loss: 0.9243, Acc: 64.67%\n",
      "Epoch 3/3, Batch 15170, Loss: 0.6583, Acc: 64.66%\n",
      "Epoch 3/3, Batch 15180, Loss: 0.2483, Acc: 64.67%\n",
      "Epoch 3/3, Batch 15190, Loss: 0.7400, Acc: 64.66%\n",
      "Epoch 3/3, Batch 15200, Loss: 0.0010, Acc: 64.66%\n",
      "Epoch 3/3, Batch 15210, Loss: 0.0128, Acc: 64.65%\n",
      "Epoch 3/3, Batch 15220, Loss: 0.8916, Acc: 64.62%\n",
      "Epoch 3/3, Batch 15230, Loss: 0.4378, Acc: 64.63%\n",
      "Epoch 3/3, Batch 15240, Loss: 0.7727, Acc: 64.63%\n",
      "Epoch 3/3, Batch 15250, Loss: 0.0402, Acc: 64.63%\n",
      "Epoch 3/3, Batch 15260, Loss: 0.9215, Acc: 64.62%\n",
      "Epoch 3/3, Batch 15270, Loss: 0.4064, Acc: 64.63%\n",
      "Epoch 3/3, Batch 15280, Loss: 1.1020, Acc: 64.64%\n",
      "Epoch 3/3, Batch 15290, Loss: 0.5260, Acc: 64.65%\n",
      "Epoch 3/3, Batch 15300, Loss: 0.9535, Acc: 64.64%\n",
      "Epoch 3/3, Batch 15310, Loss: 0.5454, Acc: 64.65%\n",
      "Epoch 3/3, Batch 15320, Loss: 0.9273, Acc: 64.63%\n",
      "Epoch 3/3, Batch 15330, Loss: 0.5256, Acc: 64.64%\n",
      "Epoch 3/3, Batch 15340, Loss: 0.4598, Acc: 64.63%\n",
      "Epoch 3/3, Batch 15350, Loss: 0.0255, Acc: 64.65%\n",
      "Epoch 3/3, Batch 15360, Loss: 0.2122, Acc: 64.65%\n",
      "Epoch 3/3, Batch 15370, Loss: 1.0044, Acc: 64.64%\n",
      "Epoch 3/3, Batch 15380, Loss: 0.0336, Acc: 64.64%\n",
      "Epoch 3/3, Batch 15390, Loss: 0.3475, Acc: 64.65%\n",
      "Epoch 3/3, Batch 15400, Loss: 1.1310, Acc: 64.66%\n",
      "Epoch 3/3, Batch 15410, Loss: 0.1782, Acc: 64.67%\n",
      "Epoch 3/3, Batch 15420, Loss: 0.7518, Acc: 64.67%\n",
      "Epoch 3/3, Batch 15430, Loss: 0.6429, Acc: 64.67%\n",
      "Epoch 3/3, Batch 15440, Loss: 0.0360, Acc: 64.67%\n",
      "Epoch 3/3, Batch 15450, Loss: 1.4102, Acc: 64.66%\n",
      "Epoch 3/3, Batch 15460, Loss: 0.6260, Acc: 64.67%\n",
      "Epoch 3/3, Batch 15470, Loss: 0.1260, Acc: 64.68%\n",
      "Epoch 3/3, Batch 15480, Loss: 0.3188, Acc: 64.68%\n",
      "Epoch 3/3, Batch 15490, Loss: 0.7111, Acc: 64.69%\n",
      "Epoch 3/3, Batch 15500, Loss: 0.4768, Acc: 64.68%\n",
      "Epoch 3/3, Batch 15510, Loss: 0.2238, Acc: 64.68%\n",
      "Epoch 3/3, Batch 15520, Loss: 0.4494, Acc: 64.66%\n",
      "Epoch 3/3, Batch 15530, Loss: 0.0179, Acc: 64.66%\n",
      "Epoch 3/3, Batch 15540, Loss: 0.6976, Acc: 64.67%\n",
      "Epoch 3/3, Batch 15550, Loss: 1.7162, Acc: 64.67%\n",
      "Epoch 3/3, Batch 15560, Loss: 0.0447, Acc: 64.67%\n",
      "Epoch 3/3, Batch 15570, Loss: 0.1282, Acc: 64.67%\n",
      "Epoch 3/3, Batch 15580, Loss: 0.5747, Acc: 64.66%\n",
      "Epoch 3/3, Batch 15590, Loss: 0.0196, Acc: 64.65%\n",
      "Epoch 3/3, Batch 15600, Loss: 0.3451, Acc: 64.66%\n",
      "Epoch 3/3, Batch 15610, Loss: 0.0112, Acc: 64.65%\n",
      "Epoch 3/3, Batch 15620, Loss: 0.4707, Acc: 64.66%\n",
      "Epoch 3/3, Batch 15630, Loss: 0.6419, Acc: 64.66%\n",
      "Epoch 3/3, Batch 15640, Loss: 1.1251, Acc: 64.65%\n",
      "Epoch 3/3, Batch 15650, Loss: 0.3749, Acc: 64.65%\n",
      "Epoch 3/3, Batch 15660, Loss: 0.0200, Acc: 64.66%\n",
      "Epoch 3/3, Batch 15670, Loss: 0.0824, Acc: 64.67%\n",
      "Epoch 3/3, Batch 15680, Loss: 0.0006, Acc: 64.68%\n",
      "Epoch 3/3, Batch 15690, Loss: 0.6194, Acc: 64.69%\n",
      "Epoch 3/3, Batch 15700, Loss: 0.7681, Acc: 64.68%\n",
      "Epoch 3/3, Batch 15710, Loss: 0.1252, Acc: 64.67%\n",
      "Epoch 3/3, Batch 15720, Loss: 0.0169, Acc: 64.68%\n",
      "Epoch 3/3, Batch 15730, Loss: 0.6647, Acc: 64.68%\n",
      "Epoch 3/3, Batch 15740, Loss: 0.2952, Acc: 64.68%\n",
      "Epoch 3/3, Batch 15750, Loss: 0.1628, Acc: 64.68%\n",
      "Epoch 3/3, Batch 15760, Loss: 0.0263, Acc: 64.67%\n",
      "Epoch 3/3, Batch 15770, Loss: 1.1251, Acc: 64.66%\n",
      "Epoch 3/3, Batch 15780, Loss: 0.4258, Acc: 64.67%\n",
      "Epoch 3/3, Batch 15790, Loss: 0.0161, Acc: 64.67%\n",
      "Epoch 3/3, Batch 15800, Loss: 0.0085, Acc: 64.69%\n",
      "Epoch 3/3, Batch 15810, Loss: 0.8366, Acc: 64.70%\n",
      "Epoch 3/3, Batch 15820, Loss: 0.0643, Acc: 64.68%\n",
      "Epoch 3/3, Batch 15830, Loss: 0.9451, Acc: 64.68%\n",
      "Epoch 3/3, Batch 15840, Loss: 0.7261, Acc: 64.68%\n",
      "Epoch 3/3, Batch 15850, Loss: 1.4210, Acc: 64.68%\n",
      "Epoch 3/3, Batch 15860, Loss: 0.4999, Acc: 64.69%\n",
      "Epoch 3/3, Batch 15870, Loss: 0.1033, Acc: 64.68%\n",
      "Epoch 3/3, Batch 15880, Loss: 0.6126, Acc: 64.69%\n",
      "Epoch 3/3, Batch 15890, Loss: 0.7913, Acc: 64.70%\n",
      "Epoch 3/3, Batch 15900, Loss: 0.3770, Acc: 64.70%\n",
      "Epoch 3/3, Batch 15910, Loss: 0.7877, Acc: 64.70%\n",
      "Epoch 3/3, Batch 15920, Loss: 0.0060, Acc: 64.69%\n",
      "Epoch 3/3, Batch 15930, Loss: 1.0412, Acc: 64.69%\n",
      "Epoch 3/3, Batch 15940, Loss: 0.6781, Acc: 64.69%\n",
      "Epoch 3/3, Batch 15950, Loss: 0.5240, Acc: 64.68%\n",
      "Epoch 3/3, Batch 15960, Loss: 0.2394, Acc: 64.69%\n",
      "Epoch 3/3, Batch 15970, Loss: 1.8112, Acc: 64.68%\n",
      "Epoch 3/3, Batch 15980, Loss: 0.2109, Acc: 64.68%\n",
      "Epoch 3/3, Batch 15990, Loss: 0.7548, Acc: 64.68%\n",
      "Epoch 3/3, Batch 16000, Loss: 0.8583, Acc: 64.68%\n",
      "Epoch 3/3, Batch 16010, Loss: 1.2632, Acc: 64.68%\n",
      "Epoch 3/3, Batch 16020, Loss: 0.0007, Acc: 64.70%\n",
      "Epoch 3/3, Batch 16030, Loss: 0.6622, Acc: 64.71%\n",
      "Epoch 3/3, Batch 16040, Loss: 0.5412, Acc: 64.70%\n",
      "Epoch 3/3, Batch 16050, Loss: 0.5927, Acc: 64.68%\n",
      "Epoch 3/3, Batch 16060, Loss: 0.8931, Acc: 64.68%\n",
      "Epoch 3/3, Batch 16070, Loss: 0.7554, Acc: 64.66%\n",
      "Epoch 3/3, Batch 16080, Loss: 0.4424, Acc: 64.66%\n",
      "Epoch 3/3, Batch 16090, Loss: 0.1715, Acc: 64.66%\n",
      "Epoch 3/3, Batch 16100, Loss: 0.0482, Acc: 64.67%\n",
      "Epoch 3/3, Batch 16110, Loss: 0.9774, Acc: 64.68%\n",
      "Epoch 3/3, Batch 16120, Loss: 1.6393, Acc: 64.68%\n",
      "Epoch 3/3, Batch 16130, Loss: 1.5291, Acc: 64.67%\n",
      "Epoch 3/3, Batch 16140, Loss: 0.0202, Acc: 64.67%\n",
      "Epoch 3/3, Batch 16150, Loss: 0.6757, Acc: 64.66%\n",
      "Epoch 3/3, Batch 16160, Loss: 1.2381, Acc: 64.67%\n",
      "Epoch 3/3, Batch 16170, Loss: 0.1918, Acc: 64.66%\n",
      "Epoch 3/3, Batch 16180, Loss: 0.2890, Acc: 64.66%\n",
      "Epoch 3/3, Batch 16190, Loss: 0.0395, Acc: 64.67%\n",
      "Epoch 3/3, Batch 16200, Loss: 0.0094, Acc: 64.66%\n",
      "Epoch 3/3, Batch 16210, Loss: 0.6901, Acc: 64.67%\n",
      "Epoch 3/3, Batch 16220, Loss: 0.3440, Acc: 64.68%\n",
      "Epoch 3/3, Batch 16230, Loss: 0.5269, Acc: 64.68%\n",
      "Epoch 3/3, Batch 16240, Loss: 0.6816, Acc: 64.67%\n",
      "Epoch 3/3, Batch 16250, Loss: 1.0711, Acc: 64.67%\n",
      "Epoch 3/3, Batch 16260, Loss: 0.5299, Acc: 64.68%\n",
      "Epoch 3/3, Batch 16270, Loss: 0.4943, Acc: 64.68%\n",
      "Epoch 3/3, Batch 16280, Loss: 0.3017, Acc: 64.68%\n",
      "Epoch 3/3, Batch 16290, Loss: 1.2027, Acc: 64.67%\n",
      "Epoch 3/3, Batch 16300, Loss: 0.4973, Acc: 64.69%\n",
      "Epoch 3/3, Batch 16310, Loss: 0.2797, Acc: 64.69%\n",
      "Epoch 3/3, Batch 16320, Loss: 0.1535, Acc: 64.68%\n",
      "Epoch 3/3, Batch 16330, Loss: 0.4969, Acc: 64.69%\n",
      "Epoch 3/3, Batch 16340, Loss: 0.0143, Acc: 64.69%\n",
      "Epoch 3/3, Batch 16350, Loss: 0.3225, Acc: 64.69%\n",
      "Epoch 3/3, Batch 16360, Loss: 0.8187, Acc: 64.70%\n",
      "Epoch 3/3, Batch 16370, Loss: 0.1098, Acc: 64.70%\n",
      "Epoch 3/3, Batch 16380, Loss: 0.8748, Acc: 64.70%\n",
      "Epoch 3/3, Batch 16390, Loss: 0.0048, Acc: 64.70%\n",
      "Epoch 3/3, Batch 16400, Loss: 0.0635, Acc: 64.70%\n",
      "Epoch 3/3, Batch 16410, Loss: 0.4344, Acc: 64.71%\n",
      "Epoch 3/3, Batch 16420, Loss: 0.0073, Acc: 64.72%\n",
      "Epoch 3/3, Batch 16430, Loss: 0.7817, Acc: 64.73%\n",
      "Epoch 3/3, Batch 16440, Loss: 0.2150, Acc: 64.73%\n",
      "Epoch 3/3, Batch 16450, Loss: 0.1937, Acc: 64.74%\n",
      "Epoch 3/3, Batch 16460, Loss: 0.4650, Acc: 64.74%\n",
      "Epoch 3/3, Batch 16470, Loss: 0.7276, Acc: 64.74%\n",
      "Epoch 3/3, Batch 16480, Loss: 0.2800, Acc: 64.75%\n",
      "Epoch 3/3, Batch 16490, Loss: 0.1376, Acc: 64.76%\n",
      "Epoch 3/3, Batch 16500, Loss: 0.4254, Acc: 64.76%\n",
      "Epoch 3/3, Batch 16510, Loss: 0.0080, Acc: 64.75%\n",
      "Epoch 3/3, Batch 16520, Loss: 1.9425, Acc: 64.75%\n",
      "Epoch 3/3, Batch 16530, Loss: 0.5146, Acc: 64.75%\n",
      "Epoch 3/3, Batch 16540, Loss: 0.0044, Acc: 64.75%\n",
      "Epoch 3/3, Batch 16550, Loss: 0.6284, Acc: 64.76%\n",
      "Epoch 3/3, Batch 16560, Loss: 1.1078, Acc: 64.76%\n",
      "Epoch 3/3, Batch 16570, Loss: 0.3807, Acc: 64.77%\n",
      "Epoch 3/3, Batch 16580, Loss: 1.0033, Acc: 64.77%\n",
      "Epoch 3/3, Batch 16590, Loss: 0.4227, Acc: 64.78%\n",
      "Epoch 3/3, Batch 16600, Loss: 1.2255, Acc: 64.79%\n",
      "Epoch 3/3, Batch 16610, Loss: 1.1020, Acc: 64.78%\n",
      "Epoch 3/3, Batch 16620, Loss: 0.7545, Acc: 64.77%\n",
      "Epoch 3/3, Batch 16630, Loss: 0.2743, Acc: 64.78%\n",
      "Epoch 3/3, Batch 16640, Loss: 0.9771, Acc: 64.76%\n",
      "Epoch 3/3, Batch 16650, Loss: 0.6641, Acc: 64.77%\n",
      "Epoch 3/3, Batch 16660, Loss: 0.6396, Acc: 64.77%\n",
      "Epoch 3/3, Batch 16670, Loss: 0.5719, Acc: 64.77%\n",
      "Epoch 3/3, Batch 16680, Loss: 0.3613, Acc: 64.77%\n",
      "Epoch 3/3, Batch 16690, Loss: 0.5288, Acc: 64.77%\n",
      "Epoch 3/3, Batch 16700, Loss: 0.2146, Acc: 64.77%\n",
      "Epoch 3/3, Batch 16710, Loss: 0.8879, Acc: 64.78%\n",
      "Epoch 3/3, Batch 16720, Loss: 1.1822, Acc: 64.76%\n",
      "Epoch 3/3, Batch 16730, Loss: 0.6002, Acc: 64.77%\n",
      "Epoch 3/3, Batch 16740, Loss: 0.8337, Acc: 64.78%\n",
      "Epoch 3/3, Batch 16750, Loss: 0.5362, Acc: 64.78%\n",
      "Epoch 3/3, Batch 16760, Loss: 0.4367, Acc: 64.78%\n",
      "Epoch 3/3, Batch 16770, Loss: 0.4047, Acc: 64.77%\n",
      "Epoch 3/3, Batch 16780, Loss: 0.7150, Acc: 64.76%\n",
      "Epoch 3/3, Batch 16790, Loss: 0.5213, Acc: 64.75%\n",
      "Epoch 3/3, Batch 16800, Loss: 0.3609, Acc: 64.75%\n",
      "Epoch 3/3, Batch 16810, Loss: 1.3623, Acc: 64.76%\n",
      "Epoch 3/3, Batch 16820, Loss: 0.2292, Acc: 64.78%\n",
      "Epoch 3/3, Batch 16830, Loss: 0.7693, Acc: 64.76%\n",
      "Epoch 3/3, Batch 16840, Loss: 0.0214, Acc: 64.77%\n",
      "Epoch 3/3, Batch 16850, Loss: 0.9980, Acc: 64.76%\n",
      "Epoch 3/3, Batch 16860, Loss: 0.0081, Acc: 64.76%\n",
      "Epoch 3/3, Batch 16870, Loss: 0.9402, Acc: 64.76%\n",
      "Epoch 3/3, Batch 16880, Loss: 0.3414, Acc: 64.75%\n",
      "Epoch 3/3, Batch 16890, Loss: 0.6841, Acc: 64.74%\n",
      "Epoch 3/3, Batch 16900, Loss: 0.5800, Acc: 64.74%\n",
      "Epoch 3/3, Batch 16910, Loss: 0.4545, Acc: 64.75%\n",
      "Epoch 3/3, Batch 16920, Loss: 0.9880, Acc: 64.76%\n",
      "Epoch 3/3, Batch 16930, Loss: 1.2485, Acc: 64.76%\n",
      "Epoch 3/3, Batch 16940, Loss: 0.4504, Acc: 64.77%\n",
      "Epoch 3/3, Batch 16950, Loss: 2.1928, Acc: 64.76%\n",
      "Epoch 3/3, Batch 16960, Loss: 0.6971, Acc: 64.73%\n",
      "Epoch 3/3, Batch 16970, Loss: 0.4645, Acc: 64.73%\n",
      "Epoch 3/3, Batch 16980, Loss: 0.5629, Acc: 64.73%\n",
      "Epoch 3/3, Batch 16990, Loss: 1.7449, Acc: 64.71%\n",
      "Epoch 3/3, Batch 17000, Loss: 0.6509, Acc: 64.71%\n",
      "Epoch 3/3, Batch 17010, Loss: 1.2064, Acc: 64.71%\n",
      "Epoch 3/3, Batch 17020, Loss: 0.4405, Acc: 64.71%\n",
      "Epoch 3/3, Batch 17030, Loss: 0.0171, Acc: 64.72%\n",
      "Epoch 3/3, Batch 17040, Loss: 0.0248, Acc: 64.72%\n",
      "Epoch 3/3, Batch 17050, Loss: 0.4755, Acc: 64.72%\n",
      "Epoch 3/3, Batch 17060, Loss: 0.8836, Acc: 64.71%\n",
      "Epoch 3/3, Batch 17070, Loss: 0.2358, Acc: 64.72%\n",
      "Epoch 3/3, Batch 17080, Loss: 0.6900, Acc: 64.73%\n",
      "Epoch 3/3, Batch 17090, Loss: 0.2429, Acc: 64.72%\n",
      "Epoch 3/3, Batch 17100, Loss: 0.0299, Acc: 64.73%\n",
      "Epoch 3/3, Batch 17110, Loss: 0.5840, Acc: 64.72%\n",
      "Epoch 3/3, Batch 17120, Loss: 0.2778, Acc: 64.73%\n",
      "Epoch 3/3, Batch 17130, Loss: 0.2965, Acc: 64.71%\n",
      "Epoch 3/3, Batch 17140, Loss: 0.0331, Acc: 64.72%\n",
      "Epoch 3/3, Batch 17150, Loss: 0.7134, Acc: 64.70%\n",
      "Epoch 3/3, Batch 17160, Loss: 0.0208, Acc: 64.69%\n",
      "Epoch 3/3, Batch 17170, Loss: 1.9666, Acc: 64.69%\n",
      "Epoch 3/3, Batch 17180, Loss: 1.2147, Acc: 64.70%\n",
      "Epoch 3/3, Batch 17190, Loss: 0.0165, Acc: 64.70%\n",
      "Epoch 3/3, Batch 17200, Loss: 1.3944, Acc: 64.69%\n",
      "Epoch 3/3, Batch 17210, Loss: 0.5801, Acc: 64.69%\n",
      "Epoch 3/3, Batch 17220, Loss: 0.1488, Acc: 64.71%\n",
      "Epoch 3/3, Batch 17230, Loss: 0.7456, Acc: 64.71%\n",
      "Epoch 3/3, Batch 17240, Loss: 1.1677, Acc: 64.72%\n",
      "Epoch 3/3, Batch 17250, Loss: 0.2615, Acc: 64.72%\n",
      "Epoch 3/3, Batch 17260, Loss: 0.1284, Acc: 64.72%\n",
      "Epoch 3/3, Batch 17270, Loss: 0.2212, Acc: 64.73%\n",
      "Epoch 3/3, Batch 17280, Loss: 0.0047, Acc: 64.72%\n",
      "Epoch 3/3, Batch 17290, Loss: 0.9283, Acc: 64.72%\n",
      "Epoch 3/3, Batch 17300, Loss: 0.3596, Acc: 64.71%\n",
      "Epoch 3/3, Batch 17310, Loss: 0.9594, Acc: 64.72%\n",
      "Epoch 3/3, Batch 17320, Loss: 0.1827, Acc: 64.72%\n",
      "Epoch 3/3, Batch 17330, Loss: 0.6778, Acc: 64.73%\n",
      "Epoch 3/3, Batch 17340, Loss: 0.7074, Acc: 64.72%\n",
      "Epoch 3/3, Batch 17350, Loss: 0.4120, Acc: 64.72%\n",
      "Epoch 3/3, Batch 17360, Loss: 0.0520, Acc: 64.73%\n",
      "Epoch 3/3, Batch 17370, Loss: 0.0289, Acc: 64.72%\n",
      "Epoch 3/3, Batch 17380, Loss: 0.7450, Acc: 64.72%\n",
      "Epoch 3/3, Batch 17390, Loss: 0.0317, Acc: 64.73%\n",
      "Epoch 3/3, Batch 17400, Loss: 0.3650, Acc: 64.74%\n",
      "Epoch 3/3, Batch 17410, Loss: 0.4613, Acc: 64.75%\n",
      "Epoch 3/3, Batch 17420, Loss: 0.6452, Acc: 64.74%\n",
      "Epoch 3/3, Batch 17430, Loss: 1.3131, Acc: 64.75%\n",
      "Epoch 3/3, Batch 17440, Loss: 0.2884, Acc: 64.76%\n",
      "Epoch 3/3, Batch 17450, Loss: 0.7680, Acc: 64.76%\n",
      "Epoch 3/3, Batch 17460, Loss: 0.1638, Acc: 64.78%\n",
      "Epoch 3/3, Batch 17470, Loss: 1.1392, Acc: 64.77%\n",
      "Epoch 3/3, Batch 17480, Loss: 0.0096, Acc: 64.78%\n",
      "Epoch 3/3, Batch 17490, Loss: 0.3091, Acc: 64.79%\n",
      "Epoch 3/3, Batch 17500, Loss: 0.2807, Acc: 64.79%\n",
      "Epoch 3/3, Batch 17510, Loss: 0.6807, Acc: 64.80%\n",
      "Epoch 3/3, Batch 17520, Loss: 0.0148, Acc: 64.80%\n",
      "Epoch 3/3, Batch 17530, Loss: 0.9826, Acc: 64.81%\n",
      "Epoch 3/3, Batch 17540, Loss: 0.2306, Acc: 64.82%\n",
      "Epoch 3/3, Batch 17550, Loss: 0.3195, Acc: 64.82%\n",
      "Epoch 3/3, Batch 17560, Loss: 0.9280, Acc: 64.82%\n",
      "Epoch 3/3, Batch 17570, Loss: 1.3126, Acc: 64.82%\n",
      "Epoch 3/3, Batch 17580, Loss: 1.1519, Acc: 64.81%\n",
      "Epoch 3/3, Batch 17590, Loss: 0.0189, Acc: 64.81%\n",
      "Epoch 3/3, Batch 17600, Loss: 1.6287, Acc: 64.80%\n",
      "Epoch 3/3, Batch 17610, Loss: 0.0441, Acc: 64.80%\n",
      "Epoch 3/3, Batch 17620, Loss: 0.0044, Acc: 64.80%\n",
      "Epoch 3/3, Batch 17630, Loss: 0.0009, Acc: 64.80%\n",
      "Epoch 3/3, Batch 17640, Loss: 0.4440, Acc: 64.80%\n",
      "Epoch 3/3, Batch 17650, Loss: 0.6411, Acc: 64.81%\n",
      "Epoch 3/3, Batch 17660, Loss: 0.5902, Acc: 64.82%\n",
      "Epoch 3/3, Batch 17670, Loss: 0.7610, Acc: 64.81%\n",
      "Epoch 3/3, Batch 17680, Loss: 0.0001, Acc: 64.80%\n",
      "Epoch 3/3, Batch 17690, Loss: 0.5746, Acc: 64.81%\n",
      "Epoch 3/3, Batch 17700, Loss: 0.0650, Acc: 64.82%\n",
      "Epoch 3/3, Batch 17710, Loss: 0.4586, Acc: 64.82%\n",
      "Epoch 3/3, Batch 17720, Loss: 0.8807, Acc: 64.83%\n",
      "Epoch 3/3, Batch 17730, Loss: 1.0537, Acc: 64.84%\n",
      "Epoch 3/3, Batch 17740, Loss: 0.0748, Acc: 64.83%\n",
      "Epoch 3/3, Batch 17750, Loss: 0.1867, Acc: 64.84%\n",
      "Epoch 3/3, Batch 17760, Loss: 0.6216, Acc: 64.84%\n",
      "Epoch 3/3, Batch 17770, Loss: 0.0391, Acc: 64.85%\n",
      "Epoch 3/3, Batch 17780, Loss: 0.3087, Acc: 64.85%\n",
      "Epoch 3/3, Batch 17790, Loss: 0.9933, Acc: 64.84%\n",
      "Epoch 3/3, Batch 17800, Loss: 0.9281, Acc: 64.83%\n",
      "Epoch 3/3, Batch 17810, Loss: 0.0184, Acc: 64.84%\n",
      "Epoch 3/3, Batch 17820, Loss: 0.0439, Acc: 64.84%\n",
      "Epoch 3/3, Batch 17830, Loss: 0.7525, Acc: 64.83%\n",
      "Epoch 3/3, Batch 17840, Loss: 0.0035, Acc: 64.81%\n",
      "Epoch 3/3, Batch 17850, Loss: 0.0282, Acc: 64.81%\n",
      "Epoch 3/3, Batch 17860, Loss: 1.1464, Acc: 64.80%\n",
      "Epoch 3/3, Batch 17870, Loss: 0.0301, Acc: 64.81%\n",
      "Epoch 3/3, Batch 17880, Loss: 0.4468, Acc: 64.82%\n",
      "Epoch 3/3, Batch 17890, Loss: 0.7055, Acc: 64.81%\n",
      "Epoch 3/3, Batch 17900, Loss: 0.3743, Acc: 64.82%\n",
      "Epoch 3/3, Batch 17910, Loss: 2.1062, Acc: 64.84%\n",
      "Epoch 3/3, Batch 17920, Loss: 0.1867, Acc: 64.85%\n",
      "Epoch 3/3, Batch 17930, Loss: 0.0270, Acc: 64.84%\n",
      "Epoch 3/3, Batch 17940, Loss: 0.5075, Acc: 64.83%\n",
      "Epoch 3/3, Batch 17950, Loss: 2.2864, Acc: 64.83%\n",
      "Epoch 3/3, Batch 17960, Loss: 0.4207, Acc: 64.84%\n",
      "Epoch 3/3, Batch 17970, Loss: 0.6929, Acc: 64.83%\n",
      "Epoch 3/3, Batch 17980, Loss: 0.5847, Acc: 64.83%\n",
      "Epoch 3/3, Batch 17990, Loss: 0.0169, Acc: 64.83%\n",
      "Epoch 3/3, Batch 18000, Loss: 0.8896, Acc: 64.81%\n",
      "Epoch 3/3, Batch 18010, Loss: 0.4838, Acc: 64.82%\n",
      "Epoch 3/3, Batch 18020, Loss: 0.8152, Acc: 64.83%\n",
      "Epoch 3/3, Batch 18030, Loss: 1.1203, Acc: 64.83%\n",
      "Epoch 3/3, Batch 18040, Loss: 0.3218, Acc: 64.84%\n",
      "Epoch 3/3, Batch 18050, Loss: 0.1516, Acc: 64.84%\n",
      "Epoch 3/3, Batch 18060, Loss: 0.5794, Acc: 64.85%\n",
      "Epoch 3/3, Batch 18070, Loss: 0.0220, Acc: 64.84%\n",
      "Epoch 3/3, Batch 18080, Loss: 0.9093, Acc: 64.83%\n",
      "Epoch 3/3, Batch 18090, Loss: 0.0286, Acc: 64.82%\n",
      "Epoch 3/3, Batch 18100, Loss: 0.7779, Acc: 64.82%\n",
      "Epoch 3/3, Batch 18110, Loss: 0.0178, Acc: 64.82%\n",
      "Epoch 3/3, Batch 18120, Loss: 0.5368, Acc: 64.83%\n",
      "Epoch 3/3, Batch 18130, Loss: 0.3255, Acc: 64.83%\n",
      "Epoch 3/3, Batch 18140, Loss: 0.5357, Acc: 64.84%\n",
      "Epoch 3/3, Batch 18150, Loss: 0.8118, Acc: 64.84%\n",
      "Epoch 3/3, Batch 18160, Loss: 0.0206, Acc: 64.85%\n",
      "Epoch 3/3, Batch 18170, Loss: 0.2731, Acc: 64.86%\n",
      "Epoch 3/3, Batch 18180, Loss: 0.6980, Acc: 64.84%\n",
      "Epoch 3/3, Batch 18190, Loss: 0.9588, Acc: 64.84%\n",
      "Epoch 3/3, Batch 18200, Loss: 0.6807, Acc: 64.85%\n",
      "Epoch 3/3, Batch 18210, Loss: 0.3130, Acc: 64.86%\n",
      "Epoch 3/3, Batch 18220, Loss: 0.8292, Acc: 64.86%\n",
      "Epoch 3/3, Batch 18230, Loss: 0.5953, Acc: 64.87%\n",
      "Epoch 3/3, Batch 18240, Loss: 0.8969, Acc: 64.85%\n",
      "Epoch 3/3, Batch 18250, Loss: 0.7769, Acc: 64.85%\n",
      "Epoch 3/3, Batch 18260, Loss: 1.0674, Acc: 64.84%\n",
      "Epoch 3/3, Batch 18270, Loss: 0.2555, Acc: 64.85%\n",
      "Epoch 3/3, Batch 18280, Loss: 1.5800, Acc: 64.85%\n",
      "Epoch 3/3, Batch 18290, Loss: 0.0038, Acc: 64.87%\n",
      "Epoch 3/3, Batch 18300, Loss: 0.0084, Acc: 64.89%\n",
      "Epoch 3/3, Batch 18310, Loss: 0.8697, Acc: 64.88%\n",
      "Epoch 3/3, Batch 18320, Loss: 0.0198, Acc: 64.89%\n",
      "Epoch 3/3, Batch 18330, Loss: 0.5059, Acc: 64.90%\n",
      "Epoch 3/3, Batch 18340, Loss: 0.0173, Acc: 64.91%\n",
      "Epoch 3/3, Batch 18350, Loss: 1.6122, Acc: 64.91%\n",
      "Epoch 3/3, Batch 18360, Loss: 0.2820, Acc: 64.92%\n",
      "Epoch 3/3, Batch 18370, Loss: 0.6029, Acc: 64.92%\n",
      "Epoch 3/3, Batch 18380, Loss: 1.0066, Acc: 64.92%\n",
      "Epoch 3/3, Batch 18390, Loss: 0.7657, Acc: 64.92%\n",
      "Epoch 3/3, Batch 18400, Loss: 0.2787, Acc: 64.93%\n",
      "Epoch 3/3, Batch 18410, Loss: 0.8785, Acc: 64.93%\n",
      "Epoch 3/3, Batch 18420, Loss: 0.3528, Acc: 64.93%\n",
      "Epoch 3/3, Batch 18430, Loss: 2.6060, Acc: 64.92%\n",
      "Epoch 3/3, Batch 18440, Loss: 0.4951, Acc: 64.92%\n",
      "Epoch 3/3, Batch 18450, Loss: 0.9569, Acc: 64.91%\n",
      "Epoch 3/3, Batch 18460, Loss: 1.2251, Acc: 64.92%\n",
      "Epoch 3/3, Batch 18470, Loss: 0.8104, Acc: 64.92%\n",
      "Epoch 3/3, Batch 18480, Loss: 1.1137, Acc: 64.92%\n",
      "Epoch 3/3, Batch 18490, Loss: 0.0468, Acc: 64.92%\n",
      "Epoch 3/3, Batch 18500, Loss: 0.6540, Acc: 64.93%\n",
      "Epoch 3/3, Batch 18510, Loss: 0.6062, Acc: 64.92%\n",
      "Epoch 3/3, Batch 18520, Loss: 0.0049, Acc: 64.93%\n",
      "Epoch 3/3, Batch 18530, Loss: 0.3313, Acc: 64.94%\n",
      "Epoch 3/3, Batch 18540, Loss: 0.0352, Acc: 64.95%\n",
      "Epoch 3/3, Batch 18550, Loss: 0.8862, Acc: 64.95%\n",
      "Epoch 3/3, Batch 18560, Loss: 1.3293, Acc: 64.95%\n",
      "Epoch 3/3, Batch 18570, Loss: 0.1421, Acc: 64.95%\n",
      "Epoch 3/3, Batch 18580, Loss: 0.2016, Acc: 64.95%\n",
      "Epoch 3/3, Batch 18590, Loss: 1.2647, Acc: 64.95%\n",
      "Epoch 3/3, Batch 18600, Loss: 0.8998, Acc: 64.95%\n",
      "Epoch 3/3, Batch 18610, Loss: 0.0106, Acc: 64.94%\n",
      "Epoch 3/3, Batch 18620, Loss: 0.7586, Acc: 64.93%\n",
      "Epoch 3/3, Batch 18630, Loss: 1.4657, Acc: 64.93%\n",
      "Epoch 3/3, Batch 18640, Loss: 0.0467, Acc: 64.93%\n",
      "Epoch 3/3, Batch 18650, Loss: 0.0157, Acc: 64.93%\n",
      "Epoch 3/3, Batch 18660, Loss: 0.5672, Acc: 64.94%\n",
      "Epoch 3/3, Batch 18670, Loss: 0.5407, Acc: 64.94%\n",
      "Epoch 3/3, Batch 18680, Loss: 0.7183, Acc: 64.92%\n",
      "Epoch 3/3, Batch 18690, Loss: 0.9200, Acc: 64.92%\n",
      "Epoch 3/3, Batch 18700, Loss: 0.9150, Acc: 64.92%\n",
      "Epoch 3/3, Batch 18710, Loss: 0.7219, Acc: 64.90%\n",
      "Epoch 3/3, Batch 18720, Loss: 0.9719, Acc: 64.90%\n",
      "Epoch 3/3, Batch 18730, Loss: 1.9988, Acc: 64.91%\n",
      "Epoch 3/3, Batch 18740, Loss: 0.1389, Acc: 64.91%\n",
      "Epoch 3/3, Batch 18750, Loss: 0.9373, Acc: 64.89%\n",
      "Epoch 3/3, Batch 18760, Loss: 0.1071, Acc: 64.90%\n",
      "Epoch 3/3, Batch 18770, Loss: 1.0354, Acc: 64.90%\n",
      "Epoch 3/3, Batch 18780, Loss: 1.2055, Acc: 64.90%\n",
      "Epoch 3/3, Batch 18790, Loss: 0.5757, Acc: 64.90%\n",
      "Epoch 3/3, Batch 18800, Loss: 0.0305, Acc: 64.91%\n",
      "Epoch 3/3, Batch 18810, Loss: 0.4615, Acc: 64.90%\n",
      "Epoch 3/3, Batch 18820, Loss: 0.2158, Acc: 64.91%\n",
      "Epoch 3/3, Batch 18830, Loss: 0.6044, Acc: 64.92%\n",
      "Epoch 3/3, Batch 18840, Loss: 0.7215, Acc: 64.92%\n",
      "Epoch 3/3, Batch 18850, Loss: 0.3565, Acc: 64.92%\n",
      "Epoch 3/3, Batch 18860, Loss: 0.8103, Acc: 64.92%\n",
      "Epoch 3/3, Batch 18870, Loss: 0.7759, Acc: 64.93%\n",
      "Epoch 3/3, Batch 18880, Loss: 2.0275, Acc: 64.92%\n",
      "Epoch 3/3, Batch 18890, Loss: 0.3140, Acc: 64.91%\n",
      "Epoch 3/3, Batch 18900, Loss: 1.9992, Acc: 64.91%\n",
      "Epoch 3/3, Batch 18910, Loss: 0.2437, Acc: 64.91%\n",
      "Epoch 3/3, Batch 18920, Loss: 0.8382, Acc: 64.91%\n",
      "Epoch 3/3, Batch 18930, Loss: 0.0034, Acc: 64.92%\n",
      "Epoch 3/3, Batch 18940, Loss: 0.0314, Acc: 64.92%\n",
      "Epoch 3/3, Batch 18950, Loss: 0.3281, Acc: 64.93%\n",
      "Epoch 3/3, Batch 18960, Loss: 0.0662, Acc: 64.93%\n",
      "Epoch 3/3, Batch 18970, Loss: 0.4658, Acc: 64.94%\n",
      "Epoch 3/3, Batch 18980, Loss: 0.4818, Acc: 64.94%\n",
      "Epoch 3/3, Batch 18990, Loss: 0.0716, Acc: 64.94%\n",
      "Epoch 3/3, Batch 19000, Loss: 0.6275, Acc: 64.93%\n",
      "Epoch 3/3, Batch 19010, Loss: 1.0213, Acc: 64.93%\n",
      "Epoch 3/3, Batch 19020, Loss: 1.6152, Acc: 64.93%\n",
      "Epoch 3/3, Batch 19030, Loss: 0.0864, Acc: 64.94%\n",
      "Epoch 3/3, Batch 19040, Loss: 1.0438, Acc: 64.93%\n",
      "Epoch 3/3, Batch 19050, Loss: 0.9135, Acc: 64.93%\n",
      "Epoch 3/3, Batch 19060, Loss: 1.2661, Acc: 64.92%\n",
      "Epoch 3/3, Batch 19070, Loss: 0.5389, Acc: 64.92%\n",
      "Epoch 3/3, Batch 19080, Loss: 0.1597, Acc: 64.93%\n",
      "Epoch 3/3, Batch 19090, Loss: 0.0280, Acc: 64.93%\n",
      "Epoch 3/3, Batch 19100, Loss: 0.7667, Acc: 64.93%\n",
      "Epoch 3/3, Batch 19110, Loss: 0.0032, Acc: 64.95%\n",
      "Epoch 3/3, Batch 19120, Loss: 0.7177, Acc: 64.94%\n",
      "Epoch 3/3, Batch 19130, Loss: 0.0141, Acc: 64.94%\n",
      "Epoch 3/3, Batch 19140, Loss: 0.0243, Acc: 64.93%\n",
      "Epoch 3/3, Batch 19150, Loss: 0.0077, Acc: 64.93%\n",
      "Epoch 3/3, Batch 19160, Loss: 0.9808, Acc: 64.92%\n",
      "Epoch 3/3, Batch 19170, Loss: 0.1810, Acc: 64.92%\n",
      "Epoch 3/3, Batch 19180, Loss: 0.2503, Acc: 64.91%\n",
      "Epoch 3/3, Batch 19190, Loss: 1.2413, Acc: 64.91%\n",
      "Epoch 3/3, Batch 19200, Loss: 0.5219, Acc: 64.89%\n",
      "Epoch 3/3, Batch 19210, Loss: 0.5045, Acc: 64.91%\n",
      "Epoch 3/3, Batch 19220, Loss: 0.5392, Acc: 64.91%\n",
      "Epoch 3/3, Batch 19230, Loss: 0.8171, Acc: 64.90%\n",
      "Epoch 3/3, Batch 19240, Loss: 0.5431, Acc: 64.90%\n",
      "Epoch 3/3, Batch 19250, Loss: 0.6445, Acc: 64.91%\n",
      "Epoch 3/3, Batch 19260, Loss: 0.0600, Acc: 64.91%\n",
      "Epoch 3/3, Batch 19270, Loss: 0.7557, Acc: 64.90%\n",
      "Epoch 3/3, Batch 19280, Loss: 1.0683, Acc: 64.89%\n",
      "Epoch 3/3, Batch 19290, Loss: 0.1905, Acc: 64.89%\n",
      "Epoch 3/3, Batch 19300, Loss: 1.7363, Acc: 64.90%\n",
      "Epoch 3/3, Batch 19310, Loss: 0.2056, Acc: 64.92%\n",
      "Epoch 3/3, Batch 19320, Loss: 0.5823, Acc: 64.90%\n",
      "Epoch 3/3, Batch 19330, Loss: 1.6025, Acc: 64.91%\n",
      "Epoch 3/3, Batch 19340, Loss: 2.3329, Acc: 64.91%\n",
      "Epoch 3/3, Batch 19350, Loss: 0.2705, Acc: 64.90%\n",
      "Epoch 3/3, Batch 19360, Loss: 0.7716, Acc: 64.88%\n",
      "Epoch 3/3, Batch 19370, Loss: 0.4286, Acc: 64.89%\n",
      "Epoch 3/3, Batch 19380, Loss: 0.2681, Acc: 64.90%\n",
      "Epoch 3/3, Batch 19390, Loss: 0.3861, Acc: 64.91%\n",
      "Epoch 3/3, Batch 19400, Loss: 0.0705, Acc: 64.91%\n",
      "Epoch 3/3, Batch 19410, Loss: 0.5414, Acc: 64.91%\n",
      "Epoch 3/3, Batch 19420, Loss: 0.0363, Acc: 64.91%\n",
      "Epoch 3/3, Batch 19430, Loss: 0.1146, Acc: 64.91%\n",
      "Epoch 3/3, Batch 19440, Loss: 1.3953, Acc: 64.91%\n",
      "Epoch 3/3, Batch 19450, Loss: 1.3330, Acc: 64.91%\n",
      "Epoch 3/3, Batch 19460, Loss: 0.0383, Acc: 64.91%\n",
      "Epoch 3/3, Batch 19470, Loss: 0.4529, Acc: 64.91%\n",
      "Epoch 3/3, Batch 19480, Loss: 0.0437, Acc: 64.89%\n",
      "Epoch 3/3, Batch 19490, Loss: 0.7759, Acc: 64.90%\n",
      "Epoch 3/3, Batch 19500, Loss: 0.3700, Acc: 64.88%\n",
      "Epoch 3/3, Batch 19510, Loss: 0.7311, Acc: 64.89%\n",
      "Epoch 3/3, Batch 19520, Loss: 0.1215, Acc: 64.88%\n",
      "Epoch 3/3, Batch 19530, Loss: 0.5794, Acc: 64.88%\n",
      "Epoch 3/3, Batch 19540, Loss: 0.4151, Acc: 64.87%\n",
      "Epoch 3/3, Batch 19550, Loss: 1.0863, Acc: 64.86%\n",
      "Epoch 3/3, Batch 19560, Loss: 1.3795, Acc: 64.85%\n",
      "Epoch 3/3, Batch 19570, Loss: 0.1384, Acc: 64.85%\n",
      "Epoch 3/3, Batch 19580, Loss: 0.6065, Acc: 64.86%\n",
      "Epoch 3/3, Batch 19590, Loss: 0.5731, Acc: 64.87%\n",
      "Epoch 3/3, Batch 19600, Loss: 1.0910, Acc: 64.87%\n",
      "Epoch 3/3, Batch 19610, Loss: 1.3347, Acc: 64.86%\n",
      "Epoch 3/3, Batch 19620, Loss: 0.5456, Acc: 64.86%\n",
      "Epoch 3/3, Batch 19630, Loss: 0.7787, Acc: 64.85%\n",
      "Epoch 3/3, Batch 19640, Loss: 0.4415, Acc: 64.86%\n",
      "Epoch 3/3, Batch 19650, Loss: 0.4201, Acc: 64.86%\n",
      "Epoch 3/3, Batch 19660, Loss: 0.9362, Acc: 64.86%\n",
      "Epoch 3/3, Batch 19670, Loss: 0.5932, Acc: 64.87%\n",
      "Epoch 3/3, Batch 19680, Loss: 0.4727, Acc: 64.87%\n",
      "Epoch 3/3, Batch 19690, Loss: 0.0295, Acc: 64.88%\n",
      "Epoch 3/3, Batch 19700, Loss: 0.5775, Acc: 64.90%\n",
      "Epoch 3/3, Batch 19710, Loss: 0.0297, Acc: 64.89%\n",
      "Epoch 3/3, Batch 19720, Loss: 0.2187, Acc: 64.89%\n",
      "Epoch 3/3, Batch 19730, Loss: 0.5343, Acc: 64.89%\n",
      "Epoch 3/3, Batch 19740, Loss: 0.3224, Acc: 64.89%\n",
      "Epoch 3/3, Batch 19750, Loss: 0.5819, Acc: 64.88%\n",
      "Epoch 3/3, Batch 19760, Loss: 0.2506, Acc: 64.88%\n",
      "Epoch 3/3, Batch 19770, Loss: 0.0917, Acc: 64.89%\n",
      "Epoch 3/3, Batch 19780, Loss: 0.0279, Acc: 64.89%\n",
      "Epoch 3/3, Batch 19790, Loss: 0.0347, Acc: 64.90%\n",
      "Epoch 3/3, Batch 19800, Loss: 0.5369, Acc: 64.91%\n",
      "Epoch 3/3, Batch 19810, Loss: 0.6594, Acc: 64.90%\n",
      "Epoch 3/3, Batch 19820, Loss: 0.0801, Acc: 64.91%\n",
      "Epoch 3/3, Batch 19830, Loss: 0.5337, Acc: 64.92%\n",
      "Epoch 3/3, Batch 19840, Loss: 0.6924, Acc: 64.93%\n",
      "Epoch 3/3, Batch 19850, Loss: 1.0391, Acc: 64.91%\n",
      "Epoch 3/3, Batch 19860, Loss: 1.1568, Acc: 64.91%\n",
      "Epoch 3/3, Batch 19870, Loss: 0.8991, Acc: 64.91%\n",
      "Epoch 3/3, Batch 19880, Loss: 0.1344, Acc: 64.90%\n",
      "Epoch 3/3, Batch 19890, Loss: 1.4439, Acc: 64.90%\n",
      "Epoch 3/3, Batch 19900, Loss: 0.2200, Acc: 64.89%\n",
      "Epoch 3/3, Batch 19910, Loss: 0.6516, Acc: 64.90%\n",
      "Epoch 3/3, Batch 19920, Loss: 0.9552, Acc: 64.90%\n",
      "Epoch 3/3, Batch 19930, Loss: 0.4318, Acc: 64.90%\n",
      "Epoch 3/3, Batch 19940, Loss: 1.3618, Acc: 64.91%\n",
      "Epoch 3/3, Batch 19950, Loss: 0.7690, Acc: 64.90%\n",
      "Epoch 3/3, Batch 19960, Loss: 2.6602, Acc: 64.90%\n",
      "Epoch 3/3, Batch 19970, Loss: 0.1800, Acc: 64.90%\n",
      "Epoch 3/3, Batch 19980, Loss: 1.1632, Acc: 64.89%\n",
      "Epoch 3/3, Batch 19990, Loss: 0.5482, Acc: 64.89%\n",
      "Epoch 3/3, Batch 20000, Loss: 0.5893, Acc: 64.89%\n",
      "Epoch 3/3, Batch 20010, Loss: 0.8615, Acc: 64.88%\n",
      "Epoch 3/3, Batch 20020, Loss: 0.2423, Acc: 64.87%\n",
      "Epoch 3/3, Batch 20030, Loss: 0.5526, Acc: 64.85%\n",
      "Epoch 3/3, Batch 20040, Loss: 0.1667, Acc: 64.86%\n",
      "Epoch 3/3, Batch 20050, Loss: 1.0780, Acc: 64.86%\n",
      "Epoch 3/3, Batch 20060, Loss: 0.7466, Acc: 64.87%\n",
      "Epoch 3/3, Batch 20070, Loss: 0.2720, Acc: 64.87%\n",
      "Epoch 3/3, Batch 20080, Loss: 0.6061, Acc: 64.86%\n",
      "Epoch 3/3, Batch 20090, Loss: 0.9398, Acc: 64.85%\n",
      "Epoch 3/3, Batch 20100, Loss: 0.3460, Acc: 64.84%\n",
      "Epoch 3/3, Batch 20110, Loss: 0.7833, Acc: 64.85%\n",
      "Epoch 3/3, Batch 20120, Loss: 2.1952, Acc: 64.85%\n",
      "Epoch 3/3, Batch 20130, Loss: 0.4428, Acc: 64.84%\n",
      "Epoch 3/3, Batch 20140, Loss: 0.8571, Acc: 64.84%\n",
      "Epoch 3/3, Batch 20150, Loss: 1.3407, Acc: 64.85%\n",
      "Epoch 3/3, Batch 20160, Loss: 1.2692, Acc: 64.84%\n",
      "Epoch 3/3, Batch 20170, Loss: 0.6833, Acc: 64.85%\n",
      "Epoch 3/3, Batch 20180, Loss: 0.1189, Acc: 64.85%\n",
      "Epoch 3/3, Batch 20190, Loss: 1.0645, Acc: 64.86%\n",
      "Epoch 3/3, Batch 20200, Loss: 0.0487, Acc: 64.86%\n",
      "Epoch 3/3, Batch 20210, Loss: 0.3456, Acc: 64.86%\n",
      "Epoch 3/3, Batch 20220, Loss: 0.0404, Acc: 64.87%\n",
      "Epoch 3/3, Batch 20230, Loss: 0.9146, Acc: 64.86%\n",
      "Epoch 3/3, Batch 20240, Loss: 0.0181, Acc: 64.85%\n",
      "Epoch 3/3, Batch 20250, Loss: 0.5999, Acc: 64.85%\n",
      "Epoch 3/3, Batch 20260, Loss: 0.3335, Acc: 64.86%\n",
      "Epoch 3/3, Batch 20270, Loss: 0.0089, Acc: 64.85%\n",
      "Epoch 3/3, Batch 20280, Loss: 0.7944, Acc: 64.86%\n",
      "Epoch 3/3, Batch 20290, Loss: 0.1322, Acc: 64.86%\n",
      "Epoch 3/3, Batch 20300, Loss: 0.8116, Acc: 64.85%\n",
      "Epoch 3/3, Batch 20310, Loss: 0.9279, Acc: 64.85%\n",
      "Epoch 3/3, Batch 20320, Loss: 1.2526, Acc: 64.85%\n",
      "Epoch 3/3, Batch 20330, Loss: 0.2120, Acc: 64.86%\n",
      "Epoch 3/3, Batch 20340, Loss: 1.0470, Acc: 64.87%\n",
      "Epoch 3/3, Batch 20350, Loss: 1.1721, Acc: 64.87%\n",
      "Epoch 3/3, Batch 20360, Loss: 1.2905, Acc: 64.86%\n",
      "Epoch 3/3, Batch 20370, Loss: 1.0922, Acc: 64.85%\n",
      "Epoch 3/3, Batch 20380, Loss: 0.0482, Acc: 64.86%\n",
      "Epoch 3/3, Batch 20390, Loss: 0.5560, Acc: 64.86%\n",
      "Epoch 3/3, Batch 20400, Loss: 0.8464, Acc: 64.86%\n",
      "Epoch 3/3, Batch 20410, Loss: 0.9395, Acc: 64.86%\n",
      "Epoch 3/3, Batch 20420, Loss: 0.0207, Acc: 64.86%\n",
      "Epoch 3/3, Batch 20430, Loss: 0.6046, Acc: 64.87%\n",
      "Epoch 3/3, Batch 20440, Loss: 0.7310, Acc: 64.86%\n",
      "Epoch 3/3, Batch 20450, Loss: 1.4869, Acc: 64.87%\n",
      "Epoch 3/3, Batch 20460, Loss: 0.0376, Acc: 64.87%\n",
      "Epoch 3/3, Batch 20470, Loss: 1.3786, Acc: 64.88%\n",
      "Epoch 3/3, Batch 20480, Loss: 0.8065, Acc: 64.88%\n",
      "Epoch 3/3, Batch 20490, Loss: 0.2463, Acc: 64.89%\n",
      "Epoch 3/3, Batch 20500, Loss: 0.5341, Acc: 64.89%\n",
      "Epoch 3/3, Batch 20510, Loss: 0.2287, Acc: 64.91%\n",
      "Epoch 3/3, Batch 20520, Loss: 1.1352, Acc: 64.91%\n",
      "Epoch 3/3, Batch 20530, Loss: 0.6317, Acc: 64.91%\n",
      "Epoch 3/3, Batch 20540, Loss: 0.0528, Acc: 64.91%\n",
      "Epoch 3/3, Batch 20550, Loss: 0.4356, Acc: 64.92%\n",
      "Epoch 3/3, Batch 20560, Loss: 0.0921, Acc: 64.91%\n",
      "Epoch 3/3, Batch 20570, Loss: 0.4804, Acc: 64.93%\n",
      "Epoch 3/3, Batch 20580, Loss: 0.4593, Acc: 64.93%\n",
      "Epoch 3/3, Batch 20590, Loss: 0.0017, Acc: 64.94%\n",
      "Epoch 3/3, Batch 20600, Loss: 0.0732, Acc: 64.93%\n",
      "Epoch 3/3, Batch 20610, Loss: 0.3255, Acc: 64.94%\n",
      "Epoch 3/3, Batch 20620, Loss: 1.9591, Acc: 64.95%\n",
      "Epoch 3/3, Batch 20630, Loss: 0.8124, Acc: 64.95%\n",
      "Epoch 3/3, Batch 20640, Loss: 0.1193, Acc: 64.96%\n",
      "Epoch 3/3, Batch 20650, Loss: 0.6923, Acc: 64.98%\n",
      "Epoch 3/3, Batch 20660, Loss: 0.0374, Acc: 64.98%\n",
      "Epoch 3/3, Batch 20670, Loss: 0.0360, Acc: 64.99%\n",
      "Epoch 3/3, Batch 20680, Loss: 0.0258, Acc: 65.01%\n",
      "Epoch 3/3, Batch 20690, Loss: 0.2489, Acc: 65.00%\n",
      "Epoch 3/3, Batch 20700, Loss: 0.6312, Acc: 65.01%\n",
      "Epoch 3/3, Batch 20710, Loss: 0.2437, Acc: 65.01%\n",
      "Epoch 3/3, Batch 20720, Loss: 0.0011, Acc: 65.02%\n",
      "Epoch 3/3, Batch 20730, Loss: 0.8800, Acc: 65.01%\n",
      "Epoch 3/3, Batch 20740, Loss: 1.1020, Acc: 65.03%\n",
      "Epoch 3/3, Batch 20750, Loss: 2.0251, Acc: 65.02%\n",
      "Epoch 3/3, Batch 20760, Loss: 0.2080, Acc: 65.03%\n",
      "Epoch 3/3, Batch 20770, Loss: 0.0369, Acc: 65.03%\n",
      "Epoch 3/3, Batch 20780, Loss: 1.0711, Acc: 65.03%\n",
      "Epoch 3/3, Batch 20790, Loss: 0.2680, Acc: 65.04%\n",
      "Epoch 3/3, Batch 20800, Loss: 0.6009, Acc: 65.04%\n",
      "Epoch 3/3, Batch 20810, Loss: 0.7215, Acc: 65.02%\n",
      "Epoch 3/3, Batch 20820, Loss: 0.1925, Acc: 65.02%\n",
      "Epoch 3/3, Batch 20830, Loss: 0.5426, Acc: 65.02%\n",
      "Epoch 3/3, Batch 20840, Loss: 1.6572, Acc: 65.03%\n",
      "Epoch 3/3, Batch 20850, Loss: 0.2338, Acc: 65.02%\n",
      "Epoch 3/3, Batch 20860, Loss: 0.9598, Acc: 65.03%\n",
      "Epoch 3/3, Batch 20870, Loss: 1.0876, Acc: 65.02%\n",
      "Epoch 3/3, Batch 20880, Loss: 0.3819, Acc: 65.02%\n",
      "Epoch 3/3, Batch 20890, Loss: 0.9521, Acc: 65.02%\n",
      "Epoch 3/3, Batch 20900, Loss: 0.5653, Acc: 65.02%\n",
      "Epoch 3/3, Batch 20910, Loss: 0.2861, Acc: 65.03%\n",
      "Epoch 3/3, Batch 20920, Loss: 0.4663, Acc: 65.04%\n",
      "Epoch 3/3, Batch 20930, Loss: 0.4484, Acc: 65.05%\n",
      "Epoch 3/3, Batch 20940, Loss: 0.0216, Acc: 65.05%\n",
      "Epoch 3/3, Batch 20950, Loss: 0.0395, Acc: 65.06%\n",
      "Epoch 3/3, Batch 20960, Loss: 0.5667, Acc: 65.05%\n",
      "Epoch 3/3, Batch 20970, Loss: 0.0381, Acc: 65.06%\n",
      "Epoch 3/3, Batch 20980, Loss: 0.9232, Acc: 65.05%\n",
      "Epoch 3/3, Batch 20990, Loss: 1.1752, Acc: 65.05%\n",
      "Epoch 3/3, Batch 21000, Loss: 0.6076, Acc: 65.05%\n",
      "Epoch 3/3, Batch 21010, Loss: 0.0404, Acc: 65.05%\n",
      "Epoch 3/3, Batch 21020, Loss: 0.4348, Acc: 65.05%\n",
      "Epoch 3/3, Batch 21030, Loss: 0.3822, Acc: 65.05%\n",
      "Epoch 3/3, Batch 21040, Loss: 1.1118, Acc: 65.05%\n",
      "Epoch 3/3, Batch 21050, Loss: 0.4163, Acc: 65.06%\n",
      "Epoch 3/3, Batch 21060, Loss: 0.0232, Acc: 65.07%\n",
      "Epoch 3/3, Batch 21070, Loss: 1.1307, Acc: 65.06%\n",
      "Epoch 3/3, Batch 21080, Loss: 0.0161, Acc: 65.07%\n",
      "Epoch 3/3, Batch 21090, Loss: 0.8221, Acc: 65.08%\n",
      "Epoch 3/3, Batch 21100, Loss: 0.9111, Acc: 65.09%\n",
      "Epoch 3/3, Batch 21110, Loss: 0.3224, Acc: 65.08%\n",
      "Epoch 3/3, Batch 21120, Loss: 0.8636, Acc: 65.06%\n",
      "Epoch 3/3, Batch 21130, Loss: 0.4451, Acc: 65.07%\n",
      "Epoch 3/3, Batch 21140, Loss: 0.0803, Acc: 65.07%\n",
      "Epoch 3/3, Batch 21150, Loss: 0.0340, Acc: 65.07%\n",
      "Epoch 3/3, Batch 21160, Loss: 1.3328, Acc: 65.08%\n",
      "Epoch 3/3, Batch 21170, Loss: 0.8177, Acc: 65.07%\n",
      "Epoch 3/3, Batch 21180, Loss: 0.6108, Acc: 65.07%\n",
      "Epoch 3/3, Batch 21190, Loss: 0.5250, Acc: 65.07%\n",
      "Epoch 3/3, Batch 21200, Loss: 0.1459, Acc: 65.08%\n",
      "Epoch 3/3, Batch 21210, Loss: 0.1541, Acc: 65.08%\n",
      "Epoch 3/3, Batch 21220, Loss: 0.3085, Acc: 65.09%\n",
      "Epoch 3/3, Batch 21230, Loss: 0.6318, Acc: 65.09%\n",
      "Epoch 3/3, Batch 21240, Loss: 0.0711, Acc: 65.11%\n",
      "Epoch 3/3, Batch 21250, Loss: 0.5528, Acc: 65.10%\n",
      "Epoch 3/3, Batch 21260, Loss: 0.6909, Acc: 65.10%\n",
      "Epoch 3/3, Batch 21270, Loss: 0.3746, Acc: 65.11%\n",
      "Epoch 3/3, Batch 21280, Loss: 0.7994, Acc: 65.10%\n",
      "Epoch 3/3, Batch 21290, Loss: 0.1001, Acc: 65.10%\n",
      "Epoch 3/3, Batch 21300, Loss: 1.0897, Acc: 65.10%\n",
      "Epoch 3/3, Batch 21310, Loss: 0.8282, Acc: 65.11%\n",
      "Epoch 3/3, Batch 21320, Loss: 0.9430, Acc: 65.10%\n",
      "Epoch 3/3, Batch 21330, Loss: 0.0334, Acc: 65.11%\n",
      "Epoch 3/3, Batch 21340, Loss: 0.9690, Acc: 65.10%\n",
      "Epoch 3/3, Batch 21350, Loss: 0.4139, Acc: 65.11%\n",
      "Epoch 3/3, Batch 21360, Loss: 0.5506, Acc: 65.11%\n",
      "Epoch 3/3, Batch 21370, Loss: 0.6623, Acc: 65.10%\n",
      "Epoch 3/3, Batch 21380, Loss: 0.2936, Acc: 65.10%\n",
      "Epoch 3/3, Batch 21390, Loss: 1.7553, Acc: 65.11%\n",
      "Epoch 3/3, Batch 21400, Loss: 0.6628, Acc: 65.11%\n",
      "Epoch 3/3, Batch 21410, Loss: 0.4602, Acc: 65.11%\n",
      "Epoch 3/3, Batch 21420, Loss: 0.5193, Acc: 65.10%\n",
      "Epoch 3/3, Batch 21430, Loss: 0.0752, Acc: 65.11%\n",
      "Epoch 3/3, Batch 21440, Loss: 0.3626, Acc: 65.11%\n",
      "Epoch 3/3, Batch 21450, Loss: 0.1691, Acc: 65.11%\n",
      "Epoch 3/3, Batch 21460, Loss: 0.8353, Acc: 65.12%\n",
      "Epoch 3/3, Batch 21470, Loss: 0.5472, Acc: 65.12%\n",
      "Epoch 3/3, Batch 21480, Loss: 0.3266, Acc: 65.12%\n",
      "Epoch 3/3, Batch 21490, Loss: 0.4618, Acc: 65.11%\n",
      "Epoch 3/3, Batch 21500, Loss: 0.7741, Acc: 65.10%\n",
      "Epoch 3/3, Batch 21510, Loss: 0.3443, Acc: 65.12%\n",
      "Epoch 3/3, Batch 21520, Loss: 0.8963, Acc: 65.10%\n",
      "Epoch 3/3, Batch 21530, Loss: 1.1763, Acc: 65.10%\n",
      "Epoch 3/3, Batch 21540, Loss: 0.8599, Acc: 65.09%\n",
      "Epoch 3/3, Batch 21550, Loss: 0.0794, Acc: 65.10%\n",
      "Epoch 3/3, Batch 21560, Loss: 0.0051, Acc: 65.09%\n",
      "Epoch 3/3, Batch 21570, Loss: 0.2662, Acc: 65.11%\n",
      "Epoch 3/3, Batch 21580, Loss: 0.9071, Acc: 65.10%\n",
      "Epoch 3/3, Batch 21590, Loss: 0.6463, Acc: 65.10%\n",
      "Epoch 3/3, Batch 21600, Loss: 1.0642, Acc: 65.11%\n",
      "Epoch 3/3, Batch 21610, Loss: 0.9609, Acc: 65.11%\n",
      "Epoch 3/3, Batch 21620, Loss: 0.4857, Acc: 65.11%\n",
      "Epoch 3/3, Batch 21630, Loss: 0.7131, Acc: 65.11%\n",
      "Epoch 3/3, Batch 21640, Loss: 1.9488, Acc: 65.11%\n",
      "Epoch 3/3, Batch 21650, Loss: 0.5067, Acc: 65.12%\n",
      "Epoch 3/3, Batch 21660, Loss: 0.3205, Acc: 65.13%\n",
      "Epoch 3/3, Batch 21670, Loss: 0.0513, Acc: 65.12%\n",
      "Epoch 3/3, Batch 21680, Loss: 0.0255, Acc: 65.11%\n",
      "Epoch 3/3, Batch 21690, Loss: 0.3949, Acc: 65.11%\n",
      "Epoch 3/3, Batch 21700, Loss: 0.0051, Acc: 65.12%\n",
      "Epoch 3/3, Batch 21710, Loss: 1.2330, Acc: 65.11%\n",
      "Epoch 3/3, Batch 21720, Loss: 0.0157, Acc: 65.11%\n",
      "Epoch 3/3, Batch 21730, Loss: 0.3421, Acc: 65.11%\n",
      "Epoch 3/3, Batch 21740, Loss: 0.4060, Acc: 65.11%\n",
      "Epoch 3/3, Batch 21750, Loss: 0.9125, Acc: 65.10%\n",
      "Epoch 3/3, Batch 21760, Loss: 1.4446, Acc: 65.10%\n",
      "Epoch 3/3, Batch 21770, Loss: 1.2726, Acc: 65.10%\n",
      "Epoch 3/3, Batch 21780, Loss: 0.0360, Acc: 65.12%\n",
      "Epoch 3/3, Batch 21790, Loss: 0.0336, Acc: 65.10%\n",
      "Epoch 3/3, Batch 21800, Loss: 1.8071, Acc: 65.11%\n",
      "Epoch 3/3, Batch 21810, Loss: 0.0300, Acc: 65.12%\n",
      "Epoch 3/3, Batch 21820, Loss: 1.9795, Acc: 65.12%\n",
      "Epoch 3/3, Batch 21830, Loss: 1.0406, Acc: 65.11%\n",
      "Epoch 3/3, Batch 21840, Loss: 0.0043, Acc: 65.10%\n",
      "Epoch 3/3, Batch 21850, Loss: 0.1304, Acc: 65.10%\n",
      "Epoch 3/3, Batch 21860, Loss: 0.7878, Acc: 65.10%\n",
      "Epoch 3/3, Batch 21870, Loss: 0.5599, Acc: 65.10%\n",
      "Epoch 3/3, Batch 21880, Loss: 1.4543, Acc: 65.09%\n",
      "Epoch 3/3, Batch 21890, Loss: 0.3384, Acc: 65.09%\n",
      "Epoch 3/3, Batch 21900, Loss: 0.7016, Acc: 65.09%\n",
      "Epoch 3/3, Batch 21910, Loss: 0.9579, Acc: 65.08%\n",
      "Epoch 3/3, Batch 21920, Loss: 0.3388, Acc: 65.07%\n",
      "Epoch 3/3, Batch 21930, Loss: 0.0143, Acc: 65.08%\n",
      "Epoch 3/3, Batch 21940, Loss: 1.6325, Acc: 65.08%\n",
      "Epoch 3/3, Batch 21950, Loss: 0.7683, Acc: 65.09%\n",
      "Epoch 3/3, Batch 21960, Loss: 0.5134, Acc: 65.08%\n",
      "Epoch 3/3, Batch 21970, Loss: 0.0974, Acc: 65.08%\n",
      "Epoch 3/3, Batch 21980, Loss: 0.3353, Acc: 65.09%\n",
      "Epoch 3/3, Batch 21990, Loss: 0.0025, Acc: 65.09%\n",
      "Epoch 3/3, Batch 22000, Loss: 0.6463, Acc: 65.09%\n",
      "Epoch 3/3, Batch 22010, Loss: 0.0142, Acc: 65.09%\n",
      "Epoch 3/3, Batch 22020, Loss: 3.2961, Acc: 65.09%\n",
      "Epoch 3/3, Batch 22030, Loss: 0.5524, Acc: 65.08%\n",
      "Epoch 3/3, Batch 22040, Loss: 1.3982, Acc: 65.08%\n",
      "Epoch 3/3, Batch 22050, Loss: 0.7092, Acc: 65.08%\n",
      "Epoch 3/3, Batch 22060, Loss: 1.2565, Acc: 65.07%\n",
      "Epoch 3/3, Batch 22070, Loss: 0.9383, Acc: 65.07%\n",
      "Epoch 3/3, Batch 22080, Loss: 0.0667, Acc: 65.07%\n",
      "Epoch 3/3, Batch 22090, Loss: 0.0164, Acc: 65.07%\n",
      "Epoch 3/3, Batch 22100, Loss: 0.8780, Acc: 65.07%\n",
      "Epoch 3/3, Batch 22110, Loss: 0.2830, Acc: 65.08%\n",
      "Epoch 3/3, Batch 22120, Loss: 0.2010, Acc: 65.09%\n",
      "Epoch 3/3, Batch 22130, Loss: 0.0805, Acc: 65.09%\n",
      "Epoch 3/3, Batch 22140, Loss: 0.1935, Acc: 65.10%\n",
      "Epoch 3/3, Batch 22150, Loss: 0.1169, Acc: 65.10%\n",
      "Epoch 3/3, Batch 22160, Loss: 0.3057, Acc: 65.10%\n",
      "Epoch 3/3, Batch 22170, Loss: 0.8711, Acc: 65.09%\n",
      "Epoch 3/3, Batch 22180, Loss: 0.0432, Acc: 65.09%\n",
      "Epoch 3/3, Batch 22190, Loss: 0.0135, Acc: 65.10%\n",
      "Epoch 3/3, Batch 22200, Loss: 1.0071, Acc: 65.10%\n",
      "Epoch 3/3, Batch 22210, Loss: 0.1323, Acc: 65.10%\n",
      "Epoch 3/3, Batch 22220, Loss: 0.0040, Acc: 65.09%\n",
      "Epoch 3/3, Batch 22230, Loss: 0.0648, Acc: 65.10%\n",
      "Epoch 3/3, Batch 22240, Loss: 0.1904, Acc: 65.10%\n",
      "Epoch 3/3, Batch 22250, Loss: 0.2808, Acc: 65.09%\n",
      "Epoch 3/3, Batch 22260, Loss: 1.8392, Acc: 65.08%\n",
      "Epoch 3/3, Batch 22270, Loss: 0.9656, Acc: 65.08%\n",
      "Epoch 3/3, Batch 22280, Loss: 0.0042, Acc: 65.07%\n",
      "Epoch 3/3, Batch 22290, Loss: 0.4877, Acc: 65.08%\n",
      "Epoch 3/3, Batch 22300, Loss: 0.5983, Acc: 65.07%\n",
      "Epoch 3/3, Batch 22310, Loss: 1.0436, Acc: 65.08%\n",
      "Epoch 3/3, Batch 22320, Loss: 0.7383, Acc: 65.07%\n",
      "Epoch 3/3, Batch 22330, Loss: 0.0076, Acc: 65.07%\n",
      "Epoch 3/3, Batch 22340, Loss: 0.2106, Acc: 65.07%\n",
      "Epoch 3/3, Batch 22350, Loss: 0.6771, Acc: 65.07%\n",
      "Epoch 3/3, Batch 22360, Loss: 1.5062, Acc: 65.06%\n",
      "Epoch 3/3, Batch 22370, Loss: 0.4508, Acc: 65.06%\n",
      "Epoch 3/3, Batch 22380, Loss: 1.7017, Acc: 65.05%\n",
      "Epoch 3/3, Batch 22390, Loss: 0.3666, Acc: 65.04%\n",
      "Epoch 3/3, Batch 22400, Loss: 0.0182, Acc: 65.04%\n",
      "Epoch 3/3, Batch 22410, Loss: 0.4069, Acc: 65.04%\n",
      "Epoch 3/3, Batch 22420, Loss: 1.0366, Acc: 65.04%\n",
      "Epoch 3/3, Batch 22430, Loss: 0.2803, Acc: 65.03%\n",
      "Epoch 3/3, Batch 22440, Loss: 0.8893, Acc: 65.04%\n",
      "Epoch 3/3, Batch 22450, Loss: 0.1222, Acc: 65.04%\n",
      "Epoch 3/3, Batch 22460, Loss: 0.0352, Acc: 65.03%\n",
      "Epoch 3/3, Batch 22470, Loss: 0.4249, Acc: 65.03%\n",
      "Epoch 3/3, Batch 22480, Loss: 0.6346, Acc: 65.02%\n",
      "Epoch 3/3, Batch 22490, Loss: 1.9490, Acc: 65.02%\n",
      "Epoch 3/3, Batch 22500, Loss: 0.7374, Acc: 65.02%\n",
      "Epoch 3/3, Batch 22510, Loss: 0.8917, Acc: 65.02%\n",
      "Epoch 3/3, Batch 22520, Loss: 0.3413, Acc: 65.02%\n",
      "Epoch 3/3, Batch 22530, Loss: 1.0252, Acc: 65.02%\n",
      "Epoch 3/3, Batch 22540, Loss: 0.6394, Acc: 65.02%\n",
      "Epoch 3/3, Batch 22550, Loss: 2.2915, Acc: 65.03%\n",
      "Epoch 3/3, Batch 22560, Loss: 0.1099, Acc: 65.04%\n",
      "Epoch 3/3, Batch 22570, Loss: 0.3786, Acc: 65.04%\n",
      "Epoch 3/3, Batch 22580, Loss: 1.0629, Acc: 65.03%\n",
      "Epoch 3/3, Batch 22590, Loss: 1.1519, Acc: 65.03%\n",
      "Epoch 3/3, Batch 22600, Loss: 1.2364, Acc: 65.02%\n",
      "Epoch 3/3, Batch 22610, Loss: 0.0034, Acc: 65.03%\n",
      "Epoch 3/3, Batch 22620, Loss: 0.5614, Acc: 65.04%\n",
      "Epoch 3/3, Batch 22630, Loss: 0.5241, Acc: 65.05%\n",
      "Epoch 3/3, Batch 22640, Loss: 0.6928, Acc: 65.06%\n",
      "Epoch 3/3, Batch 22650, Loss: 0.3984, Acc: 65.06%\n",
      "Epoch 3/3, Batch 22660, Loss: 0.0043, Acc: 65.05%\n",
      "Epoch 3/3, Batch 22670, Loss: 0.1452, Acc: 65.06%\n",
      "Epoch 3/3, Batch 22680, Loss: 1.1538, Acc: 65.06%\n",
      "Epoch 3/3, Batch 22690, Loss: 0.8601, Acc: 65.06%\n",
      "Epoch 3/3, Batch 22700, Loss: 1.0187, Acc: 65.06%\n",
      "Epoch 3/3, Batch 22710, Loss: 0.0271, Acc: 65.07%\n",
      "Epoch 3/3, Batch 22720, Loss: 0.5976, Acc: 65.07%\n",
      "Epoch 3/3, Batch 22730, Loss: 0.2449, Acc: 65.07%\n",
      "Epoch 3/3, Batch 22740, Loss: 0.3032, Acc: 65.07%\n",
      "Epoch 3/3, Batch 22750, Loss: 0.0367, Acc: 65.08%\n",
      "Epoch 3/3, Batch 22760, Loss: 1.2720, Acc: 65.08%\n",
      "Epoch 3/3, Batch 22770, Loss: 0.0282, Acc: 65.08%\n",
      "Epoch 3/3, Batch 22780, Loss: 0.6949, Acc: 65.06%\n",
      "Epoch 3/3, Batch 22790, Loss: 0.3240, Acc: 65.04%\n",
      "Epoch 3/3, Batch 22800, Loss: 1.1233, Acc: 65.04%\n",
      "Epoch 3/3, Batch 22810, Loss: 0.5305, Acc: 65.04%\n",
      "Epoch 3/3, Batch 22820, Loss: 0.3469, Acc: 65.04%\n",
      "Epoch 3/3, Batch 22830, Loss: 0.5952, Acc: 65.04%\n",
      "Epoch 3/3, Batch 22840, Loss: 0.4271, Acc: 65.04%\n",
      "Epoch 3/3, Batch 22850, Loss: 0.9462, Acc: 65.03%\n",
      "Epoch 3/3, Batch 22860, Loss: 0.6269, Acc: 65.03%\n",
      "Epoch 3/3, Batch 22870, Loss: 0.0014, Acc: 65.04%\n",
      "Epoch 3/3, Batch 22880, Loss: 0.3177, Acc: 65.04%\n",
      "Epoch 3/3, Batch 22890, Loss: 1.7013, Acc: 65.03%\n",
      "Epoch 3/3, Batch 22900, Loss: 1.4042, Acc: 65.03%\n",
      "Epoch 3/3, Batch 22910, Loss: 0.3337, Acc: 65.03%\n",
      "Epoch 3/3, Batch 22920, Loss: 0.9315, Acc: 65.03%\n",
      "Epoch 3/3, Batch 22930, Loss: 0.0089, Acc: 65.02%\n",
      "Epoch 3/3, Batch 22940, Loss: 0.8876, Acc: 65.01%\n",
      "Epoch 3/3, Batch 22950, Loss: 0.5464, Acc: 65.02%\n",
      "Epoch 3/3, Batch 22960, Loss: 0.3806, Acc: 65.01%\n",
      "Epoch 3/3, Batch 22970, Loss: 1.7173, Acc: 65.01%\n",
      "Epoch 3/3, Batch 22980, Loss: 1.3733, Acc: 65.01%\n",
      "Epoch 3/3, Batch 22990, Loss: 1.6362, Acc: 64.99%\n",
      "Epoch 3/3, Batch 23000, Loss: 0.5688, Acc: 64.99%\n",
      "Epoch 3/3, Batch 23010, Loss: 0.0087, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23020, Loss: 0.9512, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23030, Loss: 1.4697, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23040, Loss: 0.4234, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23050, Loss: 0.0196, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23060, Loss: 0.1052, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23070, Loss: 0.7047, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23080, Loss: 0.8745, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23090, Loss: 0.1726, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23100, Loss: 0.8392, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23110, Loss: 0.0030, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23120, Loss: 1.7273, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23130, Loss: 0.6733, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23140, Loss: 1.1457, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23150, Loss: 0.0178, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23160, Loss: 0.0038, Acc: 65.01%\n",
      "Epoch 3/3, Batch 23170, Loss: 0.2209, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23180, Loss: 0.0791, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23190, Loss: 0.4412, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23200, Loss: 0.0595, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23210, Loss: 0.1084, Acc: 65.01%\n",
      "Epoch 3/3, Batch 23220, Loss: 0.3781, Acc: 65.01%\n",
      "Epoch 3/3, Batch 23230, Loss: 0.5101, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23240, Loss: 0.0108, Acc: 65.01%\n",
      "Epoch 3/3, Batch 23250, Loss: 1.0294, Acc: 65.01%\n",
      "Epoch 3/3, Batch 23260, Loss: 0.3165, Acc: 65.02%\n",
      "Epoch 3/3, Batch 23270, Loss: 0.0002, Acc: 65.01%\n",
      "Epoch 3/3, Batch 23280, Loss: 0.6307, Acc: 65.01%\n",
      "Epoch 3/3, Batch 23290, Loss: 0.8088, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23300, Loss: 0.3985, Acc: 64.99%\n",
      "Epoch 3/3, Batch 23310, Loss: 0.0326, Acc: 64.99%\n",
      "Epoch 3/3, Batch 23320, Loss: 0.1501, Acc: 64.98%\n",
      "Epoch 3/3, Batch 23330, Loss: 0.6508, Acc: 64.99%\n",
      "Epoch 3/3, Batch 23340, Loss: 0.0214, Acc: 64.99%\n",
      "Epoch 3/3, Batch 23350, Loss: 0.5694, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23360, Loss: 0.0009, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23370, Loss: 0.7457, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23380, Loss: 1.1754, Acc: 65.01%\n",
      "Epoch 3/3, Batch 23390, Loss: 0.7275, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23400, Loss: 0.3925, Acc: 65.01%\n",
      "Epoch 3/3, Batch 23410, Loss: 0.0328, Acc: 65.01%\n",
      "Epoch 3/3, Batch 23420, Loss: 0.7478, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23430, Loss: 0.3586, Acc: 65.01%\n",
      "Epoch 3/3, Batch 23440, Loss: 0.0382, Acc: 65.01%\n",
      "Epoch 3/3, Batch 23450, Loss: 0.7772, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23460, Loss: 0.0006, Acc: 65.01%\n",
      "Epoch 3/3, Batch 23470, Loss: 0.1702, Acc: 64.99%\n",
      "Epoch 3/3, Batch 23480, Loss: 0.0039, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23490, Loss: 1.1251, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23500, Loss: 0.0163, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23510, Loss: 1.1711, Acc: 64.99%\n",
      "Epoch 3/3, Batch 23520, Loss: 0.7290, Acc: 64.99%\n",
      "Epoch 3/3, Batch 23530, Loss: 1.2338, Acc: 64.99%\n",
      "Epoch 3/3, Batch 23540, Loss: 0.4504, Acc: 64.99%\n",
      "Epoch 3/3, Batch 23550, Loss: 0.4987, Acc: 64.99%\n",
      "Epoch 3/3, Batch 23560, Loss: 0.0357, Acc: 64.99%\n",
      "Epoch 3/3, Batch 23570, Loss: 0.0817, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23580, Loss: 0.6707, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23590, Loss: 0.9409, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23600, Loss: 0.4186, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23610, Loss: 0.0635, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23620, Loss: 0.8184, Acc: 65.00%\n",
      "Epoch 3/3, Batch 23630, Loss: 0.6788, Acc: 64.99%\n",
      "Epoch 3/3, Batch 23640, Loss: 0.7967, Acc: 64.98%\n",
      "Epoch 3/3, Batch 23650, Loss: 0.8981, Acc: 64.97%\n",
      "Epoch 3/3, Batch 23660, Loss: 0.4844, Acc: 64.97%\n",
      "Epoch 3/3, Batch 23670, Loss: 0.7336, Acc: 64.97%\n",
      "Epoch 3/3, Batch 23680, Loss: 0.7194, Acc: 64.96%\n",
      "Epoch 3/3, Batch 23690, Loss: 0.5743, Acc: 64.96%\n",
      "Epoch 3/3, Batch 23700, Loss: 0.0050, Acc: 64.96%\n",
      "Epoch 3/3, Batch 23710, Loss: 1.2249, Acc: 64.96%\n",
      "Epoch 3/3, Batch 23720, Loss: 0.9961, Acc: 64.95%\n",
      "Epoch 3/3, Batch 23730, Loss: 0.2752, Acc: 64.95%\n",
      "Epoch 3/3, Batch 23740, Loss: 0.6373, Acc: 64.94%\n",
      "Epoch 3/3, Batch 23750, Loss: 0.6135, Acc: 64.94%\n",
      "Epoch 3/3, Batch 23760, Loss: 0.6802, Acc: 64.94%\n",
      "Epoch 3/3, Batch 23770, Loss: 2.0200, Acc: 64.94%\n",
      "Epoch 3/3, Batch 23780, Loss: 0.0070, Acc: 64.94%\n",
      "Epoch 3/3, Batch 23790, Loss: 0.7936, Acc: 64.95%\n",
      "Epoch 3/3, Batch 23800, Loss: 0.5752, Acc: 64.94%\n",
      "Epoch 3/3, Batch 23810, Loss: 1.2592, Acc: 64.95%\n",
      "Epoch 3/3, Batch 23820, Loss: 0.3651, Acc: 64.95%\n",
      "Epoch 3/3, Batch 23830, Loss: 0.3440, Acc: 64.96%\n",
      "Epoch 3/3, Batch 23840, Loss: 0.2270, Acc: 64.95%\n",
      "Epoch 3/3, Batch 23850, Loss: 0.0100, Acc: 64.95%\n",
      "Epoch 3/3, Batch 23860, Loss: 0.0013, Acc: 64.94%\n",
      "Epoch 3/3, Batch 23870, Loss: 1.1423, Acc: 64.93%\n",
      "Epoch 3/3, Batch 23880, Loss: 0.5768, Acc: 64.93%\n",
      "Epoch 3/3, Batch 23890, Loss: 0.5330, Acc: 64.93%\n",
      "Epoch 3/3, Batch 23900, Loss: 0.0018, Acc: 64.93%\n",
      "Epoch 3/3, Batch 23910, Loss: 0.5623, Acc: 64.94%\n",
      "Epoch 3/3, Batch 23920, Loss: 0.8898, Acc: 64.94%\n",
      "Epoch 3/3, Batch 23930, Loss: 0.6385, Acc: 64.95%\n",
      "Epoch 3/3, Batch 23940, Loss: 1.8143, Acc: 64.94%\n",
      "Epoch 3/3, Batch 23950, Loss: 0.0596, Acc: 64.94%\n",
      "Epoch 3/3, Batch 23960, Loss: 0.6530, Acc: 64.93%\n",
      "Epoch 3/3, Batch 23970, Loss: 1.0831, Acc: 64.93%\n",
      "Epoch 3/3, Batch 23980, Loss: 0.6245, Acc: 64.93%\n",
      "Epoch 3/3, Batch 23990, Loss: 0.5223, Acc: 64.95%\n",
      "Epoch 3/3, Batch 24000, Loss: 0.3710, Acc: 64.94%\n",
      "Epoch 3/3, Batch 24010, Loss: 1.4958, Acc: 64.95%\n",
      "Epoch 3/3, Batch 24020, Loss: 0.9408, Acc: 64.94%\n",
      "Epoch 3/3, Batch 24030, Loss: 1.0257, Acc: 64.94%\n",
      "Epoch 3/3, Batch 24040, Loss: 0.0371, Acc: 64.94%\n",
      "Epoch 3/3, Batch 24050, Loss: 2.6156, Acc: 64.94%\n",
      "Epoch 3/3, Batch 24060, Loss: 0.0105, Acc: 64.95%\n",
      "Epoch 3/3, Batch 24070, Loss: 1.3354, Acc: 64.94%\n",
      "Epoch 3/3, Batch 24080, Loss: 0.9426, Acc: 64.94%\n",
      "Epoch 3/3, Batch 24090, Loss: 0.8856, Acc: 64.95%\n",
      "Epoch 3/3, Batch 24100, Loss: 0.7878, Acc: 64.94%\n",
      "Epoch 3/3, Batch 24110, Loss: 0.7831, Acc: 64.93%\n",
      "Epoch 3/3, Batch 24120, Loss: 0.0081, Acc: 64.94%\n",
      "Epoch 3/3, Batch 24130, Loss: 1.1573, Acc: 64.94%\n",
      "Epoch 3/3, Batch 24140, Loss: 0.6524, Acc: 64.94%\n",
      "Epoch 3/3, Batch 24150, Loss: 0.7524, Acc: 64.93%\n",
      "Epoch 3/3, Batch 24160, Loss: 0.9018, Acc: 64.93%\n",
      "Epoch 3/3, Batch 24170, Loss: 0.0525, Acc: 64.93%\n",
      "Epoch 3/3, Batch 24180, Loss: 0.0960, Acc: 64.94%\n",
      "Epoch 3/3, Batch 24190, Loss: 0.6190, Acc: 64.95%\n",
      "Epoch 3/3, Batch 24200, Loss: 0.6233, Acc: 64.94%\n",
      "Epoch 3/3, Batch 24210, Loss: 1.0268, Acc: 64.93%\n",
      "Epoch 3/3, Batch 24220, Loss: 0.8673, Acc: 64.94%\n",
      "Epoch 3/3, Batch 24230, Loss: 0.4232, Acc: 64.95%\n",
      "Epoch 3/3, Batch 24240, Loss: 0.7749, Acc: 64.95%\n",
      "Epoch 3/3, Batch 24250, Loss: 0.8728, Acc: 64.95%\n",
      "Epoch 3/3, Batch 24260, Loss: 0.0505, Acc: 64.95%\n",
      "Epoch 3/3, Batch 24270, Loss: 0.5451, Acc: 64.95%\n",
      "Epoch 3/3, Batch 24280, Loss: 3.0217, Acc: 64.95%\n",
      "Epoch 3/3, Batch 24290, Loss: 1.5794, Acc: 64.95%\n",
      "Epoch 3/3, Batch 24300, Loss: 0.8966, Acc: 64.93%\n",
      "Epoch 3/3, Batch 24310, Loss: 0.5841, Acc: 64.92%\n",
      "Epoch 3/3, Batch 24320, Loss: 0.8429, Acc: 64.91%\n",
      "Epoch 3/3, Batch 24330, Loss: 0.3418, Acc: 64.90%\n",
      "Epoch 3/3, Batch 24340, Loss: 0.6171, Acc: 64.91%\n",
      "Epoch 3/3, Batch 24350, Loss: 0.7234, Acc: 64.90%\n",
      "Epoch 3/3, Batch 24360, Loss: 0.2956, Acc: 64.90%\n",
      "Epoch 3/3, Batch 24370, Loss: 1.1036, Acc: 64.88%\n",
      "Epoch 3/3, Batch 24380, Loss: 0.5826, Acc: 64.89%\n",
      "Epoch 3/3, Batch 24390, Loss: 0.7923, Acc: 64.89%\n",
      "Epoch 3/3, Batch 24400, Loss: 0.0085, Acc: 64.89%\n",
      "Epoch 3/3, Batch 24410, Loss: 1.6002, Acc: 64.88%\n",
      "Epoch 3/3, Batch 24420, Loss: 0.3036, Acc: 64.90%\n",
      "Epoch 3/3, Batch 24430, Loss: 0.7031, Acc: 64.90%\n",
      "Epoch 3/3, Batch 24440, Loss: 1.4827, Acc: 64.90%\n",
      "Epoch 3/3, Batch 24450, Loss: 1.0365, Acc: 64.90%\n",
      "Epoch 3/3, Batch 24460, Loss: 0.5957, Acc: 64.91%\n",
      "Epoch 3/3, Batch 24470, Loss: 1.8317, Acc: 64.91%\n",
      "Epoch 3/3, Batch 24480, Loss: 0.0171, Acc: 64.92%\n",
      "Epoch 3/3, Batch 24490, Loss: 1.3161, Acc: 64.91%\n",
      "Epoch 3/3, Batch 24500, Loss: 0.0452, Acc: 64.92%\n",
      "Epoch 3/3, Batch 24510, Loss: 0.4351, Acc: 64.93%\n",
      "Epoch 3/3, Batch 24520, Loss: 0.0017, Acc: 64.93%\n",
      "Epoch 3/3, Batch 24530, Loss: 0.3451, Acc: 64.93%\n",
      "Epoch 3/3, Batch 24540, Loss: 0.1385, Acc: 64.93%\n",
      "Epoch 3/3, Batch 24550, Loss: 0.0262, Acc: 64.92%\n",
      "Epoch 3/3, Batch 24560, Loss: 0.8921, Acc: 64.93%\n",
      "Epoch 3/3, Batch 24570, Loss: 0.6916, Acc: 64.93%\n",
      "Epoch 3/3, Batch 24580, Loss: 0.4193, Acc: 64.94%\n",
      "Epoch 3/3, Batch 24590, Loss: 0.4267, Acc: 64.93%\n",
      "Epoch 3/3, Batch 24600, Loss: 0.5005, Acc: 64.94%\n",
      "Epoch 3/3, Batch 24610, Loss: 1.0271, Acc: 64.94%\n",
      "Epoch 3/3, Batch 24620, Loss: 0.4902, Acc: 64.95%\n",
      "Epoch 3/3, Batch 24630, Loss: 0.0121, Acc: 64.95%\n",
      "Epoch 3/3, Batch 24640, Loss: 0.3013, Acc: 64.95%\n",
      "Epoch 3/3, Batch 24650, Loss: 0.0119, Acc: 64.95%\n",
      "Epoch 3/3, Batch 24660, Loss: 0.3569, Acc: 64.96%\n",
      "Epoch 3/3, Batch 24670, Loss: 1.1266, Acc: 64.96%\n",
      "Epoch 3/3, Batch 24680, Loss: 0.9112, Acc: 64.96%\n",
      "Epoch 3/3, Batch 24690, Loss: 0.0609, Acc: 64.95%\n",
      "Epoch 3/3, Batch 24700, Loss: 0.3277, Acc: 64.96%\n",
      "Epoch 3/3, Batch 24710, Loss: 0.0144, Acc: 64.96%\n",
      "Epoch 3/3, Batch 24720, Loss: 0.8477, Acc: 64.95%\n",
      "Epoch 3/3, Batch 24730, Loss: 0.2937, Acc: 64.95%\n",
      "Epoch 3/3, Batch 24740, Loss: 0.3479, Acc: 64.95%\n",
      "Epoch 3/3, Batch 24750, Loss: 0.5404, Acc: 64.94%\n",
      "Epoch 3/3, Batch 24760, Loss: 0.7425, Acc: 64.93%\n",
      "Epoch 3/3, Batch 24770, Loss: 0.3632, Acc: 64.93%\n",
      "Epoch 3/3, Batch 24780, Loss: 0.0944, Acc: 64.93%\n",
      "Epoch 3/3, Batch 24790, Loss: 0.7767, Acc: 64.93%\n",
      "Epoch 3/3, Batch 24800, Loss: 0.2684, Acc: 64.94%\n",
      "Epoch 3/3, Batch 24810, Loss: 0.5108, Acc: 64.95%\n",
      "Epoch 3/3, Batch 24820, Loss: 0.9159, Acc: 64.95%\n",
      "Epoch 3/3, Batch 24830, Loss: 0.1216, Acc: 64.96%\n",
      "Epoch 3/3, Batch 24840, Loss: 1.4567, Acc: 64.95%\n",
      "Epoch 3/3, Batch 24850, Loss: 0.8765, Acc: 64.94%\n",
      "Epoch 3/3, Batch 24860, Loss: 0.0190, Acc: 64.95%\n",
      "Epoch 3/3, Batch 24870, Loss: 0.9154, Acc: 64.95%\n",
      "Epoch 3/3, Batch 24880, Loss: 0.2322, Acc: 64.96%\n",
      "Epoch 3/3, Batch 24890, Loss: 0.0220, Acc: 64.96%\n",
      "Epoch 3/3, Batch 24900, Loss: 0.0163, Acc: 64.96%\n",
      "Epoch 3/3, Batch 24910, Loss: 0.5707, Acc: 64.96%\n",
      "Epoch 3/3, Batch 24920, Loss: 0.0817, Acc: 64.97%\n",
      "Epoch 3/3, Batch 24930, Loss: 0.6350, Acc: 64.97%\n",
      "Epoch 3/3, Batch 24940, Loss: 0.3610, Acc: 64.98%\n",
      "Epoch 3/3, Batch 24950, Loss: 1.2688, Acc: 64.98%\n",
      "Epoch 3/3, Batch 24960, Loss: 0.2108, Acc: 64.98%\n",
      "Epoch 3/3, Batch 24970, Loss: 0.7305, Acc: 64.97%\n",
      "Epoch 3/3, Batch 24980, Loss: 0.9194, Acc: 64.97%\n",
      "Epoch 3/3, Batch 24990, Loss: 0.0979, Acc: 64.96%\n",
      "Epoch 3/3, Batch 25000, Loss: 0.7305, Acc: 64.96%\n",
      "Epoch 3/3, Batch 25010, Loss: 0.0583, Acc: 64.96%\n",
      "Epoch 3/3, Batch 25020, Loss: 0.0032, Acc: 64.97%\n",
      "Epoch 3/3, Batch 25030, Loss: 0.0302, Acc: 64.98%\n",
      "Epoch 3/3, Batch 25040, Loss: 0.9975, Acc: 64.97%\n",
      "Epoch 3/3, Batch 25050, Loss: 0.0166, Acc: 64.97%\n",
      "Epoch 3/3, Batch 25060, Loss: 0.0326, Acc: 64.97%\n",
      "Epoch 3/3, Batch 25070, Loss: 0.4282, Acc: 64.97%\n",
      "Epoch 3/3, Batch 25080, Loss: 0.4549, Acc: 64.97%\n",
      "Epoch 3/3, Batch 25090, Loss: 1.1735, Acc: 64.96%\n",
      "Epoch 3/3, Batch 25100, Loss: 0.7076, Acc: 64.97%\n",
      "Epoch 3/3, Batch 25110, Loss: 1.2682, Acc: 64.96%\n",
      "Epoch 3/3, Batch 25120, Loss: 1.2035, Acc: 64.95%\n",
      "Epoch 3/3, Batch 25130, Loss: 0.0644, Acc: 64.96%\n",
      "Epoch 3/3, Batch 25140, Loss: 0.4990, Acc: 64.96%\n",
      "Epoch 3/3, Batch 25150, Loss: 0.8479, Acc: 64.96%\n",
      "Epoch 3/3, Batch 25160, Loss: 0.0043, Acc: 64.96%\n",
      "Epoch 3/3, Batch 25170, Loss: 0.6321, Acc: 64.96%\n",
      "Epoch 3/3, Batch 25180, Loss: 0.0188, Acc: 64.95%\n",
      "Epoch 3/3, Batch 25190, Loss: 0.5448, Acc: 64.96%\n",
      "Epoch 3/3, Batch 25200, Loss: 1.2020, Acc: 64.95%\n",
      "Epoch 3/3, Batch 25210, Loss: 1.1549, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25220, Loss: 1.2196, Acc: 64.95%\n",
      "Epoch 3/3, Batch 25230, Loss: 0.0039, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25240, Loss: 0.5830, Acc: 64.95%\n",
      "Epoch 3/3, Batch 25250, Loss: 2.0680, Acc: 64.93%\n",
      "Epoch 3/3, Batch 25260, Loss: 0.1561, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25270, Loss: 0.6425, Acc: 64.93%\n",
      "Epoch 3/3, Batch 25280, Loss: 0.2731, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25290, Loss: 0.6395, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25300, Loss: 1.2012, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25310, Loss: 0.6568, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25320, Loss: 0.0113, Acc: 64.95%\n",
      "Epoch 3/3, Batch 25330, Loss: 0.0153, Acc: 64.95%\n",
      "Epoch 3/3, Batch 25340, Loss: 0.0189, Acc: 64.95%\n",
      "Epoch 3/3, Batch 25350, Loss: 0.7532, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25360, Loss: 1.6241, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25370, Loss: 0.3436, Acc: 64.93%\n",
      "Epoch 3/3, Batch 25380, Loss: 0.0173, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25390, Loss: 0.0417, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25400, Loss: 0.0900, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25410, Loss: 0.4738, Acc: 64.95%\n",
      "Epoch 3/3, Batch 25420, Loss: 0.3749, Acc: 64.95%\n",
      "Epoch 3/3, Batch 25430, Loss: 1.3609, Acc: 64.95%\n",
      "Epoch 3/3, Batch 25440, Loss: 0.5437, Acc: 64.95%\n",
      "Epoch 3/3, Batch 25450, Loss: 0.7974, Acc: 64.95%\n",
      "Epoch 3/3, Batch 25460, Loss: 1.5983, Acc: 64.95%\n",
      "Epoch 3/3, Batch 25470, Loss: 0.7735, Acc: 64.95%\n",
      "Epoch 3/3, Batch 25480, Loss: 1.7072, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25490, Loss: 1.6606, Acc: 64.93%\n",
      "Epoch 3/3, Batch 25500, Loss: 0.5147, Acc: 64.93%\n",
      "Epoch 3/3, Batch 25510, Loss: 0.0109, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25520, Loss: 0.0167, Acc: 64.95%\n",
      "Epoch 3/3, Batch 25530, Loss: 0.8830, Acc: 64.95%\n",
      "Epoch 3/3, Batch 25540, Loss: 0.9931, Acc: 64.95%\n",
      "Epoch 3/3, Batch 25550, Loss: 1.0108, Acc: 64.96%\n",
      "Epoch 3/3, Batch 25560, Loss: 0.6774, Acc: 64.96%\n",
      "Epoch 3/3, Batch 25570, Loss: 0.0254, Acc: 64.95%\n",
      "Epoch 3/3, Batch 25580, Loss: 0.5864, Acc: 64.95%\n",
      "Epoch 3/3, Batch 25590, Loss: 0.3965, Acc: 64.95%\n",
      "Epoch 3/3, Batch 25600, Loss: 0.8531, Acc: 64.95%\n",
      "Epoch 3/3, Batch 25610, Loss: 0.2745, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25620, Loss: 0.0506, Acc: 64.95%\n",
      "Epoch 3/3, Batch 25630, Loss: 1.1386, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25640, Loss: 0.9086, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25650, Loss: 0.2952, Acc: 64.93%\n",
      "Epoch 3/3, Batch 25660, Loss: 0.0015, Acc: 64.93%\n",
      "Epoch 3/3, Batch 25670, Loss: 0.3579, Acc: 64.93%\n",
      "Epoch 3/3, Batch 25680, Loss: 0.0188, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25690, Loss: 0.0089, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25700, Loss: 0.2096, Acc: 64.95%\n",
      "Epoch 3/3, Batch 25710, Loss: 0.6378, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25720, Loss: 1.0269, Acc: 64.95%\n",
      "Epoch 3/3, Batch 25730, Loss: 0.0026, Acc: 64.95%\n",
      "Epoch 3/3, Batch 25740, Loss: 0.1793, Acc: 64.95%\n",
      "Epoch 3/3, Batch 25750, Loss: 1.0616, Acc: 64.95%\n",
      "Epoch 3/3, Batch 25760, Loss: 0.5332, Acc: 64.95%\n",
      "Epoch 3/3, Batch 25770, Loss: 0.9003, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25780, Loss: 0.4982, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25790, Loss: 0.8132, Acc: 64.93%\n",
      "Epoch 3/3, Batch 25800, Loss: 0.4467, Acc: 64.93%\n",
      "Epoch 3/3, Batch 25810, Loss: 0.0327, Acc: 64.93%\n",
      "Epoch 3/3, Batch 25820, Loss: 0.7396, Acc: 64.93%\n",
      "Epoch 3/3, Batch 25830, Loss: 0.6568, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25840, Loss: 0.2904, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25850, Loss: 1.2701, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25860, Loss: 1.2877, Acc: 64.93%\n",
      "Epoch 3/3, Batch 25870, Loss: 0.0122, Acc: 64.93%\n",
      "Epoch 3/3, Batch 25880, Loss: 1.2337, Acc: 64.93%\n",
      "Epoch 3/3, Batch 25890, Loss: 0.5891, Acc: 64.93%\n",
      "Epoch 3/3, Batch 25900, Loss: 0.5456, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25910, Loss: 0.6962, Acc: 64.93%\n",
      "Epoch 3/3, Batch 25920, Loss: 0.9352, Acc: 64.93%\n",
      "Epoch 3/3, Batch 25930, Loss: 0.4329, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25940, Loss: 0.6938, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25950, Loss: 0.7969, Acc: 64.93%\n",
      "Epoch 3/3, Batch 25960, Loss: 0.6501, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25970, Loss: 0.0206, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25980, Loss: 1.0619, Acc: 64.94%\n",
      "Epoch 3/3, Batch 25990, Loss: 0.9926, Acc: 64.93%\n",
      "Epoch 3/3, Batch 26000, Loss: 0.8401, Acc: 64.93%\n",
      "Epoch 3/3, Batch 26010, Loss: 1.0344, Acc: 64.93%\n",
      "Epoch 3/3, Batch 26020, Loss: 1.2106, Acc: 64.93%\n",
      "Epoch 3/3, Batch 26030, Loss: 1.0837, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26040, Loss: 0.6357, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26050, Loss: 0.0549, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26060, Loss: 0.2925, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26070, Loss: 1.1970, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26080, Loss: 0.3100, Acc: 64.95%\n",
      "Epoch 3/3, Batch 26090, Loss: 0.9261, Acc: 64.95%\n",
      "Epoch 3/3, Batch 26100, Loss: 0.5047, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26110, Loss: 1.1253, Acc: 64.93%\n",
      "Epoch 3/3, Batch 26120, Loss: 0.6409, Acc: 64.93%\n",
      "Epoch 3/3, Batch 26130, Loss: 0.1315, Acc: 64.93%\n",
      "Epoch 3/3, Batch 26140, Loss: 0.5607, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26150, Loss: 0.6512, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26160, Loss: 0.0098, Acc: 64.95%\n",
      "Epoch 3/3, Batch 26170, Loss: 1.8318, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26180, Loss: 0.7338, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26190, Loss: 0.0078, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26200, Loss: 0.3708, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26210, Loss: 0.0374, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26220, Loss: 0.0480, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26230, Loss: 0.1132, Acc: 64.93%\n",
      "Epoch 3/3, Batch 26240, Loss: 0.0212, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26250, Loss: 0.0292, Acc: 64.95%\n",
      "Epoch 3/3, Batch 26260, Loss: 0.2914, Acc: 64.95%\n",
      "Epoch 3/3, Batch 26270, Loss: 1.3951, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26280, Loss: 0.7826, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26290, Loss: 0.3314, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26300, Loss: 1.2538, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26310, Loss: 1.6358, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26320, Loss: 0.0176, Acc: 64.95%\n",
      "Epoch 3/3, Batch 26330, Loss: 0.2304, Acc: 64.95%\n",
      "Epoch 3/3, Batch 26340, Loss: 0.3784, Acc: 64.95%\n",
      "Epoch 3/3, Batch 26350, Loss: 0.2605, Acc: 64.95%\n",
      "Epoch 3/3, Batch 26360, Loss: 0.8716, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26370, Loss: 0.0282, Acc: 64.95%\n",
      "Epoch 3/3, Batch 26380, Loss: 0.0523, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26390, Loss: 0.3534, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26400, Loss: 2.4771, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26410, Loss: 0.0447, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26420, Loss: 0.8501, Acc: 64.93%\n",
      "Epoch 3/3, Batch 26430, Loss: 0.0473, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26440, Loss: 0.1350, Acc: 64.95%\n",
      "Epoch 3/3, Batch 26450, Loss: 0.5809, Acc: 64.95%\n",
      "Epoch 3/3, Batch 26460, Loss: 0.2033, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26470, Loss: 1.5422, Acc: 64.95%\n",
      "Epoch 3/3, Batch 26480, Loss: 0.9411, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26490, Loss: 1.2345, Acc: 64.95%\n",
      "Epoch 3/3, Batch 26500, Loss: 0.8331, Acc: 64.95%\n",
      "Epoch 3/3, Batch 26510, Loss: 0.3079, Acc: 64.95%\n",
      "Epoch 3/3, Batch 26520, Loss: 0.6717, Acc: 64.93%\n",
      "Epoch 3/3, Batch 26530, Loss: 0.3347, Acc: 64.93%\n",
      "Epoch 3/3, Batch 26540, Loss: 0.1967, Acc: 64.93%\n",
      "Epoch 3/3, Batch 26550, Loss: 1.4923, Acc: 64.93%\n",
      "Epoch 3/3, Batch 26560, Loss: 1.7785, Acc: 64.92%\n",
      "Epoch 3/3, Batch 26570, Loss: 0.2580, Acc: 64.92%\n",
      "Epoch 3/3, Batch 26580, Loss: 2.3540, Acc: 64.91%\n",
      "Epoch 3/3, Batch 26590, Loss: 1.5828, Acc: 64.90%\n",
      "Epoch 3/3, Batch 26600, Loss: 1.0227, Acc: 64.89%\n",
      "Epoch 3/3, Batch 26610, Loss: 0.0248, Acc: 64.89%\n",
      "Epoch 3/3, Batch 26620, Loss: 0.3849, Acc: 64.89%\n",
      "Epoch 3/3, Batch 26630, Loss: 0.6763, Acc: 64.90%\n",
      "Epoch 3/3, Batch 26640, Loss: 0.2830, Acc: 64.90%\n",
      "Epoch 3/3, Batch 26650, Loss: 0.2675, Acc: 64.91%\n",
      "Epoch 3/3, Batch 26660, Loss: 0.9538, Acc: 64.90%\n",
      "Epoch 3/3, Batch 26670, Loss: 0.8555, Acc: 64.90%\n",
      "Epoch 3/3, Batch 26680, Loss: 0.5321, Acc: 64.91%\n",
      "Epoch 3/3, Batch 26690, Loss: 0.0099, Acc: 64.91%\n",
      "Epoch 3/3, Batch 26700, Loss: 0.0122, Acc: 64.91%\n",
      "Epoch 3/3, Batch 26710, Loss: 0.0853, Acc: 64.91%\n",
      "Epoch 3/3, Batch 26720, Loss: 0.0026, Acc: 64.92%\n",
      "Epoch 3/3, Batch 26730, Loss: 0.1911, Acc: 64.92%\n",
      "Epoch 3/3, Batch 26740, Loss: 0.3818, Acc: 64.93%\n",
      "Epoch 3/3, Batch 26750, Loss: 1.1882, Acc: 64.92%\n",
      "Epoch 3/3, Batch 26760, Loss: 0.2279, Acc: 64.93%\n",
      "Epoch 3/3, Batch 26770, Loss: 1.1529, Acc: 64.92%\n",
      "Epoch 3/3, Batch 26780, Loss: 1.8316, Acc: 64.92%\n",
      "Epoch 3/3, Batch 26790, Loss: 0.0742, Acc: 64.93%\n",
      "Epoch 3/3, Batch 26800, Loss: 1.7412, Acc: 64.92%\n",
      "Epoch 3/3, Batch 26810, Loss: 0.5621, Acc: 64.92%\n",
      "Epoch 3/3, Batch 26820, Loss: 0.0110, Acc: 64.93%\n",
      "Epoch 3/3, Batch 26830, Loss: 1.3139, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26840, Loss: 0.2822, Acc: 64.93%\n",
      "Epoch 3/3, Batch 26850, Loss: 0.0665, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26860, Loss: 0.0083, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26870, Loss: 0.3329, Acc: 64.95%\n",
      "Epoch 3/3, Batch 26880, Loss: 0.9458, Acc: 64.95%\n",
      "Epoch 3/3, Batch 26890, Loss: 1.4065, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26900, Loss: 1.2211, Acc: 64.94%\n",
      "Epoch 3/3, Batch 26910, Loss: 0.0166, Acc: 64.95%\n",
      "Epoch 3/3, Batch 26920, Loss: 1.6776, Acc: 64.95%\n",
      "Epoch 3/3, Batch 26930, Loss: 0.0106, Acc: 64.95%\n",
      "Epoch 3/3, Batch 26940, Loss: 0.2728, Acc: 64.95%\n",
      "Epoch 3/3, Batch 26950, Loss: 0.0180, Acc: 64.95%\n",
      "Epoch 3/3, Batch 26960, Loss: 0.0109, Acc: 64.96%\n",
      "Epoch 3/3, Batch 26970, Loss: 0.3318, Acc: 64.96%\n",
      "Epoch 3/3, Batch 26980, Loss: 0.0060, Acc: 64.96%\n",
      "Epoch 3/3, Batch 26990, Loss: 0.4699, Acc: 64.97%\n",
      "Epoch 3/3, Batch 27000, Loss: 0.3459, Acc: 64.96%\n",
      "Epoch 3/3, Batch 27010, Loss: 0.0041, Acc: 64.96%\n",
      "Epoch 3/3, Batch 27020, Loss: 1.7756, Acc: 64.96%\n",
      "Epoch 3/3, Batch 27030, Loss: 2.8736, Acc: 64.96%\n",
      "Epoch 3/3, Batch 27040, Loss: 0.0037, Acc: 64.96%\n",
      "Epoch 3/3, Batch 27050, Loss: 0.7278, Acc: 64.96%\n",
      "Epoch 3/3, Batch 27060, Loss: 0.0231, Acc: 64.95%\n",
      "Epoch 3/3, Batch 27070, Loss: 1.0958, Acc: 64.96%\n",
      "Epoch 3/3, Batch 27080, Loss: 0.2966, Acc: 64.95%\n",
      "Epoch 3/3, Batch 27090, Loss: 0.9553, Acc: 64.95%\n",
      "Epoch 3/3, Batch 27100, Loss: 0.1816, Acc: 64.95%\n",
      "Epoch 3/3, Batch 27110, Loss: 0.8558, Acc: 64.95%\n",
      "Epoch 3/3, Batch 27120, Loss: 0.1597, Acc: 64.95%\n",
      "Epoch 3/3, Batch 27130, Loss: 0.5447, Acc: 64.96%\n",
      "Epoch 3/3, Batch 27140, Loss: 0.4098, Acc: 64.97%\n",
      "Epoch 3/3, Batch 27150, Loss: 0.5036, Acc: 64.97%\n",
      "Epoch 3/3, Batch 27160, Loss: 0.4181, Acc: 64.97%\n",
      "Epoch 3/3, Batch 27170, Loss: 0.1956, Acc: 64.97%\n",
      "Epoch 3/3, Batch 27180, Loss: 0.5579, Acc: 64.97%\n",
      "Epoch 3/3, Batch 27190, Loss: 0.2200, Acc: 64.98%\n",
      "Epoch 3/3, Batch 27200, Loss: 0.6672, Acc: 64.97%\n",
      "Epoch 3/3, Batch 27210, Loss: 0.0030, Acc: 64.98%\n",
      "Epoch 3/3, Batch 27220, Loss: 1.7479, Acc: 64.98%\n",
      "Epoch 3/3, Batch 27230, Loss: 0.8569, Acc: 64.97%\n",
      "Epoch 3/3, Batch 27240, Loss: 0.8261, Acc: 64.96%\n",
      "Epoch 3/3, Batch 27250, Loss: 0.0414, Acc: 64.97%\n",
      "Epoch 3/3, Batch 27260, Loss: 0.0053, Acc: 64.97%\n",
      "Epoch 3/3, Batch 27270, Loss: 0.6907, Acc: 64.97%\n",
      "Epoch 3/3, Batch 27280, Loss: 0.4408, Acc: 64.98%\n",
      "Epoch 3/3, Batch 27290, Loss: 0.8440, Acc: 64.98%\n",
      "Epoch 3/3, Batch 27300, Loss: 0.0235, Acc: 64.99%\n",
      "Epoch 3/3, Batch 27310, Loss: 0.5895, Acc: 64.99%\n",
      "Epoch 3/3, Batch 27320, Loss: 0.6780, Acc: 64.99%\n",
      "Epoch 3/3, Batch 27330, Loss: 0.8813, Acc: 64.99%\n",
      "Epoch 3/3, Batch 27340, Loss: 0.0011, Acc: 64.99%\n",
      "Epoch 3/3, Batch 27350, Loss: 0.8561, Acc: 64.99%\n",
      "Epoch 3/3, Batch 27360, Loss: 0.4588, Acc: 64.99%\n",
      "Epoch 3/3, Batch 27370, Loss: 0.0165, Acc: 64.98%\n",
      "Epoch 3/3, Batch 27380, Loss: 0.6632, Acc: 64.99%\n",
      "Epoch 3/3, Batch 27390, Loss: 0.0249, Acc: 65.00%\n",
      "Epoch 3/3, Batch 27400, Loss: 0.3563, Acc: 65.00%\n",
      "Epoch 3/3, Batch 27410, Loss: 1.2622, Acc: 64.99%\n",
      "Epoch 3/3, Batch 27420, Loss: 0.0337, Acc: 65.00%\n",
      "Epoch 3/3, Batch 27430, Loss: 0.3278, Acc: 65.00%\n",
      "Epoch 3/3, Batch 27440, Loss: 0.6866, Acc: 65.00%\n",
      "Epoch 3/3, Batch 27450, Loss: 0.8770, Acc: 65.00%\n",
      "Epoch 3/3, Batch 27460, Loss: 1.6147, Acc: 64.99%\n",
      "Epoch 3/3, Batch 27470, Loss: 0.0411, Acc: 64.99%\n",
      "Epoch 3/3, Batch 27480, Loss: 0.1337, Acc: 64.99%\n",
      "Epoch 3/3, Batch 27490, Loss: 0.7280, Acc: 64.98%\n",
      "Epoch 3/3, Batch 27500, Loss: 0.0321, Acc: 64.98%\n",
      "Epoch 3/3, Batch 27510, Loss: 0.5658, Acc: 64.98%\n",
      "Epoch 3/3, Batch 27520, Loss: 0.7010, Acc: 64.98%\n",
      "Epoch 3/3, Batch 27530, Loss: 0.0073, Acc: 64.98%\n",
      "Epoch 3/3, Batch 27540, Loss: 0.0118, Acc: 64.99%\n",
      "Epoch 3/3, Batch 27550, Loss: 0.0466, Acc: 65.00%\n",
      "Epoch 3/3, Batch 27560, Loss: 0.6460, Acc: 64.99%\n",
      "Epoch 3/3, Batch 27570, Loss: 0.0058, Acc: 64.99%\n",
      "Epoch 3/3, Batch 27580, Loss: 0.3898, Acc: 64.98%\n",
      "Epoch 3/3, Batch 27590, Loss: 1.5466, Acc: 64.98%\n",
      "Epoch 3/3, Batch 27600, Loss: 1.2420, Acc: 64.97%\n",
      "Epoch 3/3, Average Loss: 0.5786, Accuracy: 64.97%\n",
      "Evaluating model...\n",
      "Test Accuracy: 65.07%\n",
      "Average Epistemic Uncertainty: 0.0042\n",
      "Model saved to enn_halueval_model.pt\n"
     ]
    }
   ],
   "source": [
    "# Train the model first\n",
    "print(\"Training model...\")\n",
    "trained_model = train_enn(enn, trainloader, epochs, lr, λ, z_dim, device, tb_writer)\n",
    "\n",
    "# Then evaluate the model\n",
    "print(\"Evaluating model...\")\n",
    "accuracy, uncertainty = evaluate_enn(trained_model, testloader, z_dim, device)\n",
    "\n",
    "# Save the model\n",
    "torch.save(trained_model.state_dict(), \"enn_halueval_model.pt\")\n",
    "print(\"Model saved to enn_halueval_model.pt\")\n",
    "tb_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_DIM          = 16              # must match training\n",
    "SAMPLES_Z      = 30              # how many z draws per candidate\n",
    "TRADE_OFF_LAMB = 0.5             # higher ⇒ penalise uncertainty more\n",
    "# DEVICE         = \"mps\" if torch.backends.mps.is_available() else (\n",
    "#                  \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE = \"cpu\"\n",
    "\n",
    "base   = LlamaBaseNet(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", num_classes=2).to(DEVICE)\n",
    "epinet = EpiNet(base.hidden_size, Z_DIM, [128, 64], num_classes=2).to(DEVICE)\n",
    "prior  = PriorNet(base.hidden_size, Z_DIM, num_classes=2).to(DEVICE)\n",
    "enn    = EpistemicNN(base, epinet, prior).to(DEVICE)\n",
    "\n",
    "state_dict = torch.load(\"enn_halueval_model.pt\", map_location=DEVICE)\n",
    "enn.load_state_dict(state_dict)\n",
    "enn.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def score_answer(raw_text):\n",
    "    \"\"\"Return (prob_factual, variance) for one candidate string.\"\"\"\n",
    "    logits_all = []\n",
    "    for _ in range(SAMPLES_Z):\n",
    "        z = sample_z(1, Z_DIM, DEVICE)\n",
    "        logits = enn(raw_text, z)          # ← only one tensor comes back\n",
    "        logits_all.append(logits)          # shape [1,2]\n",
    "\n",
    "    logits_stacked = torch.stack(logits_all)      # [S,1,2]\n",
    "    mean_logits    = logits_stacked.mean(0).squeeze()   # [2]\n",
    "    variance       = logits_stacked.var(0).sum().item()\n",
    "    prob_factual   = torch.softmax(mean_logits, dim=-1)[0].item()\n",
    "    return prob_factual, variance\n",
    "\n",
    "def select_best(question, answers, lam=TRADE_OFF_LAMB):\n",
    "    rows = []\n",
    "    for ans in answers:\n",
    "        text = f\"{question}\\nAnswer: {ans}\"           # keep template same as training\n",
    "        p, var = score_answer(text)\n",
    "        score  = p - lam * var\n",
    "        rows.append((score, p, var, ans))\n",
    "    rows.sort(reverse=True)\n",
    "    return rows[0], rows     # (best_row, all_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature 0.01: The Fibonacci sequence is named after the Italian mathematician Leonardo of Pisa, who is also known as Fibonacci. He introduced the sequence to the Western world in his 1202 book \"Liber Abaci\" (The Book of Calculation). However, the sequence had been previously described in Indian mathematics. Indian mathematicians such as Ping\n",
      "Temperature 0.3: The Fibonacci sequence is named after the Italian mathematician Leonardo of Pisa, who is also known as Fibonacci. He introduced the sequence to the Western world in his 1202 book \"Liber Abaci\" (The Book of Calculation). However, the sequence had been previously described in Indian mathematics. Indian mathematicians such as Ping\n",
      "Temperature 0.7: The Fibonacci sequence is named after the Italian mathematician Leonardo of Pisa, who is also known as Fibonacci. He introduced the sequence to the Western world in his 1202 book \"Liber Abaci\" (The Book of Calculation). However, the sequence had been previously described in Indian mathematics. Indian mathematicians such as Ping\n",
      "Temperature 1.0: The Fibonacci sequence is named after the Italian mathematician Leonardo of Pisa, also known as Fibonacci. He introduced this sequence to the Western world in his 1202 book \"Liber Abaci\" (The Book of Calculation). However, the sequence had been previously described in Indian mathematics. In particular, it appeared in the works\n"
     ]
    }
   ],
   "source": [
    "# MAKE SURE TO BENCHMARK\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "def get_openai_ensemble(question, temps=[0.01, 0.3, 0.7, 1.0], model=\"gpt-4o\"):\n",
    "    answers = []\n",
    "    for temp in temps:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": question}],\n",
    "            temperature=temp,\n",
    "            max_completion_tokens=64\n",
    "        )\n",
    "        answers.append(response.choices[0].message.content)\n",
    "    return answers\n",
    "\n",
    "# Example usage\n",
    "question = \"Who discovered the fibonacci sequence\"\n",
    "ensemble_answers = get_openai_ensemble(question)\n",
    "for i, ans in enumerate(ensemble_answers):\n",
    "    print(f\"Temperature {['0.01','0.3','0.7','1.0'][i]}: {ans}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== ENSEMBLE EVALUATION =====\n",
      "Best answer (score=+0.687, p_factual=0.688, var=0.003):\n",
      "The Fibonacci sequence is named after the Italian mathematician Leonardo of Pisa, also known as Fibonacci. He introduced this sequence to the Western world in his 1202 book \"Liber Abaci\" (The Book of Calculation). However, the sequence had been previously described in Indian mathematics. In particular, it appeared in the works\n",
      "\n",
      "All answers ranked by score (score = p_factual - λ·var):\n",
      "\n",
      "1. Temperature 0.01:\n",
      "   Score: +0.687 | p_factual: 0.688 | var: 0.003\n",
      "   Answer: The Fibonacci sequence is named after the Italian mathematician Leonardo of Pisa, also known as Fibonacci. He introduced this sequence to the Western world in his 1202 book \"Liber Abaci\" (The Book of Calculation). However, the sequence had been previously described in Indian mathematics. In particular, it appeared in the works\n",
      "\n",
      "2. Temperature 0.3:\n",
      "   Score: +0.430 | p_factual: 0.432 | var: 0.005\n",
      "   Answer: The Fibonacci sequence is named after the Italian mathematician Leonardo of Pisa, who is also known as Fibonacci. He introduced the sequence to the Western world in his 1202 book \"Liber Abaci\" (The Book of Calculation). However, the sequence had been previously described in Indian mathematics. Indian mathematicians such as Ping\n",
      "\n",
      "3. Temperature 0.7:\n",
      "   Score: +0.426 | p_factual: 0.427 | var: 0.003\n",
      "   Answer: The Fibonacci sequence is named after the Italian mathematician Leonardo of Pisa, who is also known as Fibonacci. He introduced the sequence to the Western world in his 1202 book \"Liber Abaci\" (The Book of Calculation). However, the sequence had been previously described in Indian mathematics. Indian mathematicians such as Ping\n",
      "\n",
      "4. Temperature 1.0:\n",
      "   Score: +0.425 | p_factual: 0.429 | var: 0.007\n",
      "   Answer: The Fibonacci sequence is named after the Italian mathematician Leonardo of Pisa, who is also known as Fibonacci. He introduced the sequence to the Western world in his 1202 book \"Liber Abaci\" (The Book of Calculation). However, the sequence had been previously described in Indian mathematics. Indian mathematicians such as Ping\n"
     ]
    }
   ],
   "source": [
    "# currently all the same answer, so nothing crazy\n",
    "\n",
    "best, table = select_best(question, ensemble_answers)\n",
    "print(\"===== ENSEMBLE EVALUATION =====\")\n",
    "print(f\"Best answer (score={best[0]:+.3f}, p_factual={best[1]:.3f}, var={best[2]:.3f}):\")\n",
    "print(best[3])\n",
    "print(\"\\nAll answers ranked by score (score = p_factual - λ·var):\")\n",
    "for rank, (score, p_factual, var, ans) in enumerate(table, 1):\n",
    "    print(f\"\\n{rank}. Temperature {['0.01','0.3','0.7','1.0'][rank-1]}:\")\n",
    "    print(f\"   Score: {score:+.3f} | p_factual: {p_factual:.3f} | var: {var:.3f}\")\n",
    "    print(f\"   Answer: {ans}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment check:\n",
      "OpenAI API key loaded: Yes\n",
      "Anthropic API key loaded: Yes\n",
      "Google API key loaded: Yes\n",
      "\n",
      "Ensemble Responses:\n",
      "\n",
      "openai-gpt-4 (temp=0.3):\n",
      "The Fibonacci sequence was discovered by Leonardo of Pisa, who is also known as Fibonacci. He introduced it to the Western world in his 1202 book \"Liber Abaci,\" but the sequence had been previously described in Indian mathematics.\n",
      "\n",
      "openai-gpt-3.5-turbo (temp=0.3):\n",
      "The Fibonacci sequence was discovered by Leonardo of Pisa, also known as Fibonacci, an Italian mathematician in the 13th century.\n",
      "\n",
      "anthropic-claude-3-7-sonnet-20250219 (temp=0.3):\n",
      "The Fibonacci sequence was first described by Leonardo of Pisa, who was also known as Fibonacci, in his book \"Liber Abaci\" published in 1202. However, Indian mathematicians were already aware of the sequence as early as the 6th century. Fibonacci introduced this sequence\n",
      "\n",
      "anthropic-claude-3-5-sonnet-20241022 (temp=0.3):\n",
      "The Fibonacci sequence was first described by Leonardo of Pisa, better known as Fibonacci, in his book \"Liber Abaci\" published in 1202. However, it's important to note that Indian mathematicians had known about these numbers centuries before Fibonacci.\n",
      "\n",
      "Fibonacci introduced the sequence\n",
      "\n",
      "google-gemini-2.0-flash (temp=0.3):\n",
      "The Fibonacci sequence was not \"discovered\" in the way we might think of discovering a new element or a new species. It was known in Indian mathematics centuries before Fibonacci.\n",
      "\n",
      "However, the sequence is named after **Leonardo Pisano**, also known as **Fibonacci**. He introduced the sequence to Western European mathematics in his\n",
      "\n",
      "===== ENSEMBLE EVALUATION =====\n",
      "Best answer (score=+0.807, p_factual=0.808, var=0.003):\n",
      "The Fibonacci sequence was first described by Leonardo of Pisa, who was also known as Fibonacci, in his book \"Liber Abaci\" published in 1202. However, Indian mathematicians were already familiar with the sequence centuries earlier. Specifically, scholars like Virahanka,\n",
      "\n",
      "All answers ranked by score (score = p_factual - λ·var):\n",
      "\n",
      "1. openai-gpt-4o (temp=0.1):\n",
      "   Score: +0.807 | p_factual: 0.808 | var: 0.003\n",
      "   Answer: The Fibonacci sequence was first described by Leonardo of Pisa, who was also known as Fibonacci, in his book \"Liber Abaci\" published in 1202. However, Indian mathematicians were already familiar with the sequence centuries earlier. Specifically, scholars like Virahanka,\n",
      "\n",
      "2. openai-gpt-4o (temp=0.7):\n",
      "   Score: +0.770 | p_factual: 0.772 | var: 0.004\n",
      "   Answer: The Fibonacci sequence was not \"discovered\" in the sense that someone suddenly realized it existed. It was known in Indian mathematics centuries before Fibonacci. However, it became known in the Western world through **Leonardo Pisano, also known as Fibonacci.**\n",
      "\n",
      "Fibonacci introduced the sequence in his book *Liber Abaci* (1\n",
      "\n",
      "3. anthropic-claude-3-7-sonnet-20250219 (temp=0.3):\n",
      "   Score: +0.619 | p_factual: 0.621 | var: 0.003\n",
      "   Answer: The Fibonacci sequence is named after the Italian mathematician Leonardo of Pisa, who is also known as Fibonacci. He introduced the sequence to the Western world in his 1202 book \"Liber Abaci\" (The Book of Calculation). However, the sequence had been previously described in Indian mathematics. Indian mathematicians like Gop\n",
      "\n",
      "4. google-gemini-2.0-flash (temp=0.5):\n",
      "   Score: +0.555 | p_factual: 0.557 | var: 0.003\n",
      "   Answer: The Fibonacci sequence was introduced to the Western world by the Italian mathematician Leonardo of Pisa, who is also known as Fibonacci. He described the sequence in his book \"Liber Abaci,\" published in 1202. However, the sequence had been previously described in Indian mathematics, particularly in the works of mathematicians such as\n"
     ]
    }
   ],
   "source": [
    "# MAKE SURE TO BENCHMARK\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "import google.genai as genai\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load API keys and initialize clients\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "print(\"Environment check:\")\n",
    "print(f\"OpenAI API key loaded: {'Yes' if OPENAI_API_KEY else 'No'}\")\n",
    "print(f\"Anthropic API key loaded: {'Yes' if ANTHROPIC_API_KEY else 'No'}\")\n",
    "print(f\"Google API key loaded: {'Yes' if GOOGLE_API_KEY else 'No'}\")\n",
    "\n",
    "# Initialize clients if keys are available\n",
    "openai_client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None\n",
    "anthropic_client = Anthropic(api_key=ANTHROPIC_API_KEY) if ANTHROPIC_API_KEY else None\n",
    "google_client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# if GOOGLE_API_KEY:\n",
    "#     genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "def get_multi_provider_ensemble(question, providers=None):\n",
    "    \"\"\"Get answers from multiple providers with different settings.\n",
    "    \n",
    "    Args:\n",
    "        question (str): The question to ask\n",
    "        providers (list): List of tuples (provider, model, temp)\n",
    "                        If None, uses default configuration\n",
    "    \n",
    "    Default providers:\n",
    "    [\n",
    "        (\"openai\", \"gpt-4\", 0.3),\n",
    "        (\"openai\", \"gpt-3.5-turbo\", 0.3),\n",
    "        (\"anthropic\", \"claude-3-opus\", 0.3),\n",
    "        (\"anthropic\", \"claude-3-sonnet\", 0.3),\n",
    "        (\"google\", \"gemini-pro\", 0.3)\n",
    "    ]\n",
    "    \n",
    "    Returns:\n",
    "        list: List of answers from different providers\n",
    "        list: List of provider descriptions for each answer\n",
    "    \"\"\"\n",
    "    if providers is None:\n",
    "        providers = [\n",
    "            (\"openai\", \"gpt-4\", 0.3),\n",
    "            (\"openai\", \"gpt-3.5-turbo\", 0.3),\n",
    "            (\"anthropic\", \"claude-3-7-sonnet-20250219\", 0.3),\n",
    "            (\"anthropic\", \"claude-3-5-sonnet-20241022\", 0.3),\n",
    "            (\"google\", \"gemini-2.0-flash\", 0.3)\n",
    "        ]\n",
    "    \n",
    "    answers = []\n",
    "    provider_info = []  # Track which provider/model gave which answer\n",
    "    \n",
    "    for provider, model, temp in providers:\n",
    "        try:\n",
    "            if provider == \"openai\" and openai_client:\n",
    "                response = openai_client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=[{\"role\": \"user\", \"content\": question}],\n",
    "                    temperature=temp,\n",
    "                    max_tokens=64\n",
    "                )\n",
    "                answers.append(response.choices[0].message.content)\n",
    "                provider_info.append(f\"{provider}-{model} (temp={temp})\")\n",
    "                \n",
    "            elif provider == \"anthropic\" and anthropic_client:\n",
    "                response = anthropic_client.messages.create(\n",
    "                    model=model,\n",
    "                    max_tokens=64,\n",
    "                    temperature=temp,\n",
    "                    messages=[{\"role\": \"user\", \"content\": question}]\n",
    "                )\n",
    "                answers.append(response.content[0].text)\n",
    "                provider_info.append(f\"{provider}-{model} (temp={temp})\")\n",
    "                \n",
    "            elif provider == \"google\" and GOOGLE_API_KEY:\n",
    "                # model_obj = genai.GenerativeModel(model)\n",
    "                response = google_client.models.generate_content(\n",
    "                    model=model,\n",
    "                    contents=question,\n",
    "                    config=genai.types.GenerateContentConfig(\n",
    "                        temperature=temp,\n",
    "                        max_output_tokens=64\n",
    "                    )\n",
    "                )\n",
    "                answers.append(response.text)\n",
    "                provider_info.append(f\"{provider}-{model} (temp={temp})\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error with {provider} {model}: {str(e)}\")\n",
    "            continue\n",
    "            \n",
    "    return answers, provider_info\n",
    "\n",
    "# Example usage\n",
    "question = \"Who discovered the fibonacci sequence\"\n",
    "\n",
    "# Default usage with all providers\n",
    "answers, providers = get_multi_provider_ensemble(question)\n",
    "\n",
    "# Print answers with provider information\n",
    "print(\"\\nEnsemble Responses:\")\n",
    "for ans, provider in zip(answers, providers):\n",
    "    print(f\"\\n{provider}:\")\n",
    "    print(ans)\n",
    "\n",
    "# Custom provider configuration example\n",
    "custom_providers = [\n",
    "    (\"openai\", \"gpt-4o\", 0.1),\n",
    "    (\"openai\", \"gpt-4o\", 0.7),\n",
    "    (\"anthropic\", \"claude-3-7-sonnet-20250219\", 0.3),\n",
    "    (\"google\", \"gemini-2.0-flash\", 0.5)\n",
    "]\n",
    "\n",
    "# Get answers with custom configuration\n",
    "custom_answers, custom_providers = get_multi_provider_ensemble(question, custom_providers)\n",
    "\n",
    "# Evaluate with ENN\n",
    "best, table = select_best(question, custom_answers)\n",
    "print(\"\\n===== ENSEMBLE EVALUATION =====\")\n",
    "print(f\"Best answer (score={best[0]:+.3f}, p_factual={best[1]:.3f}, var={best[2]:.3f}):\")\n",
    "print(best[3])\n",
    "print(\"\\nAll answers ranked by score (score = p_factual - λ·var):\")\n",
    "for rank, (score, p_factual, var, ans) in enumerate(table, 1):\n",
    "    print(f\"\\n{rank}. {custom_providers[rank-1]}:\")\n",
    "    print(f\"   Score: {score:+.3f} | p_factual: {p_factual:.3f} | var: {var:.3f}\")\n",
    "    print(f\"   Answer: {ans}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting HaluEval evaluation...\n",
      "\n",
      "===== QA SAMPLE =====\n",
      "Question: Which magazine was started first Arthur's Magazine or First for Women?\n",
      "Knowledge: Arthur's Magazine (1844–1846) was an American literary periodical published in Philadelphia in the 1...\n",
      "\n",
      "Model responses and scores:\n",
      "\n",
      "openai-gpt-4o:\n",
      "Score: +0.408 | p_factual: 0.410 | var: 0.005\n",
      "Answer: Arthur's Magazine was started first. It was published in the 19th century (1844-1846), while First f...\n",
      "\n",
      "openai-o1-mini:\n",
      "Score: +0.394 | p_factual: 0.396 | var: 0.005\n",
      "Answer: ...\n",
      "\n",
      "anthropic-claude-3-sonnet:\n",
      "Score: +0.339 | p_factual: 0.341 | var: 0.004\n",
      "Answer: Based on the provided information, Arthur's Magazine was started first. Arthur's Magazine was publis...\n",
      "\n",
      "anthropic-claude-3-haiku:\n",
      "Score: +0.043 | p_factual: 0.045 | var: 0.005\n",
      "Answer: Based on the given knowledge, Arthur's Magazine was started first. It was published from 1844 to 184...\n",
      "\n",
      "google-gemini-flash-lite:\n",
      "Score: +0.019 | p_factual: 0.021 | var: 0.003\n",
      "Answer: Arthur's Magazine was started first. It was published from 1844 to 1846, while *First for Women* beg...\n",
      "\n",
      "google-gemini-flash-preview:\n",
      "Score: +0.014 | p_factual: 0.017 | var: 0.005\n",
      "Answer: Arthur's Magazine was started first. It was published from 1844 to 1846, whereas First for Women is ...\n",
      "\n",
      "Best Answer:\n",
      "Score: +0.408 | p_factual: 0.410 | var: 0.005\n",
      "Answer: Arthur's Magazine was started first. It was published in the 19th century (1844-1846), while First for Women is a modern magazine.\n",
      "\n",
      "\n",
      "===== QA SAMPLE =====\n",
      "Question: The Oberoi family is part of a hotel company that has a head office in what city?\n",
      "Knowledge: The Oberoi family is an Indian family that is famous for its involvement in hotels, namely through T...\n",
      "\n",
      "Model responses and scores:\n",
      "\n",
      "openai-gpt-4o:\n",
      "Score: +0.700 | p_factual: 0.703 | var: 0.006\n",
      "Answer: ...\n",
      "\n",
      "openai-o1-mini:\n",
      "Score: +0.637 | p_factual: 0.638 | var: 0.004\n",
      "Answer: Delhi\n",
      "...\n",
      "\n",
      "anthropic-claude-3-sonnet:\n",
      "Score: +0.553 | p_factual: 0.555 | var: 0.004\n",
      "Answer: Based on the provided knowledge, the Oberoi family is part of The Oberoi Group, which is a hotel com...\n",
      "\n",
      "anthropic-claude-3-haiku:\n",
      "Score: +0.044 | p_factual: 0.048 | var: 0.007\n",
      "Answer: According to the knowledge provided, the Oberoi Group has its head office in Delhi....\n",
      "\n",
      "google-gemini-flash-lite:\n",
      "Score: +0.034 | p_factual: 0.036 | var: 0.005\n",
      "Answer: The Oberoi family is part of The Oberoi Group, a hotel company that has its head office in Delhi....\n",
      "\n",
      "google-gemini-flash-preview:\n",
      "Score: +0.010 | p_factual: 0.012 | var: 0.004\n",
      "Answer: The Oberoi family is part of a hotel company that has its head office in Delhi....\n",
      "\n",
      "Best Answer:\n",
      "Score: +0.700 | p_factual: 0.703 | var: 0.006\n",
      "Answer: \n",
      "\n",
      "===== DIALOGUE SAMPLE =====\n",
      "Question: [Human]: Do you like Iron Man [Assistant]: Sure do! Robert Downey Jr. is a favorite. [Human]: Yes i like him too did you know he also was in Zodiac a crime fiction film. \n",
      "Knowledge: Iron Man is starring Robert Downey Jr.Robert Downey Jr. starred in Zodiac (Crime Fiction Film)Zodiac...\n",
      "\n",
      "Model responses and scores:\n",
      "\n",
      "openai-gpt-4o:\n",
      "Score: +0.772 | p_factual: 0.775 | var: 0.005\n",
      "Answer: ...\n",
      "\n",
      "openai-o1-mini:\n",
      "Score: +0.729 | p_factual: 0.732 | var: 0.006\n",
      "Answer: Yes, that's right! Robert Downey Jr. was indeed in \"Zodiac,\" which is a crime fiction film directed ...\n",
      "\n",
      "anthropic-claude-3-sonnet:\n",
      "Score: +0.535 | p_factual: 0.537 | var: 0.004\n",
      "Answer: Based on the knowledge provided, I can confirm that Robert Downey Jr. was indeed in Zodiac, a crime ...\n",
      "\n",
      "anthropic-claude-3-haiku:\n",
      "Score: +0.493 | p_factual: 0.495 | var: 0.004\n",
      "Answer: [Assistant]: Yes, I did. Jake Gyllenhaal was also in that film.\n",
      "...\n",
      "\n",
      "google-gemini-flash-lite:\n",
      "Score: +0.463 | p_factual: 0.465 | var: 0.004\n",
      "Answer: Absolutely! Robert Downey Jr. played the role of Paul Avery, a journalist, in Zodiac. That film also...\n",
      "\n",
      "google-gemini-flash-preview:\n",
      "Score: +0.457 | p_factual: 0.458 | var: 0.004\n",
      "Answer: [Assistant]: Yes, I did know that! Robert Downey Jr. starred in Zodiac alongside Jake Gyllenhaal. It...\n",
      "\n",
      "Best Answer:\n",
      "Score: +0.772 | p_factual: 0.775 | var: 0.005\n",
      "Answer: \n",
      "\n",
      "===== DIALOGUE SAMPLE =====\n",
      "Question: [Human]: Could you recommend any books like The Secret Life of Bees? [Assistant]: Yes, its a great teen book, have you heard about A walk to remember ? It is also a great teen drama [Human]: I think I have.. is that one with Hunt Lowry? \n",
      "Knowledge: The Secret Life of Bees has genre Teen drama. Teen drama has examples: A Walk to RememberA Walk to R...\n",
      "\n",
      "Model responses and scores:\n",
      "\n",
      "openai-gpt-4o:\n",
      "Score: +0.894 | p_factual: 0.896 | var: 0.005\n",
      "Answer: ...\n",
      "\n",
      "openai-o1-mini:\n",
      "Score: +0.516 | p_factual: 0.518 | var: 0.004\n",
      "Answer: Yes, A Walk to Remember was produced by Hunt Lowry. It's a film adaptation of Nicholas Sparks' novel...\n",
      "\n",
      "anthropic-claude-3-sonnet:\n",
      "Score: +0.469 | p_factual: 0.472 | var: 0.005\n",
      "Answer: [Assistant]: Yes, Hunt Lowry produced A Walk to Remember.\n",
      "...\n",
      "\n",
      "anthropic-claude-3-haiku:\n",
      "Score: +0.435 | p_factual: 0.437 | var: 0.004\n",
      "Answer: Yes, that's right! A Walk to Remember is a film produced by Hunt Lowry. It's based on the novel by N...\n",
      "\n",
      "google-gemini-flash-lite:\n",
      "Score: +0.288 | p_factual: 0.290 | var: 0.004\n",
      "Answer: I need to clarify something. \"A Walk to Remember\" is primarily known as a film, not a book, though i...\n",
      "\n",
      "google-gemini-flash-preview:\n",
      "Score: +0.277 | p_factual: 0.279 | var: 0.005\n",
      "Answer: Yes, \"A Walk to Remember\" is a film produced by Hunt Lowry. If you're interested in books similar to...\n",
      "\n",
      "Best Answer:\n",
      "Score: +0.894 | p_factual: 0.896 | var: 0.005\n",
      "Answer: \n",
      "\n",
      "===== SUMMARIZATION SAMPLE =====\n",
      "Question: Summarize this document\n",
      "Knowledge: Marseille, France (CNN)The French prosecutor leading an investigation into the crash of Germanwings ...\n",
      "\n",
      "Model responses and scores:\n",
      "\n",
      "openai-gpt-4o:\n",
      "Score: +0.900 | p_factual: 0.902 | var: 0.005\n",
      "Answer: Here's a summary of the document:\n",
      "\n",
      "The article discusses the Germanwings Flight 9525 crash in the Fr...\n",
      "\n",
      "openai-o1-mini:\n",
      "Score: +0.897 | p_factual: 0.899 | var: 0.004\n",
      "Answer: # Summary of Germanwings Flight 9525 Investigation Document\n",
      "\n",
      "The document discusses the investigatio...\n",
      "\n",
      "anthropic-claude-3-sonnet:\n",
      "Score: +0.842 | p_factual: 0.844 | var: 0.004\n",
      "Answer: **Summary:**\n",
      "\n",
      "After the crash of Germanwings Flight 9525 in the French Alps, which killed all 150 pe...\n",
      "\n",
      "anthropic-claude-3-haiku:\n",
      "Score: +0.788 | p_factual: 0.790 | var: 0.003\n",
      "Answer: ...\n",
      "\n",
      "google-gemini-flash-lite:\n",
      "Score: +0.769 | p_factual: 0.771 | var: 0.004\n",
      "Answer: This document details the investigation into the Germanwings Flight 9525 crash, focusing on the foll...\n",
      "\n",
      "google-gemini-flash-preview:\n",
      "Score: +0.393 | p_factual: 0.395 | var: 0.004\n",
      "Answer: The document reports on the investigation into the crash of Germanwings Flight 9525, which resulted ...\n",
      "\n",
      "Best Answer:\n",
      "Score: +0.900 | p_factual: 0.902 | var: 0.005\n",
      "Answer: Here's a summary of the document:\n",
      "\n",
      "The article discusses the Germanwings Flight 9525 crash in the French Alps, which killed all 150 people on board. Key points include:\n",
      "\n",
      "1. Disputed Video Footage:\n",
      "- Two magazines (Bild and Paris Match) claime\n",
      "\n",
      "===== SUMMARIZATION SAMPLE =====\n",
      "Question: Summarize this document\n",
      "Knowledge: The Palestinian Authority officially became the 123rd member of the International Criminal Court on ...\n",
      "\n",
      "Model responses and scores:\n",
      "\n",
      "openai-gpt-4o:\n",
      "Score: +0.931 | p_factual: 0.933 | var: 0.003\n",
      "Answer: The Palestinian Authority officially joined the International Criminal Court (ICC) as its 123rd memb...\n",
      "\n",
      "openai-o1-mini:\n",
      "Score: +0.820 | p_factual: 0.822 | var: 0.004\n",
      "Answer: Here's a summary of the document:\n",
      "\n",
      "The Palestinian Authority became the 123rd member of the Internat...\n",
      "\n",
      "anthropic-claude-3-sonnet:\n",
      "Score: +0.789 | p_factual: 0.791 | var: 0.005\n",
      "Answer: ...\n",
      "\n",
      "anthropic-claude-3-haiku:\n",
      "Score: +0.750 | p_factual: 0.752 | var: 0.005\n",
      "Answer: The Palestinian Authority officially became the 123rd member of the International Criminal Court (IC...\n",
      "\n",
      "google-gemini-flash-lite:\n",
      "Score: +0.466 | p_factual: 0.468 | var: 0.005\n",
      "Answer: The Palestinian Authority officially became the 123rd member of the International Criminal Court (IC...\n",
      "\n",
      "google-gemini-flash-preview:\n",
      "Score: +0.450 | p_factual: 0.452 | var: 0.004\n",
      "Answer: # Summary of Palestinian Authority Joining the International Criminal Court\n",
      "\n",
      "The Palestinian Authori...\n",
      "\n",
      "Best Answer:\n",
      "Score: +0.931 | p_factual: 0.933 | var: 0.003\n",
      "Answer: The Palestinian Authority officially joined the International Criminal Court (ICC) as its 123rd member, granting the court jurisdiction over alleged crimes in Palestinian territories, including those committed since June 13, 2014. This move, which was opposed by Israel and the United States, allows the ICC to\n",
      "\n",
      "===== GENERAL SAMPLE =====\n",
      "Question: Produce a list of common words in the English language.\n",
      "Knowledge: ...\n",
      "\n",
      "Model responses and scores:\n",
      "\n",
      "openai-gpt-4o:\n",
      "Score: +0.994 | p_factual: 0.997 | var: 0.005\n",
      "Answer: # Common English Words\n",
      "\n",
      "1. the\n",
      "2. be\n",
      "3. to\n",
      "4. of\n",
      "5. and\n",
      "6. a\n",
      "7. in\n",
      "8. that\n",
      "9. have\n",
      "10. I\n",
      "11. it\n",
      "12. ...\n",
      "\n",
      "openai-o1-mini:\n",
      "Score: +0.991 | p_factual: 0.994 | var: 0.005\n",
      "Answer: Certainly! Here's a list of common words in the English language:\n",
      "\n",
      "1. the\n",
      "2. be\n",
      "3. to\n",
      "4. of\n",
      "5. and\n",
      "6...\n",
      "\n",
      "anthropic-claude-3-sonnet:\n",
      "Score: +0.973 | p_factual: 0.975 | var: 0.005\n",
      "Answer: ...\n",
      "\n",
      "anthropic-claude-3-haiku:\n",
      "Score: +0.965 | p_factual: 0.968 | var: 0.005\n",
      "Answer: Okay, here's a list of common words in the English language. This list is not exhaustive, but it cov...\n",
      "\n",
      "google-gemini-flash-lite:\n",
      "Score: +0.916 | p_factual: 0.918 | var: 0.003\n",
      "Answer: Here's a list of common English words:\n",
      "\n",
      "1. the\n",
      "2. be\n",
      "3. to\n",
      "4. of\n",
      "5. and\n",
      "6. a\n",
      "7. in\n",
      "8. that\n",
      "9. have\n",
      "1...\n",
      "\n",
      "google-gemini-flash-preview:\n",
      "Score: +0.885 | p_factual: 0.886 | var: 0.004\n",
      "Answer: Certainly! Here is a list of common words in the English language:\n",
      "\n",
      "1. the  \n",
      "2. be  \n",
      "3. to  \n",
      "4. of  ...\n",
      "\n",
      "Best Answer:\n",
      "Score: +0.994 | p_factual: 0.997 | var: 0.005\n",
      "Answer: # Common English Words\n",
      "\n",
      "1. the\n",
      "2. be\n",
      "3. to\n",
      "4. of\n",
      "5. and\n",
      "6. a\n",
      "7. in\n",
      "8. that\n",
      "9. have\n",
      "10. I\n",
      "11. it\n",
      "12. for\n",
      "13. not\n",
      "14. on\n",
      "15. with\n",
      "\n",
      "===== GENERAL SAMPLE =====\n",
      "Question: Provide a few examples of homophones.\n",
      "Knowledge: ...\n",
      "\n",
      "Model responses and scores:\n",
      "\n",
      "openai-gpt-4o:\n",
      "Score: +0.961 | p_factual: 0.963 | var: 0.004\n",
      "Answer: Sure! Here are a few examples of homophones:\n",
      "\n",
      "1. **Two**, **to**, and **too**\n",
      "2. **Their**, **there*...\n",
      "\n",
      "openai-o1-mini:\n",
      "Score: +0.948 | p_factual: 0.950 | var: 0.004\n",
      "Answer: ...\n",
      "\n",
      "anthropic-claude-3-sonnet:\n",
      "Score: +0.939 | p_factual: 0.940 | var: 0.003\n",
      "Answer: Here are some examples of homophones:\n",
      "\n",
      "1. There/Their/They're\n",
      "2. To/Too/Two\n",
      "3. Hear/Here\n",
      "4. Bare/Bea...\n",
      "\n",
      "anthropic-claude-3-haiku:\n",
      "Score: +0.926 | p_factual: 0.927 | var: 0.003\n",
      "Answer: # Examples of Homophones\n",
      "\n",
      "Homophones are words that sound the same but have different meanings and o...\n",
      "\n",
      "google-gemini-flash-lite:\n",
      "Score: +0.879 | p_factual: 0.881 | var: 0.005\n",
      "Answer: Here are a few examples of homophones:\n",
      "\n",
      "*   **There, their, they're:**\n",
      "    *   **There** (adverb): i...\n",
      "\n",
      "google-gemini-flash-preview:\n",
      "Score: +0.655 | p_factual: 0.658 | var: 0.005\n",
      "Answer: Certainly! Homophones are words that sound the same but have different meanings and often different ...\n",
      "\n",
      "Best Answer:\n",
      "Score: +0.961 | p_factual: 0.963 | var: 0.004\n",
      "Answer: Sure! Here are a few examples of homophones:\n",
      "\n",
      "1. **Two**, **to**, and **too**\n",
      "2. **Their**, **there**, and **they’re**\n",
      "3. **Sea** and **see**\n",
      "4. **Flower** and **flour**\n",
      "5. **Right** and **write**\n",
      "\n",
      "\n",
      "Evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "import google.genai as genai\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize API clients\n",
    "openai_client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "anthropic_client = Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))\n",
    "google_client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "def get_multi_model_ensemble(question, knowledge=None):\n",
    "    \"\"\"Get answers from 6 specified models with different configurations.\n",
    "    \n",
    "    Models:\n",
    "    1. GPT-4 (o4-mini)\n",
    "    2. GPT-4 (o1-mini)\n",
    "    3. Claude 3 Sonnet\n",
    "    4. Claude 3 Haiku\n",
    "    5. Gemini Flash Lite\n",
    "    6. Gemini Flash Preview\n",
    "    \"\"\"\n",
    "    answers = []\n",
    "    provider_info = []\n",
    "    \n",
    "    # Format the prompt with knowledge if provided\n",
    "    prompt = f\"Knowledge: {knowledge}\\nQuestion: {question}\" if knowledge else question\n",
    "    \n",
    "    try:\n",
    "        # 1. GPT-4 (o4-mini)\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.3,\n",
    "            max_completion_tokens=64\n",
    "        )\n",
    "        answers.append(response.choices[0].message.content)\n",
    "        provider_info.append(\"openai-gpt-4o\")\n",
    "        \n",
    "        # 2. GPT-4 (o1-mini)\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=\"gpt-4.1\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.3,\n",
    "            max_completion_tokens=64\n",
    "        )\n",
    "        answers.append(response.choices[0].message.content)\n",
    "        provider_info.append(\"openai-o1-mini\")\n",
    "        \n",
    "        # 3. Claude 3 Sonnet\n",
    "        response = anthropic_client.messages.create(\n",
    "            model=\"claude-3-7-sonnet-20250219\",\n",
    "            max_tokens=64,\n",
    "            temperature=0.3,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        answers.append(response.content[0].text)\n",
    "        provider_info.append(\"anthropic-claude-3-sonnet\")\n",
    "        \n",
    "        # 4. Claude 3 Haiku\n",
    "        response = anthropic_client.messages.create(\n",
    "            model=\"claude-3-5-haiku-20241022\",\n",
    "            max_tokens=64,\n",
    "            temperature=0.3,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        answers.append(response.content[0].text)\n",
    "        provider_info.append(\"anthropic-claude-3-haiku\")\n",
    "        \n",
    "        # 5. Gemini Flash Lite\n",
    "\n",
    "        # FIX GEMINI CHAT COMPLETION SYNTAX\n",
    "\n",
    "        # model = genai.GenerativeModel(\"gemini-2.0-flash-lite\")\n",
    "        response = google_client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash-lite\",  # or \"gemini-2.5-flash-preview-04-17\"\n",
    "        contents=prompt,\n",
    "        config=genai.types.GenerateContentConfig(\n",
    "            temperature=0.3,\n",
    "            max_output_tokens=64\n",
    "            )\n",
    "        )\n",
    "        answers.append(response.text)\n",
    "        provider_info.append(\"google-gemini-flash-lite\")\n",
    "        \n",
    "        # 6. Gemini Flash Preview\n",
    "        # model = genai.GenerativeModel(\"gemini-2.5-flash-preview-04-17\")\n",
    "        response = google_client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash-preview-04-17\",\n",
    "            contents=question,\n",
    "            config=genai.types.GenerateContentConfig(\n",
    "                temperature=0.3,\n",
    "                max_output_tokens=64\n",
    "            )\n",
    "        )\n",
    "        answers.append(response.text)\n",
    "        provider_info.append(\"google-gemini-flash-preview\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during API calls: {str(e)}\")\n",
    "        \n",
    "    return answers, provider_info\n",
    "\n",
    "# Test the ensemble with HaluEval dataset\n",
    "def evaluate_on_halueval(num_samples=5):\n",
    "    \"\"\"Evaluate the ensemble on HaluEval dataset samples.\"\"\"\n",
    "    # Load HaluEval dataset\n",
    "    from datasets import load_dataset\n",
    "    \n",
    "    # Load a few samples from each category\n",
    "    results = []\n",
    "    categories = [\"qa\", \"dialogue\", \"summarization\", \"general\"]\n",
    "    \n",
    "    for category in categories:\n",
    "        dataset = load_dataset(\"pminervini/HaluEval\", category, split=\"data\")\n",
    "        samples = dataset.select(range(min(num_samples, len(dataset))))\n",
    "        \n",
    "        for item in samples:\n",
    "            # Get the question and knowledge\n",
    "            if \"question\" in item:\n",
    "                question = item[\"question\"]\n",
    "                knowledge = item.get(\"knowledge\", \"\")\n",
    "            elif \"dialogue_history\" in item:\n",
    "                question = item[\"dialogue_history\"]\n",
    "                knowledge = item.get(\"knowledge\", \"\")\n",
    "            elif \"document\" in item:\n",
    "                question = \"Summarize this document\"\n",
    "                knowledge = item[\"document\"]\n",
    "            else:\n",
    "                question = item[\"user_query\"]\n",
    "                knowledge = \"\"\n",
    "            \n",
    "            # Get ensemble answers\n",
    "            answers, providers = get_multi_model_ensemble(question, knowledge)\n",
    "            \n",
    "            # Evaluate with ENN\n",
    "            best, table = select_best(question, answers)\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                \"category\": category,\n",
    "                \"question\": question,\n",
    "                \"knowledge\": knowledge,\n",
    "                \"answers\": answers,\n",
    "                \"providers\": providers,\n",
    "                \"best_answer\": best,\n",
    "                \"all_scores\": table\n",
    "            })\n",
    "            \n",
    "            # Print results for this sample\n",
    "            print(f\"\\n===== {category.upper()} SAMPLE =====\")\n",
    "            print(f\"Question: {question}\")\n",
    "            print(f\"Knowledge: {knowledge[:100]}...\")\n",
    "            print(\"\\nModel responses and scores:\")\n",
    "            for (score, p_factual, var, ans), provider in zip(table, providers):\n",
    "                print(f\"\\n{provider}:\")\n",
    "                print(f\"Score: {score:+.3f} | p_factual: {p_factual:.3f} | var: {var:.3f}\")\n",
    "                print(f\"Answer: {ans[:100]}...\")\n",
    "            \n",
    "            print(\"\\nBest Answer:\")\n",
    "            print(f\"Score: {best[0]:+.3f} | p_factual: {best[1]:.3f} | var: {best[2]:.3f}\")\n",
    "            print(f\"Answer: {best[3]}\")\n",
    "            \n",
    "    return results\n",
    "\n",
    "# Run evaluation\n",
    "print(\"Starting HaluEval evaluation...\")\n",
    "results = evaluate_on_halueval(num_samples=100)  # Test with k samples per category\n",
    "print(\"\\nEvaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for evaluation\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "import google.genai as genai\n",
    "import time\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize API clients\n",
    "openai_client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "anthropic_client = Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))\n",
    "google_client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "def evaluate_full_halueval(max_samples_per_category=None, save_results=True, checkpoint_interval=10):\n",
    "    \"\"\"\n",
    "    Evaluate the ensemble on the full HaluEval dataset with comprehensive metrics.\n",
    "    \n",
    "    Args:\n",
    "        max_samples_per_category: Maximum samples to use per category (None for all)\n",
    "        save_results: Whether to save results to disk\n",
    "        checkpoint_interval: Save results every N samples\n",
    "    \"\"\"\n",
    "    from datasets import load_dataset\n",
    "    \n",
    "    # Initialize results storage\n",
    "    results = {\n",
    "        \"qa\": [],\n",
    "        \"dialogue\": [],\n",
    "        \"summarization\": [],\n",
    "        \"general\": []\n",
    "    }\n",
    "    \n",
    "    # Track metrics\n",
    "    metrics = {\n",
    "        \"qa\": {\"scores\": [], \"p_factual\": [], \"variance\": [], \"best_models\": []},\n",
    "        \"dialogue\": {\"scores\": [], \"p_factual\": [], \"variance\": [], \"best_models\": []},\n",
    "        \"summarization\": {\"scores\": [], \"p_factual\": [], \"variance\": [], \"best_models\": []},\n",
    "        \"general\": {\"scores\": [], \"p_factual\": [], \"variance\": [], \"best_models\": []}\n",
    "    }\n",
    "    \n",
    "    # For comparing to \"ground truth\" (if available)\n",
    "    ground_truth = {\n",
    "        \"qa\": {\"y_true\": [], \"y_pred\": []},\n",
    "        \"dialogue\": {\"y_true\": [], \"y_pred\": []},\n",
    "        \"summarization\": {\"y_true\": [], \"y_pred\": []},\n",
    "        \"general\": {\"y_true\": [], \"y_pred\": []}\n",
    "    }\n",
    "    \n",
    "    # Track rate limits and timing\n",
    "    rate_limit_counter = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Process by category\n",
    "    for category in [\"qa\", \"dialogue\", \"summarization\", \"general\"]:\n",
    "        print(f\"\\n===== Processing {category.upper()} category =====\")\n",
    "        \n",
    "        # Load dataset\n",
    "        try:\n",
    "            dataset = load_dataset(\"pminervini/HaluEval\", category, split=\"data\")\n",
    "            print(f\"Loaded {len(dataset)} examples from {category} category\")\n",
    "            \n",
    "            # Limit samples if specified\n",
    "            if max_samples_per_category is not None:\n",
    "                dataset = dataset.select(range(min(max_samples_per_category, len(dataset))))\n",
    "                print(f\"Using {len(dataset)} examples\")\n",
    "            \n",
    "            # Process each example with progress bar\n",
    "            for idx, item in enumerate(tqdm(dataset, desc=f\"Processing {category}\")):\n",
    "                # Get the question and knowledge\n",
    "                if \"question\" in item:\n",
    "                    question = item[\"question\"]\n",
    "                    knowledge = item.get(\"knowledge\", \"\")\n",
    "                    # For ground truth comparison if available\n",
    "                    right_answer = item.get(\"right_answer\", \"\")\n",
    "                    hallucinated_answer = item.get(\"hallucinated_answer\", \"\")\n",
    "                elif \"dialogue_history\" in item:\n",
    "                    question = item[\"dialogue_history\"]\n",
    "                    knowledge = item.get(\"knowledge\", \"\")\n",
    "                    right_answer = item.get(\"right_response\", \"\")\n",
    "                    hallucinated_answer = item.get(\"hallucinated_response\", \"\")\n",
    "                elif \"document\" in item:\n",
    "                    question = \"Summarize this document\"\n",
    "                    knowledge = item[\"document\"]\n",
    "                    right_answer = item.get(\"right_summary\", \"\")\n",
    "                    hallucinated_answer = item.get(\"hallucinated_summary\", \"\")\n",
    "                else:\n",
    "                    question = item[\"user_query\"]\n",
    "                    knowledge = \"\"\n",
    "                    right_answer = item.get(\"chatgpt_response\", \"\")\n",
    "                    hallucinated_answer = \"\"\n",
    "                \n",
    "                # Rate limit management (to avoid API throttling)\n",
    "                if rate_limit_counter >= 20:  # Reset after 20 API calls\n",
    "                    time.sleep(10)  # Wait 10 seconds\n",
    "                    rate_limit_counter = 0\n",
    "                \n",
    "                # Get ensemble answers\n",
    "                answers, providers = get_multi_model_ensemble(question, knowledge)\n",
    "                rate_limit_counter += 6  # 6 API calls made\n",
    "                \n",
    "                # If we have ground truth, record it\n",
    "                if right_answer and hallucinated_answer:\n",
    "                    # We have paired examples - could be used for true accuracy\n",
    "                    ground_truth[category][\"y_true\"].append(0)  # 0 = not hallucinated\n",
    "                    ground_truth[category][\"y_true\"].append(1)  # 1 = hallucinated\n",
    "                \n",
    "                # Evaluate with ENN\n",
    "                best, table = select_best(question, answers)\n",
    "                \n",
    "                # Record which model had the best answer\n",
    "                best_model_idx = [score for score, _, _, _ in table].index(best[0])\n",
    "                best_model = providers[best_model_idx]\n",
    "                \n",
    "                # Store metrics\n",
    "                metrics[category][\"scores\"].append(best[0])\n",
    "                metrics[category][\"p_factual\"].append(best[1]) \n",
    "                metrics[category][\"variance\"].append(best[2])\n",
    "                metrics[category][\"best_models\"].append(best_model)\n",
    "                \n",
    "                # Store full result\n",
    "                results[category].append({\n",
    "                    \"id\": idx,\n",
    "                    \"question\": question,\n",
    "                    \"knowledge\": knowledge,\n",
    "                    \"answers\": answers,\n",
    "                    \"providers\": providers,\n",
    "                    \"best_answer\": best,\n",
    "                    \"all_scores\": table\n",
    "                })\n",
    "                \n",
    "                # Periodically save checkpoints\n",
    "                if save_results and (idx + 1) % checkpoint_interval == 0:\n",
    "                    checkpoint_file = f\"halueval_{category}_checkpoint_{idx+1}.json\"\n",
    "                    with open(checkpoint_file, 'w') as f:\n",
    "                        json.dump(results[category], f, indent=2)\n",
    "                    print(f\"Saved checkpoint for {category} at sample {idx+1}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {category} category: {str(e)}\")\n",
    "        \n",
    "        # Save category results\n",
    "        if save_results:\n",
    "            with open(f\"halueval_{category}_results.json\", 'w') as f:\n",
    "                json.dump(results[category], f, indent=2)\n",
    "            print(f\"Saved results for {category} category\")\n",
    "    \n",
    "    # Calculate and display overall metrics\n",
    "    print(\"\\n===== OVERALL EVALUATION RESULTS =====\")\n",
    "    \n",
    "    # Aggregate metrics across all categories\n",
    "    all_scores = []\n",
    "    all_p_factual = []\n",
    "    all_variance = []\n",
    "    all_best_models = []\n",
    "    \n",
    "    for category in [\"qa\", \"dialogue\", \"summarization\", \"general\"]:\n",
    "        cat_scores = metrics[category][\"scores\"]\n",
    "        cat_p_factual = metrics[category][\"p_factual\"]\n",
    "        cat_variance = metrics[category][\"variance\"]\n",
    "        cat_best_models = metrics[category][\"best_models\"]\n",
    "        \n",
    "        if cat_scores:  # Only process if we have data\n",
    "            # Category stats\n",
    "            avg_score = sum(cat_scores) / len(cat_scores)\n",
    "            avg_p_factual = sum(cat_p_factual) / len(cat_p_factual)\n",
    "            avg_variance = sum(cat_variance) / len(cat_variance)\n",
    "            \n",
    "            # Model preference\n",
    "            model_counts = {}\n",
    "            for model in cat_best_models:\n",
    "                model_counts[model] = model_counts.get(model, 0) + 1\n",
    "            \n",
    "            preferred_model = max(model_counts.items(), key=lambda x: x[1])\n",
    "            \n",
    "            print(f\"\\n{category.upper()} Category Stats:\")\n",
    "            print(f\"  Samples processed: {len(cat_scores)}\")\n",
    "            print(f\"  Average Score: {avg_score:.3f}\")\n",
    "            print(f\"  Average p_factual: {avg_p_factual:.3f}\")\n",
    "            print(f\"  Average Variance: {avg_variance:.3f}\")\n",
    "            print(f\"  Preferred Model: {preferred_model[0]} ({preferred_model[1]} times, {preferred_model[1]/len(cat_best_models)*100:.1f}%)\")\n",
    "            \n",
    "            # Extend to global lists\n",
    "            all_scores.extend(cat_scores)\n",
    "            all_p_factual.extend(cat_p_factual)\n",
    "            all_variance.extend(cat_variance)\n",
    "            all_best_models.extend(cat_best_models)\n",
    "    \n",
    "    # Global stats\n",
    "    if all_scores:\n",
    "        print(\"\\nGLOBAL Stats:\")\n",
    "        print(f\"  Total samples processed: {len(all_scores)}\")\n",
    "        print(f\"  Average Score: {sum(all_scores)/len(all_scores):.3f}\")\n",
    "        print(f\"  Average p_factual: {sum(all_p_factual)/len(all_p_factual):.3f}\")\n",
    "        print(f\"  Average Variance: {sum(all_variance)/len(all_variance):.3f}\")\n",
    "        \n",
    "        # Global model preference\n",
    "        model_counts = {}\n",
    "        for model in all_best_models:\n",
    "            model_counts[model] = model_counts.get(model, 0) + 1\n",
    "        \n",
    "        # Sort models by frequency\n",
    "        sorted_models = sorted(model_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        print(\"\\nModel Performance Ranking:\")\n",
    "        for rank, (model, count) in enumerate(sorted_models, 1):\n",
    "            print(f\"  {rank}. {model}: {count} wins ({count/len(all_best_models)*100:.1f}%)\")\n",
    "    \n",
    "    # Calculate elapsed time\n",
    "    elapsed_time = time.time() - start_time\n",
    "    hours, remainder = divmod(elapsed_time, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    print(f\"\\nTotal evaluation time: {int(hours)}h {int(minutes)}m {int(seconds)}s\")\n",
    "    \n",
    "    # Save final aggregated results\n",
    "    if save_results:\n",
    "        with open(\"halueval_full_evaluation_results.json\", 'w') as f:\n",
    "            json.dump({\n",
    "                \"metrics\": metrics,\n",
    "                \"ground_truth\": ground_truth,\n",
    "                \"elapsed_time\": elapsed_time\n",
    "            }, f, indent=2)\n",
    "        print(\"\\nSaved full evaluation results\")\n",
    "    \n",
    "    return results, metrics\n",
    "\n",
    "# Run full evaluation with configurable sample size\n",
    "# Set max_samples_per_category to a smaller number for a quicker test\n",
    "# Use None to run on the entire dataset\n",
    "print(\"Starting full HaluEval benchmark evaluation...\")\n",
    "# Adjust this number based on how much data you want to process\n",
    "# For a small test: max_samples_per_category=10 (40 total samples)\n",
    "# For medium test: max_samples_per_category=100 (400 total samples)\n",
    "# For full evaluation: max_samples_per_category=None (all ~6,700 samples)\n",
    "results, metrics = evaluate_full_halueval(max_samples_per_category=None, checkpoint_interval=5)\n",
    "print(\"\\nEvaluation complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
